{"mappings":"kpBAsBA,IAAAA,EACAC,E,iJArBA,IAAIC,EAAU,GAoBdF,EAlBA,SAAkBG,GAGhB,IAFA,IAAIC,EAAOC,OAAOD,KAAKD,GAEdG,EAAI,EAAGA,EAAIF,EAAKG,OAAQD,IAC/BJ,EAAQE,EAAKE,IAAMH,EAAMC,EAAKE,G,EAelCL,EAXA,SAAiBO,GACf,IAAIC,EAAWP,EAAQM,GAEvB,GAAgB,MAAZC,EACF,MAAM,IAAIC,MAAM,oCAAsCF,GAGxD,OAAOC,C,KCnBTE,EAAA,SAAAC,SAA8CC,KAAKC,MAAM,gkC,MCAzDC,EAAiB,IAAAC,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FC,EAAiB,IAAAN,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FE,EAAiB,IAAAP,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FG,EAAiB,IAAAR,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FI,EAAiB,IAAAT,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FK,EAAiB,IAAAV,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FM,EAAiB,IAAAX,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FO,EAAiB,IAAAZ,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FQ,EAAiB,IAAAb,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FS,EAAiB,IAAAd,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FU,EAAiB,IAAAf,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FW,EAAiB,IAAAhB,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FY,EAAiB,IAAAjB,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5Fa,EAAiB,IAAAlB,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5Fc,EAAiB,IAAAnB,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5Fe,EAAiB,IAAApB,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FgB,EAAiB,IAAArB,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,W,MCA5FiB,EAAiB,IAAAtB,IAAoBL,EAAA,SAAAM,QAA6C,SAAQC,OAAAC,KAAAC,KAAEC,WCA5F,MAAMkB,EAAe,CACnB,CACEC,MAAO,oBACPpB,IAAK,wEACLqB,IAAKC,EAAA3B,GACL4B,MAAOD,EAAAZ,IAET,CACEU,MAAO,eACPpB,IAAK,+CACLqB,IAAKC,EAAApB,GACLqB,MAAOD,EAAAX,IAET,CACES,MAAO,8BACPpB,IAAK,yDACLqB,IAAKC,EAAAnB,GACLoB,MAAOD,EAAAV,IAET,CACEQ,MAAO,QACPpB,IAAK,mCACLqB,IAAKC,EAAAlB,GACLmB,MAAOD,EAAAT,IAET,CACEO,MAAO,wBACPpB,IAAK,+DACLqB,IAAKC,EAAAjB,GACLkB,MAAOD,EAAAR,IAET,CACEM,MAAO,oCACPpB,IAAK,mCACLqB,IAAKC,EAAAhB,GACLiB,MAAOD,EAAAP,IAET,CACEK,MAAO,WACPpB,IAAK,wBACLqB,IAAKC,EAAAf,GACLgB,MAAOD,EAAAN,IAET,CACEI,MAAO,2BACPpB,IAAK,8BACLqB,IAAKC,EAAAd,GACLe,MAAOD,EAAAL,IAET,CACEG,MAAO,eACPpB,IAAK,0CACLqB,IAAKC,EAAAb,GACLc,MAAOD,EAAAJ,KAuBLM,EAAcC,SAASC,cAAc,eACrCC,EAA+BR,EAQhCS,KAAI,EAACR,MAAEA,EAAKpB,IAAEA,EAAGqB,IAAEA,EAAGE,MAAEA,GAASM,IAEzB,4EACwB7B,+DAFrB8B,OAAOD,EAAM,GAAGE,SAAS,EAAG,qDAIEV,SAAWE,yBACxCF,WAAaD,2CAIzBY,KAAK,IAhBVR,EAAYS,mBAAmB,YAAaN,GAC5CH,EAAYU,iBAAiB,SAkB7B,SAAiBC,GACf,IAAKA,EAAIC,OAAOC,UAAUC,SAAS,cACjC,M,IAIJ,IAAIC,EAAW,EAIGd,SAASC,cAAc,qBAAzC,MACMc,EAAOf,SAASC,cAAc,iBAC9Be,EAAehB,SAASC,cAAc,kBACtCgB,EAAejB,SAASkB,iBAAiB,iBAC/C,IAAIC,EAAaF,EAAavD,OAI9BuD,EAAaG,SAASC,IACpBA,EAAKC,MAAMC,UAAY,MAAuB,IAGhDP,EAAaP,iBAAiB,SAAS,MA2BvC,WACE,MAAMe,EAAcC,OAAOC,WAE3B,OAAIF,GAAe,KACVL,GAAcQ,KAAKC,IAAId,GAAYe,KAAmC,GACpEL,GAAe,IACjBL,GAAcQ,KAAKC,IAAId,GAAYe,KAAmC,GAEtEV,GAAcQ,KAAKC,IAAId,GAAYe,KAAmC,E,EAlC3DC,IAfD,EAkBjBhB,GAViBiB,GAYjBjB,EAAW,EAIbC,EAAKO,MAAMU,WAAa,0BACxBC,IAEAC,YAAW,KACTnB,EAAKO,MAAMU,WAAa,EAAE,GACzB,IAAI,IAGTP,OAAOhB,iBAAiB,UAAU,KAChCU,EAAaF,EAAavD,OAC1BuE,GAAa,IAGf,MAAMA,EAAc,KAClBlB,EAAKO,MAAMa,UAAY,cAAcrB,MAAa,EChJpD,MAiCMsB,EAAeC,GAEVC,MADK,6CAAmBD,KACbE,MAAKC,IACnB,IAAKA,EAASC,GACV,MAAM,IAAI5E,MAAM2E,EAASE,QAE7B,OAAOF,EAASG,MAAM,ICtCxBC,EAAO,CACXC,MAAO7C,SAASC,cAAc,kBAC9B6C,YAAa9C,SAASC,cAAc,iBACpC8C,cAAe/C,SAASC,cAAc,kBACtC+C,eAAgBhD,SAASC,cAAc,8BDD9BqC,MADK,2DACMC,MAAKC,IACnB,IAAKA,EAASC,GACV,MAAM,IAAI5E,MAAM2E,EAASE,QAE7B,OAAOF,EAASG,MAAM,ICARJ,MAAKU,IACzBA,EAAK9C,KAAI+C,IACP,MAAMC,EAAS,8EACyBD,EAAKE,6BAE7CR,EAAKC,MAAMrC,mBAAmB,YAAa2C,EAAO,GAClD,IAEJP,EAAKC,MAAMpC,iBAAiB,SAE5B,SAAyB4C,GACvB,IAAKA,EAAE1C,OAAOC,UAAUC,SAAS,iBAC/B,OAEFwC,EAAEC,iBAEF,IAAIC,EAAavD,SAASC,cAAc,cAEpCsD,GACFA,EAAW3C,UAAU4C,OAAO,aAG9BH,EAAE1C,OAAOC,UAAU6C,IAAI,aAEvB,IAAIC,EAAgB1D,SAASC,cAAc,mBACvC0D,EAAmBN,EAAE1C,OAAOiD,YAChCF,EAAcE,YAAcD,EAE5Bf,EAAKI,eAAepC,UAAU6C,IAAI,oBDdRI,ECgBNR,EAAE1C,OAAOiD,YDdpBtB,MADK,+DAAqCuB,KAC/BtB,MAAKC,IACnB,GAAKA,EAASC,GAGV,OAAOD,EAASG,OAFhB,MAAM,IAAI9E,MAAM2E,EAASE,OAEH,KCUUH,MAAKU,IAAQa,OAqBpBX,EArByEF,EAMzF9C,KAAI,EAAC4D,OAAEA,EAAMpE,MAAEA,EAAKqE,WAAEA,EAAUC,IAAEA,KAE5C,2DAC6CA,4EAEfD,WAAoBrE,0EAE1BA,4CACAoE,uBAG9BxD,KAAK,SAKRqC,EAAKI,eAAekB,UAAYf,GADlC,IAAqCA,CArB+E,IDhBxF,IAAAU,C,IErB5B,MAAMM,EAAO,CACXnB,eAAgBhD,SAASC,cAAc,8BFY9BqC,MADK,uDACMC,MAAKC,IACnB,IAAKA,EAASC,GACV,MAAM,IAAI5E,MAAM2E,EAASE,QAE7B,OAAOF,EAASG,MAAM,IEddJ,MAChB6B,eAA8BnB,GAC5B,IAAIoB,EAAW,GAEfpB,EAAK7B,SAAQkD,IACX,IAAIC,EAAc,uCACZD,EAASE,MAAM,GAAGpB,6CAEpBD,EAAS,GAEbmB,EAASE,MAAMrE,KAAI+C,IACjBmB,EAASI,KAAKvB,GACdC,GAEE,0CAC+BD,EAAKe,8EAEHf,EAAKc,oBAAoBd,EAAKvD,4EAEtCuD,EAAKvD,0BACzBuD,EAAKa,yBACN,IAERQ,EACEA,EACApB,EACA,6FAA6FmB,EAASE,MAAM,GAAGpB,0CACjHe,EAAKnB,eAAexC,mBAAmB,YAAa+D,EAAY,IAGlEG,aAAaC,QAAQ,QAAS3G,KAAK4G,UAAUP,G,IAG/CF,EAAKnB,eAAevC,iBAAiB,SAErC,SAAwB4C,GACtB,GAA0B,WAAtBA,EAAE1C,OAAOkE,SACX,M,ICzCJ7E,SAASS,iBAAiB,oBAAoB,KAC5C,MAAMqE,EAAc9E,SAASC,cAAc,iBAc3C,SAAS8E,IACP,IACwC,SAAlCL,aAAaM,QAAQ,SACvBhF,SAASC,cAAc,QAAQW,UAAUqE,OAAO,cAEhDjF,SAASC,cAAc,QAAQW,UAAU4C,OAAO,a,CAElD,MAAO0B,GACPC,QAAQC,IAAIF,E,EArBhBJ,EAAYO,QAA4C,SAAlCX,aAAaM,QAAQ,SAE3ChF,SAASC,cAAc,WAAWQ,iBAAiB,SAAS6E,IAE5C,UADAR,EAAYO,QAAU,OAAS,IAE3CX,aAAaC,QAAQ,QAAS,QAE9BD,aAAaa,WAAW,SAG1BR,GAAoB,IAwBtBA,IATA,WACE,MAAMS,EAASxF,SAASC,cAAc,WACA,SAAlCyE,aAAaM,QAAQ,SACvBQ,EAAO5E,UAAU6C,IAAI,cAErB+B,EAAO5E,UAAU4C,OAAO,a,CAK5BiC,EAAmB,IClCrB,IAAIC,EAAY1F,SAASC,cAAc,QACnC0F,EAAkB3F,SAASC,cAAc,iBACzC2F,EAAY5F,SAASC,cAAc,eACvC,MAAM4F,EAAY7F,SAASC,cAAc,gBACnC6F,EAAa9F,SAASC,cAAc,gBACpC8F,EAAc/F,SAASC,cAAc,iBACrC+F,EAAmBhG,SAASC,cAAc,sBAC1CgG,EAASjG,SAASC,cAAc,WAChCiG,EAAQlG,SAASC,cAAc,UAC/BkG,EAAWnG,SAASC,cAAc,aAuDxC,SAASmG,IACLV,EAAU9E,UAAU4C,OAAO,aAC3BmC,EAAgB/E,UAAU4C,OAAO,WACjBoC,EAAUtE,MAAM+E,WAAa,SACjCT,EAAUtE,MAAMgF,QAAU,IAEtCZ,EAAUa,oBAAoB,QAASC,GACvCd,EAAUa,oBAAoB,UAAWE,E,CAG7C,SAASD,EAAoBnD,GACrBA,EAAE1C,SAAWgF,GAGjBS,G,CAGJ,SAASK,EAAgBpD,GACN,WAAXA,EAAEqD,MAGNN,G,CA1EJV,EAAUjF,iBAAiB,SAE3B,SAASkG,IACa3G,SAASkB,iBAAiB,aAClCE,SAAQwF,IACdA,EAAKnG,iBAAiB,SAAS,KAC3B,MAAM4B,EAASuE,EAAKC,QAAQlJ,GAC5B+H,EAAUa,oBAAoB,QAASI,GACvCvE,EAAYC,GAAQE,MAAKU,KAarC,SAAsBA,GACN0C,EAAgB/E,UAAU6C,IAAI,WAC9BmC,EAAUtE,MAAM+E,WAAa,UAC7BT,EAAUtE,MAAMgF,QAAU,IAC1BT,EAAUiB,IAAM7D,EAAKe,WACrB6B,EAAUkB,IAAM9D,EAAKtD,MACrBmG,EAAWlC,YAAcX,EAAKtD,MAC9BoG,EAAYnC,YAAcX,EAAKc,OAC3CiC,EAAiBpC,YAAcX,EAAK+D,YAIxC,UAAyBC,UAACA,IACfA,EAAU9G,KAAI+G,IACA,WAAbA,EAAIC,OAAoBlB,EAAOmB,KAAOF,EAAI3I,KAC7B,aAAb2I,EAAIC,OAAsBhB,EAASiB,KAAQF,EAAI3I,KAClC,gBAAb2I,EAAIC,OAAyBjB,EAAMkB,KAAQF,EAAI3I,IAAG,G,CAP1D8I,CAAgBpE,E,CApBpBqE,CAAarE,GAwCTyC,EAAU9E,UAAU6C,IAAI,aARJzD,SAASC,cAAc,oBAC/BQ,iBAAiB,QAAS2F,GACtCV,EAAUjF,iBAAiB,QAAS+F,GACpCd,EAAUjF,iBAAiB,UAAWgG,GACtCf,EAAUjF,iBAAiB,UAAW4C,IAAQA,EAAEC,gBAAgB,GAjCpC,IACjBiE,OAAOrC,IAChBC,QAAQC,IAAI,SAAUF,EAAM,GAC5B,GACI,G,IC/BV,MAAMsC,EAAWxH,SAASC,cAAc,mBAClCwH,EAAazH,SAASC,cAAc,qBACpCyH,EAAY1H,SAASC,cAAc,sBACzCuH,EAAS/G,iBAAiB,SAC1B,SAAiB4C,GACfoE,EAAW7G,UAAUqE,OAAO,qBAC5ByC,EAAU9G,UAAUqE,OAAO,oB,UCEzB0C,EACAC,GARAC,GAAUC,EAAiB,GAU/B,SAASC,KACL,MAAM,IAAIlK,MAAM,kC,CAEpB,SAASmK,KACL,MAAM,IAAInK,MAAM,oC,CAsBpB,SAASoK,GAAWC,GAChB,GAAIP,IAAqBzF,WAErB,OAAOA,WAAWgG,EAAK,GAG3B,IAAKP,IAAqBI,KAAqBJ,IAAqBzF,WAEhE,OADAyF,EAAmBzF,WACZA,WAAWgG,EAAK,GAE3B,IAEI,OAAOP,EAAiBO,EAAK,E,CAC/B,MAAM7E,GACJ,IAEI,OAAOsE,EAAiBQ,KAAK,KAAMD,EAAK,E,CAC1C,MAAM7E,GAEJ,OAAOsE,EAAiBQ,KAAKC,KAAMF,EAAK,E,IAvCnD,WACG,IAEQP,EADsB,mBAAfzF,WACYA,WAEA6F,E,CAEzB,MAAO1E,GACLsE,EAAmBI,E,CAEvB,IAEQH,GADwB,mBAAjBS,aACcA,aAEAL,E,CAE3B,MAAOM,GACLV,GAAqBI,E,CAE5B,CAnBA,GAwED,IAEIO,GAFAC,GAAQ,GACRC,IAAW,EAEXC,IAAa,EAEjB,SAASC,KACAF,IAAaF,KAGlBE,IAAW,EACPF,GAAa7K,OACb8K,GAAQD,GAAaK,OAAOJ,IAE5BE,IAAa,EAEbF,GAAM9K,QACNmL,K,CAIR,SAASA,KACL,IAAIJ,GAAJ,CAGA,IAAIK,EAAUb,GAAWU,IACzBF,IAAW,EAGX,IADA,IAAIM,EAAMP,GAAM9K,OACVqL,GAAK,CAGP,IAFAR,GAAeC,GACfA,GAAQ,KACCE,GAAaK,GACdR,IACAA,GAAaG,IAAYM,MAGjCN,IAAa,EACbK,EAAMP,GAAM9K,M,CAEhB6K,GAAe,KACfE,IAAW,EAnEf,SAAyBQ,GACrB,GAAIrB,KAAuBS,aAEvB,OAAOA,aAAaY,GAGxB,IAAKrB,KAAuBI,KAAwBJ,KAAuBS,aAEvE,OADAT,GAAqBS,aACdA,aAAaY,GAExB,IAEWrB,GAAmBqB,E,CAC5B,MAAO5F,GACL,IAEI,OAAOuE,GAAmBO,KAAK,KAAMc,E,CACvC,MAAO5F,GAGL,OAAOuE,GAAmBO,KAAKC,KAAMa,E,GAgD7CC,CAAgBJ,EAnBZ,C,CAoCR,SAASK,GAAKjB,EAAKkB,GACfhB,KAAKF,IAAMA,EACXE,KAAKgB,MAAQA,C,CAYjB,SAASC,KAAO,CA5BhBxB,GAAQyB,SAAW,SAAUpB,GACzB,IAAIqB,EAAO,IAAIC,MAAMC,UAAU/L,OAAS,GACxC,GAAI+L,UAAU/L,OAAS,EACnB,IAAK,IAAID,EAAI,EAAGA,EAAIgM,UAAU/L,OAAQD,IAClC8L,EAAK9L,EAAI,GAAKgM,UAAUhM,GAGhC+K,GAAM/D,KAAK,IAAI0E,GAAKjB,EAAKqB,IACJ,IAAjBf,GAAM9K,QAAiB+K,IACvBR,GAAWY,G,EASnBM,GAAKO,UAAUV,IAAM,WACjBZ,KAAKF,IAAIyB,MAAM,KAAMvB,KAAKgB,M,EAE9BvB,GAAQlI,MAAQ,UAChBkI,GAAQ+B,SAAU,EAClB/B,GAAQgC,IAAM,GACdhC,GAAQiC,KAAO,GACfjC,GAAQkC,QAAU,GAClBlC,GAAQmC,SAAW,GAInBnC,GAAQoC,GAAKZ,GACbxB,GAAQqC,YAAcb,GACtBxB,GAAQsC,KAAOd,GACfxB,GAAQuC,IAAMf,GACdxB,GAAQwC,eAAiBhB,GACzBxB,GAAQyC,mBAAqBjB,GAC7BxB,GAAQ0C,KAAOlB,GACfxB,GAAQ2C,gBAAkBnB,GAC1BxB,GAAQ4C,oBAAsBpB,GAE9BxB,GAAQ6C,UAAY,SAAUvD,GAAQ,MAAO,E,EAE7CU,GAAQ8C,QAAU,SAAUxD,GACxB,MAAM,IAAItJ,MAAM,mC,EAGpBgK,GAAQ+C,IAAM,WAAc,MAAO,G,EACnC/C,GAAQgD,MAAQ,SAAUC,GACtB,MAAM,IAAIjN,MAAM,iC,EAEpBgK,GAAQkD,MAAQ,WAAa,OAAO,C;;;;;;;;;;;;;;;;;MChKhCC,IAIU,EAJVA,IAWM,EAXNA,GAcU,oB,GA4BgC,SAAaC,EAAQC,G,IAC9DD,EAAU,MAAKE,GAAiBD,E,KAIP,SAAAA,G,WACxBrN,MAAO,sBACmBmN,GAChB,6BAAAE,E,EA4CdE,GAAA,SAAAC,GAYA,MAAAC,EAAA,GAOA,IAAAC,EAAA,E,IAIE,IAAA9N,EAAO,EAAIA,EAAC4N,EAAA3N,OAAAD,IAAiB,CAC9B,IAAA+N,EAAAH,EAAAI,WAAAhO,GAED+N,EAAA,IAAAF,EAAAC,KAAAC,EAISA,EAAK,MACbF,EAAAC,KAAAC,GAAA,MAEDF,EAAAC,KAAA,GAAAC,EAAA,KASA,cAAAA,IAAA/N,EAAA,EAAA4N,EAAA3N,QAAA,cAAA2N,EAAAI,WAAAhO,EAAA,KAcM+N,EAAC,QAAQ,KAAAA,IAAA,UAAAH,EAAAI,aAAAhO,IAEb6N,EAAMC,KAAAC,GAAa,GAAG,IAItBF,EAAMC,KAASC,GAAG,UAEbF,EAAIC,KAAOC,GAAI,EAAK,GAAC,IACxBF,EAAAC,KAAc,GAAHC,EAAS,MAEpBF,EAAAC,KAAWC,GAAG,OACdF,EAAAC,KAAMC,GAAS,EAAI,GAAI,IACvBF,EAAAC,KAAc,GAAHC,EAAG,I,cAiGV,C,eAOQ,K,eAIH,K,sBAKN,KAKNE,sBAAA,K,kBAUQ,iE,0BAKLtD,KAASuD,kBAAgB,K,kEAc7BC,mBAAA,mBAAAC,KAcAC,gBAAOC,EAAAC,GACP,IAAAxC,MAAAyC,QAAAF,GAAA,MAAAlO,MAAA,iDAEFuK,KAAA8D,Q,yDAMSC,EAAA,GACP,QAAA1O,EAAA,EAAAA,EAAAsO,EAAArO,OAAAD,GAAA,GAEF,MAAA2O,EAAAL,EAAAtO,GAUM4O,EAAA5O,EAAA,EAAAsO,EAAArO,OACK4O,EAAAD,EAAAN,EAAAtO,EAAA,KACG8O,EAAA9O,EAAA,EAAAsO,EAAArO,OACF8O,EAAMD,EAAAR,EAAAtO,EAA0B,GAAE,EAC3CgP,EAAAL,GAAA,EACWM,GAAA,EAAAN,IAAA,EAAAE,GAAA,EACd,IAAAK,GAAA,GAAAL,IAAA,EAAAE,GAAA,ECvXAI,EAAA,GAAAJ,EAqBSD,IACRK,EAAA,GAEDP,IAAAM,EAAA,KAmBUR,EAAO1H,KAAAoI,EAAWJ,GAAAI,EAAAH,GAAAG,EAAAF,GAAAE,EAAAD,GACxB,C,gCAaWb,EAAGC,G,2CAKZ5D,KAAO0D,gBAAOV,GAAAW,GAAAC,E,EAiBpBc,aAASf,EAAAC,GC/ET,OAAA5D,KAAAwD,qBAAAI,EAAAH,KAAAE,GF+MK,SAAAgB,G,MAGFzB,EAAA,GAED,IAAA0B,EAAA,EAAAxB,EAAA,E,iCAWE,GAAIyB,EAAK,IAAA3B,EAAAE,KAAAnL,OAAuB6M,aAC9BD,QAEF,GAAOA,EAAK,KAAAA,EAAA,IAAgBE,CAC7B,MAAAC,EAAAL,EAAAC,KAED1B,EAAAE,KAAAnL,OAAA6M,cAAA,GAAAD,IAAA,KAAAG,E,uBAWM,MAMNC,IAAA,EAAAJ,IAAA,OANWF,EAAAC,OAMX,OAHSD,EAAAC,OAGT,KAFCD,EAAAC,MAED,MAgBM1B,EAACE,KAAQnL,OAAA6M,aAAA,OAAAG,GAAA,KAEb/B,EAAME,KAAAnL,OAAgB6M,aAClB,OAAK,KAAAG,GAGT,KAAM,CAED,MAAKD,EAAML,EAAIC,KACZM,EAAKP,EAAGC,KAEd1B,EAAAE,KAAMnL,OAAY6M,cAAiB,GAAPD,IAAO,OAAAG,IAAA,KAAAE,E,WAInC/M,KAAM,G,CE9PCgN,CACGnF,KAAAoF,wBAAAzB,EAAAC,GAEd,ECyDEwB,wBAAUzB,EAAAC,G,sEAGVG,EAAO,GACR,QAAA1O,EAAA,EAAAA,EAAAsO,EAAArO,QAAA,CACK,MAAO0O,EAAQqB,EAAI1B,EAAA2B,OAAAjQ,MAEzB6O,EADuB7O,EAAMsO,EAAOrO,OACpC+P,EAAA1B,EAAA2B,OAAAjQ,IAAA,IAEFA,EAQM,MAEA+O,EAFA/O,EAAAsO,EAAArO,OAEA+P,EAAA1B,EAAqB2B,OACrBjQ,IAAA,KAGMA,EACR,MAOOkQ,EAPPlQ,EAAAsO,EAAArO,OAOO+P,EAAA1B,EAAA2B,OAAAjQ,IAAA,GAET,KADCA,EACD,MAAA2O,GAAA,MAAAE,GAAA,MAAAE,GAAA,MAAAmB,EAAA,UAAAC,GAEF,MAAAnB,EAAAL,GAAA,EAAAE,GAAA,EAQyB,GAAAH,EAAA1H,KAAAgI,GAAA,KAAAD,EAAA,CAA4C,MAAAE,EAAAJ,GAAA,MAAAE,GAAA,EAWzD,GATZL,EAAA1H,KAAAiI,GASe,KAAAiB,EAAA,CAEX,MAAOhB,EAAUH,GAAA,MAAAmB,EAEbxB,EAAiB1H,KAAKkI,EACxB,C,CAIJ,CACI,OAAOR,CAET,EAEQD,QAAmC,IAAI9D,KAAAyF,eAAA,CAAEzF,KAAAyF,eAAA,GAEnDzF,KAAA0F,eAAA,GAEF1F,KAAA2F,sBAAA,GAI4E3F,KAAAsD,sBAAA,GACpD,QAAAjO,EAAA,EAAAA,EAAA2K,KAAA4F,aAAAtQ,OAAAD,IAExB2K,KAAAyF,eAAApQ,GAAA2K,KAAA4F,aAAAN,OAAAjQ,GAQE2K,KAAA0F,eAAA1F,KAAAyF,eAAApQ,MAAA2K,KAAA2F,sBAAAtQ,GAAA2K,KAAA6F,qBAAaP,OAAAjQ,GAHF2K,KAAAsD,sBAAAtD,KAAA2F,sBAAAtQ,MC3IXA,GAAA2K,KAAAuD,kBAAAjO,SAQU0K,KAAO0F,eAAU1F,KAAA6F,qBAAAP,OAAAjQ,MACnB2K,KACFsD,sBAAmBtD,KAAA4F,aAAAN,OAAAjQ,M;;;;;;;;;;;;;;;;oBAYDI,M,uBAInB4L,W,KACDtC,KAAA,yB,QAjCF+G,GAA2C,SAAI7C,G,QACxCD,GAA+CC,G,UACFS,gBAAAqC,GAAA,E,EC0ElDC,GAEA,SAAA/C,GAIJ,OAAM6C,GAAS7C,GAAAgD,QAAA,S,EAcbC,GAA8C,SAAEjD,G,WAEhDkD,GAAGzB,aAAAzB,GAAA,E,OACEhI,GACL8B,QAAAD,MAAc,wBAAA7B,E,QAEd,I;;;;;;;;;;;;;;;;;ACjFF,SACEmL,G,uBA+BJ,SAAAC,GAGgB9N,EAAA+N,GACd,KAAAA,aAAuBlR,QAAQ,OAASkR,EACzC,OAAAA,EAAAC,aAUe,KAAAC,KAUhB,WAAAA,KAFCF,EAEDG,WAME,KACErR,YAEHsR,IAAAnO,MAAA,IAED,MAEE,KAAO6I,MAGT7I,EAAA,GAEU,MACR,QAGF,OAAA+N,EAGC,UAAAK,KAAAL,EAQQA,EAAAM,eAAAD,IAiBH,cAjBqCA,IAC1CpO,EAAAoO,GAAAN,GAAA9N,EAAAoO,GAAAL,EAAAK,KAIC,OACEpO,C;;;;;;;;;;;;;;;;;SChEO;;;;;;;;;;;;;;;;;sDD6GI,oB,OAAQ,OAAKc,O,QACpB,IAAAwN,EAAA,OAAAA,E,MACF,IAAApR,MAAO,kC,CC/GEqR,GAAsBC,sBA0D/BC,GAAN,KCrIA,IAwBE,OAAWC,MDwEZ,MAEY,YAAAvH,QAAA,IAAAA,EAAA+B,IAAA,MAcuC,ECxF3ByF,ID0Fc,M,GAEnB,oBAAVtP,SAAqB,O,UAI3BuP,EAAMvP,SAAQwP,OAAID,MAAA,gC,OAElBlM,GAnBiB,M,OAEAoM,EAAMF,GAAqBjB,GAAAiB,EAAA,I,OAC1CE,GAAAzR,KAAAC,MAAAwR,EAAA,EClFmBC,E,CACxB,MAAArM,GCoBG,YADE8B,QAAAwK,KAAA,+CAAAtM,I,GAmCAuM,GACqBC,IAEzB,MAAIC,EA5BI,CAAAD,I,eAEF,Q,EAAA,QAAAE,EAAAX,YAAA,IAAAW,OAAA,EAAAA,EAAAC,qBAAA,IAAAC,OAAA,EAAAA,EAAAJ,EAAA,EA0BKK,CAAqBL,G,IAC9BC,EAAI,O,QAEcA,EAAAK,YAAoB,K,GAItCC,GAAW,GAAAA,EACT,IAAUN,EAAGpS,OAAY,MAAY,IAAAG,MAAA,gBAAAiS,yC,MAGrCO,EAAAC,SAAaR,EAAUS,UAASH,EAAA,O,MAEnC,MAAAN,EAAA,GAGC,CAMFA,EAAAS,UAAA,EAAAH,EAAA,GAEFC,GASa,CAGXP,EAAOS,UAAK,EAAAH,GACZC,EAEF,EAsBQG,GAAiB,KACvB,IAAAT,EACF,eAAAA,EAAAX,YAAA,IAAAW,OAAA,EAAAA,EAAAU,MAAA;;;;;;;;;;;;;;;;;MC3EIC,GASDC,aAAAC,GAED,MAAW,CAAA1L,EAAK2L,KACT3L,EAAMkD,KAAS0I,OAClB5L,GAEHkD,KAAAhK,QAAAyS,GACW,mBAAAD,IAIAxI,KAAK2I,QAAQxJ,OAAA,SC/DG,IAAtBqJ,EAAkBlT,OAAIkT,EAAA1L,GACX0L,EAAA1L,EAAgB2L,GACzB,CAEV,CC/BAlC,cAyBEvG,KAAM0I,OAAY,OAClB1I,KAAKhK,QAAY,OAGXgK,KAAA2I,QACE,IAAAC,SAAA,CAAA5S,EAAuB0S,KAExB1I,KAAAhK,UAEHgK,KAAO0I,OAAKA,CAAA,GAIjB;;;;;;;;;;;;;;;;GAgCD,SAAAG,GAAAC,EAAAC,GCtEA,GAAAD,EAAAE,IAAA,UAAAvT,MAAA,gH,MAgGIwT,EAAYF,GAAK,eAEjBG,EAAKJ,EAASI,KAAE,EAChBC,EAAKL,EAASK,KAAEL,EAAAM,Q,IACjBD,EAAA,UAAA1T,MAAA,wDAED,MAAA4T,EAAAjU,OAAAkU,OAAA,CAWEC,IAAA,kCAAkBN,I,MAGlBC,IAAIA,E,wGAqBOtT,KAAU4G,UA7CV,CACXgN,IAAK,OACLC,KAAK,S,GA8CW7T,KAAA4G,UAAA6M,IARb,I;;;;;;;;;;;;;;;;uBAoCS,oB,WAAI,iBAAAK,UAAA,UAAAA,UAAA,UACV,E,UAUHC,K,MACkB,oBAAZtQ,W,OAED,SAAAA,OAAA,UAAAA,OAAA,+DAAAuQ,KAAAC,K,UAkEHC,K,OACiB,IAAtBlH,KAAsB,IAAAA,E,yBAiBI,iBAAdmH,S,OACV9O,G,OACD,C,qCCvCmBqD,EAAAwE,EAAAkH,G,MAClBlH,G,UAEOxE,E,KACJ0L,WAAWA,E,gDAIChK,KAAOiK,GACR3I,WAKjB7L,MAAAyU,mBAAAzU,MAAAyU,kBAAAlK,KAAAmK,GAAA7I,UAAA8I,OAEO,E,gBAKN9L,KAAYzD,G,0CAKPwP,EAAUrK,KAAKsK,OAAAhM,GAClBwE,EAAKuH,E,wDApKP,OACQ,MADH5B,EACQxQ,OAAAwQ,GAAA,IAAA8B,KAAA,G,CAmKMC,CAAUH,EAAAL,GAAA,QAE1BS,EAAA,GAAAzK,KAAA0K,gBAAA5H,MAAA6H,MAhLL,OAiLC,IAAAV,GAAAU,EAAAF,EAAAT,E,aAzLmBY,EAAAF,EAAqBJ,GAEjCtK,KAAa4K,U,mBAEb5K,KAAAsK,OAAOA,C,WAmBK;;;;;;;;;;;;;;;;GAyMtB,SAASO,GAAI5H,G,qBCpQX,SAAI6H,GAAUjQ,G,OACZjF,KAAM4G,UACJ3B,E;;;;;;;;;;;;;;;;GCnBN,MAAAkQ,GAAA,SAAAjC,GAEA,IAAAkC,EAAA,GAAAC,EAAA,GAAApQ,EAAA,GAAAqQ,EAAA,GACA,IACA,MAAAC,EAAArC,EAAAsC,MAAA,KACAJ,EAAAH,GAAA3E,GAAAiF,EAAA,SACAF,EAAAJ,GAAA3E,GAAAiF,EAAA,SACAD,EAAAC,EAAA,GAEAtQ,EAAAoQ,EAAA,aAKWA,EAAgB,CACf,CAAV,MAAShQ,GAAC,CACV,MAAK,CACH+P,OAAQA,E,SAGRnQ,KAAKA,E,UACGqQ,E,EChBRG,GAAsB,SAAAvC,G,MACrBmC,EAAAF,GAAAjC,GAAAmC,OACL,QAAAA,GAAA,iBAAAA,KAAArE,eAAA,MC5BA,E,eA0DE,MAAMqE,EAAAF,GAA0CjC,GAAemC,O;;;;;;;;;;;;;;;;;ACxB/D,SAAOK,GACOC,EAAAhB,GAEd,OAAOnV,OAAMkM,UACJsF,eAAK7G,KAAAwL,EAAAhB,E,UAKdiB,GAAYD,EAAAhB,GACd,OAAAnV,OAAAkM,UAAAsF,eAAA7G,KAAAwL,EAAAhB,GAAAgB,EAAAhB,QC5CA,C,UA2BIkB,GAA6BF,GAEjC,UAAAhB,KAAAgB,E;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;yDCuBIG,G,qBACYC,GAGd,OAFC3L,KAAA4L,kBAAAD,EAED3L,I,sBAEc6L,GAGd,OAFC7L,KAAA6L,oBAED7L,I,iBAEc8L,GAGd,OAFC9L,KAAA+L,aAAAD,EAED9L,I,4BAEcwI,GA7Bd,OA8BCxI,KAAAgM,kBAAAxD,EA9BDxI,I,CAFAuG,YAAiBxH,EAAAkN,EAA6CxC,GAY1DzJ,KAAAjB,OAqBLiB,KAAAiM,kBCtEDjM,KAAAyJ,OCAAzJ,KAAA6L,mBAAA,EAuDI7L,KAAM+L,aAAA,GAEN/L,KAAK4L,kBAAK,O,KACRI,kBAAqB,I;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgFzB,MAAAE,G,mDAmBE,IAAIlM,KAAAmM,kBAAAC,IAAAC,GACF,CACE,MAAKC,EAAA,IAAAhE,G,QAAyB6D,kBAAkBI,IAAEF,EAAAC,GAAsBtM,KAAAwM,cAAAH,IAAArM,KAAAyM,uBACxE,I,4EAKD,MAAAxR,G,CAMH,C,OAIE+E,KAAMmM,kBAAoBO,IACxBL,GAAK1D,O,+BAMD3I,KAAA2M,4BAAAC,aAAA,EAAAA,EAAAC,Y,EAC+B,QAAnClF,EAAAiF,aAAmC,EAAAA,EAAAE,gBAAA,IAAAnF,K,SACnC6E,cAAUH,KAAArM,KAAAyM,uBAST,CAEN,GAAAK,EAAA,Y,qDAXe,I,0DAQd,CAJC,MAAA7R,GACF,GAAA6R,EAAA,YAEY,MAAC7R,CACZ,CAOF,C,eAGE,OAAM+E,KAAA+M,S,sBAIGhO,OAAYiB,KAAgBjB,KAAA,MAAUtJ,MAAS,yBAAAsX,EAAAhO,qBAAAiB,KAAAjB,S,QACnDgO,UACA,MAAOtX,MAAO,iBAAiBuK,KAAOjB,kC,oBAGxCiB,KAAAyM,uB,CAGL,G;;;;;;;;;;;;;;;;GAAAO,CAAcD,GAAA,IACZ/M,KAAOiN,uBAAuB,CAC/BC,mBAhHmC,aA0HpC,CAPE,MAAOjS,GAOT,CAWE,IAAK,MAAKiS,EACRC,KAAyBnN,KAAKmM,kBAAIiB,UAAA,CAGpC,MAAMf,EAAgBrM,KAAA2M,4BAAuBO,GAC3C,IAEE,MAAAG,EAAArN,KAAAiN,uBAAA,C,uBAOFE,EAAMnX,QAAAqX,EAQT,CANG,MAAIpS,GAMP,CAED,CAlDK,C,eA2DG4R,EAtK4B,aAuKlC7M,KAAAmM,kBAAuBmB,OACrBT,GAEF7M,KAAAuN,iBAAsBD,OAAAT,GACtB7M,KAAKwN,UAAAF,OAAgBT,E,sBASnBY,EAAArM,MAAAsM,KAAA1N,KAAAwN,UAAAG,gBACH/E,QAAAgF,IAAA,IAEDH,EAAAI,QAAAjD,GAAA,aAAAA,IASO7S,KAAA6S,GACHA,EAAOkD,SAAAR,cAEJG,EAAMI,QAAYjD,GACrB,YAAIA,IAEF7S,KAAM6S,KAAAmD,a,kBAMJ,OAAuB,MAAvB/N,KAAA+M,S,eAQDF,EApN6B,a,OAqNhC7M,KAAQwN,UAAQpB,IAAAS,E,cArNgB,a,OAwN7B7M,KAAAuN,iBAAAb,IAAAG,IAAA,E,YAEHmB,EAAK,I,MAELpB,UAAA,IAAAoB,EAOA3B,EAAArM,KAAA2M,4BAAAqB,EAAAd,oB,QAOIV,cAAeH,GACR,MAAA5W,MACL,GAAAuK,KAAAjB,QAAAsN,mC,IAGHrM,KAACiO,iBAAM,MAAAxY,MAAA,aAAAuK,KAAAjB,oC,wDAEPsN,EAEJO,YAKK,UAAAM,EACNC,KAAqBnN,KAAAmM,kBAAAiB,UAAkB,CAKrCf,IAFqBrM,KAAC2M,4BAA8BO,IAEpDC,EAAAnX,QAAAqX,EAEH,CAEO,OAAAA,C,CAlUSa,OAAA1F,EAAAqE,GAET,IAAAlF,EAKJ,MAAA0E,EAAArM,KAAA2M,4BAAAE,GAiULsB,EAAA,QAAAxG,EAAA3H,KAAAoO,gBAAA1B,IAAAL,UAAA,IAAA1E,IAAA,IAAA0G,IAEDF,EAAA9S,IAAAmN,GACAxI,KAASoO,gBAAA7B,IAAAF,EAAA8B,GACP,MAAOG,EAAetO,KAAAwN,UAAAd,IAAAL,GAGxB,OAFCiC,GAAA9F,EAAA8F,EAAAjC,GAEQ,KACA8B,EAAUb,OAAA9E,EAAiB,CCxXpC,CA8CI+F,sBAAsBlB,EAAUR,GACjC,MAAA2B,EAAAxO,KAAAoO,gBAAA1B,IAAAG,GAED,GAAA2B,EACE,UAAMhG,KAAgBgG,EAAW,IAC7BhG,EAAS6E,EAAAR,EAMd,CAJG,MAAKlF,GAIR,CAED,C,wBAQqBuF,mBACNA,EAA+CN,UAAA,K,4BAI5D,IAAAS,GAAiBrN,KAAI+M,YACjBM,EAAWrN,KAAI+M,UAAMd,gBAAuCjM,KAAAyO,UAAA,CAEzDvB,oB,EAAwBA,ED6BG,c,YC5BnCN,YAGC5M,KAAOwN,UAAWjB,IAAKW,EAAoBG,GAC5CrN,KAAAuN,iBAAAhB,IAAAW,EAAAN,GACF5M,KAAAuO,sBAAAlB,EAAAH,G,wJDuBqC,a,yDAAA,Y;;;;;;;;;;;;;;;;GElCpC,MAAAwB,GAAA,GAyCA,IAAAC,GACMC,O,KAkCLD,GAAA,KAjCSC,GAC4C,MAClD,GAAO,Q,GAITA,GACE,qBAGJA,MAAA,eAEWA,MAAA,eAmBXA,GAAIA,GAAQ,iB,GACVA,GAAsB,mB,MAGxBC,GAA0B,C,MAClBF,GAAOG,M,QAGRH,GAAgBI,Q,KACtBJ,GAAAK,K,aAGDlS,MAAA6R,GAA0CM,M,OACnCN,GAAsCO,QAU5CC,GAAAR,GAAAK,KAaCI,GAA4B,C,CAC7BT,GAAAG,OAAA,MACD,CAAAH,GAAyCI,SAAA,M,IACZC,MAAA,O,CAC5BL,GAAAU,MAAA,OAED,CAAAV,GAAAM,OAAA,SAWEK,GAAuB,CAAAjC,EAAAkC,KAASpO,K,GACjCoO,EAAAlC,EAAAmC,SAAA,OACD,MAAKC,GAAkB,IAAAjJ,MAAAkJ,cACrBC,EAAKP,GAAwCG,G,IAC7CI,EACD,UAAAla,MAAA,8DAAA8Z,MADMxS,QAAW4S,GAAO,IAAAF,OAAApC,EAAAtO,WAAAoC,EACxB,E,SAGCqO,eACD,OAAAxP,KAAA4P,SACD,CACEJ,aAAKK,GACL,KAAKA,KAAAlB,IAAkB,UAASmB,UAAU,kBAAMD,+BACjD7P,KAAA4P,UAAAC,CApFD,C,YAaAA,GAqBA7P,KAAA4P,UAAA,iBAAAC,EAAAhB,GAAAgB,I,CA3BEE,iBAID,OAAA/P,KAAAgQ,WA0EF,CAEKD,eAAUF,GACd,sBAAAA,EAAU,MAAQ,IAAIC,UAAG,qDACvB9P,KAAKgQ,YAAYH,C,CAEpBI,qBAEe,OAAAjQ,KAAAkQ,eAId,CACED,mBAAIJ,GACJ7P,KAAIkQ,gBAAmBL,C,UAaf1O,G,sBAEkBnB,KAAGkQ,gBACnBlQ,KAAO2O,GAAIG,SAAA3N,G,iBACFnB,KAAA2O,GAA0CG,SACnD3N,E,iCAKcnB,KAAAkQ,gBAAelQ,KAAA2O,GAAAI,WAAA5N,G,iBACpBnB,KAAA2O,GAASI,WAAA5N,E,iBAIrB+O,iBACiBlQ,KACjBkQ,gBAAUlQ,KAAA2O,GAAAK,QAAA7N,G,KACb6O,YAAchQ,KAAA2O,GAAAK,QAAA7N,E,kCAINnB,KAAAkQ,gBAAAlQ,KAAA2O,GAAAU,QAAAlO,G,iBACEnB,KAAS2O,GAAIU,QAAAlO,E,UAGvBA,GAELnB,KAAAkQ,iBAAAlQ,KAAAkQ,gBAAAlQ,KAAA2O,GAAAM,SAAA9N,GACHnB,KAAAgQ,YAAAhQ,KAAA2O,GAAAM,SAAA9N,E,2GCzQA,IAAIgP,GACAC,GAqBJ,MAAMC,GAAmB,IAAIC,QACvBC,GAAqB,IAAID,QACzBE,GAA2B,IAAIF,QAC/BG,GAAiB,IAAIH,QACrBI,GAAwB,IAAIJ,QA0DlC,IAAIK,GAAgB,CAChBjE,IAAInU,EAAQoO,EAAMiK,GACd,GAAIrY,aAAkBsY,eAAgB,CAElC,GAAa,SAATlK,EACA,OAAO4J,GAAmB7D,IAAInU,GAElC,GAAa,qBAAToO,EACA,OAAOpO,EAAOuY,kBAAoBN,GAAyB9D,IAAInU,GAGnE,GAAa,UAAToO,EACA,OAAOiK,EAASE,iBAAiB,QAC3BpK,EACAkK,EAASG,YAAYH,EAASE,iBAAiB,G,CAI7D,OAAOE,GAAKzY,EAAOoO,G,EAEvB4F,IAAG,CAAChU,EAAQoO,EAAM8B,KACdlQ,EAAOoO,GAAQ8B,GACR,GAEX2D,IAAG,CAAC7T,EAAQoO,IACJpO,aAAkBsY,iBACR,SAATlK,GAA4B,UAATA,IAGjBA,KAAQpO,GAMvB,SAAS0Y,GAAaC,GAIlB,OAAIA,IAASC,YAAY7P,UAAU8P,aAC7B,qBAAsBP,eAAevP,WA7GnC8O,KACHA,GAAuB,CACpBiB,UAAU/P,UAAUgQ,QACpBD,UAAU/P,UAAUiQ,SACpBF,UAAU/P,UAAUkQ,sBAqHEC,SAASP,GAC5B,YAAa/P,GAIhB,OADA+P,EAAK3P,MAAMmQ,GAAO1R,MAAOmB,GAClB6P,GAAKX,GAAiB3D,IAAI1M,M,EAGlC,YAAamB,GAGhB,OAAO6P,GAAKE,EAAK3P,MAAMmQ,GAAO1R,MAAOmB,G,EAtB9B,SAAUwQ,KAAexQ,GAC5B,MAAMyQ,EAAKV,EAAKnR,KAAK2R,GAAO1R,MAAO2R,KAAexQ,GAElD,OADAqP,GAAyBjE,IAAIqF,EAAID,EAAWE,KAAOF,EAAWE,OAAS,CAACF,IACjEX,GAAKY,E,EAsBxB,SAASE,GAAuBrJ,GAC5B,MAAqB,mBAAVA,EACAwI,GAAaxI,IAGpBA,aAAiBoI,gBAhGzB,SAAwCe,GAEpC,GAAIrB,GAAmBnE,IAAIwF,GACvB,OACJ,MAAMG,EAAO,IAAInJ,SAAQ,CAAC5S,EAAS0S,KAC/B,MAAMsJ,EAAW,KACbJ,EAAGzT,oBAAoB,WAAY8T,GACnCL,EAAGzT,oBAAoB,QAASrB,GAChC8U,EAAGzT,oBAAoB,QAASrB,EAAM,EAEpCmV,EAAW,KACbjc,IACAgc,GAAU,EAERlV,EAAQ,KACV4L,EAAOkJ,EAAG9U,OAAS,IAAIoV,aAAa,aAAc,eAClDF,GAAU,EAEdJ,EAAGvZ,iBAAiB,WAAY4Z,GAChCL,EAAGvZ,iBAAiB,QAASyE,GAC7B8U,EAAGvZ,iBAAiB,QAASyE,EAAM,IAGvCyT,GAAmBhE,IAAIqF,EAAIG,E,CA0EvBI,CAA+B1J,GA9JhB2J,EA+JD3J,GAzJV0H,KACHA,GAAoB,CACjBgB,YACAkB,eACAC,SACAjB,UACAR,kBAZiD0B,MAAMnP,GAAMgP,aAAkBhP,IAgK5E,IAAIoP,MAAM/J,EAAOkI,IAErBlI,GAlKW,IAAC2J,C,CAoKvB,SAASpB,GAAKvI,GAGV,GAAIA,aAAiBgK,WACjB,OA3IR,SAA0BC,GACtB,MAAM/J,EAAU,IAAIC,SAAQ,CAAC5S,EAAS0S,KAClC,MAAMsJ,EAAW,KACbU,EAAQvU,oBAAoB,UAAWwU,GACvCD,EAAQvU,oBAAoB,QAASrB,EAAM,EAEzC6V,EAAU,KACZ3c,EAAQgb,GAAK0B,EAAQE,SACrBZ,GAAU,EAERlV,EAAQ,KACV4L,EAAOgK,EAAQ5V,OACfkV,GAAU,EAEdU,EAAQra,iBAAiB,UAAWsa,GACpCD,EAAQra,iBAAiB,QAASyE,EAAM,IAe5C,OAbA6L,EACKxO,MAAMsO,IAGHA,aAAiB4I,WACjBhB,GAAiB9D,IAAI9D,EAAOiK,EAAQ,IAIvCvT,OAAM,SAGXuR,GAAsBnE,IAAI5D,EAAS+J,GAC5B/J,C,CA6GIkK,CAAiBpK,GAG5B,GAAIgI,GAAerE,IAAI3D,GACnB,OAAOgI,GAAe/D,IAAIjE,GAC9B,MAAMqK,EAAWhB,GAAuBrJ,GAOxC,OAJIqK,IAAarK,IACbgI,GAAelE,IAAI9D,EAAOqK,GAC1BpC,GAAsBnE,IAAIuG,EAAUrK,IAEjCqK,C,CAEX,MAAMpB,GAAUjJ,GAAUiI,GAAsBhE,IAAIjE,GC5KpD,SAASsK,GAAOhU,EAAM4C,GAASqR,QAAEA,EAAOC,QAAEA,EAAOC,SAAEA,EAAQC,WAAEA,GAAe,IACxE,MAAMT,EAAU3I,UAAUqJ,KAAKrU,EAAM4C,GAC/B0R,EAAcrC,GAAK0B,GAoBzB,OAnBIO,GACAP,EAAQra,iBAAiB,iBAAkB6E,IACvC+V,EAAQjC,GAAK0B,EAAQE,QAAS1V,EAAMoW,WAAYpW,EAAMqW,WAAYvC,GAAK0B,EAAQtB,aAAclU,EAAM,IAGvG8V,GACAN,EAAQra,iBAAiB,WAAY6E,GAAU8V,EAE/C9V,EAAMoW,WAAYpW,EAAMqW,WAAYrW,KAExCmW,EACKlZ,MAAMqZ,IACHL,GACAK,EAAGnb,iBAAiB,SAAS,IAAM8a,MACnCD,GACAM,EAAGnb,iBAAiB,iBAAkB6E,GAAUgW,EAAShW,EAAMoW,WAAYpW,EAAMqW,WAAYrW,IAAO,IAGvGiC,OAAM,SACJkU,C,CAiBX,MAAMI,GAAc,CAAC,MAAO,SAAU,SAAU,aAAc,SACxDC,GAAe,CAAC,MAAO,MAAO,SAAU,SACxCC,GAAgB,IAAIC,IAC1B,SAASC,GAAUC,EAAQnN,GACvB,KAAMmN,aAAkB3C,cAClBxK,KAAQmN,GACM,iBAATnN,EACP,OAEJ,GAAIgN,GAAcjH,IAAI/F,GAClB,OAAOgN,GAAcjH,IAAI/F,GAC7B,MAAMoN,EAAiBpN,EAAKV,QAAO,aAAe,IAC5C+N,EAAWrN,IAASoN,EACpBE,EAAUP,GAAajC,SAASsC,GACtC,KAEEA,KAAmBC,EAAW1B,SAAWD,gBAAgB/Q,aACrD2S,IAAWR,GAAYhC,SAASsC,GAClC,OAEJ,MAAMpE,EAAS3T,eAAgBkY,KAAc/S,GAEzC,MAAMyQ,EAAK5R,KAAKoR,YAAY8C,EAAWD,EAAU,YAAc,YAC/D,IAAI1b,EAASqZ,EAAGuC,MAQhB,OAPIH,IACAzb,EAASA,EAAO6b,MAAMjT,EAAKkT,iBAMjBzL,QAAQgF,IAAI,CACtBrV,EAAOwb,MAAmB5S,GAC1B8S,GAAWrC,EAAGG,QACd,E,EAGR,OADA4B,GAAcpH,IAAI5F,EAAMgJ,GACjBA,C,CDiCPgB,GC/BS,CAAC2D,IAAc,IACrBA,EACH5H,IAAK,CAACnU,EAAQoO,EAAMiK,IAAaiD,GAAUtb,EAAQoO,IAAS2N,EAAS5H,IAAInU,EAAQoO,EAAMiK,GACvFxE,IAAK,CAAC7T,EAAQoO,MAAWkN,GAAUtb,EAAQoO,IAAS2N,EAASlI,IAAI7T,EAAQoO,KD4BzD6B,CAASmI;;;;;;;;;;;;;;;;;ME7FE4D,GAoB/BC,wB,OASoBxU,KAASyO,UAAAgG,e,gGCvD7B,MAAA7J,EAAA8J,EAAAC,e,iHC4DGC,GAAqB,IAAAC,GAAkB,iBCmDxCC,GAC2B,CAE3B,gBAAqD,YACtD,0CAED,uCAaE,qDACD,uCAED,qDAME,6BACF,2CC5IA,iCAkCE,+CAGA,gCACA,8CAEA,qCACA,mDAEA,iCAGA,+CAEA,oCAEA,kDAEA,oCAEA,kDAEA,+BAcK,2BAAM,kBCtEb,iCA2DE,6BAAI,kB,UACG,U,SACO,eAwBZC,GAAuB,IAAAnB,I,GAQD,IAAAA,I,SASsDoB,GAAAC,EAAAlI,G,IA3D9EkI,EAAAxG,UACEyG,aAEAnI,E,OANgB9R,GAQhBka,GAAqBC,MAAA,aAAUrI,EAAAhO,4CAAAkW,EAAAlW,OAAA9D,E,WC8EVoa,GAAAtI,G,MACtBuI,EAAAvI,EAAAhO,KAED,GAAAwW,GAAYnJ,IAAAkJ,GAEV,OADAH,GAAMC,MAAA,sDAAkBE,OACxB,EAGFC,GAAyBhJ,IAAA+I,EAAAvI,G,IAIrB,MAAOkI,KAAEF,GAAYpH,SAAAqH,GAAAC,EAAAlI,G,OACpB,C,UAoBJyI,GAAAP,EAAAQ,GAED,MAAMC,EAAgBT,EAAAxG,UAAAkH,YAAA,aAAAhB,aAAA,CACtB7H,UAAW,IAQX,OAFA4I,KAASE,mBAEFX,EAAAxG,UAAOkH,YAAAF,E;;;;;;;;;;;;;;;;;MAmJfI,GAAA,IAAA1L,GAAA,iBAnC0B,C,SAIb,6E,eAIU,gC,gBACb,kF,cACR,kDACD,aACE,0E,uBAEkB,6E,uBAAS,wD,WAAG,gFAIjC,+FAED,6FAWE,aAAmC;;;;;;;;;;;;;;;;;2ECzQ5BnK,KAAA8V,+B,CAEFC,mCAAUlG,GACX7P,KAAAgW,iB,KACEF,gCAA+BjG,C,CAEhC9Q,WAGN,OADCiB,KAAOgW,iBACRhW,KAAAiW,KAEM,CAGDrJ,cAEF,OADA5M,KAAAgW,iBACMhW,KAAMkW,Q,CAKZ7N,a,OACArI,KAAKgW,iBAEEhW,KAAAmW,O,wBAGFnW,KAAAoW,U,iBAGN,OAAApW,KAAAqW,UACF,CAEMC,cAAezG,GAIhB7P,KAAAqW,WAAAxG,C,CAKFmG,iBACA,GAAAhW,KAAUsW,UAAA,MAAAT,GAAAzL,OAAA,eACNmM,QAACvW,KAAYiW,O,aAIbrJ,EAAAvE,EAAAoG,G,KACD4H,YAAE,E,KACHH,SAAA9gB,OAAAkU,OAAA,GAAOsD,G,KACRuJ,QAAA/gB,OAAAkU,OAAA,GAAAjB,GACFrI,KAAAiW,MAAA5N,EAAAtJ,KACFiB,KAAA8V,gCAAAzN,EAAA0N,+BAED/V,KAASoW,WAAA3H,EACPzO,KAAOyO,UAAWyG,aAAQ,IAAaxJ,GAAG,WAAA1L,MAAA,UAC5C;;;;;;;;;;;;;;;;eCIqCkW,EAAoBM,EAAM,CAAO,G,MACxDN,E,GACO,iBAAbM,EAAwB,CAG5BA,EAAY,CACbzX,KAFGyX,E,wBAgBFzX,KLnBkC,YKyBlCgX,gCAAa,G,GAEbU,EAAMpO,EAAAtJ,K,GAGA,iBAAA0X,IAAeA,EAAA,MAAAZ,GAAAzL,OACnB,eAAe,C,QAAEnS,OAAUwe,K,OAC3B7J,EAAAxE,O,sCAEFsO,EAAK3B,GAA8CrI,IAAA+J,G,GACnDC,EAAI,C,GAEEC,GAA+B/J,EAAA8J,EAAA9J,UAAA+J,GAAAtO,EAAAqO,EAAArO,QAAA,OAAAqO,E,mDAKpCjI,EAAM,IAAAmI,GAAAH,G,UACL1J,KAAKwI,GAAiC5H,SAAAc,EAAAyG,aAAAnI,G,QAE5B,IAAA8J,GAA0CjK,EAAAvE,EAAAoG,G,UACrDlC,IAAAkK,EAAAK,GACDA,C,aA8BoCC,EL7EF,a,QK8E9BhC,GAAOrI,IAAAqK,G,OL9EuB,c,GK8EE3O,KAAA,OAAA4O,K,YAACnB,GAAAzL,OAAA,U,QAChC2M,I,kBAmDNE,GAAAC,EAAAC,EAAAC,G,UAGCC,EAA2D,QAArD1P,EAAAmN,GAAoDoC,UAAC,IAAAvP,IAAAuP,EAC3DE,IAAKC,GAAe,IAClBD,K,QACKC,EAAAlQ,MAAA,S,EACCgQ,EAAAhQ,MAAwB,S,MACvBmQ,EAAA,C,QACL,C,+BAGYD,oBAA2BF,O,OAE1CI,GAAAC,EAAAnb,KAAA,iBAAAgb,sDACFE,GAAAD,GAAAE,EAAAnb,KAAA,O,sFAED8Y,GAAiDsC,KAAAD,EAAArf,KAAA,K,IAGtC,IAAAuT,GAAA,GAAA2L,aAAA,M,QACFA,EACL1V,QAAMwV,KACN,W;;;;;;;;;;;;;;;;ovDvB7NJ,IAAAvO,SAAA,CAAA5S,EAAA0S,KAOA,IAMA,IAAAgP,GAAA,EAOA,MAAAC,EAAA,0DAMAjF,EAAAkF,KAAA7N,UAAAqJ,KAAAuE,GAKAjF,EAAAmF,UAAA,KAQOnF,EAASE,OAAWkF,QAGXJ,GAAUE,KAAC7N,UAAcgO,eACzBJ,GAGT3hB,GAAQ,IAiMhB0c,EAAAsF,gBAAA,KCrODN,GAAA,GAaShF,EAAMuF,QAAU,KACxB,IAAAtQ,EAEDe,GAAA,QAAAf,EAAA+K,EAAA5V,aAAA,IAAA6K,OAAA,EAAAA,EAAA7E,UAGG,GACH,C,CA8BI,MAAKhG,GACH4L,EAAA5L,E;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GuBzCiD,IAAEob,GAAA;;;;;;;;;;;;;;;;;AChBxD,MAAAC,G,SCRY,MAAP1P,EAAazI,KAAKoY,YAAWjb,WACtB6C,KAAOqY,cAAe9N,I,0DAM7BA,G,MACD+N,EAAAtY,KAAAoY,YAAAxb,QAAAoD,KAAAqY,cAAA9N,IACD,OAAY,MAAZ+N,EAAY,K,MAIdld,OAAOmP,GACPvK,KAAAoY,YAAAjb,WAAA6C,KAAAqY,cAAA9N,GAEF,CAGA8N,cAAA5C,GCzDA,OAAAzV,KAAAuY,QAAA9C,CAoCA,CAIErf,WACA,OAAO4J,KAAAoY,YAAAhiB,U,CAKTmQ,YAAA6R,GAMEpY,KAAMoY,YAAYA,EAElBpY,KAAKuY,QAAO,WACZ;;;;;;;;;;;;;;;;SAmDEC,G,IACAjO,EAAA9B,GACI,MAAAA,SACFzI,KAAAyY,OAAAlO,GAEGvK,KAAIyY,OAAOlO,GAAO9B,C,KAGvB8B,GACA,OAAAe,GAAsBtL,KAAAyY,OAAAlO,GAAAvK,KAAAyY,OAAAlO,GACvB,IACD,CAEKnP,OAAMmP,UACPvK,KAAAyY,OAAAlO,E,eAKHvK,KAAAyY,OAAA,GAEGzY,KAAA0Y,mBAAA,C;;;;;;;;;;;;;;;;GA+CJ,MAAAC,GAAA,SAAAC,GAUF,IAYa,uBAAAvf,aAA8C,IAAxBA,OAAUuf,GAAc,CAGlD,MAAAC,EAAAxf,OAAAuf,GAID,O,yEAAM,IAAGT,GAAMU,EACnB,CACO,C,MAAL5d,GAAK,C,WAGJud,E,EAGeM,GAAAH,GAAA,gBACTI,GAAAJ,GAAA,kB,GAmB+B,IAAW9D,GAAA,sB,oBAKlD,E,OACF,WACD,OAAAtf,GAEF,CAKA,C,GAeSyjB,GAAA,SAAA/V,G,MACL8C,EAAekT,GACbhW,GAEFiW,EAAU,IAAKC,G,SACTpT,G,QAGFmT,EAAUE,S,OAEPjT,GACIzC,gBAAA2V,E,EAIZC,GAAA,YAAAC,GACD,IAAAzW,EAAA,GAEF,QAAAzN,EAAA,EAAAA,EAAAkkB,EAAAjkB,OAAAD,IAAA,CAIM,MAAMmkB,EACRD,EAASlkB,GACJ+L,MAASyC,QACd2V,IAAUA,GAAA,iBAAAA,GAED,iBAATA,EAASlkB,OAAAwN,GAAAwW,GAAA/X,MAAA,KAAAiY,GAEX1W,GAAA,iBAAA0W,EAAA1O,GAAA0O,GAEWA,EAIP1W,GAAU,G,CAOd,OAAAA,CAEK,E,YAYD2W,IAAQ,E,MAOVC,GAAW,SAAAC,EAAAC,GACXC,IAAuCD,IAAA,IAAAD,IAAA,IAAAA,EAAA,+CACxC,IAAAA,GAEEG,GAAQtK,SAAAb,GAAAI,QACXgL,GAAWD,GAAA9c,IAAAgd,KAAAF,IACXF,GAAAb,GAAAxM,IAAA,uBAEF,mBAAAoN,EAAAI,GAAAJ,GAYMI,GACK,KAAChB,GAAG3d,OAAA,mB,EAIb6e,GAA8B,YACvBV,GAgBP,IAbuC,I,KAGvCE,IAAgB,EAChB,OAAAM,KAAA,IAAAhB,GAAArM,IAAA,oBAAAgN,IAAA,IASKK,GACK,CAIX,MAAAjX,EAAAwW,GAAA/X,MAAA,KAAAgY,GAeDQ,GAAAjX,EAQE,C,EAIAoX,GAAoC,SAAAC,GACpC,OAAO,YAAYZ,G,gBAKX,YAAAA,G,MACLzW,EAAK,4BAAAwW,MAAAC,G,GACqBzc,MAAKgG,E,KAEtB,YAAAyW,G,MACTzW,EAAW,yBAAIwW,MAAAC,K,SAESzc,MAAOgG,G,iBAGhB,YAAAyW,G,QACN,qBAAuBD,MAAkCC,G,GAC5D9B,KAAA3U,E,EAYRsX,GAAA,SAAAvf,GACD,MAAwB,iBAAVA,IAAaA,UAAAwf,OAAAC,mBAAAzf,IAAAwf,OAAAE,kB,EAgHzBC,GAAU,SAAAC,EAAAC,G,kBAEV,GA1BD,eA0BCD,GAtBJ,eAsBoBC,EAAA,S,GA1BjB,e,GAIH,e,kDA2BqB,OAAfC,EAA4BC,EAAAD,GAAA,EAAAF,EAAAnlB,OAAAolB,EAAAplB,OAAAslB,EAAAD,GAC5B,EACQ,OAADA,EAAC,EACFF,EAAQC,GAAE,G,6CA2CpBG,GAAA,SAAAtQ,EAAAgB,GAaF,GAAAA,GAAAhB,KAAAgB,EAAA,OAAAA,EAAAhB,GAaE,MAAM,IAAO9U,MAAoB,yBAAqB8U,EAAA,gBAAAO,GAAAS,G,EAEtDuP,G,YAGE,GAAgB,iBAALvP,G,sBAEX,MAAKpW,EAAA,G,UAKI4lB,KAAAxP,EAAOpW,EAAOkH,KAAK0e,GAK9B5lB,EAAA0c,OACF,IAAAtH,EAAA,IC7nBA,QAAAlV,EAAA,EAAAA,EAAAF,EAAAG,OAAAD,IA0CW,IAADA,IAACkV,GAAsB,KAC7BA,GAAUO,GAC0C3V,EAAAE,I,uCAiBtD2lB,GAAsD,SAAA/X,EAAAgY,G,oBACpDta,GAAAsa,EAAK,OAGNhY,G,MAGCiY,EAAA,G,IAID,IAAA9X,EAAA,EAAAA,EAAAzC,EAAAyC,GAAA6X,EAAA7X,EAAA6X,EAAAta,EAAAua,EAAA7e,KAAA4G,EAAAkF,UAAA/E,EAAAzC,IAxCDua,EACU7e,KAAA4G,EACAkF,UAAA/E,IAA0D6X,I,OAD1DC,C,EAwCX,SAAAC,GAAA5P,EAAA6P,GCzED,UAAA7Q,KAAAgB,IAAA3E,eAAA2D,IAAA6Q,EAAA7Q,EAAAgB,EAAAhB,G,UA2D0B,SAAmB8Q,G,IAEnBjB,GAAAiB,GAAA,uB,MAGlBC,EAAC,K,IAGLC,EAAAtgB,EAAAugB,EAAOC,EAAKpmB,EAGV,I,eAGCgmB,IACCK,IAAe,MAGpBH,EAAAF,EAAA,GAEDA,EAAA9hB,KAAAC,IAAA6hB,K,mBAGMI,EAAKliB,KAAKoiB,IACZpiB,KAAKqiB,MAAMriB,KAAAyD,IAAAqe,GAAA9hB,KAAqBsiB,KAAAP,G,EAEhCG,EAAKH,EAIRE,EAAAjiB,KAAAuiB,MAAAT,EAAA9hB,KAAAwiB,IAAA,EA1BW,GA0BXN,GAAAliB,KAAAwiB,IAAA,EA1BW,OAgCX9gB,EAAA,EAEDugB,EAAAjiB,KAAAuiB,MAAqBT,EAAA9hB,KAAAwiB,IAAA,Y,QAiBjB,G,IAKF1mB,EAxDU,GAwDVA,KAAA,EACD2mB,EAAA3f,KAAAmf,EAAA,OAjFDA,EAAAjiB,KACUqiB,MAAAJ,EACA,G,IAAAnmB,EAsBE,GAtBcA,KAAA,EAChB2mB,EAAa3f,KAAApB,EAAA,IAAb,GALFA,EAAK1B,KAAAqiB,MAAgC3gB,EAAK,G,OAONsgB,EAAA,EAAU,G,EAAMU,U,MAC1DhZ,EAAK+Y,EAAK7jB,KACR,IA2EL,IAAA+jB,EAAA,GAED,IAAA7mB,EAAA,EAAAA,EAAA,GAAAA,GAAA,GAOE,IAAQ8mB,EAACjU,SAAqBjF,EAAAmZ,OAAA/mB,EAAA,MAAAe,SAAA,IACL,IAAvB+lB,EAAO7mB,SAAgB6mB,EAAA,IAAAA,G,GACHA,C,QAErBD,EAAAG,a,QC7ECC,GAA0C,IAAIC,OAAC,qBAe/CC,GAAmC,SAAAvZ,G,MACL2G,KAAA3G,GAAA,C,MAC5BwZ,EAASpC,OAAApX,G,GAGVwZ,IAfkC,YAelCA,GATiB,WASjB,OAAAA,C,CAGH,W,EA9BEC,GAAgC,SAAAtB,G,IAEhCA,G,CAED,MAAAngB,GA2CHnB,YAAS,KAqBP,MAAA6iB,EAAA1hB,EAAA0hB,OAAA,GAGQ,MADJC,GAAgB,yCAAAD,GACP1hB,CAAA,GAGN1B,KAAIqiB,MAAS,G,GC5HtBiB,GAAA,SAAAzB,EAAA0B,GAsBA,MAAMpc,EAAA5G,WAAAshB,EAAA0B,GAkBJ,MAfmB,iBAAbpc,GAED,oBAAAqc,MAILA,KAAO,WACRA,KAAAC,WAAAtc,GAEe,iBAAAA,KAAA,OAIdA,EAAM,QAEDA,C;;;;;;;;;;;;;;;;;kBCsBDuc,G,YACEC,SA/BwBld,KAAAkd,SAAVC,SAA2BF,GA+BvB,IAAArU,SAAA,CAAA5S,EAAA0S,K,YAKnB,KACI1I,KAAAkd,SAAkBld,KAAGmd,SAAAF,GAAA9iB,KAAAnE,EAAA0S,GAC3B1S,EAAA,QACF,K,wBA9CiBonB,GAClB,IAAkBzV,EACkB,QAApCA,EAAO3H,KAAAqd,wBAA6B,IAAA1V,KAAA+E,MAAAvS,MAAA+iB,KAAAI,iBAAAF,I,CA6CrCG,wBCxEDX,GAAA,oDAAA5c,KAAAwd,wFAgDO,CACAjX,YAAMiX,EAAAH,GACArd,KAAAwd,WACAxd,KAAAqd,mBACArd,KAAAkd,SAAAG,aAAkC,EAAAA,EAAA1I,aAAA,CAClC7H,UAAA,IAEA9M,KAAAkd,UAAAG,SAA2CA,EAAA3Q,MAAAvS,MAAA+iB,GAAAld,KAAAkd,YACjD;;;;;;;;;;;;;;;;+BAyFDld,KAAKyd,M,KAeGA,MAACN,SAAAF,GAA4B9d,OAAEue,G,GAMf,+BAAlBA,EAAapf,M,GACR,kEACN,MACIsK,QAAAF,OAAiBgV,KAxBT,IAAA9U,SAAA,CAAA5S,EAAA0S,KAMnB5O,YAAA,KACUkG,KAACyd,MACPzd,KAAAmd,SAAOF,GAAA9iB,KAAAnE,EAAA0S,G,UAIT,EAAK,G,wBAeM0U,G,WAGDpd,KAAIyd,MAAEE,qBAAAP,G,wFAGHA,G,yJAKcpd,KAAAwd,S,gGAChBxd,KAAA4d,iBAAAC,GAAA,uJ,mBAEE7d,KAAS4d,iBAAGC,GAAA,2J,GAGb,kK,GAGEA,E,aAEVL,EAAKI,EAAuBE,G,cACvBN,E,KACNI,iBACIA,E,mBACEE,E,KACNL,MACI,K,yCAMPzd,KAAAyd,OAAUK,EAAA5P,QAAA6P,GAAA/d,KAAAyd,MAAAM,G,EAQkC,MAAAC,G,SAC5Cf,G,OAGArU,QAAS5S,QAAA,CAGTioB,YAASje,KAAAie,a,wBAaHb,G,8CAMTA,GAAA,CAEDG,wBAAA,C,YAIOU,GACLje,KAAKie,a,EASoCD,GAAAE,MAAA;;;;;;;;;;;;;;;;;SAkDZ;;;;;;;;;;;;;;;;;AAmC/B,MAAAC,G,kBAOE,MAAiC,OAA5Bne,KAAAoe,aAAoBhC,OAAO,EAAC,E,gBAIjC,MAAmB,mBAAbpc,KAAAqe,SAAa,wBAAAre,KAAAqe,O,YAInB,OAAMre,KAAAse,K,aAIDC,IAAYve,KAAGoe,eAClBpe,KAAKoe,aAAeG,EAKhBve,KAACwe,mBAAgB1F,GAAAvM,IAAA,QAAAvM,KAAAse,MAAAte,KAAAoe,c,CAIzBhoB,WAME,IAAI6M,EAAAjD,KAAAye,cAIJ,OADIze,KAAC0e,iBAAiBzb,GAAS,IAAAjD,KAAA0e,eAAwB,KACjDzb,C,eAGN,MAAA0b,EAAU3e,KAAA4e,OAAA,qBACLC,EAAA7e,KAAe8e,8BAA4B,OAAA9e,KAAA+e,YAAA,GAChD,MAAK,GAAAJ,IAAe3e,KAAM0H,QAAOmX,G,CA5RnCtY,YAAAmB,EAAAkX,EAAAG,EAAAC,EAAAC,GAAA,EAAAP,EAAA,GAAAI,GAAA,EAAAI,GAAA,GAYSlf,KAAM4e,OAANA,EACA5e,KAAQ+e,UAARA,EACC/e,KAAagf,cAAbA,EACAhf,KAAaif,YACbjf,KAAS0e,eAATA,EACD1e,KAAkB8e,8BAAlBA,EACA9e,KAAakf,gBAAbA,EAlCTlf,KAASse,MAAA5W,EAAI2U,cACbrc,KAAaqe,QAAAre,KAAAse,MAAKlC,OAAApc,KAAAse,MAAAa,QAAA,QAUVnf,KAAcoe,aAAAtF,GAASpM,IAAA,QAAAhF,IAAA1H,KAAAse,K,WAiZ7Bc,GAAiEC,EAAA5V,EAAA6V,G,IAIjEC,E,GAHA1F,GAA8B,iBAAApQ,EAAA,8B,sDA3LA,c,EA+LM8V,GAAAF,EAAAT,OAAA,kBAAAS,EAAAjB,aAAA,Y,IA9LnC,iBA+LC3U,E,+CAAI8V,GAAAF,EAAAT,OAAA,sBAAAS,EAAAjB,aAAA,O,WA5X2CiB,G,gIAgYnCC,GAAO,CAAA/U,EAAA9B,K,OACjB8B,E,YAIOrV,EAAGiD,KAAA,I;;;;;;;;;;;;;;;;oCAsCPmT,GAAmCtL,KAAAwf,UAAAC,KAAAzf,KAAAwf,UAAAC,GAAA,G,KACxCD,UAAWC,IAAKC,C,iBAGS1f,KAAAwf,U,oBAG1BA,UAAA,E;;;;;;;;;;;;;;;;kBAqCM,G,uBAIAH,EAAejpB,W,UACmCupB,KAAAC,GAAAD,GAAA,IAAAE,I,GAC7CF,E;;;;;;;;;;;;;;;;;oBA2D2BG,EAAWtX,G,KAAGuX,mBAAMD,E,KAAIE,QAAAxX,E,iEAI3DxI,KAAKggB,QACP,KAIJ,C,eAWSC,EAAcplB,G,SACnBqlB,iBAAAD,GAAAplB,E,+GAIImF,KAAAkgB,iBAAmBlgB,KACvBmgB,oBAIF,IAAM,IAAA9qB,EAAA,EAAYA,EAAG+qB,EAAK9qB,SAAAD,EAAA+qB,EAAA/qB,IAAAqnB,IAAA,K,+EAKxB1c,KAAYggB,UACZhgB,KAAAggB,UAEUhgB,KAAKggB,QAAA,MAGnB,KAMM,CAEWhgB,KAACmgB,oB,cAQVE,G,gBACUA,E,sBACK,G,wBACC,E,wCAEhB,I;;;;;;;;;;;;;;;;2BA9PJC,cACe,E,mBAGPC,E,qBACG,IAAAC,GAA8CC,G,KACxDC,WAAA,E,KACDC,qBAAuB7mB,YAAA,KACvBkG,KAAI4gB,KAAA,gC,KAEFC,Y,KACAF,qBAAuB,IAAG,G,KAE1B/E,MAzBA,MNzBkB,SAAAR,G,GACvBtR,MAAA,aAAAlS,SAAAkpB,WAAA1F,QACI,C,SAKD,MAAA2F,EAAkB,WACTnpB,SAAQopB,KAMpBC,IACMA,GAAc,EACrB7F,KAPMthB,WAAUinB,EAAaxnB,KAAQqiB,MAAM,IAc3C,EAMAhkB,SAAAS,kBAEFT,SAAAS,iBAAA,mBAAA0oB,GAGa,GAEJ1nB,OAAOhB,iBAAY,OAAY0oB,GAAO,IAG/CnpB,SAAAspB,cASStpB,SAAQspB,YAAK,sBACT,KAEH,aADOtpB,SAAKkpB,YACTC,GAAA,IAQJ1nB,OAAM6nB,YAAA,SAAAH,GAkBf,C,GMvBe,K,GACR/gB,KAAA0gB,UAAA,OAED1gB,KAAKmhB,gBAAY,IAAUC,IAAA,IAAAjgB,KACvB,MAACkgB,EAAcC,EAAAC,EAAYC,EAAAC,GAAAtgB,EAElC,GADEnB,KAAA0hB,wBAAAvgB,GACFnB,KAAAmhB,gBCzbe,GDyrBjBnhB,KAAA2gB,uBC1uBD1gB,aAAAD,KAAA2gB,sBA4CM3gB,KAAA2gB,qBAAA,MAGK3gB,KAAA2hB,gBAAiB,EDwrBJ,UCtrBNN,EAQlBrhB,KAAAzK,GAAA+rB,EAmDEthB,KAAA4hB,SAAAL,MAciB,ID+mBhB,UC/mB4CF,EAmCjC,UAAA5rB,MAAA,kCAA2C4rB,GA/BlDC,GAaCthB,KACFmhB,gBAAUU,cAAA,EAOb7hB,KAAA8hB,gBAAAC,WAAAT,GAAA,KAEDthB,KAAA6gB,WAAA,KAMmB7gB,KAAA6gB,WAEoC,KAEhD,IAAA1f,K,aAELnB,KAAA0hB,wBAAAvgB,GAEInB,KAAA8hB,gBAAAE,eAAAC,EAAApnB,EAAA,IACF,KACImF,KAAA6gB,WAAA,G,KACFqB,O,QAGW,C,MACmB,K,EACkB,IAAA3oB,KAAAqiB,MAAA,IAAAriB,KAAA4oB,U,KAC7ChB,gBAAAiB,2BAAAC,EAAA,GAAAriB,KAAAmhB,gBAAAiB,0B,EACD,ED6HoB,I,6RCtHtBE,EAAStiB,KACPkiB,MAAAG,G,KAEFzB,KAAI,+BACa0B,G,uCAIU,G,cAU7BnB,gBAAcoB,cAAIviB,KAAAzK,GAAAyK,KAAA4hB,U,KAClBY,uBAAUxiB,KAAAzK,GAAAyK,KAAA4hB,S,wBAOHa,aAAA,C,2BAMPC,gBAAA,C,6BAKI5Y,SACJ6Y,GAAAF,eAIAE,GAAAD,gBAAA,oBAAA9qB,UAAA,MAAAA,SAAAgrB,eLhFsB,iBAA1BvpB,QAA4EA,OAAA,QAAAA,OAAA,6BAAAuQ,KAAAvQ,OAAAwpB,SAAA7jB,OAjB5E,iBAAA8jB,SAAA,iBAAAA,QAAAC,I,yBKsG6B,C,YAM5B/iB,KAAA0gB,WAAA,EAED1gB,KAAAmhB,kBAOOnhB,KAAAmhB,gBAAarJ,QAClB9X,KAAAmhB,gBAAA,MAIInhB,KAAAgjB,iBACAprB,SAAOopB,KAAAiC,YAAcjjB,KAAAgjB,gBACvBhjB,KAAAgjB,eAAqB,MAErBhjB,KAAI2gB,uB,aACE3gB,KAAU2gB,sB,KAGfA,qBAAA,K,8BA0BH3gB,KACE4gB,KAAA,8BAGH5gB,KAAAkjB,YAEDljB,KAAAmjB,gBACEnjB,KAAAmjB,cAAAnjB,KAAA2hB,gBACD3hB,KAAAmjB,cAAA,M,SAUGnjB,KAAK0gB,YACN1gB,KAAA4gB,KAAA,6BACF5gB,KAAAkjB,Y,uBAkBCljB,KAAIojB,WAAWC,EAAO/tB,O,KACpBguB,OAAMC,iBAAmB,aAAOF,EAAA/tB,Q,QAEzBwQ,GAAiCud,GAGzCnI,EAAAF,GAAAwI,E,MAGF,QAAAnuB,EAAA,EAAAA,EAAA6lB,EAAA5lB,OAAAD,IAED2K,KAAAmhB,gBAAAsC,eAAAzjB,KAAAsgB,cAAApF,EAAA5lB,OAAA4lB,EAAA7lB,IAKM2K,KAAKsgB,e,wBAYF/qB,EAAAmuB,G,oBAELV,eAAMprB,SAAqBgrB,cAAA,U,MAC3BP,EAAI,C,OAGL,KACFA,EAAA,GAAA9sB,EAED8sB,EAAA,GAAAqB,EAKE1jB,KAAKgjB,eAActkB,IAAGsB,KAAAkiB,MAAAG,GAEtBriB,KAAAgjB,eAAgB9pB,MAAAyqB,QAAA,OAChB/rB,SAAKopB,KAAS4C,YAAY5jB,KAAAgjB,e,CAM1BtB,wBAAiBvgB,GAGjB,MAAI0iB,EACF/Y,GAAyC3J,GAAA7L,O,sBAI3C0K,KAAKsjB,OAAQC,iBAAgB,iBACtBM,E,CAeRtd,YAAAud,EAAAzE,EAAA0E,EAAAC,EAAAC,EAAAC,EAAAC,GAEOnkB,KAAS8jB,SACf9jB,KAAKqf,SAAKA,E,KACR0E,cAAUA,E,KACVC,cAAiBA,E,sBAGjBE,mBAAqBA,E,mBACdC,E,eACA,E,KACNN,cAAA,E,KACFlC,gBAAA,EACF3hB,KAAA4gB,KAAA1G,GAAA4J,GAED9jB,KAAAsjB,OAAAc,GAAA/E,GAKErf,KAAKkiB,MAAK5C,IAEJtf,KAACgkB,gBAAY1E,EAAA,GAAAtf,KAAAgkB,eAClB5E,GAAAC,EDzGA,eCyGAC,GAGH,EAS4B,MAAA8B,GAK3BiD,uBAED,MAAAC,EAAA1sB,SAAAgrB,cAAA,U,yCArXA,KAAW,oGA8XLhrB,SAAAopB,KAAA4C,YAAAU,GACF,IAQDA,EAAAC,cAAA3sB,UA1XHqiB,GAAA,gCAgBmB,CAJJ,MAAAhf,GAEQ,MAAAupB,EAAb5sB,SAAA4sB,OACaF,EAAA5lB,IAAb,gEAAsB8lB,EAAA,0BACb,CAajB,OAxCWF,EAAAG,gBAAKH,EAAAI,IAAAJ,EAAAG,gBA+BPH,EAAGC,cAAAD,EAAAI,IAAUJ,EAAMC,cAAQ3sB,SAC/B0sB,EAAS1sB,WACd0sB,EAAKI,IAAOJ,EAAG1sB,UAOV0sB,C,CAqKPxM,QCzOA9X,KAAA2kB,OAAW,EACT3kB,KAAO4kB,WACR5kB,KAAA4kB,SAAAF,IAAA1D,KAAAxlB,YAAA,GAED1B,YAAA,KAKc,OAAAkG,KAAA4kB,WACbhtB,SAAAopB,KAAAiC,YAAAjjB,KAAA4kB,UASuB5kB,KAAA4kB,SAAkB,KAClC,GAEFrrB,KAAAqiB,MAAA,K,MAUFiJ,EAAA7kB,KAAuB8kB,aACxBD,IAEG7kB,KAAA8kB,aAAoB,KACFD,I,CAUvBtC,cAAAhtB,EAAAmuB,GAaD,IAXA1jB,KAAA+kB,KAAAxvB,EAIEyK,KAAIglB,KAAKtB,E,KAGPiB,OAAM,EAIV3kB,KAAAilB,gB,CA9DAA,cCCF,GAAAjlB,KAAA2kB,OAAA3kB,KAAA6hB,cAAA7hB,KAAAklB,oBAAAC,MAAAnlB,KAAAolB,YAAA9vB,OAAA,QAEM0K,KAAAqlB,gBAEN,MAAAhD,EAAA,GACAA,EAAA,GAAAriB,KAAA+kB,KACA1C,EAAA,GAAAriB,KAAAglB,KACM3C,EAAwC,IAAAriB,KAAAqlB,cACxC,IAAAC,EAAAtlB,KAAAkiB,MAAAG,GASAkD,EAAA,GACAlwB,EAAA,EACA,KAAA2K,KAAAolB,YAAA9vB,OAAgB,IAGhB,KADA0K,KAAAolB,YAAmB,GACnBI,EAAAlwB,O,GAAiBiwB,EAAAjwB,QH6WW,MGpThC,MAzDqB,CAEjB,MAAAmwB,EAAOzlB,KAAIolB,YAAA/Q,QAEXkR,WAAmBlwB,EAAA,IAAAowB,EAAAC,IAAnBH,MAAmBlwB,EAAA,IAAAowB,EAAAE,GAAnBJ,KAAmBlwB,EAAA,IAAAowB,EAAAD,EAEzBnwB,GAmDE,CAIE,C,OACIiwB,GACFC,E,6CAWF,CAAK,Q,CASL9B,eAAAmC,EAAAC,EAAAhrB,G,KAQEuqB,YAAU/oB,KAAQ,CACjBqpB,IAAKE,EAERD,GAAME,EACFL,EAAA3qB,I,YAQQmF,KAAKilB,a,iBAoBL9uB,EAAC2vB,G,KAERZ,oBAAA7pB,IAAAyqB,G,aAEA9lB,KAAKklB,oBAAM5X,OAA0BwY,GAE3C9lB,KAAAilB,aAAA,EAMOc,EAAqBjsB,WAAAksB,EAAAzsB,KAAAqiB,M,YAUzBqK,OAAA9vB,GATkB,K,aAGH4vB,G,GAER,G,uBAiBNG,eAAA/vB,EAAAgwB,GACDrsB,YAAA,KACH,I,6BAOO,MAAMssB,EAAApmB,KAAA4kB,SAAAF,IAAA9B,cAAA,UAAKwD,EAAG3c,KAAA,kBAAK2c,EAAOpqB,OAAA,EAAGoqB,EAAA1nB,IAAAvI,EAEpCiwB,EAAAC,OAAAD,EAAAE,mBAAA,WAGa,MAAKC,EAAKH,EAActF,WAEhCyF,GAAA,WAAAA,GAA6C,aAA7CA,IAGGH,EAAiBC,OAAKD,EAAAE,mBAAA,K,0CAE5BH,IAGK,EACFC,EAAAnO,QAAA,KACIgC,GAAkB,oCAAwB9jB,GACzC6J,KAAK6hB,cAAA,EAEL7hB,KAAO8X,OAAK,EAEjB9X,KAAK4kB,SAAKF,IAAA1D,KAAA4C,YAAAwC,E,OACLnrB,G,SAQN2gB,MAAM,G,CAQHrV,YAAAigB,EAA2BC,EAAsBC,EAAAxE,G,GACvDliB,KAAA8kB,aAAsB4B,EACtB1mB,KAAAkiB,MAAsBA,EAKpBliB,KAAKklB,oBAAoB,IAAK7W,IAIjCrO,KAAAolB,YAAA,G,KAOGC,cAAK9rB,KAAAqiB,MAAsB,IAAAriB,KAAA4oB,U,KAG3BN,cAAU,EACL/X,K,KAcoD0c,YAAIxmB,KAAAymB,kBAdpC,C,KAA+BrE,yBAAAuE,K,OHuJ5D,aGvJgE3mB,KAAAoiB,0BAAAoE,EAC7DntB,OH+J8B,UG/J9B2G,KAAAoiB,0BAAAqE,EAGKzmB,KAAA4kB,SAAmBxD,GAAAwF,gBAErB,IAACC,EAAA,GAGD,GAAC7mB,KAAA4kB,SAAelmB,KAAK,gBAAAsB,KAAA4kB,SAAAlmB,IAAA0d,OAAA,OAAayK,EAAA,4BAALjvB,SAAA4sB,OAAK,c,OAAkBsC,EAAI,eAAAD,EAAA,iB,IAAM7mB,KAAA4kB,SAAAF,IAAAtR,O,qDAI7D,MAAKnY,GACLgf,GAAW,2BAAQhf,EAAA0hB,OAAA1C,GAAAhf,EAAA0hB,OAAK1C,GAAAhf,E;;;;;;;;;;;;;;;;UA6BF,KACZ,oB,aAAA8rB,GAAwBC,aACpC,oBAAAC,YAAAF,GAAAE,WAIG,MAAAC,G,sBAeA7H,EAAqB6E,EAAoBC,EAAAH,EAAAD,G,QAEtC,C,EHrDiB,K,OGuDtBja,MAAU,oBAAA+Y,mBAAAsE,UAAAC,GAAAxd,KAAAiZ,SAAAsE,YAAA9E,EAAA,E,SACMA,EAAe,EAAA6B,G,IACrB7B,EACH,GAAA8B,G,IAEF9B,EAAyB,GAAA2B,G,IACzB3B,EAAuB,EAAA0B,GAC7B3E,GAAkBC,EHjDS,Y,UGwDdgI,G,kBAEAA,E,eACH5G,E,UACT,2BAA0BzgB,KAAAuf,S,qBACrB,E,GAIRhT,IAAA,iCACF,IAED,IAAAK,EASE,GAAM9C,KAAyB,CACzB,MAAOwd,EAAGtnB,KAAWif,UAAC,mBAEvBrS,EAAY,CACZ2a,QAAc,C,mDAEJ,mBAAAvnB,KAAA+jB,eAA+B,KAWxB/jB,KAAAikB,YAAArX,EAAA2a,QAAA,wBAAAvnB,KAAAikB,aACZjkB,KAAOgkB,gBAACpX,EAAkB2a,QAAA,uBAAmBvnB,KAAAgkB,eAIxD,MAAAviB,EAAA,GAE+C+lB,EAAA,IAAAxnB,KAAAuf,QAAAJ,QAAA,UAAA1d,EAAA,aAAAA,EAAA,YAAAA,EAAA,YAAAA,EAAA,WACzC+lB,IAAc5a,EACjB,MAAK,C,UASH,CAGJ5M,KAAMynB,OAAY,IAAIV,GAAoC/mB,KAAAuf,QAAA,GAAA3S,E,CAC1D,MAAM1M,GACFF,KAAC4gB,KAAA,kC,iCAGL8G,GAAA1nB,KAAA4gB,KAAA8G,QACE1nB,KAAI6gB,W,MAGH4G,OAAAE,OAAA,KACA3nB,KAAK4gB,KAAM,wBACf5gB,KAAA2hB,gBAAA,GAGC3hB,KAAKynB,OAAKG,QAAA,KACN5nB,KAAC4gB,KAAS,0C,wCAKP6G,OAAAI,UAAAC,I,kCAGLL,OAAKxP,QAAShd,IACf+E,KAAA4gB,KAAA,yCAGK,MAAAmH,EAAA9sB,EAAyB6H,SAAiB7H,EAAAJ,KAC3CktB,GAAK/nB,KAAA4gB,KAAAmH,GACN/nB,KAAC6gB,WAAa,C,SAMjB,C,qEAMCmH,GAAe,E,GAEf,oBAAAte,qBAAqBue,UAAM,CACzB,MAAKC,EAAA,iCACCC,EAAMze,UAAAue,UAAA9gB,MAAA+gB,GAEjBC,KAAA7yB,OAAA,GAEO8yB,WAAAD,EAA6B,UAAAH,GAAA,EAEnC,C,OACMA,GAAkC,OAA5BjB,KAA4BG,GAAAxE,c,kCACY5J,GAAAJ,oBAAA,IAAAI,GAAApM,IAAA,6B,yBAI9CoM,GAA0B1d,OAAA,6B,cAE3BP,GAGH,GAFFmF,KAAIqoB,OAAQhsB,KAAKxB,GAEXmF,KAACqoB,OAAQ/yB,SAAA0K,KAAAsoB,YAAA,CAEhB,MAAAC,EAAAvoB,KAAAqoB,OAAAlwB,KAAA,IAED6H,KAAAqoB,OAAA,KAKM,MAAMG,EAAQ3d,GAAA0d,G,iBAIlB,C,sBAIIE,G,+BAEK,E,CASHC,mBAAsB7tB,G,GACxBgf,GAAgE,OAA1D7Z,KAA0DqoB,OAAA,kCAIlExtB,EAAKvF,QAAU,GAChB,MAAAmzB,EAAApO,OAAAxf,G,aAII,O,6BAAA,IAGN,CAGC,OADMmF,KAAS2oB,qBAAa,GACxB9tB,C,qBAYQ+tB,G,GACC,OAAX5oB,KAAKynB,OAAM,O,MAEX5sB,EAAK+tB,EAAA,K,QAEL/E,eAAShpB,EAAavF,O,YAChBiuB,iBAAiB,iBAAA1oB,EAAAvF,Q,sBAEtB,O,KAAA+yB,O,KACFQ,aAAAhuB,OACF,CAGK,MAAMiuB,EAAA9oB,KAAA0oB,mBAAiC7tB,GAC3B,OAARiuB,GAAQ9oB,KAAA6oB,aAAAC,E,OAOdjuB,G,KACDkuB,iBAED,MAAI1F,EAAKvY,GAAiBjQ,G,KACxBuoB,WAAaC,EAAK/tB,O,KAClBguB,OAAKC,iBAAkB,aAAKF,EAAA/tB,QAtehC,MAAA4lB,EAAAF,GAAAqI,EAkP6C,OApO1BnI,EAAA5lB,OAAT,GAAA0K,KAAmBgpB,YAAA/wB,OAAAijB,EAAA5lB,SAEnB,IAAc,IAAAD,EAAA,EAAAA,EAAA6lB,EAAd5lB,OAAcD,IAAoB2K,KAAAgpB,YAAA9N,EAAA7lB,G,aAGlC2K,KAAQ0gB,WAAR,EACa1gB,KAAAipB,iBACNC,cAAPlpB,KAA4BipB,gBAChBjpB,KAAAipB,eAAb,MArCUjpB,KAAAynB,SAWXznB,KAAAynB,OAAkC3P,QA4BpC9X,KAAKynB,OAAG,K,aAIbznB,KAAA0gB,YA6cF1gB,KAAA4gB,KAAA,+BC7jBD5gB,KAAAkjB,YAmDIljB,KAAkB8kB,eAMpB9kB,KAAA8kB,aAAA9kB,KAAA2hB,gBAMA3hB,KAAA8kB,aAAA,MAkBA,CCnCAhN,QAIM9X,KAAM0gB,Y,uCAER1gB,KAAAkjB,Y,CAQD6F,iBACDG,cAAKlpB,KAAAipB,gBACLjpB,KAAKipB,eAAWE,aAAkB,K,aACAnpB,KAAQgpB,YAAA,K,qBAAS,GAEnDzvB,KAAMqiB,MFsQyC,M,CE7P/CoN,YAAa/lB,GASd,IAEOjD,KAAAynB,OAAmB2B,KAAAnmB,EAO1B,CANC,MAAAhI,GAEI+E,KAAA4gB,KAAS,0CAAe3lB,EAAA6H,SAAA7H,EAAAJ,KAAA,uBAE1Bf,WAAAkG,KAAA6gB,UAAoB7G,KACpBha,MAAA,EACH,CA7DD,CCyCEuG,YAAAud,EAAAzE,EAAA0E,EAAAC,EAAAC,EAAOC,EAAwBC,GAC/BnkB,KAAA8jB,OAAOA,E,KAACC,cAAYA,E,KAAEC,gBACvBhkB,KAAAikB,YAEDjkB,KAAAipB,eAAe,KACbjpB,KAAAqoB,OAAY,KACbroB,KAAAsoB,YAAA,EA3CDtoB,KAAAojB,UAAA,EACEpjB,KAAK6jB,cAAC,E,KAACjD,KAAQ1G,GAAAla,KAAA8jB,Q,KAAGR,OAAAc,GAAA/E,GAPZrf,KAAOuf,QAAG2H,GAAKmC,eAAAhK,EAAA6E,EAAAC,EAAAH,EAAAD,G,+BAoBjBuF,6BAAK,E,GAGsBC,eAAM;;;;;;;;;;;;;;;;;2CCNnC,CACA5G,G,IAUK6G,sC,OACLxpB,KAAKypB,2B,iBAERpK,GAYF,MAAAqK,EAAAxC,OAAA,cAEe,IAAAyC,EAAAD,IAAYxC,GAAA0C,mBAS1B,GAROvK,EAAIL,gBACZ0K,GAAA9M,GAAA,mFAEe+M,GAAA,GAKPA,EAAkB3pB,KAAU6pB,YAAC,CACrC3C,QAMQ,CACR,MAAA4C,EAAA9pB,KAAA6pB,YAAA,GAEe,UAAAE,KAAAC,GAAuBC,eAAAF,KAAA,eAAAD,EAAAztB,KAAA0tB,GACjCC,GAA0BP,6BAAA,CAC1B,CAGJ,CAIIS,mBAIJ,GAAOlqB,KAAK6pB,YAAAv0B,OAAA,SAAA0K,KAAA6pB,YAAA,GACb,UAAAp0B,MAAA,0BAEK,CAQJ00B,mBACD,OAAAnqB,KAAA6pB,YAAAv0B,OAAA,EAAA0K,KAAA6pB,YAAA,GAED,IAKE,CAIItjB,YAAK8Y,GAITrf,KAAMoqB,gBAAY/K,EAClB,EAOc2K,GAAAP,6BAAiD,EAgG/D,MAAIY,GAOFC,SACA,MAAIC,EAAAvqB,KAAAwqB,kBAAAN,mBACLlqB,KAAAyqB,MAAA,IAAAF,EAAAvqB,KAAA0qB,mBAAA1qB,KAAA2qB,UAAA3qB,KAAA4qB,eAAA5qB,KAAA6qB,eAAA7qB,KAAA8qB,WAAA,KAAA9qB,KAAAmkB,eAIHnkB,KAAA+qB,0BAAAR,EAAA,gCAeE,MAAAS,EAAAhrB,KAAAirB,cAAAjrB,KAAAyqB,OAI2CS,EAAZlrB,KAAAmrB,iBAAoBnrB,KAAAyqB,OACjDzqB,KAAKorB,IAAMprB,KAAGyqB,M,oBAIdzqB,KAAKqrB,eAAe,KAGpBrrB,KAAAsrB,YAAA,EAYFxxB,YAAe,KAEfkG,KAAAyqB,OAAAzqB,KAAAyqB,MAAArX,KAAA4X,EAAyBE,EAAgB,GAC1C3xB,KAAAqiB,MAAA,IAEK,MAAU2P,EAAAhB,EAAkB,kBAC1BgB,EAAqB,IAACvrB,KAAOwrB,gBAAM3O,IAAA,KACzC7c,KAAAwrB,gBAA8B,K,kBAE1BxrB,KAAeyqB,OAAOzqB,KAASyqB,MACjC5G,cAhGD,QAkGF7jB,KAAA4gB,KAAA,wDAAA5gB,KAAAyqB,MAAA5G,cAAA,wCAEQ7jB,KAAAsrB,YAAA,EACHtrB,KAAeyqB,MAAAgB,yBAUAzrB,KAAOyqB,OAASzqB,KAAAyqB,MAAArH,UAjHpB,MAmHIpjB,KAAY4gB,KACzB,oDAAA5gB,KAAAyqB,MACArH,UAAA,uCAORpjB,KAAA4gB,KAAA,+CAMM5gB,KAAe8X,SAIrB,GCrTSve,KAAAqiB,MAAW2P,I,oBAiDlB,WAAgBvrB,KAAAzK,GAAiB,IAAAyK,KAAA0rB,iB,kBAExBnB,G,OAAKoB,IAAWpB,IAAAvqB,KAAAyqB,MAAAzqB,KAAA4rB,kBAAAD,GACxBpB,IAAAvqB,KAAAqrB,gBAhDDrrB,KAAA4gB,KAAA,8BACQ5gB,KAAA6rB,8BAAC7rB,KAAS4gB,KAAA,6B,eAEZ2J,GACJ,OACEznB,IAGoB,IAAhB9C,KAAA8rB,S,+CAEFvB,IAAgBvqB,KAAGqrB,eAAmBrrB,KAAA+rB,4BAAAjpB,GACtC9C,KAAS4gB,KAAA,6B,cAMToL,G,QAEA,C,QAEDA,G,0GAOChsB,KAAC4gB,KAAQ,2CAAQ5gB,KAAAqrB,eAAAvH,QAEjB9jB,KAAAyqB,MAAAzqB,KACFqrB,eAGIrrB,KAAAqrB,eAAiB,K,qBAIhBY,G,GDwIyB,MCrI5BA,EAAA,CAEL,MAAAC,EAAAD,EAAA,EDsJ+B,MChJjCC,EAAAlsB,KAAAmsB,6BDmID,MElNAD,GA8CMlsB,KAAA4gB,KAAA,wCACA5gB,KAAAqrB,eAAAvT,QAEA9X,KAAAorB,MAAAprB,KAAAqrB,gBAA4BrrB,KAAGosB,MAAApsB,KAAcqrB,gBAAArrB,KAAA8X,SF0Kb,MExKtCoU,IACMlsB,KAAA4gB,KAAA,0BA8BN5gB,KAAAqsB,8BA6FIrsB,KAAAmsB,6BAMA,C,6BAAqCG,G,MAAGC,EAAM1R,GAAA,IAAAyR,GAAGzxB,EAAAggB,GAAA,IAAAyR,GACjD,GAAU,MAANC,EAAMvsB,KAAAwsB,oBAAA3xB,OACV,UAAA0xB,EAKI,UAAU92B,MACP,2BAA4B82B,GAFnCvsB,KAAKysB,oBAAUpwB,KAAexB,EAEK,C,CAIrCsxB,6BACMnsB,KAACqsB,6BAAkB,GAEvBrsB,KAAM4gB,KAAQ,oCACd5gB,KAAMsrB,YAAU,EACdtrB,KAAGqrB,eAAYI,wBACfzrB,KAAG0sB,wBAGH1sB,KAAA4gB,KAAQ,8B,oBACDwI,KAAA,CACPuD,EAAA,IACEnH,EAAA,CACImH,EFsBE,I,EEnBJ,M,uBAYN3sB,KAAAqrB,eAAgBuB,QAGlB5sB,KACE4gB,KAAmB,mCAKnB5gB,KAAKqrB,eAAejC,KAAG,CAEvBuD,EAAM,IACNnH,EAAM,CACDmH,EFXyB,IEYzBnH,EAAK,M,KAaR5E,KAAM,kC,KACN6J,MAAArB,KAAA,C,MAEA5D,EAAA,CACGmH,EF1BN,IE4BSnH,EAAC,MAMTxlB,KAAAorB,IAASprB,KAAGqrB,eACZrrB,KAAK6sB,sB,2BAEEP,G,MAILC,EAAQ1R,GACS,IAASyR,GAEzBzxB,EAAAggB,GAAA,IAAAyR,GACJ,MAAAC,EAAAvsB,KAAA8sB,WAAAjyB,GAEyC,MAAtB0xB,GAAsBvsB,KAAA+sB,eAAAlyB,E,gBAElCiI,GACN9C,KAAAgtB,qBAEAhtB,KAAAqgB,WAAsCvd,E,sBAEtC9C,KAAMsrB,a,iCAGFtrB,KAAA+qB,2BAAgB,IACd/qB,KAAI4gB,KAAG,kCACP5gB,KAAIsrB,YAAc,EACvBtrB,KAAAyqB,MAAAgB,yB,YAMCQ,G,WFxF8B,I,MAGC,MEwF/BA,EAAqB,CAErB,MAAM5iB,EAAA4iB,EAEA,E,GFtEX,M,GEwES,MAAAgB,EAAsB73B,OAAUkU,OAAE,GAAAD,GAChCrJ,KAAK2qB,UAACzL,kBAEV+N,EAAeC,EACbltB,KAAK2qB,UAAAjjB,MAGP1H,KAAImtB,aAAWF,E,MAGhB,GFrFJ,MEqFIf,EAAA,CACAlsB,KAAA4gB,KAAA,qCACJ5gB,KAAAosB,IAAApsB,KAAAqrB,eAEc,QAAAh2B,EAAA,EAAAA,EAAsB2K,KAAgBysB,oBAAqBn3B,SAAAD,EAAA2K,KAAA+sB,eAAA/sB,KAAAysB,oBAAAp3B,IACpE2K,KAAOysB,oBAAuB,G,2BAEhC,KF9GL,ME8GWP,E,KAEJkB,sBACE/jB,GF/GV,MEgHQ6iB,E,KACAmB,SAAAhkB,GF7GY,MEkHb6iB,EAAAoB,GAAA,iBAAAjkB,GF7G+B,ME8GjC6iB,GACFlsB,KAAA4gB,KAAA,wBAED5gB,KAAiBgtB,qBACVhtB,KAAAutB,iCACKD,GAAwB,mCAAApB,EAClC,C,CAUAiB,aAAKK,GACN,MAAAC,EAAAD,EAAA7H,GAEO+H,EAAAF,EAAAnS,E,yBAGNrb,KAAA2qB,UAAMjjB,KAAgBA,EAGlB,IADF1H,KAAK8rB,SAGL9rB,KAAKyqB,MAAAmC,QACN5sB,KAAA2tB,yBAAA3tB,KAAAyqB,MAAAgD,GT3DyB,MS4D3BC,GAAA9Q,GAAA,sCAGK5c,KAAC4tB,mB,6GAYNrD,GAEDvqB,KAAAqrB,eAAA,IAAAd,EAAAvqB,KAAA0qB,mBAAA1qB,KAAA2qB,UAAA3qB,KAAA4qB,eAAA5qB,KAAA6qB,eAAA7qB,KAAA8qB,WAAA9qB,KAAA6tB,W,KAOIxB,4BAAmB9B,EAAA,gC,MACnB9J,EAAMzgB,KAAWirB,cAA6BjrB,KAAAqrB,gB,EAAarrB,KAAAmrB,iBAAAnrB,KAAAqrB,gB,KAAEA,eAACjY,KAAAqN,EAAAqN,G,IAGrB,KAGrC9tB,KAACqrB,iBAIDrrB,KAAA4gB,KAAM,gCACN5gB,KAAAqrB,eAAiBvT,Q,cFpNrB,K,uBE6NK,qCAAApQ,G,KACFijB,UACDjjB,OAIN,IAAA1H,KAAA8rB,OAAA9rB,KAAA8X,SAUO9X,KAA6B+tB,oBAC5B/tB,KAAAsqB,S,0BAKOC,EAAAkD,G,KAGT7M,KAAA,oCAEL5gB,KAAAyqB,MAAAF,EAEDvqB,KAAA8rB,OAAA,EAIE9rB,KAAMguB,WACNhuB,KAAMguB,SAAUP,EAAMztB,KAAA6tB,WAElB7tB,KAAKguB,SAAC,MAUX,IAAAhuB,KAAA+qB,2BAEO/qB,KAAa4gB,KACnB,kCAKI5gB,KAAKsrB,YAAC,GAEJzO,IAAgC,KAAW7c,KAAGutB,+BAAU,GAAGh0B,KAAAqiB,MFvQ/B,K,iCE2QhC5b,KAAIsrB,YAAgB,IAAAtrB,KAAA8rB,SACpB9rB,KAAI4gB,KAAI,4BACT5gB,KAAAiuB,UAAA,CAEItB,EAAA,IACNnH,EAAA,CAGCmH,EFnPU,IEuPLnH,EAAA,M,2CASD6F,e,KACCA,eAAA,KAENrrB,KAAAorB,MAAAb,GAAAvqB,KAAAosB,MAAA7B,GAEDvqB,KAAA8X,O,mBAYkB6T,G,WACZ,KAILA,GAAA,IAAA3rB,KAAA8rB,OAee,I,KAAVA,QAAU9rB,KAAA4gB,KAAA,8BAbhB5gB,KAAA4gB,KAAkB,+BAMR5gB,KAAC2qB,UACPnM,oBAEA1F,GAAoC1d,OAAA,QAAA4E,KAAA2qB,UAAAjjB,MAElC1H,KAAQ2qB,UAAIvM,aAAApe,KAAA2qB,UAAAjjB,O,KAGXoQ,O,CAICsV,sBACNc,GAKAluB,KAAA4gB,KAAM,0DAAqB5gB,KAAGmuB,UAAUnuB,KAAAmuB,QAAcD,GAAOluB,KAAAmuB,QAAA,M,mBAMrD,K,KAGHrW,O,WAGNjd,GAGC,GAEA,IAFAmF,KAAA8rB,OAGa,mCAER9rB,KAAAorB,IAAAhC,KAAYvuB,E,CAUlBid,QAIC,IAFF9X,KACE8rB,SAMI9rB,KAAC4gB,KAAA,gCAEL5gB,KAAM8rB,OAAoC,EAC/B9rB,KAAA+tB,oBACA/tB,KAAAmjB,gBACTnjB,KAAAmjB,gBAEMnjB,KAAKmjB,cACX,M,gEAQCnjB,KAAAyqB,QAECzqB,KAACyqB,MAAA3S,QACL9X,KAAMyqB,MAAQ,M,KAKRY,iBAEPrrB,KAAAqrB,eAAAvT,QAEe9X,KAACqrB,eAAa,MAE5BrrB,KAAMwrB,kBACNvrB,aAAgBD,KAAGwrB,iBACfxrB,KAACwrB,gBAAsB,K,aAyBSj2B,EAAKo1B,EAAAC,EAAAC,EAAAC,EAAAzK,EAAA2N,EAAA7K,EAAAgL,EAAAhK,G,KAAE5uB,GAACA,E,KAC1Co1B,UAAUA,E,KAEVC,eAAgBA,E,oBACFC,E,gBACFC,E,gBACFzK,E,cACF2N,E,mBACL7K,E,KACFgL,QAAEA,E,KACJhK,gBACFnkB,KAAA0rB,gBAAA,EAEO1rB,KAAAysB,oBAAgD,GACtDzsB,KAAI8rB,OAAO,E,oCAETtB,kBAAU,IAAeR,GAAGW,G,KAC5B/J,KAAM,sB,KACN0J,Q;;;;;;;;;;;;;;;;SA2DF8D,G,IACAC,EAAKxzB,EAAayzB,EAAYC,GAAC,C,MAC/BF,EAASxzB,EAAAyzB,EACFC,GAAA,CAKRC,iBAAA1lB,GAAA,C,mEAeMulB,EAAAxzB,EAAyByzB,GAAc,C,mBACrCD,EAAAC,GAA4B,C,YAC7BG,GAAC;;;;;;;;;;;;;;;;oBAqCDC,KAAcnV,G,GAGnBnY,MAAAyC,QAAA7D,KAAA2uB,WAAAD,IAAA,CAGK,MAAApsB,EAAqB,IACjBtC,KAAA2uB,WAAAD,IAEN,IAAC,IAAAr5B,EAAS,EAAGA,EAAKiN,EAAAhN,OAAAD,IAAAiN,EAAAjN,GAAAmT,SAAAjH,MAAAe,EAAAjN,GAAAu5B,QAAArV,E,YAMtBvZ,KAAK6uB,mBAAmBH,GAExB1uB,KAAI2uB,WAAKD,GAAoB1uB,KAAA2uB,WAAAD,IAAA,G,KAC3BC,WAAUD,GAAUryB,KAAA,C,SACbmM,E,QACAomB,I,MAENE,EAAU9uB,KAAK+uB,gBAAAL,G,sBAIdlmB,EAAIomB,G,wBAGCF,G,MACNpsB,EAAAtC,KAAA2uB,WAAAD,IAAA,G,IAED,IAAAr5B,EAAM,EAAAA,EAAAiN,EAAAhN,OAA2BD,IAC/B,GAAIiN,EAAOjN,GAAOmT,WAAUA,KAAAomB,GAA2BA,IAAAtsB,EAAAjN,GAAAu5B,SAKzD,YAJAtsB,EAAI0sB,OAAA35B,EAAc,E,uBAUlBwkB,GACO7Z,KACAivB,eAAkBC,MAAAC,GAE1BA,IAAAT,IACG,kBAAkBA,E,CAGhBnoB,YAAM0oB,GACZjvB,KAAIivB,eAAKA,E,KACPN,WAAU,GACV9U,GAAsCzY,MAAAyC,QAAAorB,MAAA35B,OAAA,+B;;;;;;;;;;;;;;;;oBA8BZ85B,G,4BAG1B,IAAIC,E,8BAGiC,WAAAX,EAAA,uBAAAA,G,6CAOjCY,O,+CAkBA,E,4GASEtvB,KAAAsvB,UAEFtvB,KAAAsvB,SAAU,EACXtvB,KAAAuvB,QAAA,aACF,IACF,GACFl2B,OAAAhB,iBAAA,gBAEuB2H,KAAAsvB,UACtBtvB,KAAAsvB,SAAI,EACCtvB,KAAAuvB,QAAkB,UAAU,GACzB,IAED,G;;;;;;;;;;;;;;;;6BAmCI,G,QACPl6B,EAAI2K,KAACwvB,UAAAn6B,EAAA2K,KAAuByvB,QAAAn6B,OAAAD,IAAA,KAAA2K,KAAAyvB,QAAAp6B,KAAAg5B,GAAA,IAAAruB,KAAAyvB,QAAAp6B,I,OAC7Bg5B,GAAA,G,CASG9nB,YAAgBmpB,EAAqBC,G,eAEvC3vB,KAAAyvB,QAAQC,EAAAtkB,MAAA,K,IAIVwkB,EAAU,EAEZ,IAAM,IAAMv6B,EAAG,EAAIA,EAAC2K,KAAAyvB,QAAcn6B,OAAUD,IAAE2K,KAASyvB,QAAAp6B,GAAAC,OAAA,IACnD0K,KAAMyvB,QAAWG,GAAU5vB,KAC7ByvB,QAAOp6B,GAEVu6B,KAGC5vB,KAAMyvB,QAAAn6B,OAAoBs6B,EACtB5vB,KAAAwvB,UAAO,CACX,MACExvB,KAAAyvB,QAAYC,EACZ1vB,KAAAwvB,UAAgBG,C,WAOhBE,K,OAEF,IAAOC,GAAO,G,UAGRC,GAAsDC,G,OAC5DA,EAAAR,WAAAQ,EAAAP,QAAIn6B,OAAA,KACJ06B,EAAKP,QAAUO,EAAGR,U,gEAOcQ,G,MAC1BA,EAAKR,U,sCAEgBQ,EAAAP,QAAAE,E,mCAIlBK,EAAAP,QAAAn6B,OAAmB06B,EAAAP,QAAwBO,EAAAP,QAAAn6B,OAAA,G,0EAe7C06B,G,KACLR,WAASQ,EAAAP,QAAAn6B,OAA0B,OAAI,K,MAGxC26B,EAAA,G,IACF,IAAA56B,EAAA26B,EAAAR,UAAAn6B,EAAA26B,EAAAP,QAAAn6B,OAAA,EAAAD,IAAA46B,EAAA5zB,KAAA2zB,EAAAP,QAAAp6B,IAEO,WAAAy6B,GAAqDG,EAAA,E,aAK/CD,EACNE,G,MAIPD,EAAA,GAEO,QAAA56B,EAAA26B,EAAaR,UAAAn6B,EAAA26B,EAAAP,QAAAn6B,OAAAD,IAAA46B,EAAA5zB,KAAA2zB,EAAAP,QAAAp6B,I,yFAEnB,CACA,MAAK86B,EAAcD,EAAA9kB,MAAA,K,8DAInB,IAAK0kB,GAA6BG,EAAO,E,UAcvCG,GACUJ,G,OAKXA,EAAAR,WAAAQ,EAAAP,QAAAn6B,M,UAaD+6B,GAA0CC,EAAAC,G,MAE1CC,EAAIT,GAAkBO,GAAAG,EAAAV,GAAAQ,G,GAClB,OAAJC,EAAI,OAAAD,E,GACFC,IAASC,EAAS,OAACJ,GACSK,GAAAJ,GAAAI,GAAAH,I,UAE1B96B,MAAA,8BAAoB86B,EAApB,8BAAoBD,EAAA,I,UA95BAK,GAAhBX,EAAsCY,G,GACtCC,GAAAb,KAAmBa,GAAsBD,GAAA,S,IACzC,IAAkBv7B,EAAA26B,EAAAR,UAAAsB,EAAlBF,EAAApB,UAAqCn6B,GAAA26B,EAAAP,QAAAn6B,OAAAD,IAAAy7B,IACrC,GAAsBd,EAAAP,QAAAp6B,KAAAu7B,EAAtBnB,QAAAqB,GAAA,S,kBA9DOC,GAGHf,EAAAY,G,IACNv7B,EAAgB26B,EAAAR,UAChBsB,EAAgBF,EAAApB,U,GAChBqB,GAAyBb,GAAAa,GAAAD,GAAA,S,KACzBv7B,EAAoB26B,EAAAP,QAAAn6B,QAAA,CACpB,GAAyB06B,EAAAP,QAAAp6B,KAAAu7B,EAAAnB,QAA6BqB,GAAA,WACtDz7B,IACAy7B,C,QAEA,C,OAmBAE,GAKAzqB,YAA8BypB,EAAAiB,GA+BpCjxB,KAAIixB,aAAaA,EAMjBjxB,KAAAkxB,OAAAC,GAAkBnB,EAAW,GAG3BhwB,KAAAoxB,YAAA73B,KAAa83B,IAAC,EAAArxB,KAAWkxB,OAAM57B,QAElC,QAAAD,EAAA,EAAAA,EAAA2K,KAAAkxB,OAAA57B,OAAAD,IAAA2K,KAAAoxB,aAAAE,GAAAtxB,KAAAkxB,OAAA77B,I,QAxCc,E,SClGfk8B,GAAAC,G,GAQEA,EAAMJ,YDu3BgD,ICv3BrB,UAAA37B,MAAU+7B,EAASP,aAATO,yCAASA,EAAAJ,YAAA,M,GACpDI,EAAMN,OAAa57B,ODs3B+B,GCt3BjB,UAAAG,MAAQ+7B,EAAWP,aAAXO,gGAAWC,GAAAD,G,uBAU5C,IAARA,EAAQN,OAAA57B,OAAsB,GAC/B,gBAAAk8B,EAAAN,OAAA/4B,KAAA,Q;;;;;;;;;;;;;;;;SCZAu5B,WAAAtC,GACD/K,qBACE,OAAO,IAAAqN,E,CAET3C,gBAAOL,GAEL,O,2CAAQ,CACT1uB,KAAA2xB,S,eAQC,IAAAC,E,EAJAC,MAAA,CACD,YAQY,oBAAAj6B,eAAsB,IAAZA,SAAYS,wBAClC,IAAAT,SAAA,QAMQk6B,EAAO,mBACfF,EAAA,eACF,IAAAh6B,SAAA,WAEYk6B,EAAA,sBCzEbF,EAAA,kBAwFS,IAAAh6B,SAAA,UACGk6B,EAAkB,qBAIlBF,EAAQ,iBACF,IAAAh6B,SAAA,eACNk6B,EACN,yBAEAF,EAAS,iB,eAMF,E,GACOh6B,SAAMS,iBAAAy5B,GAAA,K,MACnBC,GAAAn6B,SAAAg6B,GACIG,IAAA/xB,KAAA2xB,WACD3xB,KAAG2xB,SAAWI,EAClB/xB,KAAQuvB,QAAK,UAAWwC,G;;;;;;;;;;;;;;;;oBArCF3D,G,6BAEfpuB,KAAWgyB,e,EAChB,C,EACDC,E,mBAMGnnB,GAAiBonB,I,GAEpBlyB,KAAAmyB,WAAA,0D,KACFC,UAAAC,YAAAH,GACFI,IAAAtyB,KAAAuyB,eAAAN,GAAAK,EAgDF,CAED5lB,IAAA8lB,GAgCExyB,KAAAyyB,kBAiBE,MAAAnmB,EAAW,IAAAhE,GAgBboqB,EAAA,CAIEC,OAAY,IACbjgB,QAdA,CAEDvP,EAAAqvB,EAAAI,MAAAx8B,WAIEy8B,EAAOL,EAAKM,cAUdxE,WAAAxrB,IAWI,MAAKuG,EAAKvG,EAAiB,EAI9B,OAAAA,EAAA,EAAAwJ,EAAAtW,QAAAqT,GAEDiD,EAAA5D,OAAAW,EAAA,GAgBArJ,KAAA+yB,iBAAA12B,KAAAq2B,GAIE1yB,KAAIgzB,uB,MAGF5e,EAAQpU,KAAK+yB,iBAA+Bz9B,OAAA,EAIhD,OAFC0K,KAAAmyB,YAAAnyB,KAAAizB,SAAA7e,GAED9H,EAAA3D,O,QAKCuqB,EAAAC,EAAAC,EAAA9E,GAEDtuB,KAAAyyB,kBAIE,MAAIY,EAAWH,EAAOI,iBAGpBjF,EAAY6E,EAAMN,MAASx8B,WAE9B4J,KAAA4gB,KAAA,qBAAAyN,EAAA,IAAAgF,GAEDrzB,KAAAuzB,QAAAnnB,IAAAiiB,IAAAruB,KAAAuzB,QAAAhnB,IAAA8hB,EAAA,IAAAza,KAOMiG,GAAyBqZ,EAAAM,aAAAC,cAAAP,EAAAM,aAAAE,eAAA,sDAC7B7Z,IAAmC7Z,KAAAuzB,QAAA7mB,IAAA2hB,GAAAjiB,IAAAinB,GAAA,gDACnC,MAAIM,EACI,C,WACMrF,E,OAGN6E,EAQRS,MAASV,EACVE,OAMCpzB,KAAIuzB,QAAS7mB,IAAC2hB,GACZ9hB,IAAO8mB,EAAAM,GAEL3zB,KAAoBmyB,YAAKnyB,KAAA6zB,YAAAF,E,UAIxBvf,GACL,MAAA0f,EAAS9zB,KAAS+yB,iBAAA3e,GACnBpU,KAAAqyB,YAAA,IAAAyB,EAAAphB,SAAA5P,WAED9C,KAAA+yB,iBAAA3e,GASMpU,KAAGgzB,uBACE,IAADhzB,KAACgzB,uBAAAhzB,KAAA+yB,iBAAA,IACLe,EAAAxF,YAAqBwF,EAAKxF,WAAExrB,EAAA,G,aAKzB6wB,G,MACLI,EAAWJ,EACRC,MAEHvF,EAAa0F,EAASnB,MAAMx8B,WAG5Bi9B,EAAIU,EAAcT,iB,UAChB,aAAYjF,EACH,QAAAgF,G,cAYXM,EAAWP,MACZY,EAAA,EAAAD,EAAAjB,aACDkB,EAAS,EAAML,EAAGP,KAGpBY,EAAA,EAAAL,EAAAM,SAIEj0B,KAAAqyB,YAXK,IAWa2B,GAAAlxB,IACnB,MAAAuG,EAAAvG,EAAA,EAEDxI,EAAAwI,EAAA,EAKMoxB,GACGC,sBAAe9qB,EAAA0qB,IAEQ/zB,KAAKuzB,QAAQ7mB,IACxC2hB,IAAKruB,KAAeuzB,QAAA7mB,IAAA2hB,GAAA3hB,IAAA2mB,MAKdM,IACV3zB,KAAA4gB,KAAA,kBAAA9d,GAED,OAAAxI,GAAA0F,KAAAo0B,cAAA/F,EAGQgF,GACMM,EAAWrF,YAAGqF,EAAArF,WAAAh0B,EAAA+O,GACtB,G,8BASiBA,EAAAgrB,G,GACpBhrB,GAAA,iBAAAA,GAAAiC,GAAAjC,EAAA,MAEF,MAAAirB,EAAA9oB,GAAAnC,EAAA,KAED,GAAAjI,MAAAyC,QAAAywB,OAAAnV,QAAA,YAGQ,CACE,MAAKoV,EAAa,gBAAAF,EAAAb,aAAAgB,WAAAp+B,WAAA,IACfq+B,EAAeJ,EAAAzB,MAAAx8B,WACpBwmB,GAAiB,wGAAA2X,QAAAE,mDACrB,C,mBAGH3rB,GAED9I,KAAA8qB,WAAAhiB,EAIE9I,KAAA4gB,KAAQ,wBACR5gB,KAAO8qB,WAAW9qB,KAAK00B,UAOvB10B,KAAQmyB,YAAanyB,KAAIqyB,YAAQ,sBACjCryB,KAAA20B,uCAA4C7rB,E,CAG9C6rB,uCAAAC,IAMyBA,GAAgC,KAApBA,EAAat/B,QACjDu/B,GAAAD,MAED50B,KAAA4gB,KAAA,iEAME5gB,KAAM80B,mBA3Y6D,I,CA+YrEC,qBAAMjsB,GACJ9I,KAAI6qB,eAAiB/hB,EAKrB9I,KAAI4gB,KAAK,6BAKT5gB,KAAM6qB,eAAkB7qB,KAAKg1B,cArT/Bh1B,KAAAmyB,YAAAnyB,KAAAqyB,YAAA,uB,CAiBEqC,UAED,GAAA10B,KAAAmyB,YAAAnyB,KAAA8qB,WAAA,C,wBAEMmK,EAAG5pB,GAAQvC,GAAA,eACXosB,EAAK,CAwSdC,KAAArsB,GAsBgB,OAAL9I,KAAKo1B,cAAAF,EAAA,UACb,iBAAAl1B,KAAAo1B,gBAAAF,EAAA,QAAAl1B,KAAAo1B,eAEDp1B,KAAAqyB,YAAA4C,EAAAC,GAAAG,IASS,MAAI/6B,EAAA+6B,EAAQ,EACpBx6B,EAAAw6B,EAAA,WAEDr1B,KAAA8qB,aAAAhiB,IAQc,OAAAxO,EAAA0F,KAAAs1B,uBAAA,EAGdt1B,KAAAu1B,eAAAj7B,EAAAO,GAIU,GAGV,C,CAmBAm6B,cASEh1B,KAAOmyB,YAAMnyB,KAAA6qB,gBAAA7qB,KAAAqyB,YAAA,YACdvpB,MAAA9I,KAAA6qB,iBAEKwK,IACJ,MAAO/6B,EAAK+6B,EAAA,EACbx6B,EAAAw6B,EAAA,WAEK,OAAA/6B,EAAA0F,KAAAw1B,2BAAA,EACGx1B,KAAKy1B,mBAAAn7B,EAAAO,EAAA,GAGd,CAIAmX,SAAA0jB,EAAAtC,GAIE,MAAA/E,EAAaqH,EAAA9C,MAAAx8B,WACdi9B,EAAAqC,EAAApC,iBACFtzB,KAAA4gB,KAAA,uBAAAyN,EAAA,IAAAgF,GAEDxZ,GAAA6b,EAAAlC,aAAAC,cAIaiC,EAAAlC,aAAAE,eAAS,wDAiBpB1zB,KAAAo0B,cAAA/F,EAAAgF,IASarzB,KAAAmyB,YAAAnyB,KAAA21B,cACJtH,EACLgF,EAAUqC,EACD5C,aAAaM,E,CAK1BuC,cAAAtH,EAAAgF,EAAAuC,EAAAxC,GAOEpzB,KAAA4gB,KAAO,eAAIyN,EAAA,QACJgF,GAKR,MAAAW,EAAA,CAED7wB,EAAAkrB,GAWI+E,IACAY,EAAO,EAAA4B,E,EAEA,EAAIxC,G,KAKZf,YAVc,IAUd2B,E,iBAEF3F,EAAAxzB,EAAAyzB,GAEDtuB,KAAAyyB,kBAMMzyB,KACFmyB,WAAYnyB,KAAK61B,kBACH,IAAKxH,EAAAxzB,EAAAyzB,GACrBtuB,KAAQ81B,0BAAgBz5B,KAAA,CACtBgyB,WAAWA,EACXsE,OAAO,I,KACL93B,E,WACMyzB,G,mBAKLD,EAAUxzB,EACTyzB,G,4BAIH6D,WAAgBnyB,KACf61B,kBAAiB,KAAAxH,EAAAxzB,EAAAyzB,G,KACZwH,0BAAaz5B,KAAA,C,WAClBgyB,E,OACI,K,KACLxzB,EACFyzB,c,CAOHyH,mBAAA1H,EAAAC,GAIEtuB,KAAAyyB,kBACDzyB,KAAAmyB,WAAAnyB,KAAA61B,kBAAA,KAAAxH,EAAA,KAAAC,GAEDtuB,KAAA81B,0BAAAz5B,KAAA,CAIEgyB,WAAYA,EACbsE,OAAA,KAED93B,KAAA,KAIEyzB,WAAYA,GAGd,C,kBAIcqE,EAAMtE,EAASxzB,EAAAyzB,GAC5B,MAAA5b,EAAA,CAEDvP,EAAAkrB,EAUc7I,EAAA3qB,GAGdmF,KAAA4gB,KAAA,gBAAA+R,EAAAjgB,GASE1S,KAAAqyB,YAAiBM,EAACjgB,GAAiBtY,IACpCk0B,GAAAx0B,YAAA,KAEDw0B,EAAAl0B,EAAA,EAAAA,EAAA,KAOSb,KAAIqiB,MAAA,MASb,C,IAIEyS,EAAWxzB,EAAAyzB,EAAAC,GAOZvuB,KAAAg2B,YAAA,IAAA3H,EAAAxzB,EAAAyzB,EAAAC,EAED,C,MAIEF,EAAWxzB,EAAAyzB,EAAAC,GAOZvuB,KAAAg2B,YAAA,IAAA3H,EAAAxzB,EAAAyzB,EAAAC,EAED,C,YAGSoE,EAAItE,EAAAxzB,EAAAyzB,EAAAC,GAOZvuB,KAAAyyB,kBA/MD,MAAA/f,EAAA,CAKqBvP,EAAAkrB,EACX7I,EAAA3qB,Q,eCxkBZmF,KAAAi2B,iBAAA55B,KAAA,CAsBSs2B,SACRjgB,UAEe4b,eAEhBtuB,KAAAk2B,uBC3BA,MAAA9hB,EAAApU,KAAAi2B,iBAAA3gC,OAAA,EA0BgB6gC,8BAAU/hB,GACxBgiB,4BAAe/H,EAChB,CAEMgI,SAAMjiB,GACP,MAAAue,EAAe3yB,KAAKi2B,iBACf7hB,GAAAue,OAEPjgB,EAAO1S,KAAYi2B,iBAAS7hB,GAAA1B,QAE9B4b,EAAAtuB,KAAAi2B,iBAAA7hB,GAAAka,WAEFtuB,KAAAi2B,iBAAA7hB,GAAAkiB,OAAAt2B,KAAAmyB,WAIMnyB,KAAAqyB,YAAaM,EAAYjgB,GAAE5P,IAC7B9C,KAAS4gB,KAAG+R,EAAA,YAAmB7vB,UAC/B9C,KAAAi2B,iBAAA7hB,GAOApU,KAAAk2B,uBAMF,IAAAl2B,KAAAk2B,uBAAAl2B,KAAAi2B,iBACE,IAGJ3H,KAAAxrB,EAAA,EAAAA,EAAA,KCzBA,CAMEyzB,YAAW9H,GAEV,GAAAzuB,KAAAmyB,WAAA,CAED,MAAWzf,EAAA,CACFtP,EAAAqrB,G,wBA6BC/b,GACR1S,KAAOqyB,YAAK,IAAA3f,GAAAE,I,GAId,OAHCA,EAAA,EAGU,CACG,MAAA4jB,EAAc5jB,EAAA,EAC3B5S,KAAA4gB,KAAA,sCAAA4V,E,IAKA,C,mBAKC,GAAI,MAAA1zB,EAAc,CAKnB9C,KAAA4gB,KAAA,gBAAA9V,GAAAhI,I,QAGDA,EAAmB,EACbwvB,EAAAtyB,KAAAuyB,eAAiBkE,GAEdnE,WAGEtyB,KAAAuyB,eAAAkE,GAEVnE,EAAAxvB,EAAA,GAEC,KAAO,cAAMA,EAAA,0CAAAA,EAAA,MACd,MAAAA,G,iBAGDA,EAAA,EAAAA,EAAwB,G,aAEvB6vB,EAAA3R,G,gCAGD2R,EAAqB3R,GACN,MAAT2R,EAAc3yB,KAAA02B,cACT1V,EAAK,EAAeA,EAAc,KAAAA,EAAA,GAChC,MAAA2R,EAAa3yB,KAAO02B,cAAe1V,EAAgB,EAC5DA,EAAY,KAAAA,EAAA,GAEL,MAAP2R,EAAO3yB,KAAA22B,iBAAS3V,EAAA,EAAAA,EAAqC,GAKxD,OAAA2R,EAAA3yB,KAAAu1B,eAAAvU,EAAA,EAAAA,EAAA,GAGD,Q,EAAYhhB,KAAUy1B,mBAAoBzU,EAAA,EAAAA,EAAA,GAC1B,OAAR2R,EAAQ3yB,KAAA42B,uBAAkB5V,GAC5BsM,GACK,6CAAaxiB,GAAA6nB,GAAA,qC,UAGflF,EAAAI,G,KACLjN,KAAA,oB,KAKAuR,YAAY,E,KAOb0E,gCAAA,IAAArwB,MAAAC,UACFzG,KAAA82B,iBAAArJ,G,mBAGDI,EACE7tB,KAAO+2B,kBAAM/2B,KAAAg3B,oBACdh3B,KAAAi3B,gB,uBAGD,EACEj3B,KAAAk3B,kBAAS,E,qBAKTrd,IAAa7Z,KAAAoyB,UAAA,0DACdpyB,KAAAm3B,2BAAAl3B,aAAAD,KAAAm3B,2B,KAIKA,0BAAyBr9B,YAAA,KACzBkG,KAAAm3B,0BAAgC,KAChCn3B,KAAAo3B,sBAAA,GAIL79B,KAAAqiB,MAAAlb,G,oBAKGV,KAAIoyB,WAAYpyB,KAAA+2B,kBAAA/2B,KAAAq3B,iBAAA,E,YAQhBtF,GAEAA,IAAQ/xB,KAAK2xB,UACL3xB,KAAIs3B,kBAAAt3B,KAAA80B,qB,KAEVlU,KAAA,2CAEF5gB,KAAKs3B,gBHlJoB,IGmJ1Bt3B,KAAAoyB,WAAApyB,KAAAq3B,iBAAA,IAEFr3B,KAAA2xB,SAAAI,CAED,C,UAKEwF,GACDA,GACDv3B,KAAU4gB,KAAW,wBACf5gB,KAAKs3B,gBH/JkB,IGiKhBt3B,KAAKoyB,WAAApyB,KAAYq3B,iBAAA,KAG1Br3B,KAAA4gB,KAAA,8CACA5gB,KAAOoyB,WAAKpyB,KAAAoyB,UAAmBta,Q,CAInC0f,wB,GAIEx3B,KAAA4gB,KAAM,4BACN5gB,KAAAmyB,YAAkB,EAClBnyB,KAAAoyB,UAAgB,KAEhBpyB,KAAAy3B,0BAEAz3B,KAAIuyB,eAAe,G,yBAEjB,GAAIvyB,KAAA2xB,UAKF,GAAI3xB,KAAK62B,+BACA,EAIE,IAAArwB,MAAAC,UAAAzG,KAAA62B,+BH3LS,MG6LrB72B,KAAAs3B,gBHjMwB,KGmMzBt3B,KAAA62B,+BAA8B,IAEjC,OAdK72B,KAAS4gB,KAAA,8C,KACJ0W,gBAAAt3B,KAAA80B,mB,qDAcX,MAAS4C,GAAA,IAAAlxB,MAAAC,UAAAzG,KAAA23B,2BACP,IAAOC,EAAKr+B,KAAA83B,IAAA,EAAArxB,KAAAs3B,gBAAAI,GACbE,EAAAr+B,KAAA4oB,SAAAyV,EACD53B,KAAS4gB,KAAA,0BAAAgX,EAAA,MACP53B,KAAOq3B,iBAAKO,GAEP53B,KAAWs3B,gBAAA/9B,KAAAoiB,IAAA3b,KAAA80B,mBHzMJ,IGyMI90B,KAAAs3B,gBAChB,C,KAEOJ,kBAAU,E,iCAMhBl3B,KACC63B,mBAAa,CAEhB73B,KAAA4gB,KAAA,+BAnND5gB,KAAA23B,4BAAA,IAAAnxB,MAAAC,UAMyBzG,KAAA62B,+BAAuC,KACzC,MAAAiB,EAAb93B,KAAA+sB,eAAmE/S,KAAAha,MAT5D+3B,EAAkB/3B,KAAKguB,SAAAhU,KAAAha,MAWtCg4B,EAAAh4B,KAAAw3B,sBAAAxd,KAAAha,MAKA8jB,EAAA9jB,KAAAzK,GAAA,IAAA2+B,GAAyC+D,oBAC1C9T,EAAAnkB,KAAAmkB,c,SAvBD+T,EAAA,KAImC,MAAAC,EAAA,WAAWD,IAAApgB,SAAoBsgB,GAAA,EAA3DJ,IC9BL5B,EAEYiC,EAAA,SAAAnG,GACdoG,GAAmBJ,EAAA,0DACpBA,EAAA7F,YAAAH,EAEe,EACdkE,gBACDte,MAAAqgB,EAEY9F,YAAAgG,GAET,MAAMpb,EAAmBjd,KAAAu4B,mBACzBv4B,KAAMu4B,oBAAmB,EACzB,IAMD,MAAAtU,EAAAD,SAAApb,QAAAgF,IAAA,CACqB5N,KAAAw4B,mBAAArb,SAAAF,GACRjd,KAACy4B,uBAAwBtb,SAAAF,KAEvCmb,EAQane,GAAA,0CAPHA,GAA6B,8CACtCja,KAAA8qB,WAAA7G,KAAAhG,YACMje,KAAA6qB,eAAA7G,KAAAlb,M,6FAEG8T,GAAsBsR,EAAA,KAAAluB,KAAA2qB,UAAAv0B,WAAA,KAC/B4J,KAAA04B,UJIiC,cIJjC,GACMvU,GAiBI,CAfV,MAAAwU,GAEQ34B,KAAA4gB,KAAqB,wBAAY+X,GAClCP,IACKp4B,KAAA2qB,UAAA1L,WAOJrC,GAAY+b,GACpBR,IAGU,CCxEb,CAuBA,CAgBEO,UAAAxK,G,6CAEEluB,KAAA44B,kBAAsB1K,IAAY,EAC9BluB,KAACoyB,UAAWpyB,KAAAoyB,UAAAta,SAEjB9X,KAAAm3B,4BAhBWl3B,aAAcD,KAAAm3B,2BAClBn3B,KAAAm3B,0B,MAGAn3B,KAAOmyB,YAAqBnyB,KAAAw3B,wB,QAGlCtJ,GACAjU,GAA4B,mCAAKiU,UAClCluB,KAAA44B,kBAAA1K,GAQFziB,GAAAzL,KAAA44B,qBAED54B,KAAAs3B,gBLM+B,IKanBt3B,KAAQoyB,WAAEpyB,KAAAq3B,iBAAA,G,kBAOM5J,GACxB,MAAIoL,EAAOpL,GAAA,IAAAjnB,MAAAC,UACXzG,KAAI84B,oBACK,C,iBACcD,G,+BAUtB,IAAMxjC,EAAA,EAAAA,EAAA2K,KAAAi2B,iBAAA3gC,OAAAD,IAAA,C,iCAEL0jC,GAAe,MAAUA,EAAMrmB,SAAoBqmB,EAAIzC,SACjDyC,EAAIzK,YAAGyK,EAAAzK,WAAuB,qBACzBtuB,KAAGi2B,iBAAkB5gC,GAChC2K,KAASk2B,uB,CAUX,IAAAl2B,KAAAk2B,uBAAAl2B,KAAAi2B,iBAAA,GAEF,C,iBAC6B5H,EAAK2K,GAEhC,IAAI3F,EAGFA,EADF2F,EACWA,EAAQjhC,KAAG86B,GAAA/X,GAAU+X,KAAA16B,KAAA,KADX,U,MAEnB8gC,EAAUj5B,KAAGo0B,cAAM/F,EAAAgF,GACnB4F,GAASA,EAAA3K,YAAU2K,EAAA3K,WAAA,oB,eAEbD,EAAYgF,G,MAClB6F,EAA4B,IAACpJ,GAAyCzB,GAAAj4B,W,IACtE6iC,E,GASAj5B,KAAAuzB,QAAAnnB,IAAA8sB,GAAA,CAEF,MAAMC,EAAAn5B,KAAgBuzB,QAAA7mB,IAAUwsB,GAC9BD,EAAQE,EAAEzsB,IAAA2mB,G,EACR/lB,OAAK+lB,GACS,IAAd8F,EAAIhU,MAAWnlB,KAAAuzB,QAAAjmB,OAAA4rB,E,aAEfxyB,E,wBAGF0yB,EAAAC,GAEFpf,GAA2B,uBAAYmf,EAAA,IAAAC,G,KACrCvO,WAAc,K,gCAEdsH,UAAMta,QAEJ,kBADFshB,GAC0B,sBAAFA,I,KAItB9D,yBACDt1B,KAAAs1B,wB,IAEIt1B,KAAKs3B,gBL1GuD,IK8G3Dt3B,KAAGw4B,mBAAiBjb,yBAGhC,CC5JAkY,mBAAA2D,EAAAC,GA6BMpf,GAAA,4BAAoBmf,EAAA,IAAAC,GAEbr5B,KAAA6qB,eAAA,KACX7qB,KAAAu4B,oBAAA,EAWqB,kBAAba,GAA2B,sBAAdA,IAGnBp5B,KAAOw1B,6BACRx1B,KAAAw1B,4B,GAAAx1B,KAAAy4B,uBAAAlb,wB,wBAYGyD,GAGEhhB,KAAAs5B,uBAAqBt5B,KAAAs5B,uBACvBtY,G,wFAQJhhB,KAAS00B,UACP10B,KAAAg1B,cAOA,UAAAuE,KAAAv5B,KAAAuzB,QAAA5lB,SAAA,UAAAgmB,KACE4F,EAAA5rB,SAAoB3N,KAAA6zB,YAAAF,GAGtB,QAAMt+B,EAAA,EAASA,EAAG2K,KAAGi2B,iBAAA3gC,OAAAD,IAAA2K,KAAAi2B,iBAAA5gC,IAAA2K,KAAAq2B,SAAAhhC,GACrB,KAAI2K,KAAA81B,0BAAwBxgC,QAAA,CAC5B,MAAUod,EAAG1S,KAAA81B,0BAA6BzhB,QACtCrU,KAAI61B,kBAAkBnjB,EAAAigB,OAAAjgB,EAAA2b,WAAA3b,EAAA7X,KAAA6X,EAAA4b,WAC1B,C,IACE,IAAAkL,EAAA,EAAAA,EAAex5B,KACb+yB,iBAAmBz9B,OAAAkkC,IAAgBx5B,KAAA+yB,iBAAuByG,IAAAx5B,KAAAizB,SAAAuG,E,CAI9DxC,oBACA,MAAIvI,EAAA,G,MAGS,KAEP3kB,OACmB2vB,EAAnBz5B,KAAA2qB,UAAmB1L,UAAK,aACR,QAEtBwP,EAAA,OAAWgL,EAAa,IAASvhB,GAAAjS,QAAA,cAC1B0D,KAAsC8kB,EAAA,uBnD2HhC,iB,WAAe,gBAAA/kB,UAAA,UmD1H7B+kB,EAAA,4BAEDzuB,KAAAu2B,YAAA9H,E,0BAWM8I,EAAAlI,GAAAqK,cAAAC,kB,OACIluB,GAAoBzL,KAAA44B,oBAAArB,C,aAMpB5M,EAAWC,EAAe8L,EAAAQ,EAAA4B,EAAAN,EAAAC,EAAArD,GCrEpC,G,uBDuEYzK,E,oBAGIC,E,mBACL8L,E,sBACSQ,E,yBACH4B,E,sDAGAL,E,KAEVrD,cAAMA,E,QAELlB,GAAkC0F,8B,UAC9B1f,GACY,KAAYla,KAAAzK,GACxB,K,uBAGG,CAAW,E,KACnBg+B,QAAA,IAAA3f,I,KAEHqiB,iBAAA,GACFj2B,KAAA+yB,iBAAW,GACZ/yB,KAAAk2B,qBAAA,EAEDl2B,KAAAgzB,qBAAA,EAOEhzB,KAAA81B,0BAAmB,G,KAGf3D,YAAI,E,KAEFmF,gBNhHqB,I,wBACgC,I,4BMiHhC,K,mBACjB,K,mDAMK,E,KAIb/E,eAAA,GACFvyB,KAAAgyB,eAAW,EACZhyB,KAAAoyB,UAAA,KAnIDpyB,KAAA8qB,WAIU,KAHA9qB,KAAQ6qB,eAAR,KAGA7qB,KAASu4B,oBAAA,EACfv4B,KAAAs1B,uBAAA,EA+HLt1B,KAAAw1B,2BAAA,ECrLDx1B,KAAA+2B,kBAAA,EA8CI/2B,KAAA23B,2BAAyB,KAE7B33B,KAAA62B,+BAAA,KAQEzB,IAAqBtrB,KAAA,UAAArU,MAAA,kFACnBi8B,GACYgI,cACT73B,GAAA,UAAA7B,KAAA65B,WAAiB75B,OAMrB,IAAA2qB,EAAAjjB,KAAAyX,QAAA,YAAAkQ,GAAAqK,cAAA73B,GAAA,SAAA7B,KAAA85B,UAAA95B,K,KA+BA45B,4BAAA,E,GAKA3B,kBAAA;;;;;;;;;;;;;;;;;MA0BC8B,G,YAIOC,EAAKC,GACb,WAAAF,GAAAC,EAAAC,E,aAIQxjB,EAAKwjB,GACbj6B,KAAAjB,KAAA0X,E;;;;;;;;;;;;;;;;SA8BCyjB,G,oBAYEl6B,KAAOm6B,QAAKngB,KAAAha,K,CAYfo6B,oBAAAC,EAAAC,G,QAKG,IAAAP,GzBgUH,ayBhUyBM,GACpBE,EAAc,IAChBR,GzB8TH,ayB9TeO,GAGd,OAAyC,IAAnCt6B,KAAgCm6B,QAAGK,EAAAD,E,kBAatCR,GAAAU,G;;;;;;;;;;;;;;;;2BAmCEP,GAEHQ,0B,OACDC,E,CAEFD,wBAAA7qB,G,GAGDA,C,SAMM4K,EAAGC,G,OACLF,GAAwBC,EAAA1b,KACtB2b,EAAI3b,K,aAINk7B,GAKF,MAASl3B,GAAuC,kD,qBAElCs3B,EAAOC,G,OACnB,C,WAOF,OAAMP,GAAgCU,G,WAYtC,OAAM,IAAGV,GzBgOb,ayBhOoDY,G,UAE9CC,EAAY77B,GAKf,OAJG8a,GAA6B,iBAAA+gB,EAAA,gDAIhC,IAAAb,GAAAa,EAAAD,GAED,C,WAOC,YACD,E,SAMe,IAAgBE;;;;;;;;;;;;;;;;sBAiC9B,OAAA76B,KAAA86B,WAAAxlC,OAAA,YAED,IAGEsd,EAHFqnB,EAAAj6B,KACE86B,WAAAC,M,GAMDnoB,EAAA5S,KAAAg7B,iBAAAh7B,KAAAg7B,iBAAAf,EAAA1vB,IAAA0vB,EAAAxxB,OAED,CAIE8B,IAAS0vB,EAAG1vB,IACR9B,MACFwxB,EAAOxxB,OAEJzI,KAAAi7B,WAEH,I,EADKhB,EAAAiB,MACCjB,EAAAkB,WAIFn7B,KAAI86B,WAAYz+B,KAAI49B,GACxBA,EAAWA,EAAImB,WAIf,I,EADCnB,EAAAmB,OACMnB,EAAAkB,WACRn7B,KAAA86B,WAAAz+B,KAAA49B,GACFA,IAAAiB,K,OAGGtoB,C,kBAOK5S,KAAI86B,WAAUxlC,OAAA,C,QAMtB,OAAA0K,KAAA86B,WAAAxlC,OAAA,YACD,MAAU2kC,EAAAj6B,KAAA86B,WAAsB96B,KAAA86B,WAAAxlC,OAAA,GAC9B,OACE0K,KAAAg7B,iBAAoBh7B,KAAAg7B,iBAASf,EAC7B1vB,IAAK0vB,EAAAxxB,OAGA,CACL8B,IAAA0vB,EAAM1vB,IAIN9B,MAAOwxB,EAAIxxB,M,CAMflC,YAAkB0zB,EAAAoB,EAAAC,EAAAL,EAAAD,EAAA,MAChBh7B,KAAIi7B,WAAcA,E,KAEXD,iBAAUA,E,KAEVF,WAAA,G,IACLS,EAAM,E,MACNtB,EAAKkB,W,KAKHE,EAAMC,EAAgBrB,EAAA1vB,IAAY8wB,GAAA,EAElCJ,IAAIM,IAAc,GAClBA,EAAI,EAGYtB,EADdj6B,KACEi7B,WAAgBhB,EAAKiB,KAKvBjB,EAAWmB,U,IACX,IAAAG,EAAY,CAEdv7B,KAAA86B,WAAOz+B,KAAW49B,GACnB,KAGF,CAGHj6B,KAAA86B,WAAAz+B,KAAA49B,GAQ0BA,EAApBj6B,KAAAi7B,WAAoBhB,EAAAmB,MAGVnB,EAAAiB,IAEf,C,QApYCM,GAwZFC,KAAOlxB,EAAW9B,EAAAizB,EAAAR,EAAAE,G,qHAMhBO,QACD,OAAA37B,KAAAk7B,KAAAS,QAAA,EAAA37B,KAAAo7B,MAAAO,OAED,CAIAR,UACE,OAAO,C,CAsBRS,iBAAAjJ,GACE,OAAE3yB,KAAAk7B,KAAAU,iBAAAjJ,QAAA3yB,KAAAuK,IAAAvK,KAAAyI,QAAAzI,KAAAo7B,MAAAQ,iBAAAjJ,E,CCxePkJ,iBAAAlJ,GAUM,OAAI3yB,KAAKo7B,MACXS,iBAAOlJ,MAAA3yB,KAAauK,IAAAvK,KAAWyI,QAAAzI,KAAAk7B,KAAAW,iBAAAlJ,EAGjC,C,OAiBI,OAAA3yB,KAAOk7B,KAAIC,UAAiBn7B,KACxBA,KAAWk7B,KAA8CY,M,CAK/DC,SACA,OAAI/7B,KAAA87B,OAAAvxB,G,sBAKA6wB,MAAMD,UAAYn7B,KAAAuK,IACdvK,KAACo7B,MAAUY,Q,CAYnBC,OAAM1xB,EAAA9B,EAAW6yB,GAMjB,IAAIY,EAAAl8B,K,MACFu7B,EAAMD,EAAA/wB,EAAiB2xB,EAAA3xB,K,OAIhB2xB,EAAPX,EAAA,EAAWW,EAAAT,KAAA,eAAAS,EAAAhB,KAAYe,OACrB1xB,EACA9B,EAAA6yB,GAAA,MAEI,IAAAC,EAAaW,EAAAT,KAAA,KAAchzB,EAAA,gBAC7ByzB,EAAAT,KAAA,oBAAAS,EAAAd,MAAAa,OAAA1xB,EAAA9B,EAAA6yB,I,EAAEa,Q,CAWRC,aACA,GAAAp8B,KAAAk7B,KAAAC,UAAA,OAASkB,GAAsCC,W,IAC7CJ,EAAIl8B,K,cACEu8B,UAAaL,EAAEhB,KAAIA,KAAKqB,WAAKL,IAAAM,gB,6DAWtCphC,OAAAmP,EAAA+wB,GACF,IAAAY,EAAAO,ECnID,GDqIAP,EAAAl8B,KCrIAs7B,EAAA/wB,EAAA2xB,EAAA3xB,KAAA,EAqCyB2xB,EAAAhB,KAAUC,WAAAe,EAAAhB,KAAAqB,UAAAL,EAAAhB,UAAAqB,WAAAL,IAAAM,gBAC/BN,EAAOA,EAAAT,KAAK,KAAS,KAAK,KAAAS,EAAAhB,KAAY9/B,OAAAmP,EAAA+wB,GAAA,UACvC,CAGA,GAFWY,EAAAhB,KAAUqB,WAAAL,IAAAQ,gBACZR,EAAAd,MAAKD,WAAce,EAAAd,MAAYmB,UAAUL,EAAAd,MAAAF,KAAAqB,WAAAL,IAAAS,iBAClD,IAAArB,EAAA/wB,EAAA2xB,EAAA3xB,KAAA,CACiC,GAAA2xB,EAAAd,MAAAD,UAAA,OAAAkB,GAAAC,WAEpBG,EAAQP,EAAAd,MAAAU,OACdI,EAAQA,EAAGT,KAAMgB,EAAClyB,IAAUkyB,EAAQh0B,MAAA,UAAAyzB,EAAAd,MAAAgB,a,CAM3CF,IAAAT,KAAA,oBAAAS,EAAAd,MAAAhgC,OAAAmP,EAAA+wB,GACD,CACE,OAAMY,EAAAC,Q,CAORI,SACE,OAAMv8B,KAAI07B,K,CAIVS,SACD,IAAAD,EAAAl8B,KApCC,OAHFk8B,EAAAd,MAAoBmB,WAAgBL,EAAAhB,KAAAqB,WAAAL,IAAAU,eAClCV,EAAKhB,KAAGqB,UAAAL,EAAAhB,UAAAqB,WAAAL,IAAAQ,gBADoBR,EAAAhB,KAAAqB,UAAVL,EAAAd,MAAgBmB,WAAAL,IAAAW,cAGlCX,C,CCPFM,eACE,IAAAN,EAAMl8B,KAAA68B,aASP,OARKX,EAAAd,MAAQF,KAAKqB,W,EAGfL,EAAAT,KAAO,KAAS,eAAAS,EAAAd,MAAAsB,gBAEnBR,IAAAU,cACDV,EAAYA,EAAAW,cAEXX,CACD,CAGAS,gB,wBAME,OAJAT,EAAAhB,KAAQA,KAAAqB,WACTL,IAAAQ,eACMR,IAAAW,cAEGX,C,CAKRU,cACD,MAAAE,EAAA98B,KAAAy7B,KAAA,UAAAD,GAAAuB,IAAA,KAAA/8B,KAAAo7B,MAAAF,MAED,OAAAl7B,KAAAo7B,MAAAK,KAAA,UAAAz7B,KAAA07B,MAAAoB,EAAA,K,CAQWJ,eC5Db,MAAAM,EAAAh9B,KAAAy7B,KAAA,UAAAD,GAAAuB,IAAA/8B,KAAAk7B,KAAAE,MAAA,MA8CE,OAAOp7B,KAAAk7B,KAAAO,KAAA,UAAAz7B,KAAA07B,MAAA,KAAAsB,E,CACRH,aAEe,MAAA3B,EAAAl7B,KAAAk7B,KAAAO,KAAA,WACdz7B,KAAAk7B,KACAQ,MAAA,KAAkB,MAEXN,EAAAp7B,KAAAo7B,MAAAK,KAAA,WAAAz7B,KAAAo7B,MAAAM,MAAA,WAAE,OAA4B17B,KAAAy7B,KAAA,WAAAz7B,KAAA07B,MAAAR,EAAAE,E,CAOrC6B,iBAAS,MAA8BC,EAAAl9B,KAAAm9B,S,gBAAE,EAAAD,IAAYl9B,KAAA27B,QAAA,C,UACtD,GAAA37B,KAAAu8B,UAAAv8B,KAAAk7B,KAAAqB,SAAA,UAAA9mC,MAAA,0BAAAuK,KAAAuK,IAAA,IAAAvK,KAAAyI,MAAA,KAEe,GAAAzI,KAAAo7B,MAAAmB,SAAA,UAAA9mC,MAAkB,mBAEhCuK,KACAuK,IAAA,IAAavK,KAAAyI,MAAA,YAEb,MAAOy0B,EAAAl9B,KAAAk7B,KAAAiC,SACL,GAAID,IAA0Bl9B,KAA9Bo7B,MAAA+B,SAAA,UAAA1nC,MAA8B,uB,UAClBuK,KAAAu8B,SAAA,I,eAUyB9zB,EAAAizB,EAAYR,EAAAE,G,SAAE7wB,EAAYvK,KAAAyI,QACnEzI,KAAA07B,MAAA,MAAAA,IAAAF,GAAAuB,ICjFA/8B,KAAAk7B,KAAA,MAAAA,IAAAmB,GAAAC,WAwCEt8B,KAAAo7B,MAGE,MAFUA,EAGVA,EAAAiB,GAEAC,U,eASoBc,OAAA,E,MC2DrBf,GAQDJ,OAAA1xB,EAAgB9B,GACd,OAAO,IAAI4zB,GAAgBr8B,KAAAq9B,YAAAr9B,KAAAs9B,MAAArB,OAAA1xB,EAAA9B,EAAAzI,KAAAq9B,aAAA5B,KAAA,UAAAD,GAAA4B,MAAA,W,QAQzB7yB,G,OACA,IAAO8xB,GAA2Br8B,KAAOq9B,YAAAr9B,KAAoBs9B,MAAEliC,OAAWmP,EAAAvK,KAAAq9B,aAAA5B,KAAA,UAAAD,GAAA4B,MAAA,W,CAa7E1wB,IAAAnC,GApGD,IAAAgxB,EACMtB,EAACj6B,KAAAs9B,MACL,MAAKrD,EAAMkB,WAAU,CAEjB,GADAI,EAACv7B,KAAUq9B,YAAG9yB,EAAA0vB,EAAA1vB,KACF,IAAXgxB,EAAW,OAAAtB,EAAAxxB,MACX8yB,EAAA,EAAiBtB,EAAIA,EAAOiB,KAC5BK,EAAA,IAAetB,EAAIA,EAAOmB,MAChC,CA8FF,WClJD,C,kBA0EoB7wB,G,MAYd0vB,EAAWj6B,KAACs9B,MAAAC,EACV,KAOL,MAAAtD,EAAAkB,WAAA,CAMK,GALNI,EAAcv7B,KACZq9B,YACa9yB,EACb0vB,EAAA1vB,KAEa,IAATgxB,EAAS,CACT,GAAQtB,EAAAiB,KAAUC,UASP,OAAAoC,IAAahzB,I,KAJxB,IAHS0vB,IAAAiB,MAGJjB,EAAUmB,MAAGD,WAAQlB,EAAWA,EACrCmB,M,YAKA,CAAIG,EAAS,EAAAtB,IAAAiB,KACJK,EAAA,I,EAMKtB,EAKVA,EAAKA,EAAKmB,M,WAGZ3lC,MAAK,wE,uBASJ6nC,MAAAnC,S,mDAiBHn7B,KAAIs9B,MAAUvB,Q,4BAUVC,Q,CAiBRJ,iBAAYjJ,GACb,OAAA3yB,KAAAs9B,MAAA1B,iBAAAjJ,EACD,CAeEkJ,iBAAQlJ,GACR,OAAI3yB,KAAKs9B,MAAQzB,iBAAElJ,E,CAOnB6K,YAAAC,GACA,OAAM,IAAAC,GAAwB19B,KAAAs9B,MAAU,KAAAt9B,KAAUq9B,aAAW,EAAAI,E,iBAIvDlzB,EAAUkzB,GAChB,OAAI,IAAAC,GAAkC19B,KAAAs9B,MAAA/yB,EAAAvK,KAAAq9B,aAAA,EAAAI,E,wBAEvBlzB,EAAGkzB,G,OAKhB,IACEC,GACoB19B,KAAAs9B,MAAY/yB,EAAAvK,KAAAq9B,aAAuB,EAAAI,E,8BAKvD,IAAAC,GACO19B,KACLs9B,MAAA,KACAt9B,KAAKq9B,aACL,EAAAI,E,aAYFJ,EAAOC,EAAcjB,GAA+BC,Y,KACrDe,YAAMA,E,WACDC,C;;;;;;;;;;;;;;;;;SAiDoBK,GACvBzC,EAAWE,G,OAEV5gB,GACN0gB,EAAKn8B,KAAAq8B,EAAWr8B,K,aAGem8B,EAC7BE,G,UAG8BF,EAAAE,E;;;;;;;;;;;;;;;;OCtNjCwC,G,GD2KctB,WAAc,I,WFjM1B/xB,EAAA9B,EAAAizB,EAAAR,EAAAE,GAED,OAAIp7B,I,CAwBFi8B,OAAO1xB,EAAK9B,EAAA6yB,GAEf,WAAAE,GAAAjxB,EAAA9B,EAAA,KACD,C,SAkBU6yB,G,YAcRK,QACD,QACD,CAMCR,UACD,Q,CAnGAS,iBAA0CjJ,GAAb,OAAM,C,CCsBlCkJ,iBAAAlJ,GAED,OAAQ,C,UAON,OAAO,I,CAETqJ,SAQE,OAAK,I,UAYP,Q,UAWE,Q,iEEFS,UAAK6B,C,EAUdC,GAAA,SAAAC,G,GACAA,EAAYC,aAAA,CACb,MAAAnuB,EAAAkuB,EAAAluB,MAEDgK,GAAA,iBAAAhK,GAAA,iBAAAA,GAAA,iBAAAA,GAGGvE,GACcuE,EAAA,8C,MACfgK,GAAAkkB,IAAuBH,IAAoCG,EAAA5C,UAAA,gC,GAIlD4C,IAAAH,IAAAG,EAAAE,cAAA9C,UAAA,qD;;;;;;;;;;;;;;;;;AAiCX,IAAA+C,G,YAYEC,GACDC,qCAAAvuB,GAEDquB,GAAQruB,C,CAEPuuB,uCAED,OAAAF,E,CAECF,aAED,OAAS,C,CAERC,cAEG,OAAAj+B,KAAAq+B,a,CAEYC,eAAQC,GACtB,OAAK,IAAMJ,GAAen+B,KAAAw+B,OAAAD,E,CAErBE,kBAAsBC,GAE3B,MAAkB,cAAdA,EAAsB1+B,KAAcq+B,cACnCF,GAAsCC,0BAAC9B,U,CAEvCqC,SAAgB3O,GACrB,OAAII,GAAuBJ,GAAehwB,KACN,cAA/B+vB,GAA+BC,GAAAhwB,KAAAq+B,cAC/BF,GAAmCC,0BAAA9B,U,YAGxC,OAAO,C,CAhIXsC,wBAAAF,EAAAG,GACE,OAAS,I,CAEIC,qBAASJ,EAAAK,GACtB,oBAAAL,EAAA1+B,KAAAs+B,eAAAS,GACOA,EAAS5D,WAAA,cAAAuD,EAAA1+B,KACLm+B,GAASC,0BAAA9B,WAAAwC,qBAAAJ,EAAAK,GAAAT,eAAAt+B,KAAAq+B,c,CAEVW,YAAChP,EAAA+O,GACX,MAASE,EAAAlP,GAAMC,GACf,OAAgB,OAAAiP,EAAmBF,EACpBA,EAAA5D,WAAM,cAAA8D,EAAAj/B,MAER6Z,GAAM,cAAAolB,GAAA,IAAApO,GAAAb,GAAA,8CACbhwB,KAAkB8+B,qBAAAG,EAAAd,GAAeC,0BAAA9B,WAAA0C,YAAAtO,GAAAV,GAAA+O,IAoHxC,CAEe5D,UACV,Q,CAKS+D,cAEd,QAae,CAIIC,aAAY/qB,EAAOue,GACrC,OAAU,CACV,CACA9iB,IAAAuvB,GACA,OAAOA,IAAUp/B,KAAAi+B,cAAA9C,UAAA,CAClB,SAAAn7B,KAAAq/B,WAEe,YAAAr/B,KAAAi+B,cAAApuB,OAKJ7P,KAASq/B,UACnB,CACmB9Q,OACnB,GAAiB,OAAVvuB,KAAAs/B,UAAU,CAClB,IAAAC,EAAA,GAEev/B,KAAAq+B,cAAAlD,YAAAoE,GACd,YACAC,GACmBx/B,KAAAq+B,cAAAxuB,OAAA,KAEb,MAAApG,SAAYzJ,KAAYw+B,OAC9Be,GAAU91B,EAAY,IAEpB81B,GADiB,WAAf91B,EACQg2B,GAAQz/B,KAAAw+B,QAEVx+B,KAAgBw+B,OACnBx+B,KAAIs/B,UAAMtmB,GAAAumB,EACf,CACA,OAAAv/B,KAAUs/B,S,CAKZD,WACD,OAAAr/B,KAAAw+B,MAEe,CAKdkB,UAAuB9O,GACnB,OAAAA,IAAYuN,GAAWC,0BACnB9B,WAAG,EAEH1L,aAAGuN,GAAmBC,2BAAyB,GAGhDvkB,GAAO+W,EAAAoN,aAAA,qBACfh+B,KAAA2/B,mBAAA/O,GAOC,CAKA+O,mBAAUC,GACN,MAAGC,SAAgBD,EAAApB,OACrBsB,SAA4B9/B,KAACw+B,OAC7BuB,EAAU5B,GAAoB6B,iBAAA7gB,QAAA0gB,GACzBI,EAAA9B,GAAA6B,iBAAA7gB,QAAA2gB,GAGN,OAFCjmB,GAA8BkmB,GAAA,wBAAAF,GAC9BhmB,GAA6BomB,GAAA,wBAAAH,GAC9BC,IAAAE,EAEF,WAAAH,EAEe,EASH9/B,KAAAw+B,OAAAoB,EAAApB,QAAiB,EAERx+B,KAAGw+B,SAAKoB,EAAApB,OAAA,EACd,EAGAyB,EAAAF,CAId,CACAG,YACA,OAAOlgC,IACR,CAEDmgC,YAQE,OAA4C,CAE5C,CAIAC,OAAIxP,GACA,GAAAA,IAAY5wB,KAAM,OAAK,EAEhB,GAAA4wB,EAAAoN,aAAuB,CAE3B,MAAI4B,EAAYhP,EAEhB,OAAA5wB,KAAAw+B,SAAAoB,EAAApB,QAAAx+B,KAAAq+B,cAAA+B,OAAAR,EAAAvB,cACL,S,CASA93B,YAAGi4B,EAAcH,EAAAF,GAAAC,0BAAsB9B,YACvCt8B,KAAIw+B,SAGLx+B,KAAAq+B,gBAEGr+B,KAAAs/B,UAAY,KACdzlB,QAA0CnT,IAAA1G,KAAAw+B,QAExC,OAFwCx+B,KAExCw+B,OAAA,4DACFV,GAAe99B,KAAAq+B,c,KAYhB2B,iBAAA,CAED,SACD,UAEK,SAGJ,U,SCrQO,I,cAxFoC9F,G,QACzCzf,EAAMC,GACP,MAAA2lB,EAAA5lB,EAAAwf,KAAAgE,cAWMqC,EAAa5lB,EAAAuf,KAAqBgE,cACnCsC,EAAQF,EACVX,UAAaY,G,OACR,I,EAAA9lB,GAAAC,EAAA1b,KAAA2b,EAAA3b,MACLwhC,C,aAKDtG,GACF,OAAAA,EAAAgE,cAAA9C,S,qBA2BiBd,EAAGC,GACnB,OAAKD,EAAK4D,cAAoBmC,OAAG9F,EAAU2D,c,WAK3C,OAAKlE,GAAgCU,G,kBAUjC,IAAIV,GlC+ZZ,akC/Z0B,IAAAoE,GAAA,kBAAAqC,I,YAGTzpB,G,QACK0pB,GAAC7F,G,OACd,IAAAb,GAAAhjB,EAAA,IAAAonB,GAAA,kBAAAJ,G,mCA8CAxkC,KAAAyD,IAAA;;;;;;;;;;;;;;;;iCAUA4V,IACC5S,KAAS0gC,MAAO,GAAU1gC,KAAe2gC,UAI/C,O,KADEA,WACK/tB,C,sBAiBP5S,KAAA27B,O,EAAsBrmC,EAAS,EAXhC4S,SAAA3O,KAAAyD,IAAA4jC,GAAAC,GAAA,KAaC7gC,KAAA2gC,SAAe3gC,KAAI27B,MAAA,E,MACjBmF,GAZJ9kB,EAYShc,KAAA27B,MAZTzzB,SAAA9G,MAAA4a,EAAA,GAAA7jB,KAAA,aAAA6jB,E,KAaI0kB,MAAKprC,EAAA,EAAAwrC,C,WAiCG,SACEC,EAAAxF,EAAAyF,EAAAC,G,kBAMJ,SAAeC,EAAKC,G,QACrBA,EAAMD,E,iBAUL,OAAS,K,GACV,I,WACDH,EAAWG,G,EACZF,IAAAI,KACD,IAAA5F,GAAAjxB,EAAA62B,EAAAnH,KAAAuB,GAAA4B,MAAA,WAEC,CAEF,MAAAiE,EAAAn5B,SAAA5S,EAAA,MAAA4rC,EACJhG,EAAAoG,EAAAJ,EAAAG,GA5LDjG,EAAAkG,EAAAD,EAAA,EAAAF,GAMuB,OASrBC,EAAQL,EAAAM,GAVS92B,EAAAy2B,EAATA,EAAAI,GAAmBA,EACN,IAAA5F,GAKZjxB,EAAA62B,EAAAnH,KAAAuB,GAAA4B,MAAAlC,EAAAE,EACD,C,EC2BRmG,E,YDzDF,IAAAtH,EAAA,KAkCCuH,EAAA,KA6KFptB,EAAA2sB,EAAAzrC,OE7PD,MAAAmsC,EAAA,SAAAC,EAAAhG,GA2BU,MAAUwF,EAAA9sB,EAAAstB,EACTP,EAAK/sB,EACbA,GAAAstB,EAED,MAAcC,EAAaL,EAAqBJ,EAAA,EAAAC,GACzCC,EAAiBL,EAAUG,GACjC32B,EAAAy2B,IAAAI,KATHQ,EAAA,IAAApG,GAAAjxB,EAAA62B,EAAAnH,KAAAyB,EAAA,KAAAiG,GACU,EASTC,EAAA,SAAAC,GAAA5H,GDlCDA,EAAAiB,KAAA2G,EA8BS5H,EAAA4H,IAEGL,EAAMK,EACd5H,EAAA4H,EA8BJ,EAYM,QAAAxsC,EAAA,EAAAA,EAAAysC,EAAAnG,QAAYtmC,EAAA,CACd,MAAA0sC,EAAkBD,EAAME,eAEfN,EAAAnoC,KAAmBwiB,IAAK,EAAA+lB,EAASnG,OAC1CtmC,EAAA,IACK0sC,EAAAN,EAAAC,EAAAlG,GAAA4B,QAMCqE,EAAQC,EAAAlG,GAA0C4B,OACjDqE,EAAAC,EAAAlG,GAAmBuB,KAE3B,CACF,OAAAyE,CAED,CAWIS,CADE,IAAAC,GAAmBnB,EAAAzrC,S,OAGrB,IAAO+mC,GAAK4E,GAAA1F,EAAAgG,E;;;;;;;;;;;;;;;;mBAyBN,G,SAQPY,qBAqBI,OApBNtoB,GAAAuoB,IAAAC,GAAA,uCAEDC,OAAA,IAAAC,GAAA,CAYM,YAAAH,IAGF,CACE,YAAiBC,KAEhBC,EAEN,CAED51B,IAAA81B,GAUE,MAAAC,EAAmBj3B,GAA+BxL,KAAA0iC,SAAAF,GAChD,IAAKC,EAAW,UAAAhtC,MAAA,wBAAA+sC,GACf,OAAAC,aAAApG,GAAAoG,EEhJA,I,UAGDE,GACA,OAASr3B,GAC0CtL,KAAA4iC,UAAAD,EAAAvsC,W,UAE9CusC,EAAAE,GAEDhpB,GAAkB8oB,IAAAG,GAAA,uEAEtB,MAAA/B,EAAa,GACd,IAAAgC,GAAA,EAdD,MAAAC,EAAoBH,EAA4BrF,YAAAzD,GAAAkJ,MAA5B,ICFtBC,EDEiCC,EAAAH,EAAAI,UAFvB,KAAKD,GAEuCJ,KAAAJ,EAAAU,YAAAF,EAAAlJ,MAerD8G,EAAA1kC,KAAA8mC,GC5CDA,EAAAH,EAAAI,UA4BMF,EAAAH,EAAAO,GAAiCvC,EAAA4B,EAAAY,cACjCnB,GAEN,MAAAoB,EAAAb,EAAAvsC,WACMqtC,EAAAruC,OAAAkU,OAAA,GAAAtJ,KAAqB4iC,WAEda,EAAAD,GAAAb,EAaH,MAAAe,EAAYtuC,OAAAkU,OAAA,GAAAtJ,KAAA0iC,UAElB,OADAgB,EAAWF,GAAQN,EACb,IAAAX,GAAiCmB,EAAAD,E,cAKnCrC,EAAcyB,G,QACdc,GAAyB3jC,KAAA0iC,UAAA,CAAAkB,EAAAJ,K,MAC1BpvB,EAAA5I,GAAAxL,KAAA4iC,UAAAY,GAGC,GAFD3pB,GAAAzF,EAAA,oCAAAovB,GAECI,IACGxB,GAAmC,CAI1C,GAAAhuB,EAAAivB,YAAAjC,EAAAnH,MACE,CA3BQ,MAA2B8G,EAAgC,GAAtBiC,EAAsBH,EAAArF,YAAAzD,GAAAkJ,MAFzD,IAAAE,EAA6BH,EAAGI,UAGvC,KAAAD,GAGHA,EAAApkC,OAAAqiC,EAAAriC,MAAAgiC,EAAoB1kC,KACnB8mC,GACHA,EAAAH,EAAAI,UC5CJ,ODqECrC,EAAA1kC,KAAA+kC,GCrEDkC,GAAAvC,EAAA3sB,EAAAmvB,aAuBY,CACV,OAAAnB,EACA,EACA,MAAAyB,EAAAhB,EAAAn2B,IAAA00B,EAAAriC,MACA,IAAA+kC,EAAAF,EAuBc,OA3BJC,IAAAC,IAAA1oC,OAAA,IAAA2+B,GAKXqH,EAAAriC,KAAA8kC,KAsBeC,EAAA7H,OAAAmF,EAAsBA,EAAAnH,KAC7B,KAEL,WAAUsI,GAAOmB,EAAA1jC,KAAA4iC,U,CAIpBmB,kBAAA3C,EAAAyB,GAEe,MAAAa,EAAAC,GAAwB3jC,KAAA0iC,UAAAkB,IAC/B,GAAAA,IAAAxB,GACL,OAAUwB,EACV,CACO,MAAMC,EAAAhB,EAAAn2B,IAAA00B,EAAAriC,MACL,OAAA8kC,EAAKD,EAAAxoC,OAAA,IAAA2+B,GAAAqH,EAAAriC,KAAA8kC,IAEhBD,CAEe,KAIZ,WAAUrB,GAAKmB,EAAA1jC,KAAA4iC,U,eAERA,GACP5iC,KAAA0iC,SAAYA,EACZ1iC,KAAA4iC,WACJ;;;;;;;;;;;;;;;;UC7EA,MAAAoB,GA2BE1H,wBACE,OAAI2H,KAAiBA,GACR,IAAAD,GAA4B,IAAA3H,GAAgB6H,IAAA,KAAA3B,GAAAJ,S,CAI1DnE,aARD,Q,CAAmDC,c,2BAF/CgG,E,CAWL3F,eAAAC,GClCD,OAAAv+B,KAAAmkC,UAAAhJ,UAgCEn7B,KACM,IAAAgkC,GACFhkC,KAAAmkC,UAAW5F,EAAAv+B,KAAAokC,U,CAQd3F,kBAAAC,GAfQ,iBAAMA,EAAiB,OAAA1+B,KAAAi+B,cACnB,CACA,MAAAoG,EAAMrkC,KAAAmkC,UAAAz3B,IAAAgyB,G,OALnB,O,EAAIuF,GAAGI,CAMH,CAaL,CC3CD1F,SAAA3O,GAyCE,MAAAiP,EAAkBlP,GAAiBC,GACjC,OAAI,OAAAiP,EAAAj/B,KACFA,KAAMy+B,kBAAiBQ,GAASN,SAAQjO,GAASV,G,CAGpCsU,SAAC5F,G,mBACPyF,UAAaz3B,IAACgyB,E,8BAKnB7kB,GAAiBklB,EAAA,8CAEd,cAANL,EAAM,OAAA1+B,KAAAs+B,eAAAS,GACL,CAIA,MAAAqC,EAAW,IAAArH,GAAmB2E,EAAAK,GAC/B,IAAA+E,EAAAS,EACFxF,EAAA5D,WACO2I,EAAA9jC,KAAAmkC,UAAA/oC,OAAAsjC,GAEJ6F,EACAvkC,KAAKokC,UACLL,kBACY3C,EACZphC,KAAAmkC,aA/BFL,EAAA9jC,KAA0BmkC,UAC1BlI,OAAAyC,EAA0BK,GADMwF,EAAiBvkC,KAAAokC,UAAAI,aAAApD,EAAAphC,KAAAmkC,YAEf,MAAAM,EAAAX,EAAqB3I,UAAA8I,GAAAjkC,KAAAq+B,c,cALlDyF,EAAAW,EAAoBF,EAMvB,CAiCL,CCzEDvF,YAAAhP,EAAA+O,GAiCE,MAAAE,EAAAlP,GAAAC,GAIE,GAAY,OAAZiP,EAAY,OAAAF,EACb,CAEDllB,GAGA,cAHAkW,GAAAC,IAGU,IAAAa,GAAAb,GAAA,8CACR,MAAO0U,EAAe1kC,KAAAy+B,kBAAAQ,GAAAD,YAAAtO,GAAAV,GAAA+O,GACvB,OAAA/+B,KAAA8+B,qBAAAG,EAAAyF,EAED,C,CAKgBvJ,UACd,OAAOn7B,KAAKmkC,UAAAhJ,S,CAGK+D,cACjB,OACEl/B,KAAMmkC,UAAAxI,O,CAIH9rB,IAAAuvB,GACL,GAAAp/B,KAAOm7B,UAAW,YACnB,MAAA5vB,EAAA,GArCD,IAAAo5B,EACqB,EACX3I,EAAA,EAAA4I,GACkB,ECK5B,GDPU5kC,KAAKm/B,aAAAkD,IAAM,CAAA93B,EAAAs0B,KACMtzB,EAAAhB,GAAAs0B,EAAjBhvB,IAAAuvB,GACSuF,IACfC,GAAAZ,GAAAa,gBAAAj7B,KAAAW,GAAAyxB,EAAAziC,KAAA83B,IAAA2K,EAAA3hB,OAAA9P,IAkCLq6B,GAAA,MC9BCxF,GAAuCwF,GAAA5I,EAAA,EAAA2I,EAAA,CACjC,MAAC3jC,EAAa,GAErB,UAAAuJ,KAAAgB,EAAAvK,EAAAuJ,GAAAgB,EAAAhB,GAED,OAAAvJ,CAeE,CAGQ,OAFGo+B,IAAgBp/B,KAAAi+B,cAAA9C,YAAA5vB,EAAA,aAAAvL,KAAAi+B,cAAApuB,OAEZtE,C,CAYfgjB,OAQA,UAAAvuB,KAAAs/B,UAAA,CAQA,IAAAC,EAAA,GAQAv/B,KAAAi+B,cAAA9C,YAAAoE,GAAA,YACEC,GACMx/B,KAAAi+B,cAAApuB,OAEN,KAIF7P,KAAAm/B,aAAAkD,IACE,CAAA93B,EAAAs0B,KAQK,MAAOiG,EAAAjG,EAAAtQ,OACf,KAAAuW,IAAAvF,GAAA,IAAAh1B,EAAA,IAAAu6B,EAAA,IAaO9kC,KAAAs/B,UAA0B,KAARC,EAAe,GAAMvmB,GAAoBumB,EAEjE,CAGA,OAAAv/B,KAAgBs/B,S,CAMAV,wBAAuBF,EAAAG,EAAAzqB,G,MACnC2wB,EAAI/kC,KAAAglC,cAAuB5wB,G,GAK1B2wB,EAAA,CACF,MAAAE,EAAAF,EAAAG,kBAAA,IAAAnL,GAAA2E,EAAAG,IACJ,OAAAoG,IAAAlmC,KAAA,IAED,CAAS,OAAAiB,KAAAmkC,UAAAe,kBAAAxG,EAKP,C,kBAEOiE,GACL,MAAMoC,EAAC/kC,KAAQglC,cAAcrC,GAK7B,GAAAoC,EAAO,CACR,MAAAhJ,EAAAgJ,EAAAhJ,SACF,OAAAA,KAAAh9B,IAED,CAAS,OAAAiB,KAAAmkC,UAAApI,QAKP,CAGAoJ,cAAcxC,GACd,MAAM5G,EAAW/7B,KAAIolC,kBAAAzC,GACrB,OAAO5G,EAAe,IAAAhC,GAAmCgC,EAAA/7B,KAAAmkC,UAAAz3B,IAAAqvB,IAC3D,IC9KA,C,iBAmCuB4G,GAAc,MAAAoC,EAAA/kC,KAAAglC,cAAArC,GACpC,GAAAoC,EAAA,CAEe,MAAA/I,EAAA+I,EAAA/I,SAMP,OAAAA,KAAAj9B,IAIR,QAAAiB,KAAAmkC,UAAAnI,QAEK,CAMJqJ,aAAO1C,GAIR,MAAA3G,EAAAh8B,KAAAslC,iBAAA3C,GAEK,OAAU3G,EAAA,IAAAjC,GACdiC,EAAoBh8B,KAAAmkC,UAAAz3B,IAAAsvB,IAEJ,IAGjB,CAEKmD,aAAU/qB,EAAAue,GAGd,MAAOoS,EAAS/kC,KAACglC,cAAY5wB,GAG/B,OAAA2wB,IAAAnJ,kBAAA2J,GC5EA5S,EAAA4S,EAAAxmC,KAAAwmC,EAAAtL,QAmCOj6B,KAAAmkC,UAAAvI,iBAAAjJ,EAKL,CACA6K,YAAAmF,GAEF,OAAA3iC,KAAAwlC,gBAAA7C,EAGa8C,UAAA9C,EACX,C,gBAC+B+C,EAAI/C,GACjC,MAAAoC,EAAA/kC,KAAAglC,cAAQrC,G,GACNoC,EAAI,OAAQA,EAAIS,gBAAIE,GAAAn7B,GAAKA,IACxB,CACH,MAAOo7B,EAAK3lC,KAAAmkC,UAAAqB,gBAAAE,EAAA3mC,KAAAg7B,GAAAkJ,MACb,IAAAE,EAAAwC,EAAAC,OAUD,WAAAzC,GAAAR,EAAAxI,QAAAgJ,EAAAuC,GAEG,GAEMC,EAAUvC,UAClBD,EAAAwC,EAAAC,OAgBK,OAAKD,C,qBAC4ChD,G,OAC9C3iC,KAAA6lC,uBAAAlD,EAAAmD,UAAAnD,E,wBAGEoD,EAAApD,G,QACL3iC,KAAMglC,cAAQrC,G,KACd,OAAMoC,EAAKc,uBAAqBE,GAAOx7B,GACvCA,I,SAOIvK,KAAMmkC,UAAW0B,uBAAAE,EACfhnC,KAAIg7B,GACJkJ,M,QAEK2C,O,cAAQjD,EAAQxI,QAAAgJ,EAAA4C,GAAA,G,gBAA2CH,O,OAIrED,C,YAKN/U,GAED,OAAA5wB,KAAAm7B,UAOSvK,EAAKuK,UAAA,GACb,EAEDvK,EAAAoN,cAAApN,EAAAuK,UAGA,EACMvK,IAAAoV,IACF,EAEA,C,WAEArD,G,OAGaG,IAAiB9iC,KAAMokC,UAAA6B,SAAAtD,GAAA,OAAA3iC,KAErC,CACF,MAAAukC,EAAAvkC,KAAAokC,UAAA8B,SAAAvD,EAAA3iC,KAAAmkC,WAED,WAAAH,GAAAhkC,KAAAmkC,UAAAnkC,KAAAq+B,cAAAkG,EAQE,C,WAGEnwB,G,OACAA,IAAW0uB,IAAmC9iC,KAAAokC,UAAA6B,SAAA7xB,E,cAG9Cwc,IAAO5wB,KAAI,SACZ,GAAA4wB,EAAAoN,aAAA,SACF,CAED,MAAAmI,EAAAvV,EAOM,GAAA5wB,KAAAi+B,cAAAmC,OAAA+F,EAA2BlI,eACzB,IAAKj+B,KAAAmkC,UAASxI,UACTwK,EAAIhC,UAAAxI,QAAA,C,MAEXyK,EAAWpmC,KAAAw9B,YAAA6E,IAERgE,EAAAF,EAAA3I,YAAA6E,IACL,IAAMiE,EAAQF,EAAAhD,UACRmD,EAAaF,EAAajD,UAC5B,KAAKkD,GAAEC,GAAA,CACT,GAAMD,EAAWvnC,OAAMwnC,EAAOxnC,OAAAunC,EAAArM,KAAamG,OAAAmG,EAAetM,MAAA,SACtDqM,EAAYF,EAAAhD,UACZmD,EAASF,EACXjD,S,CAIF,OAAuB,OAAnBkD,GAA4C,OAArBC,C,QAGzB,CAAO,CApBkB,Q,gBAsCvB5D,G,OACNA,IAAmBG,GAAoB,KACnC9iC,KACFokC,UAAO13B,IAAMi2B,EAAIvsC,W,CAerBmQ,YAAI49B,EAAA9F,EAAY+F,G,KAETD,Y,KACL9F,cAAcA,E,KACd+F,UAAWA,E,KACX9E,UAAM,KAQPt/B,KAAAq+B,eAAAP,GAAA99B,KAAAq+B,eACFr+B,KAAAmkC,UAAAhJ,WAAAthB,IAAA7Z,KAAAq+B,eAAAr+B,KAAAq+B,cAAAlD,UAAA,uCAED,E,GAOC0J,gBAAA,iB,MAwDCmB,GAAiC,I,cAtDnChC,G,UAOQpT,GACN,OAAIA,IAAU5wB,KAAA,EAEJ,C,QAGV4wB,GAGF,OAAAA,IAAA5wB,I,eAOQ,OAAWA,I,mBAOf0+B,G,OACKsF,GAAA1H,U,+CAaW4H,IAAAF,GAAA1H,WAAAiG,GAAAJ,Q,UAWnBqE,iBAAAzM,GAAA,CAEOU,IAAA,CAKNhyB,MAAI,IAAAsxB,G9C8ML,a8C7MeiK,GAAA1H,a,WAKZ,IAAMvC,G9C4MZ,a8C5M+CiM,O,GAY5CtL,aAAAsJ,GAAA1H,W,GAED8B,0BAAA4F,G,GAOgBgC,G,SbsFLn2B,GACb2wB,GAAA3wB,CCxaA,C,CYkVGm2B,I,SC3S4BS,GAAqBlsC,EAAAsjC,EAAA,M,GAAI,OAAAtjC,EAAA,OAAAypC,GAAA1H,W,GAKvD,iBAAA/hC,GAAA,cAAAA,IAAAsjC,EAAAtjC,EAAA,cAEesf,GAGJ,OADVgkB,GACU,iBAAAA,GAAA,iBAAAA,GAAA,iBAAAA,GAAA,QAAAA,EAAA,uCAAAA,GAEN,iBAAAtjC,GAAA,WAAiBA,GACR,OAAJA,EAAI,YAAAA,IAAA,WAEG,iBAARA,GAAW,QAAcA,EAAW,C,OAExC,IAAM4jC,GADQ5jC,EACqBksC,GAAA5I,G,iBAE7Bz8B,MAgDZ,CAYE,IAAO64B,EAAA+J,GAAA1H,WAoCH,OAnCLnhB,GAAA5gB,GAAA,CAAAgQ,EAAAm8B,KAED,GAAAp7B,GAAA/Q,EAAAgQ,IAYiC,MAAjBA,EAAGpC,UAAa,EAAC,GAAW,CAM7B,MAAC02B,EAAA4H,GAAAC,IAEf7H,EAAAb,cAAAa,EAAA1D,YAAAlB,IAAA6E,qBAAAv0B,EAAAs0B,GAED,CASQ,IAEE5E,EAAQqE,e,MAEd,CAlGuB,C,MACrBqI,EAAa,G,IACbC,GAAW,EAmBZ,G,GAhBMrsC,GACe,CAAAgQ,EAAAs8B,KACpB,GAAqB,MAArBt8B,EAAMpC,UAAA,EAAY,GAAG,CAEtB,MAAA02B,EAAA4H,GAAAI,GACFhI,EAAA1D,YACFyL,MAAA/H,EAAAZ,cAAA9C,UAEewL,EAAAtqC,KAAA,IAAA09B,GAEdxvB,EACAs0B,IAGA,KAEG,IAAA8H,EAAArxC,OAAA,OAAA0uC,GAAA1H,WACH,MAAOwK,EAASxD,GAAAqD,EAAAhJ,IAAAyD,KAAAriC,MAAAmlC,IACjB,GAAA0C,EAAA,CAED,MAAAG,EAAAzD,GAAAqD,EAAAtE,GAAAkB,cAYM,WAAAS,GACK8C,EAAAL,GAAsB5I,GAAA,IAAA0E,GAAA,CACxB,YAAAwE,GACC,CAIC,YAAI1E,KAEd,YAAA2B,GAAA8C,EAAAL,GAAA5I,GAAA0E,GAAAJ,QAED,C,WdwTGtyB,G,MclQyB42B;;;;;;;;;;;;;;;;;AAqC1B,MAAAO,WAA0C9M,GAC3C+M,aAAAC,GAED,OAAAA,EAAAvI,SAAA3+B,KAAAmnC,WAUE,CACD9D,YAAApJ,GAED,OAASA,EAAA0E,SAAA3+B,KAAAmnC,YAAAhM,SAKP,CAEEhB,QAAO1f,EAAIC,G,MACN0sB,EAAApnC,KAAAinC,aAAAxsB,EAAAwf,MACDoN,EAAArnC,KAAgBinC,aAAKvsB,EAAAuf,MACzBsG,EAAU6G,EAAS1H,UAAA2H,G,OACL,IAAZ9G,EAAiB/lB,GAAaC,EAAA1b,KAAA2b,EAAA3b,M,aAG5BuoC,G,QAIAb,GAAgC7L,GACjCX,EACC+J,GAAO1H,WACL0C,YAAAh/B,KAAAmnC,WAAAI,G,OAKH,IAAAxN,GAAAuN,EAAArN,E,WAQH,MAAAA,EAAY+J,GAAA1H,WAAA0C,YAAAh/B,KAAAmnC,WAAAnB,IACb,WAAAjM,G/CgRH,a+ChRGE,EACH,CCzPA7jC,WAoEE,OAAO+6B,GAAAnxB,KAAgBmnC,WAAe,GAAEhvC,KAAA,IACzC,CAEDoO,YAAA4gC,GAYEtV,QAII7xB,KAAAmnC,WAAYA,EAGhBttB,IAAyBuW,GAAA+W,IAAA,cAAApX,GAAAoX,GAAA,0D;;;;;;;;;;;;;;;;YAmGtB,IAzDH,cAAgCjN,GACjCC,QAAA1f,EAAAC,GAEe,MAAA6lB,EAAA9lB,EAAAwf,KAAAyF,UAAAhlB,EAAAuf,MAIT,OAAe,IAAXsG,EAAqB/lB,GAAuBC,EAAA1b,KAAA2b,EAAA3b,MACvCwhC,C,aAIbtG,GACD,OAAW,CACZ,CAEDG,oBAAAC,EAAAC,G,6BAgBE,OAASP,GAAiCU,G,WAI1C,OAAMV,GAAoCyN,GAC1C,CAEAC,SAAI7M,EAAA8M,GACA,MAAAH,EAAAd,GAA4C7L,GAE5C,OAAI,IAAAb,GAA+B2N,EAAAH,EAEvC,C,iBAQM,Q;;;;;;;;;;;;;;;;YA8BHI,GAAAC,G,MACD,CACDn+B,KAAA,QACFm+B,e,UAQQC,GAAAnJ,EAAAkJ,G,MACL,C,KACE,c,aAMDA,EACDlJ,UAAOA,E,CAIX,SAAAoJ,GAAApJ,EAAAkJ,GAIE,OAKIn+B,KAAA,gB,aAIQm+B,EAEblJ,Y,UAOAqJ,GAAArJ,EAAAkJ,EAAAI,GAED,OASMv+B,KAAA,gBACCm+B,aAAYA,EACflJ,UAAWA,E;;;;;;;;;;;;;;;;;gCCkBLuJ,S,wBAME,K,KAAJC,U,eAgBoB,MAAhBloC,KAAAkoC,S,gCAsBLloC,KAAAioC,UAAA,oCACFjoC,KAAAmoC,gB,CAoBHC,oBAEA,OADIvuB,GAAe7Z,KAAAioC,UAAA,oCACbjoC,KAAAqoC,cAAeroC,KACjBsoC,gBjD6JH,Y,UiDnJC,OAAMtoC,KAAAuoC,O,CAUNC,mBAOA,OAFE3uB,GAAoB7Z,KAAAuoC,QAAA,kCAEhBvoC,KAAAyoC,c,CAkBPC,kBAOD,OANM7uB,GAAe7Z,KACnBuoC,QAAY,kCAKRvoC,KAAM2oC,YAAO3oC,KAAA4oC,cjD6GrB,YiDhGC,CAEDC,WASE,OAAM7oC,KAAA8oC,SACN,CAOEC,mBAKA,OAAA/oC,KAAA8oC,WAAe,KAAA9oC,KAAAkoC,S,mBAabruB,GAAe7Z,KACb8oC,UAAY,oCAKT9oC,KAAAgpC,M,mBAGLhpC,KAAIipC,M,wBAIGjpC,KAAAioC,WAAAjoC,KAAAuoC,SAAAvoC,KAAA8oC,U,yBAGHpV,gBACE1zB,KAAAipC,SAAA5G,E,oBAOA6G,GAqCZ,O,oCAjCUlpC,KAAWgpC,O,EAEdf,UAAAjoC,KAAAioC,U,EACDkB,eAAcnpC,KAAOmpC,e,mBACbnpC,KAAemoC,iB,gBAQTnoC,KAAGqoC,c,EAMhBC,gBACCtoC,KAAesoC,gB,EAElBC,QAAAvoC,KAAAuoC,QACF9M,EAAA2N,cAAAppC,KAAAopC,cACD3N,EAAOgN,eAAazoC,KAAAyoC,eACrBhN,EAAAkN,YAAA3oC,KAAA2oC,YAEDlN,EAASmN,cAAA5oC,KAAA4oC,cAIPnN,EAAOwN,OAAUjpC,KAAAipC,OAClBxN,EAAAyM,UAAAloC,KAAAkoC,UAEQzM,C,gGAeHz7B,KAAAuoC,SAAe,EACnBvoC,KAAA2oC,aAAuB,EACrB3oC,KAAAopC,eAAkB,EAClBppC,KAAIgpC,OAAA,EAWHhpC,KAAAkoC,UAAA,GAEHloC,KAAAmoC,iBAAyB,KACvBnoC,KAAAsoC,gBAAkB,GAClBtoC,KAAKyoC,eAAA,KAWJzoC,KAAA4oC,cAAA,GAEH5oC,KAAOipC,OAAA5G,EACR,EA0MA,SAAAgH,GAAAC,GAED,MAASC,EAAA,GAQP,GAAID,EAAS7V,YAAA,OAAA8V,EACb,IAAIC,E,KAEGP,SAAA5G,GAAAmH,EAAA,YACLF,EAAeL,SAAIQ,GAAAD,EACjB,SAIFF,EAAML,SAAgBnG,GAA+B0G,EAAA,QAEjD3vB,GAAiByvB,EAAAL,kBAA2BjC,GAAa,4B,EACvDsC,EAAQL,OAAA7yC,Y,EAML,QAAA0U,GAAA0+B,G,EACLvB,UAAM,C,QACNqB,EAAAH,eAAA,aAC4B,U,KAGlBr+B,GAAAw+B,EAERnB,kB,EAEHE,gBAAAkB,EAAAG,IAAA,IAAA5+B,GAAAw+B,EAAAhB,iB,MAEDC,QAAgB,C,MAKjBoB,EAAML,EAAAF,cAAA,oB,KACSt+B,GAAgBw+B,EAAAb,gBAC9Ba,EAAYX,cAAGY,EAAAI,IAAA,IAAA7+B,GAGQw+B,EACrBV,e,UAOEE,Y,EASOc,iBAAqBL,E,sBAE9BA,EACE,YAAaD,EAEbN,Q,cAaSM,G,QAIX,GC5xBN,G,EDmyBKrB,Y,EACF,GAAAqB,EAAAnB,iBACDmB,EACEjB,gBAAU98B,EACV,GAAA+9B,EAAAhB,iBACF/8B,EAEE,KAAA+9B,EACAH,gBAING,EAAAf,UC/2BAh9B,EAAA,GAAA+9B,EAAAb,eAqGMa,EAAKX,cAAAp9B,EAAA,GAAA+9B,EAAAV,eACPr9B,EAAmB,KAAA+9B,EAAAF,eAtCrBE,EAAoBR,UAAsB,CAAtBv9B,EAAoB,EAAA+9B,EAAAN,OAHxC,IAAmBa,EAAAP,EAAwBpB,UAI1B,KAAf2B,IAEwBA,EAAlBP,EAAcM,iBAAI,IACT,KAIfr+B,EAA4C,GAAAs+B,C,QAI5CP,EAAML,SAAa5G,KACjB92B,EACA,EAAA+9B,EAA4BL,OAE7B7yC,YACDmV,C;;;;;;;;;;;;;;;;GAkDH,MAAAu+B,WAAA1b,GAEKmI,YAAU9H,GACd,MAAO,IAAKh5B,MAAA,0BACb,CAEe4uB,oBAAA0lB,EAAA3W,GAIV,YAAC1sB,IAAA0sB,EAAyB,OAAAA,GAGhCvZ,GAAAkwB,EAAAvW,aAAAC,YAAA,kDAUQsW,EAA8BnX,MAAGx8B,W,CAMxB6iC,OAAK+Q,EAAY7W,EAAAC,EAAA9E,GAC9B,MAAKD,EAAA2b,EAAoBpX,MAAQx8B,W,KAC/BwqB,KAAM,qBAAayN,EAAa,IAAA2b,EAAkB1W,kB,MAIjD2W,EAAAH,GAAAI,aAAAF,EAAA5W,GACJ+W,EAAA,GAEGnqC,KAAAoqC,SAAAH,GAAmBE,EACrB,MAAIE,EAAehB,GAAAW,EAAAxW,cACnBxzB,KAAKsqC,aAAYjc,EAAQ,QAAAgc,GAAiC,CAAAE,EAAA33B,KACxD,IAAA/X,EAAM+X,E,GACQ,MAAV23B,I,EAEO,K,QAGH,OAANA,GAAMvqC,KAAA02B,cAAArI,EAAAxzB,GAAA,EAAAu4B,GACP5nB,GAAAxL,KAAAoqC,SAAAH,KAAAE,EAAA,CACF,IAAA7vC,EAG6BA,EAFzBiwC,EAEmB,MAAnBA,EAAyB,oBAEZ,cAAAA,EAJS,KAK9Bjc,EAAAh0B,EAAA,KAED,I,CAiBI0X,SAAAw4B,EAAApX,GAID,MAAA6W,EAAAH,GAAAI,aAAAM,EAAApX,UAEKpzB,KAAAoqC,SAAmBH,EACzB,CAOAv9B,IAAA+9B,GAEA,MAAAJ,EAAAhB,GAC+BoB,EAAAjX,cAK1BnF,EAAaoc,EAAO7X,MAAUx8B,WAE5BkW,EAAA,IAAAhE,GAuBP,OAjBDtI,KAAAsqC,aAAAjc,EAAA,QAAAgc,GAAA,CAAAK,EAAA93B,KAEe,IAAA/X,EAAA+X,EAIS,MAAjB83B,IACA7vC,EAAA,KACD6vC,EAAU,MAEH,OAAVA,GACE1qC,KAAA02B,cAAoBrI,EAAAxzB,GAAA,EAAsB,MACzCyR,EAAAtW,QAAA6E,IACJyR,EAAA5D,OAAA,IAAAjT,MAAAoF,GAAA,IAIMyR,EAAA3D,OAMR,CAEQ6lB,iBAAA1lB,G,CCpQTwhC,aAAAjc,EAAAgc,EAAA,GAAA7hC,GAwDA,OAVA6hC,EAAA,gBAUAzhC,QAAAgF,IAAA,CACE5N,KAAAw4B,mBAAArb,UAAA,GAODnd,KAAAy4B,uBAAAtb,UAAA,KAAAhjB,MAAA,EAAA8pB,EAAAD,MAEeC,KAAAhG,cAAAosB,EACW,KAAApmB,EAAAhG,aAEzB+F,KAAAlb,QAAAuhC,EACGM,YAGHA,+BAAoB,WAAO,WAAA3qC,KAAA2qB,UAAAjjB,KAAA2mB,EAA3Bsc,OAA2B3qC,KAAA2qB,UAAA5L,UAAA6rB,GAAAP,GAC5BrqC,KAAA4gB,KAAA,4BAAAzqB,GAEQ,MAAA00C,EAAA,IAAAC,eACPD,EAAAvkB,mBAAA,KACOqkB,wBACR3qC,KAAA4gB,KAAA,qBAAAzqB,EAAA,qBAAA00C,EAAAvwC,OAAA,YAAAuwC,EAAAE,cAEe,IAAA1V,EAAA,KACE,GAACwV,EAAMvwC,QAAW,KAAAuwC,EAAAvwC,OAAA,KACnC,IAEe+6B,EAAAxqB,GAGdggC,EAAAE,aAKe,CAFC,MAAU9vC,GACJ2hB,GAAA,qCAAAzmB,EAAA,KAAA00C,EAAAE,aACP,CACbviC,EAAA,KAAA6sB,EACO,MAOkB,MAAAwV,EAAAvwC,QAAA,MAAAuwC,EAAAvwC,QAAAsiB,GAAA,sCAAAzmB,EAAA,YAAA00C,EAAAvwC,QAEVkO,EAAIqiC,EAAUvwC,QAO9BkO,EAAA,IACF,GAkBOqiC,EAAAz3B,KAAU,MAAMjd,GAAiB,GACjC00C,EAAIzhB,MAAG,G,aAUAuB,EAAW+L,EAAY8B,EAAAC,G,aAKhC9N,Y,KACD+L,cAAMA,E,KACL8B,mBAAaA,E,KACbC,uBAA0BA,EAC3Bz4B,KAAA4gB,KAAA1G,GAAA,WAOIla,KAAKoqC,SAAA,EACb;;;;;;;;;;;;;;;;oBAoEMpa,GACF,OAAAhwB,KAAAgrC,UAAArM,SAAA3O,E,qBAGDhwB,KAAAgrC,UAAahrC,KAASgrC,UAAUhM,YAAUhP,EAAAib,E,oBAKxCD,UAAIhH,GAAmB1H,U;;;;;;;;;;;;;;;;GA6B5B,SAAA4O,KAED,OAQMziC,MAAA,KACJk+B,SAAW,IAAI/yB,I,UAgBdu3B,GAAAC,EAAApb,EAAAn1B,GACF,GAAAu1B,GAAAJ,GAEeob,EAAA3iC,MAAA5N,EAIduwC,EAAOzE,SAAA0E,aACR,UAAAD,EAAA3iC,MAAA2iC,EAAA3iC,MAAA2iC,EAAA3iC,MAAAu2B,YAAAhP,EAAAn1B,OAEe,CACd,MAAOywC,EAAAvb,GAAyBC,GACjCob,EAAAzE,SAAAv6B,IAAAk/B,IAAAF,EAAAzE,SAAAp6B,IAAA++B,EAAAJ,MAIGC,GAFYC,EAAAzE,SAAAj6B,IAAwB4+B,GACtCtb,EAAWU,GAAkCV,GAE7Bn1B,E,WCjFZ0wC,GAAgCH,EAAsBI,EAAAt6B,GAEtD,O,EAAAzI,MAAKyI,EAAMs6B,EAAWJ,EAAsB3iC,OAuChD,SAAO2iC,EAEDl6B,GAEPk6B,EAAAzE,SAAA3tC,SAAA,CAAAyyC,EAAAlhC,KAED2G,EAAA3G,EAAAkhC,EAAA,G;;;;;;;;;;;;;;;;IA5C4CL,GAAK,CAAA7gC,EAAakhC,KAG1DF,GAAOE,EAFF,IAAA3b,GAAA0b,EAAAp1C,WAAA,IAAAmU,GAEqC2G,EACxC,G,CA4GJ,MACEw6B,G,MAUA,MAAIC,EAAA3rC,KAAA4rC,YAAAl/B,MAIEmsB,EAAOzjC,OAAGkU,OAAA,GAAgBqiC,G,OAChC3rC,KAAA6rC,OAAe1wB,GAAwBnb,KAAA6rC,OAAA,CAAAC,EAAArjC,KAEnCowB,EAACiT,GAAAjT,EAAmBiT,GAAArjC,CAAA,I,aAStBowB,C,aAIK+S,G,KACLA,YAAaA,E,KAMbC,MAAI,I;;;;;;;;;;;;;;;;mCAsCE7rC,KAAM+rC,eAAcr/B,M,EAGX,G,OAIR,E,GAEN+hB,GAAA,CAAAqd,EAAArjC,KACFA,EAAA,GAAA6C,GAAAtL,KAAAgsC,eAAAF,K,OAEDG,GAAA,EAGD,IAEFA,GAAAjsC,KAAAksC,QAAA3V,YAAA4V,GAaCtvB,GAAiB7c,KAAAosC,aAAwBpyB,KAAQha,MAAOzG,KAAAqiB,MAAA,EAAAriB,KAAA4oB,SArCT,KAsC/C,C,YACSkqB,EAAGH,GACVlsC,KAAAksC,QAAeA,EAEflsC,KAAAgsC,eAAqB,GACrBhsC,KAAA+rC,eAAe,IAAAL,GACbW,GAIF,MAAA3rC,E,IAAqC,IAAyBnH,KAAA4oB,SAC/DtF,G,2CAEC;;;;;;;;;;;;;;;;GAmDF,IAAAyvB,GACEC,G,SAoCDC,GAAAnZ,GAED,MAAM,CACFoZ,UAAC,E,cAEHpZ,QAAMA,EACNqZ,QAAA,E;;;;;;;;;;;;;;;;IA1CAH,G,KAOcD,GAAA,KANHC,GACM,yB,GACjBA,GACE,iB,GACDA,GAAA,mCACHA,GAAaA,GAA+B,gBAAM,qB,MAkF9CI,G,kBAIIjO,GAIN,GAAAtO,GAAApwB,KAAAgwB,MAUY,UAAAhwB,KAAA4sC,aAAAnkC,M,OAIJoR,GAAe7Z,KAAA4sC,aAAAjG,SAAAxL,UAAA,4D,MAIjB,MAACwG,EAAe3hC,KAAA4sC,aAAoBC,QAAC,IAAA/c,GAAuB4O,IAClE,OAAM,IAAAiO,GAAe9c,KAAuC8R,EAAA3hC,KAAA8sC,OAC5D,EAZH,OAPQjzB,GAELkW,GAEA/vB,KACAgwB,QAAA0O,EACA,iDACH,IAAAiO,GAAAjc,GAAA1wB,KAAAgwB,MAAAhwB,KAAA4sC,aAAA5sC,KAAA8sC,O,CAiBGvmC,YAAgBypB,EAAY4c,EAAAE,GAC5B9sC,KAAAgwB,KAASA,EACVhwB,KACC4sC,aACEA,EAEJ5sC,KAAM8sC,SACe9sC,KAAqByJ,KAAA6iC,GAClCS,eAEiC/sC,KAAAsG,OA1HvC,CACDmmC,UAAM,EACLO,YAAA,EAEA3Z,QAAA,KAEDqZ,QAAA,EAwHD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MA4IEO,G,kBACQvO,G,OACNtO,GAAoBpwB,KAAAgwB,MAAA,IAAAid,GAAAjtC,KAAAsG,OAAAupB,KAAA7vB,KAAAknC,KAAAzI,kBAAAC,IACrB,IAAAuO,GAAAjtC,KAAAsG,OAAAoqB,GAAA1wB,KAAAgwB,MAAAhwB,KAAAknC,K,aAEK5gC,EAAM0pB,EAAKkX,G,YACT5gC,E,iBAKL4gC,KAAMA,E;;;;;;;;;;;;;;;;GA2Cb,MAAAgG,GAOEC,kBAAgBzO,GAChB,GAAAtO,GAAApwB,KAAAgwB,MAAA,CAIO,MAAA2R,EAAA3hC,KAAA2mC,SAAAkG,QAAA,IAAA/c,GAAA4O,IACL,OAAOiD,EAAWxG,UACR,KACVwG,EAAAl5B,MACH,IAAAwkC,GAAAjtC,KAAAsG,OAAAupB,KAAA8R,EAAAl5B,OAUgB,IAAGykC,GAA4BltC,KAAAsG,OAAWupB,KAAA8R,EACzD,CAKO,OAJD9nB,GACKkW,GAET/vB,KAAAgwB,QAAA0O,EAAA,kEACK,IAAAwO,GAAAltC,KAAuBsG,OAACoqB,GAAyC1wB,KAAAgwB,MAAAhwB,KAAA2mC,SAG1E,CAOEvwC,WACE,MAAI,aAAA4J,KAAuBgwB,KAAA,KAAAhwB,KAAAsG,OAAAlQ,WAAA,WAAyB4J,KAAA2mC,SAAmBvwC,WAAG,G,aAEjEkQ,EAAA0pB,EAAA2W,G,YAACrgC,E,KAAa0pB,KAACA,E,KACvB2W,SAAMA,E;;;;;;;;;;;;;;;;iCAwCR,OAAA3mC,KAAAotC,iBACF,CAOAC,aAED,OAAArtC,KAAAstC,SAUE,CACAC,kBAAYvd,GACZ,GAAMI,GAAWJ,GAAA,OAAAhwB,KAAAwtC,uBAA8CxtC,KAACstC,UAEhE,MAAMhC,EAASvb,GACbC,GAMF,OAAMhwB,KAAUytC,mBAASnC,E,uBAGrB,OACFtrC,KAAAwtC,uBAAAxtC,KAAAstC,WAAAttC,KAAA0tC,MAAApJ,SACG/5B,E,WAKH,OAAMvK,KAAA0tC,K,aAOQA,EAAAN,EAAAE,G,KAAoDI,MAACA,E,uBACxDN,E;;;;;;;;;;;;;;;;GCv2Bb,SAAAO,GAAAC,EAAAC,EAAAnf,EAAAof,EAAAC,EAAAC,GAEF,MAAMC,EAAAH,EAAAjgC,QAAAqgC,KAA6BzkC,OACvBilB,IAIVuf,EAAUp8B,MAAA,CAAA4I,EAAAC,I,SAgC4BkzB,EAAAnzB,EAAAC,GACtC,GAAiB,MAAjBD,EAAMikB,WAA8B,MAAXhkB,EAAAgkB,UAAW,MAAA37B,GAAA,sCACpC,MAAIorC,EAAO,IAAApU,GACItf,EAAAikB,UAAAjkB,EAAAmtB,c,qCAIf,OAAOgG,EAAc3E,OAAM9O,QAAAgU,EAAAC,E;;;;;;;;;;;;;;;;GAvCjBC,CAAAT,EAAAnzB,EAAAC,K,EACH1hB,SAAWk1C,I,MACdI,E,SAYFV,EAAAM,EAAAF,GAEF,MAAiB,UAAjBE,EAAWzkC,MAAmB,kBAAAykC,EAAAzkC,OAK9BykC,EAAMK,SAAeP,EAASpP,wBAAOsP,EAAAxP,UAAAwP,EAAAtG,aAAAgG,EAAA3E,SALPiF,C,CAdNM,CAA0CZ,EAAAM,EAAAF,GAChED,EAAA/0C,SAAAy1C,IACEA,EAAAC,WAAAR,EAAAzkC,OAAAokC,EAAAxxC,KAAAoyC,EAAOE,YAAOL,EAA2BV,EAAOgB,QAAA,GACnD,GAGH,C,SAwGSC,GAAAb,EAAAc,G,MACL,CACAd,WAAUA,EACVc,YAAYA,E,aAUEC,EAAQC,EAAA/8B,EAAqBg9B,G,OAExCJ,GAAA,IAAAK,GAAAF,EAAA/8B,EAAAg9B,GAAAF,EAAAD,Y,UAEJK,GAAAJ,EAAAK,EAAAn9B,EAAAg9B,GACH,OAAAJ,GAAAE,EAAAf,WAAA,IAAAkB,GAAAE,EAAAn9B,EAAAg9B,GCpPA,C,SAuCEI,GAAAN,G,OAQ+BA,EAAYf,WAAAR,qBAAAuB,EAAAf,WAAAsB,UAAA,I,UAAiBC,GAAAR,G,OAFjDA,EAAAD,YAAiBtB,qBAAAuB,EAAAD,YAAAQ,UAAA,I;;;;;;;;;;;;;;;;OAyB3BE,GAwBH,MAAAC,GAIEprB,kBAAiB9Y,GAClB,IAAAkgC,EAAA,IAAAgE,GAAA,MASD,OAPAt0B,GAAA5P,GAAA,CAAAmkC,EAAAC,KAISlE,IAAAl/B,IAAA,IAAAujB,GAAuB4f,GAAcC,EAAA,IAG9ClE,CASE,CAGDtQ,UAED,cAAAn7B,KAAAyI,OAAAzI,KAAA2mC,SAAAxL,SAeE,CA+BEyU,iCAAmBC,EAAAC,GACpB,SAAA9vC,KAAAyI,OAAAqnC,EAAA9vC,KAAAyI,OAAA,OACMunB,KAAMH,KACdpnB,MAAAzI,KAAAyI,OA+BA,GAAA2nB,GAAAyf,GAAA,YAED,CAIW,MAAM5Q,EACblP,GAAA8f,GAEHE,EAAA/vC,KAAA2mC,SAAAj6B,IAAAuyB,GAED,UAAA8Q,EAAA,CAOkB,MAAGC,EAAAD,EAAYH,iCAAOlf,GAAAmf,GAAAC,GAChC,GAAc,MAAAE,EAAA,CAEF,MAAC,CACGhgB,KAFSigB,GAAA,IAAAngB,GAAAmP,GAAA+Q,EAAAhgB,MAG7BvnB,MAAAunC,EAAwBvnC,MAEd,CAAS,WACd,CAAK,OAAY,IACtB,CAEJ,CC9KaynC,yBAAAL,GACX,OACE7vC,KAAO4vC,iCAAmCC,GAAM,QAElD,CAQAhD,QAAAgD,GAEW,GAAAzf,GAAAyf,GAAkC,OAAA7vC,KACzC,CAEF,MAAai/B,EAAAlP,GAA4C8f,GAGpDlO,EAAA3hC,KAAA2mC,SAAAj6B,IAAAuyB,GACP,cAAA0C,IAAAkL,QAAAnc,GAAAmf,IAEW,IAAAJ,GAA6C,KACxD,CAOI,CA4BJljC,IAAMsjC,EACCM,GAEH,GAAI/f,GAEJyf,GAAc,WAAAJ,GAAwBU,EAAAnwC,KAAA2mC,UAGtC,CASA,MAAA1H,EAAAlP,GACF8f,GAWOO,G,oCACP7jC,IAAImkB,GAAUmf,GAAkBM,G,uDAiB9B,C,iBAmBCN,GAED,OAAA7vC,KAAA2mC,SAAAxL,UAAA,IAAkBsU,GAAY,MAC9B,IAAAA,GAAqB,KAAazvC,KAAK2mC,UACvC,CACC,MAAA1H,EAAAlP,GAAA8f,GAECQ,EAAerwC,KAAA2mC,SAAcj6B,IAC/BuyB,GAOH,GAAAoR,EAAA,CACD,MAAAD,EAAAC,EAAAj1C,OAAAs1B,GAAAmf,IAEF,IAAA/L,EASW,OAFYA,EAAAsM,EAAAjV,UAAAn7B,KAAA2mC,SAAAvrC,OAAA6jC,GACMj/B,KAAS2mC,SAAI1K,OAAAgD,EAAAmR,GACd,OAAdpwC,KAAAyI,OAAcq7B,EAAA3I,UAAA,IAAAsU,GAAA,MACX,IAAAA,GAAmBzvC,KAAAyI,MAAAq7B,EAC3B,CAAK,OAAO9jC,I,EAoBnB0M,IAAAmjC,GACI,GAAAzf,GAA6Byf,GAAA,OAAA7vC,KAAAyI,MACvB,CACR,MAAUw2B,EAAAlP,GAAc8f,GACpBS,EAAatwC,KAAI2mC,SAAIj6B,IAAAuyB,GASzB,OAAQqR,EAAWA,EAAA5jC,IAAAgkB,GAAAmf,IACpB,IACD,CAEF,CAyBIU,QAAAV,EAAAW,GACA,GAAIpgB,GAAYyf,GAAa,OAAAW,EAC3B,CASD,MAAAvR,EAAAlP,GAAA8f,GAEAO,GADepwC,KAAQ2mC,SAACj6B,IAAAuyB,IAAA,IAAAwQ,GAAA,OACxBc,QAAA7f,GAAAmf,GAAAW,GACH,IAAA1M,EAQI,OAPJA,EAAAsM,EAAAjV,UAAAn7B,KAAA2mC,SAAAvrC,OAAA6jC,GAEWj/B,KAAA2mC,SAAgB1K,OAAGgD,EAC9BmR,GAIY,IAAIX,GACPzvC,KAAAyI,MAAAq7B,EAEL,C,CA4BA2M,KAACr1B,GASL,OAAApb,KAAA0wC,MAAA7gB,KAAAzU,EAEF,CAsBEs1B,MAAAC,EAAAv1B,GAEW,MAAAw1B,EAAA,GAYX,OANI5wC,KAAA2mC,S,0BAEFiK,EAAatF,GAAW3J,EAAO+O,MAAAT,GAA0BU,EAAArF,GAAAlwB,EAAA,IAI3DA,EAAAu1B,EAAA3wC,KAAAyI,MAAAmoC,EAEF,CASaC,WAAA7gB,EAAAxU,G,iCAKX,CACAs1B,YACIC,EAAiBJ,EAAan1B,GAYpC,MAAA5I,IAAA5S,KAAAyI,OAAA+S,EAAAm1B,EAAA3wC,KAAAyI,OCnZA,GAAAmK,EAAA,OAAAA,EAoCa,GAAAwd,GAAmB2gB,GAAA,YAE9B,CAID,MAAA9R,EAAAlP,GAAAghB,GAAAC,EAAAhxC,KAAA2mC,SAAAj6B,IAAAuyB,GAED,OAAA+R,IAAAF,YAEGpgB,GACaqgB,GAAAd,GAEQU,EAAA1R,GAAAzjB,G,IAGlB,C,eAGQwU,EAAGxU,GACb,OAAIxb,KAAQixC,eAAcjhB,EAAAH,KAAiBrU,E,gBAEzCu1B,EAAgBG,EAAA11B,G,GACjB4U,GAAA2gB,GAAA,OAAA/wC,KAEG,CACWA,KAAQyI,OAAE+S,EAAA01B,EAAAlxC,KAAAyI,O,MAAEw2B,EAAIlP,GAAAghB,GAAGC,EAAAhxC,KAAA2mC,SAAAj6B,IAAAuyB,GAGlC,OAAQ+R,EAAkBA,EAACC,eAAAvgB,GAAAqgB,GAAAd,GAAAiB,EAAAjS,GAAAzjB,GAC5B,IAAAi0B,GAAA,KACG,CAGL,CAoCC0B,QAAA31B,GACAxb,KAAAoxC,SAAAvhB,KAAArU,EAMD,CAED41B,SAASF,EAAA11B,GAIPxb,KAAA2mC,SAAW/K,kBAAkB,CAAA8C,EAAAiD,KAEzBA,EAAcyP,SAACnB,GAAAiB,EAAAxS,GAAAljB,EAAA,IAEjBxb,KAAMyI,OAAS+S,EAAG01B,EAAWlxC,KAAeyI,M,cAE1C+S,G,KACAmrB,SAAI/K,kBAAsB,CAAA8C,EAAAiD,KACxBA,EAAAl5B,OAAA+S,EAAAkjB,EAAAiD,EAAel5B,MAAA,G,aAKlBA,EAAAk+B,EFnDoB,MACxB6I,QAAA,IAAAnT,GAAAgV,KAED7B,IEgDK8B,IACFtxC,KAAAyI,QAEGzI,KAAA2mC,SACFA,CAGF;;;;;;;;;;;;;;;;SCsDS4K,G,eAzBT,OAAe,IAAAA,GAAK,IAAA9B,GAAA,M,aAMpB+B,GACAxxC,KAAYwxC,Y,uDAaZ,C,iDASE,GAAgB,MAAZC,EAAY,CACjB,MAAAC,EAAAD,EAAAzhB,KAUF,IAAAvnB,EAAAgpC,EAAAhpC,MAEe,MAAAonC,EAAAxf,GAGOqhB,EAAA1hB,GAIb,OAFHvnB,EAASA,EAAAu2B,YAAA6Q,EAAA5V,GAEL,IAAAsX,GAAoBI,EAAgBH,WAAAjlC,IAAAmlC,EAAAjpC,GAC3C,CAAK,CAQD,MAAAokC,EAAA,IAAA4C,GAAiCxV,GAE9B2X,EAAkBD,EAClBH,WACNjB,QAACvgB,EAAA6c,G,gBAGF,C,WAGAgF,GAA2CF,EAAiB3hB,EAAM8hB,G,MAC5DH,E,UAKAG,GAAA,CAAAxG,EAAArR,K,EACF8X,GAAAC,EAAA/B,GAAwBjgB,EAAAsb,GAAArR,EAAA,I,WAuB1BgY,GAEAN,EACA3hB,G,GAEFI,GAAoBJ,GAAqB,OAACuhB,GAAAW,QAC3C,CAEG,MAACC,EAAmBR,EAAAH,WAAuBjB,QAAQvgB,EAAA,IAAAyf,GAAA,OACrD,OAAK,IAAA8B,GAAgCY,E,EAgBvC,SAAKC,GAA6BT,EAAA3hB,G,OAC0B,MAA1DqiB,GAA4CV,EAAc3hB,E,aAahD2hB,EAAA3hB,G,QACP2hB,EAAAH,WAAAtB,yBAAAlgB,G,OACM,M,EAAW2hB,EAAAH,WAAA9kC,IAAA+kC,EAAAzhB,MAAA2O,SAAAtO,GAAAohB,EAAAzhB,SACnB,I,aAQ2C2hB,G,QACxC,G,EAKCA,EAAAH,WAAA/oC,MAUT,O,QAPKwxB,EAAA+D,cAAA/D,EAAAkF,aAAAkD,IAAA,CAAA3D,EAAAG,KACD8H,EAAatqC,KAAG,IAAA09B,GAAc2E,EAAAG,GAAA,IAE7B8S,EAAAH,WAAA7K,SAAA/K,kBAAA,CAAA8C,EAAAiD,KACA,MAAAA,EAAAl5B,OAAAk+B,EAAAtqC,KAAA,IAAA09B,GAAA2E,EAAAiD,EAAAl5B,OAAA,IAGLk+B,C,UAKE2L,GAAiDX,EAAA3hB,GACjD,GAAAI,GAAqCJ,GAAA,OAAA2hB,EACtC,CAED,MAAAY,EAAAF,GAGMV,EAAU3hB,GACd,OAAO,IAAAuhB,GAAA,MAAAgB,EAAmB,IAAA9C,GAAA8C,GACMZ,EAACH,WAAA3E,QAAA7c,G,EAgBjC,SAAMwiB,GAAgBb,GACtB,OAAOA,EAAKH,WAAArW,S,UAiBRsX,GAAmBd,EAAa1X,G,UACvBpK,KACF8hB,EACDH,WACMvX,E,aAII4V,EAAA6C,EAAAzY,G,GACZ,MAANyY,EAAMjqC,M,OAINwxB,EAAM+E,YAAG6Q,EAAA6C,EAAAjqC,OAKV,CACC,IAAAkqC,EAAa,KAsBX,OArBFD,EAAS/L,SAAA/K,kBAAA,CAAA0P,EAAA3J,KACV,cAAA2J,G,+DAKaqH,EAAGhR,EAAAl5B,OAEjBwxB,EAAA2Y,GAAwC3C,GAA4BJ,EAAQvE,GAAA3J,EAAA1H,EAAA,IAY5EA,EAAA0E,SAAAkR,GAAe1U,WAAmB,OAAbwX,IAA4B1Y,IAAA+E,YAAAiR,GAAAJ,EAAA,aAAA8C,IAC7C1Y,CAGL,CAED;;;;;;;;;;;;;;;;GA+CE,SAAO4Y,GACKH,EAAA1iB,G,OACR8iB,GAAa9iB,EAAY0iB,E,CA8H7B,SAAAK,GAAwBL,EAAAM,GAGxB,MAAIjO,EAAQ2N,EAAKO,UAAAC,WAAA33B,GACXA,EAAAy3B,UAAeA,IAErBn5B,GAAsBkrB,GAA0C,EAAI,gD,MAClEoO,EAAcT,EAAAO,UAAAlO,G,EACdkO,UAAgBjkB,OAAA+V,EAAW,G,IAM1BqO,EAAAD,EAAAphB,QAECshB,GAAQ,EACVh+C,EAAAq9C,EAAaO,UAAG39C,OAAA,E,KAChB89C,GAAe/9C,GAAA,IAMf,MAAAi+C,EAAAZ,EAAAO,UAAA59C,GACIi+C,EAASvhB,UAIT18B,GAAM0vC,GAAUwO,GAAgBD,EAAAH,EAAAnjB,MAChCojB,GACE,EAGIriB,GAAcoiB,EAAAnjB,KAClBsjB,EAAKtjB,QAIPqjB,GACc,I,OAUlBD,E,IACEC,E,OAsDU,SACdX,GAIAA,EAAKc,cAAQC,GAA6Cf,EAAeO,UAAAS,GAAA7jB,MACvE6iB,EAAUO,UAAS39C,OACjB,EAAAo9C,EAAAiB,YAAAjB,EAAAO,UAA8BP,EAAaO,UAAQ39C,OAAA,GAAA09C,QAErDN,EAAAiB,aAAA,C,EA1DGjB,I,EAKH,GAAAS,EAAAjM,KAAAwL,EAAIc,cAAAvB,GAAwDS,EAAAc,cAAAL,EAAAnjB,UAC5D,CAEH7U,GADEg4B,EAAAxM,UACFjI,IAEDgU,EAAAc,cAAAvB,GAGSS,EAAAc,cAAAvD,GAAoCkD,EAAAnjB,KAAA0O,GAAA,GAG3C,CACA,OAAM,CACN,CAxBE,OAAK,C,UAkCH6U,GAA2BK,EAAA5jB,G,GAE7B4jB,EAAA1M,KAAA,OAAAnW,GAAA6iB,EAAA5jB,QAGF,UAAA0O,KAAAkV,EAAAjN,SAII,GAAMiN,EAAUjN,SACd//B,eAAA83B,IAAA3N,GAAkCkf,GAClC2D,EAAA5jB,KAAA0O,GAAA1O,GAAA,SAEF,Q,CA2BJ,SAAM0jB,GAAuBG,GAC7B,OAAKA,EAAQ9hB,O,CAYT,SAAU0hB,GAAAK,EACdjmC,EACAkmC,GAKA,IAAApC,EAAgBJ,GAAkBW,QAClC,IAAI,IAAC78C,EAAO,EAACA,EAAAy+C,EAAAx+C,SACND,EAAA,CAGH,MAAIw+C,EAAMC,EACRz+C,GAOF,GAAUwY,EAAAgmC,GAAA,CAMV,MAAAG,EAAAH,EAAA7jB,KACF,IAAA6f,EACA,GAAAgE,EAAA3M,KACOnW,GAAAgjB,EAAAC,IACRnE,EAAAxf,GAAA0jB,EAAAC,GAEYrC,EACXI,GAESJ,EAAe9B,EAAAgE,EAAA3M,OACHnW,GACZijB,EAAiBD,KACdlE,EAAexf,GAAa2jB,EAAWD,GAC7CpC,EAAAI,GACoBJ,EAClB9hB,KACAgkB,EAAA3M,KACDvI,SAACkR,SAGN,KAAAgE,EAAAlN,SAiDL,MAAA5jC,GAAA,8CA/CG,GAAAguB,GAAAgjB,EAAAC,GACHnE,EAAAxf,GAAA0jB,EAAAC,GAEerC,EAAAE,GAGdF,EAAoC9B,EAAAgE,EAAAlN,eAEzB,GAAA5V,GAAAijB,EAAAD,GAQA,GAPPlE,EAAAxf,GACF2jB,EAASD,GAMA3jB,GAAAyf,GACH8B,EAAgBE,GAGpBF,EAAA9hB,KAAAgkB,EAAAlN,cAEJ,CACD,MAAAsN,EAAAzoC,GAAAqoC,EAAAlN,SAAA5W,GAAA8f,IAEe,GAAAoE,EAAA,C,0BAOHtC,EAAAI,GAAAJ,EAAA9hB,KAAAqkB,EACP,CAOO,CAOZ,CAEK,CACJ,CAGD,OAAAvC,CAEK,CAgDL,SAAAwC,GAAAzB,EAAA0B,EAAAC,EAAAC,EAAAC,GAEK,GAAUD,GAAAC,EAyBf,CAED,MAAAC,EAAAlC,GAAAI,EAAAc,cAAAY,GAmBE,IAAAG,GAAQ/B,GAAgCgC,GAAA,OAAAH,E,GAItCE,GAAI,MAAAF,GAAAjC,GAAAoC,EAAA3kB,MACI,C,MACRhiB,EAAU,SAAAgmC,G,gFAEF,EAGD,OAAApB,G,sCAPH,W,CAlDQ,CAMV,MAAAF,EACFF,GAAoBK,EAAAc,cAAAY,GAClB,GACE,MADE7B,EACF,OAAaA,EACR,CACL,MAAMkC,EAAQnC,GAAiCI,EAAAc,cAAAY,GAC/C,GAAI5B,GAAeiC,GAAA,OAAAJ,EACf,GACa,MADbA,GACgBjC,GAAYqC,EAAA5kB,M,CAOhC,OAAS4iB,GAAOgC,EADWJ,GAAArQ,GAAA1H,WAE5B,CALC,OAAM,IAMP,CAEN,C,UA2RGoY,GACAC,EAAAN,EAAAC,EAAAC,GACH,OAAAJ,GAAAQ,EAAAjC,UAAAiC,EAAAP,SAAAC,EAAAC,EAAAC,EAED,CAqBE,SAAOK,GAAKD,EAAAE,GACb,O,SA7QoBnC,EAAA0B,EAAAS,G,IACjBC,EAAgB9Q,GAAI1H,W,MACpByY,EAAA1C,GAA0BK,EAAAc,cAAAY,G,GAC1BW,EAMF,OALEA,EAAA/W,cACA+W,EAAA5V,aAAAkD,IAAA,CAAA3D,EAAAiR,K,iCAISmF,EACL,GAAAD,EAA4B,CAGhC,MAAAL,EAAYlC,GAAYI,EAAAc,cAAAY,GAgBxB,OAfAS,EAAY1V,aAAwBkD,IAAQ,CAAA3D,EAAAG,KAC5C,MAAA5E,EAAYwY,GAAqCH,GAAAkC,EAAA,IAAA1kB,GAAA4O,IAAAG,GAC7CiW,EAAYA,EACFhW,qBAAiBJ,EAAOzE,EAAY,I,mBAUlD6a,EAAkBA,EAAAhW,qBAAyBsC,EAAAriC,KAAAqiC,EAAAnH,KAAA,IAErC6a,C,CAUN,O,kFACEA,C,CAqOLE,CAAAL,EAAAjC,UAAAiC,EAAAP,SAAAS,EAED,C,SA8BII,GAA2CN,EAAkB3kB,EAAAklB,EAAAC,G,gBA/NxBzC,EAAuB0B,EAAA1E,EAAAwF,EAAAC,GAC7Dt7B,GAAAq7B,GAAAC,EAAA,6DACF,MAAAnlB,EAAAigB,GAAAmE,EAAA1E,GAED,GAAA0C,GAGAM,EAASc,cAAAxjB,GASR,YAED,CAcM,MAAKolB,EACP9C,GAA4CI,EAAQc,cAAAxjB,GAGlD,OAAAwiB,GAAoB4C,GAChBD,EAAQxW,SAAA+Q,GAcX+C,GAAA2C,EAAAD,EAAAxW,SAAA+Q,GAEN,CAED,CAyKI2F,CACcV,EAAAjC,UAAAiC,EAAAP,SAAApkB,EAAAklB,EAAAC,E,UAiBZG,GAA8BX,EAAA3kB,G,qBApJlC,OAAKqiB,GAGFK,EAAkBc,cAAAxjB,E,EAkJS2kB,EAAAjC,UAAAzC,GAAA0E,EAAAP,SAAApkB,G,aAWJ2kB,EAClBY,EACY7P,EACZ/J,EACA1f,EAAA7H,G,gBA3JqBs+B,EAAA0B,EAAAmB,EAAA7P,EAAA/J,EAAA1f,EAAA7H,G,IACzBohC,E,kEAIuB,MAArBD,E,SAAqBC,EAAA/C,GAAA+B,EAAAe,E,MAGnBC,EAAStV,UAAO9rB,G,EAGhB+mB,WAAaqa,E,oCAGXphC,EAAUmvB,a,EAQPtnB,EAAIu5B,EAAY3P,uBAAAH,EAAAtxB,GAAAohC,EAAAhQ,gBAAAE,EAAAtxB,G,MACtB4uB,EAAAI,U,oBAGD,IAAA7H,EAAA4H,EAAAuC,IAAA+P,EAAAp5C,KAAA8mC,G,qBAOAsS,C,GA2HmCd,EAAYjC,UAAAiC,EAAAP,SAAAmB,EAAA7P,EAAA/J,EAAA1f,EAAA7H,E,aAU7BugC,EACdrJ,EAAOoK,G,gBAxMdhD,EAAA0B,EAAA9I,EAAA6J,GACH,MAAMnlB,EAAAigB,GAAcmE,EAAA9I,GAChBiH,EAAaF,GAAYK,EAAAc,cAAAxjB,GAC7B,GAAmB,MAAnBuiB,EAAmB,OAAYA,EAE7B,GAAA4C,EAAqB1H,mBAAAnC,GAKjB,OAAMmH,GAJVH,GACYI,EAAAc,cAAAxjB,GAGwBmlB,EAAA7F,UAAA7Q,kBAAA6M,IAChC,OAAU,I,0CAsMgBqJ,EAAAjW,G,UAMZuR,GAAuC0E,EAAAP,SAAA1V,GAAAiW,EAAAjC,U,aAEzB1iB,EAAG0iB,G;;;;;;;;;;;;;;;;6BAuCxBxE,G,MAETzkC,EAASykC,EAAIzkC,K,EACPykC,EAAWxP,U,GAM8B,gBAAXj1B,GAC9B,kBAAAA,GAAA,kBAAAA,EAAA,6C,GAEL,cAAA6hC,EAAA,mD,MACFqK,EAAA31C,KAAA41C,UAAAlpC,IAAA4+B,GACF,GAAAqK,EAAA,C,eAGD,mBAAAlsC,GAAmD,kBAALosC,EAA4B71C,KAAA41C,UAAArpC,IAAA++B,EAAAvD,GAAAuD,EAAA4C,EAAAtG,aAAA+N,EAAA/N,oB,wEAG7D,GAAO,kBAAJn+B,GACC,kBAAfosC,EAA6B71C,KAAA41C,UAAArpC,IAAA++B,EAAAxD,GAAAwD,EAAAqK,EAAA3N,e,yFAI/B,sBAAAv+B,GAA4D,kBAAvBosC,EACtC,MAAA9yC,GAAA,mCAAAmrC,EAAA,mBAAAyH,GAD6D31C,KAAA41C,UAAArpC,IAAA++B,EAAAvD,GAAAuD,EAAA4C,EAAAtG,aAAA+N,EAAA3N,SAC7D,CAED,MAAAhoC,KAAA41C,UAAArpC,IAAA++B,EAAA4C,EAYE,C,uDAIA,CACA3nC,cACAvG,KAAO41C,UAAc,IAAIhiC,G;;;;;;;;;;;;;;;;SAoEvBkiC,GAAyB,I,MAjB7BC,iBAAAzK,GAOE,OAAW,IACX,C,mBACal3B,EAAA4hC,EAAA/5B,GACX,OAAK,I,SAYJg6B,GACJF,iBAAAzK,GAED,MAAArR,EAAAj6B,KAAAk2C,WAAAlI,WAQE,GAAM/T,EAAAwT,mBAAenC,GAAA,OAAArR,EAAYqV,UAAA7Q,kBAAA6M,GAE3B,CAEN,MAAA6K,EAAqC,MAArCn2C,KAAAo2C,wBAA+D,IAAIlH,GAAAlvC,KAAAo2C,yBAAA,MAAAp2C,KAAAk2C,WAAApH,YACjE,OAAAuH,GAAwCr2C,KAAAs2C,QAAAhL,EAAA6K,EACvC,CAEH,CAEAI,mBAAAniC,EAAAoiC,EAAAv6B,GACE,MAAAs5B,EAAkC,MAAlCv1C,KAAAo2C,wBAAwCp2C,KAAAo2C,wBAAA7G,GAAAvvC,KAAAk2C,YACvCT,EAAAgB,GAAAz2C,KAAAs2C,QAAAf,EAAAiB,EAAA,EAAAv6B,EAAA7H,GAEH,OAAoB,IAAbqhC,EAAAngD,OAAa,KACrBmgD,EAAA,EAED,CASElvC,YAAW+vC,EAAGJ,EAAAE,EAAmB,MAC7Bp2C,KAAKs2C,QAAEA,E;;;;;;;;;;;;;;;;gCAoDTI,EAAA,IAAAC,G,IAKAC,EAAcC,E,GAGfC,EAAArtC,OAAA6iC,GAAAyK,UAAA,CACH,MAAAC,EAAAF,EC1iDAE,EAAA1wC,OAAAmmC,SAAAmK,EAAAK,GAAAC,EAAAC,EAAAH,EAAAhnB,KAAAgnB,EAAA9P,KAAAkQ,EAAAC,EAAAX,IAuBc78B,GAAyBm9B,EAAA1wC,OAAA0mC,WAAA,mBAK/B6J,EAAQG,EAAmB1wC,OAAMomC,QAAOyK,EAAcrI,YAAAzB,eAAAjd,GAAA4mB,EAAAhnB,MACtD4mB,EAAYU,GAAAJ,EAAAC,EAAAH,EAAAhnB,KAAAgnB,EAAA9P,KAAAkQ,EAAAC,EAAAR,EAAAH,G,MAEf,GAAAI,EAAArtC,OAAA6iC,GAAAiL,MAAA,CAEH,MAAO/C,EAAAsC,EACRtC,EAAAluC,OAAAmmC,SAAAmK,E,SCmEEM,EAAAnI,EAAA/e,EAAAwnB,EAAAJ,EAAAtI,EAAA4H,GAVD,IAAAe,EACS1I,E,SAAiBoC,SAAA,CAAAtB,EAAjBhR,KACA,MAAKmV,EAAL/D,GAAYjgB,EAAA6f,GACR6H,GAAM3I,EAAAhf,GAAAikB,MAAAyD,EAAAR,GAAAC,EAAAO,EAAAzD,EAAAnV,EAAAuY,EAAAtI,EAAA4H,GAAA,IAcpBc,EAAArG,SAAA,CAAAtB,EAAAhR,KC5GD,MAAAmV,EAAA/D,GAAAjgB,EAAA6f,GAsDI6H,GACiC3I,EAAAhf,GAAAikB,MAAAyD,EAAAR,GAAAC,EAAAO,EAAAzD,EAAAnV,EAAAuY,EAAAtI,EAAA4H,GAAA,IAGlCe,C,CFxBFE,CAAAT,EAAAC,EAAA3C,EAAAxkB,KAAAwkB,EAAA7N,SAAAyQ,EAAAC,EAAAX,IAMO78B,GAAa26B,EAAAluC,OAAA0mC,WAAA,mBAId6J,EAAiBrC,EAAWluC,OAAOomC,QAAMyK,EAAArI,YAAAzB,aACxCuJ,EAAcgB,GACPV,EAAAC,EAAA3C,EAAAxkB,KAAAwkB,EAAA7N,SAAAyQ,EAAAC,EAAAR,EAAAH,G,MAGX,GAAOI,EAAMrtC,OACX6iC,GAAqCS,eAAmB,C,MAExD8K,EAAAf,EAGGF,EADNiB,EAAA/K,O,SGuF6CoK,EAAAnI,EAAA/e,EAAAonB,EAAA/C,EAAAqC,G,IAC5CzkC,E,GAEkC,MADlCqjC,GACuB8B,EAAWpnB,GAAiB,OAAA+e,EAEnD,CACD,MAAAzoC,EAAA,IAAA2vC,GAAAmB,EAAArI,EAAAsF,GAEKyD,EAAA/I,EAAAf,WAAAsB,UACJ,IAAAyI,EACD,GAAA3nB,GAAAJ,IAAA,cAAAD,GAAAC,GAAA,CAEO,IAAAsK,EACN,GAAOyU,EAAWD,YAAUtB,qBAAGlT,EAAAoa,GAAmC0C,EAAA7H,GAAAR,QACnE,CAvDD,MAAAiJ,EAAAjJ,EAGAD,YAEWQ,UADKz1B,GAAMm+B,aAAAhU,GAAA,iDACN1J,EAAAsa,GAAMwC,EAAAY,EACC,CAEnBD,EAAAb,EAAArpC,OAAAoqC,eAAAH,EAAAxd,EAAAoc,EAgDL,MAED,MAAApL,EAAAvb,GAEGC,GAEG,IAAMogB,EAAAiG,GACiBe,EAAA9L,EAAAyD,EAA8CD,aAE1E,MAAAsB,GAAArB,EAAAD,YAAArB,mBAAAnC,KAAA8E,EAAA0H,EAAArZ,kBAAA6M,IAEDyM,EAAA,MAAA3H,EAAA8G,EAGSrpC,OAAAmxB,YAAA8Y,EAAAxM,EAAuB8E,EAAmB1f,GAAAV,GAAA1pB,EAAAowC,GACjC3H,EAAKf,WAAAsB,UAAAhL,SAAAgH,GACF4L,EAAArpC,OAAAmxB,YAAA8Y,EAAAxM,EAAAtH,GAAA1H,WAAA5L,GAAAV,GAAA1pB,EAAAowC,GAEjBoB,EAESC,EACT5c,WAAiB4T,EAAAD,YAAmBtB,uBAI9Bv7B,EAAAyiC,GACJ0C,EAAA7H,GACoCR,IAChC98B,EAAA+rB,eACJ+Z,EAAAb,EAAArpC,OAAAoqC,eAAAF,EAAA9lC,EAAAykC,I,UAII3H,EAASD,YAAKtB,sBACkB,MAAlC8H,GAAkC8B,EAAAvnB,M,GAExBkf,EAAMgJ,EAAmB9lC,EAAAilC,EAAArpC,OAAAqqC,e;;;;;;;;;;;;;;;;GHzI1BC,CAAAjB,EAAAC,EAAAU,EAAA7nB,KAAAonB,EAAAC,EAAAX,G,SIiGbQ,EACYnI,EACLqJ,EACAxL,EAELwK,EAASC,EACTX,G,GACsB,MAAxBpB,GAAwB8B,EAAAgB,GAAA,OAAArJ,EAG1B,MAAA8H,EAAA9H,EAAAD,YAAAzB,aAwBEyB,EAAcC,EAAOD,Y,GACrB,MAAAlC,EAAAnkC,MAAA,CAOD,GAAA2nB,GAAAgoB,IAAAtJ,EAAAtB,sBAAAsB,EAAAvB,kBAAA6K,GAAA,OAAAd,GAAAJ,EAAAnI,EAAAqJ,EAAAtJ,EAAAQ,UAAA3Q,SAAAyZ,GAAAhB,EAAAC,EAAAR,EAAAH,G,MA1IwC0B,GAAW,CAAI,IAAAZ,EAAA,IAAA/H,GAAA,MDuDlD,OCoFPX,EAAAQ,UAAAnQ,aAAA2D,IAAA,CAAAuV,EAAApe,KDnMDud,IAAAjrC,IAAA,IAAAujB,GAAAuoB,GAAApe,EAAA,IA+GQ2d,GACUV,EAAAnI,EAAAqJ,EAAAZ,EAAAJ,EAAAC,EAAAR,EAAAH,E,CAEZ,OAAO3H,C,CAEV,CAGC,IAAAyI,EAAW,IAAA/H,GAAmB,MAM9B,OALD7C,EAAAuE,SAAA,CAAAmH,EAAA7vC,KAEG,MAAA8vC,EAAgBtI,GAAAmI,EAAAE,GACZxJ,EAAMvB,kBAAAgL,KAAAf,EAA+BA,EAAcjrC,IAAA+rC,EAAAxJ,EAAAQ,UAAA3Q,SAAA4Z,IAAA,IAElDX,GAA6BV,EAAAnI,EAAAqJ,EAAAZ,EAAAJ,EAAAC,EAAAR,EAAAH,E,EHvErC8B,CAAAtB,EAAAC,EAAAU,EAAA7nB,KAAA6nB,EAAAjL,aAAAwK,EAAAC,EAAAX,EAEF,SAAAI,EAAArtC,OAAA6iC,GAAAmM,gBAEY,MAAA11C,GACX,2BAAA+zC,EAAArtC,MAHDmtC,E,SG4EUM,EAA+BnI,EAAc/e,EAAAonB,EAAAV,G,MACrDgC,EAAA3J,EAAAD,YAED6J,EAA+BxJ,GAAAJ,EAAA2J,EAAApJ,UAAAoJ,EAAAlL,sBAAApd,GAAAJ,GAAA0oB,EAAArL,c,OAC7BuL,GAA2B1B,EAAOyB,EAAA3oB,EAAAonB,EAAAtB,GAAAY,E,CHhFrCmC,CAAA3B,EAAAC,EAAAL,EAAA9mB,KAAAonB,EAAAV,EAGC,CAGA,MAAM5I,EAAS4I,EAAGoC,a,gBA6BJ3B,EACV4B,EACArC,G,MAMF1H,EAAU+J,EAAA/K,W,GACVgB,EAAAxB,qBAAA,CACF,MAAAwL,EAAAhK,EAAAM,UAAAtR,cAAAgR,EAAAM,UAAAnU,UAEW8d,EAAA5J,GAA4C8H,I,iJAWvD,C,CAjDA+B,CACE/B,EAAKP,EACW9I,G,CAQhBiB,UAAW6H,EAQT9I,QAACA,E,UAsCD8K,GAES1B,EAAAnI,EAAAoK,EAAA/B,EAAA9wC,EAAAowC,G,qBAGb,GAAiC,MAA7BpB,GAA6B8B,EAAA+B,G,SAE/B,CACA,IAAIpB,EAAe5B,E,GACjB/lB,GAA8B+oB,G,GAE/Bt/B,GAAAk1B,EAAAD,YAAAtB,qBAAA,8D,4BAQG,MAAAsB,EACFS,GAAiCR,GAGvBqK,E,KADqBtK,aAAc9K,GAAkB8K,EAAA9K,GAAA1H,YAG/Dyb,EAAab,EAAArpC,OAAUoqC,eAASlJ,EAAUf,WAAUsB,UAAkB8J,EAAA1C,EAExE,KAAM,C,oBAKEqB,EAAgBb,EAAKrpC,OAAAoqC,eAAAlJ,EAAAf,WAAAsB,UAAA+J,EAAA3C,EACzB,KACF,CACA,MAAIpL,EAAYvb,GAAkCopB,GACnD,GACY,cAAX7N,EAAuB,CAGnBzxB,GAA0C,IAAAgX,GAAAsoB,GAAA,yDAC5C,MAAAG,EAAgBC,EAAkBjK,UAE/B6G,EAAIpH,EAAsBD,YAAWQ,U,oBAITyI,EAAN,MAArByB,EAA2BtC,EAAArpC,OAAAywB,eAAAgb,EAAAE,GAEnBD,EAAmBjK,S,MAEjC,MAASmK,EAAa/oB,GAAAyoB,G,MAGhB,GAAII,EACV9L,mBAAYnC,GAAkB,CAEjC6K,EAAApH,EAAAD,YAAAQ,UAEM,MAAAoK,EAAAzE,GAAAmC,EAAA+B,EAAAI,EAAAjK,UAAA6G,GACDwD,EAAA,MAAAD,EAAAH,EAAAjK,UAAA7Q,kBAAA6M,GAAAtM,YAAAya,EAAAC,GAEEH,EAAAjK,UAAA7Q,kBAAA6M,E,MACNqO,EAAStD,GAAAe,EAAA9L,EAAAyD,EAAAD,aACHiJ,EAAA,MAAN4B,EAAMzC,EAAArpC,OAAAmxB,YAAAua,EAAAjK,UAAAhE,EAAAqO,EAAAF,EAAAnzC,EAAAowC,GAEI6C,EAAAjK,S,CAEV,CACJ,OAAAsK,GAAA7K,EAAAgJ,EAAAwB,EAAA/L,sBAAApd,GAAA+oB,GAAAjC,EAAArpC,OAAAqqC,eK9LA,CA4BA,CASA,SAAAZ,GAAAJ,EAAAC,EAAAgC,EAAAU,EAAAzC,EAAAC,EAAAR,EAAAH,G,4BAiBE,MAAIoD,EAAiBjD,EAAAK,EAAArpC,OAAAqpC,EAAArpC,OAAAksC,mB,gIAMrBC,EAAmBF,EAAgB7B,eAAAgC,EAAA3K,UAAA4K,EAAA,KAEnC,KAAO,CACL,MAAM5O,EAAAvb,GAAqCopB,GAC3C,IAAAc,EAAmB1M,kBAAA4L,IAAAtoB,GAAAsoB,GAAA,EAEnB,OAAMhC,EACN,MAAMsC,EAAiB/oB,GAAayoB,GAElCpa,EADgBkb,EAAO3K,UAAA7Q,kBAAA6M,GACHtM,YAAAya,EAAWI,G,iGAIhCM,EAAAhL,GAAAgI,EAAA6C,EAAAC,EAAAzM,sBAAApd,GAAA+oB,GAAAW,EAAA5B,gB,OAGDU,GAAiC1B,EAAAiD,EAAAhB,EAAA/B,EAFjC,IAAAnB,GAAOmB,EAAW+C,EAAA9C,GAEeX,E,aAM1BQ,EAAAC,EAAAgC,EAAAU,EAAAzC,EAAAC,EAAAX,G,qCAGC,IAAKT,GACTmB,EAAqBD,EAAAE,G,MAEJ8B,G,EACpBjC,EAAArpC,OAAAoqC,eAAAd,EAAAnJ,WAAAsB,UAAAuK,EAAAnD,GACD0D,EAAgBR,GACGzC,EAAOY,GAAkB,EAAAb,EAAArpC,OAAAqqC,oBAE5C,CAEA,MAAA5M,EAAUvb,GAAAopB,GACV,iBAAA7N,EACJyM,EAAAb,EAAArpC,OAAAywB,eAAA6Y,EAAAnJ,WAAAsB,UAAAuK,GJjGAO,EAAAR,GAAAzC,EAAAY,EAAAwB,EAAA/L,qBAAA+L,EAAAlM,kBAiES,CACL,MAASoM,EAAiB/oB,GAAIyoB,GACrBkB,EAASd,EAChBjK,UAAW7Q,kBAAM6M,G,IAEjB8E,EAEH,GAAAhgB,GAAAqpB,GACDrJ,EAAYyJ,MACH,CACR,MAAAhb,EAAAv4B,EAAAyvC,iBAAAzK,GAIO8E,EAHM,MAAAvR,EACuC,cAAvCyb,GAAsCb,IAAC5a,EAAAF,SAAA4b,GAAAd,IAAAte,UAE7C0D,EAEWA,EACZG,YACEya,EAELI,GAhCJ7V,GAAA1H,UAOkB,CACQ,GAAA+d,EAAAja,OAAjBgQ,GAGLgK,EAAAjD,MAHK,CAEQiD,EAAAR,GAAgBzC,EADCD,EAAArpC,OAAAmxB,YAAAua,EAAAjK,UAAAhE,EAAA8E,EAAAqJ,EAAAnzC,EAAAowC,GACD6C,EAAA/L,qBAAA0J,EAAArpC,OAAAqqC,eAC7B,CAwBL,CAEY,CAMX,OAAOkC,C,UAEN1C,GAAA3I,EAAAzD,GACD,OAAAyD,EAAYf,WAAAP,mBAAAnC,E,UCtCVkP,GAAAtD,EAAMjd,EACAua,G,SAGNrD,SAAO,CAAItB,EAAChR,KACb5E,IAAA+E,YAAA6Q,EAAAhR,EAAA,IAGC5E,C,UAGF2d,GAA8BV,EAAAnI,EAAA/e,EAAAwnB,EAAAJ,EAAAtI,EAAA+H,EAAAH,GAxB9B,GAAA3H,EACmBD,YAAAQ,UACAnU,YAA0C4T,EAAAD,YAAAtB,qBAAA,OAAAuB,E,IEoB3D0L,EADAhD,EAAc1I,EAMU0L,EAAxBrqB,GAAwBJ,GAAAwnB,EACzB,IAAA/H,GAAA,MAAAc,QAAAvgB,EAAAwnB,GAED,MAAArB,EAAApH,EAAAD,YAAAQ,U,SAOE3I,SAAA/K,kBAAA,CAAA0P,EAAqB3J,KACrB,GAAAwU,EAAc7R,SAAOgH,GAAA,CACrB,MAMO8E,EAASoK,GAAQtD,EANxBnI,EAAAD,YACMQ,UACJ7Q,kBAEA6M,GAEsB3J,GACzB8V,EAAAH,GAAAJ,EAAAO,EAAA,IAAA3nB,GAAAwb,GAAA8E,EAAAgH,EAAAtI,EAAA+H,EAAAH,EAED,K,EAqBE/P,SAAA/K,kBAAA,CAAA0P,EAAwBoP,KACxB,MAAMC,GAAe5L,EAAAD,YAAArB,mBAAAnC,IAAiB,OAAjBoP,EAAiBjyC,MACtC,IAAA0tC,EAAA7R,SAAAgH,KAAAqP,EAEO,CAIP,MACDvK,EAAAoK,GAAAtD,EADyBnI,EAAAD,YAAAQ,UAAA7Q,kBAAA6M,GACzBoP,GAEDjD,EAAAH,GAAAJ,EAAAO,EAAA,IAAA3nB,GAAAwb,GAAA8E,EAAAgH,EAAAtI,EAAA+H,EAAAH,EAcE,KAOAe,C,UDoOFmD,GAAAC,EAAA7qB,G,MAmBE8qB,EAASvL,GACMsL,EAAA3E,Y,OAGf4E,IAGED,EAAAjnB,MAAOJ,aACDE,iBAAAtD,GAAmBJ,KAAA8qB,EAAArc,kBAAM1O,GAAgBC,IAAAmL,WAC7C2f,EAAAnc,SAAA3O,GAEL,I,UAyIC+qB,GAAmBF,EAAS/D,EAAQM,EAAa/C,GAEnDyC,EAAWrtC,OAAA6iC,GAAoBiL,OAAQ,OAAAT,EAAAxwC,OAAA+sB,UACxCxZ,GAAA01B,GAAAsL,EAAA3E,YAAA,6DAEDr8B,GAAAw1B,GAAAwL,EAAA3E,YAAA,4DASE,MAAAiB,EAAW0D,EAAA3E,WACZtjC,EAAAooC,GAAAH,EAAAI,WAAA9D,EAAAL,EAAAM,EAAA/C,G,QAmCC,O,EA7BFwG,EAAAI,W,EAAAroC,EAAAm8B,UJq+BMl1B,GAAiBk1B,EAAAf,WAAAsB,UAAAnP,UAAA+W,EAAArpC,OAAA2mB,YAAA,0B,qFI18BrB3a,GAASjH,EAAkBm8B,UAASD,YAAAtB,uBAAA2J,EAAArI,YAAAtB,qBAAA,2DACpCqN,EAAA3E,WAAAtjC,EAAAm8B,UACAmM,GAAqCL,EAAEjoC,EAAOk7B,QAAal7B,EAAAm8B,UAAAf,WAAAsB,UAAA,K,UAuB3D4L,GAAmDL,EAAA/M,EAAAE,EAAAmN,GACnD,MAAApN,EAAsBoN,EAAoB,CAC1CA,GACDN,EAAAO,oBAED,O,SRnjB8BxN,EAAAE,EAAAE,EAAAqN,G,MAC1BxN,EAAU,GACXyN,EAAA,GAqCD,OA3BDxN,EAAA90C,SAAAk1C,I,IL8MsBxP;;;;;;;;;;;;;;;;GK5MvB,kBAAAwP,EAAAzkC,MAGamkC,EAAA3E,OAAA7O,oBAGH8T,EAAAlG,QAAAkG,EAAAtG,eAAA0T,EAAAj/C,MLsMaqiC,EKtMbwP,EAAAxP,U,MLwMJ,c,aKxMIwP,EAAAtG,a,UL0MFlJ,IK1ME,IAGRiP,GAAwDC,EAAUC,EAAA,gBAAAC,EAAAuN,EAAArN,GAClEL,GAAcC,EAAAC,EAAA,cAAAC,EAAAuN,EAAArN,GACdL,GAAAC,EAAAC,EAAA,cAAAyN,EAAAD,EAAArN,GAEFL,GAAAC,EAAAC,EAAA,gBAAAC,EAAAuN,EAIOrN,GAKLL,GAC4CC,EAAAC,EAAA,QAAAC,EAAAuN,EAAArN,GAE5CH,C,CQ4gBF0N,CAAAV,EAAAW,gBAAA1N,EAAAE,EAAAD,E;;;;;;;;;;;;;;;;GAmFE,IAAA0N,GA6lCEC,G,SA/9BAC,GAA4CC,EAAA9E,EAAAM,EAAAyE,G,MAC5CxoB,EAAWyjB,EAAAxwC,OAAA+sB,Q,GASZ,OAAAA,EAAA,CAED,MAAAwnB,EAAee,EAAkCE,MAAApvC,IAAA2mB,G,OAC3CxZ,GACF,MAAAghC,EACuB,gDAEvBE,GACgCF,EAAuB/D,EAAWM,EAAMyE,E,CAE3E,CAED,IAAAhO,EAAiB,GACf,IAAI,MAAKgN,KAAAe,EAAgBE,MAAAnuC,SACvBkgC,EAAOA,EAAIrtC,OAAAu6C,GAA6BF,EAAE/D,EAAAM,EAAAyE,I,OAE1ChO,C,WAq0BFkO,GAAyBH,EAAA5rB,G,IACzB8e,EAAA,K,IACA,MAAI+L,KAAMe,EAAaE,MAAMnuC,SAC3BmhC,EACEA,GAAA8L,GAAAC,EAAA7qB,G,OAIJ8e,C,CAiOJ,MAAMkN,GAoBHz1C,YAAA01C,GAjBDj8C,KAAAi8C,gBAA2CA,EAE1Cj8C,KAAAk8C,eAAA,IAAAzM,GAAA,MAqCGzvC,KAAOm8C,kB,eJvxBK5K,GAAkBW,Q,UAC1B,G,aAII,GIqxBZlyC,KAAOo8C,cAAI,IAAAxoC,IACZ5T,KAAAq8C,cAAA,IAAAzoC,GAED,E,SAIS0oC,GAAGC,EAAAvsB,EAAAwsB,EAAAxJ,EAAAjhB,GAiBX,O,SJx9CgB2gB,EAAA1iB,EAAAkX,EACP8L,EAAKjhB,G,GAKRihB,EAAAN,EAAAiB,YAAA,qDACDjtC,IAAAqrB,OAAA,G,EAeAkhB,UAAA52C,KAAA,CAOA2zB,OAEFkX,KAAMA,EACJ8L,UACAjhB,QAAOA,IAGZA,IAAA2gB,EAAAc,cAAAzB,GAAAW,EAAAc,cAAAxjB,EAAAkX,IAEKwL,EAAUiB,YAAAX,C,EIk6CbuJ,EAAAJ,kBAAAnsB,EAAAwsB,EAAAxJ,EAAAjhB,GAgBFA,EAED0qB,GAAAF,EAAA,IAAAtP,GTn8CI,CACDR,UAAM,EACLO,YAAA,EAEA3Z,QAAA,KAEDqZ,QAAA,GS67CH1c,EAAAwsB,IAFC,E,UAiCEE,GAAAH,EAAAvJ,EAAAlG,GAAA,GAqBF,MAAA+G,E,SJr8CGnB,EAAqBM,G,IAEnB,IAAA39C,EAAM,EAAAA,EAAOq9C,EAASO,UAAU39C,OAAAD,IAAA,CAChC,MAAKsnD,EACHjK,EAAAO,UAAA59C,GAGF,GAAAsnD,EAAM3J,UAAcA,EAAA,OAAA2J,C,QAMpB,I,CIw7CLC,CAAAL,EAAAJ,kBAAAnJ,GAoBC,GAlBFD,GAAAwJ,EAAAJ,kBAAAnJ,GAsBS,C,IAIApG,EAAa,IAAQ6C,GAExB,MAWF,OARF,MAAAoE,EAAA3M,KACA0F,EAAWA,EAAArgC,IAAAsjB,MAAkC,GAC9C1U,GAAA04B,EAAAlN,UAAAtY,IAEKue,IAAArgC,IAAA,IAAAujB,GAAkCzB,IAAA,MAIpCouB,GAAqCF,EAAc,IAAA5P,GAAAkH,EAAA7jB,KAAA4c,EAAAE,G,CApBnD,MAAM,E,CAyCR,SAAO+P,GAA+BN,EAACvsB,EAAAwsB,GACxC,OAAAC,GAAAF,EAAA,IAAAtP,GT1iDG,CACAR,UAAA,EACAO,YAAM,EACN3Z,QAAQ,K,QACN,GSsiDLrD,EAAAwsB,GAED,CGn0DE,SAASM,GAAAP,EAAAvsB,EAAAkX,EAAA9T,G,MACP2pB,EAAUC,GACiBT,EAAAnpB,G,GAEf,MAAZ2pB,EAAY,CACb,MAAAE,EAAAC,GAAAH,GAEMI,EAAAF,EAAAjtB,KAAAqD,EAAA4pB,EAAA5pB,QACDwc,EAAKxf,GAAwB8sB,EAAAntB,G,OAE/BotB,GAA0Bb,EAAAY,EAD1B,IAAAlQ,GAAqBT,GAA4BnZ,GAAAwc,EAAA3I,G,OAGlD,E,CCvPL,SAAAmW,GAAAd,EAAAvsB,EAAAskB,GAME,MACD5B,EAAA6J,EAAAJ,kBAEDmB,EAAAf,EAAAL,eAAArL,WAAA7gB,GAAA,CAAA2gB,EAAAiL,KAQE,MACO9M,EAAEiN,GAAAH,EADFvrB,GAAAsgB,EAAA3gB,I,GAEH8e,EAAa,OAAKA,CAAA,I,OAEpBqF,GAAAzB,EAAA1iB,EAAAstB,EAAAhJ,GAfK,E,CCoHT,SAAAmI,GAAAF,EAAAzF,GC/IA,OAAAyG,GAAAzG,EAAAyF,EAAAL,eAAA,KAAArJ,GAAA0J,EAAAJ,kBAAAtsB,MAyBA,C,SAK6B0tB,GAAUzG,EAAA0G,EAAA1O,EAAAsI,G,GAAIhnB,GAAY0mB,EAAA9mB,MAAA,OAAAytB,GAAA3G,EAAA0G,EAAA1O,EAAAsI,GACrD,CAEF,MAAAwE,EAAA4B,EAAA9wC,IAAAmjB,MAKyB,MAAlBif,GAAoB,MAAA8M,IAAA9M,EAAAiN,GAAAH,EAAA/rB,OAAE,IAAGge,EAAI,GAAI,MAAOnP,EAAC3O,GAAA+mB,EAAA9mB,MAC9C0tB,EAAA5G,EAAA3J,kBAAAzO,GAEFiD,EAAA6b,EAAA7W,SAAAj6B,IAAAgyB,GACkC,GAAAiD,GAAA+b,EAAW,CAE7C,MAAAC,EAGa7O,IAAArQ,kBAAaC,GAA+B,KAC3Ckf,EAAGC,GAAmCzG,EAAA1Y,GAClDmP,IAAArtC,OAAA+8C,GAEEG,EAEA/b,EAAIgc,EAAAC,GAEJ,CAIA,OADAhC,IAAY/N,EAAMA,EAAYrtC,OAAMm7C,GAAkBC,EAAA9E,EAAAM,EAAAtI,KACtDjB,CACF,C,CAK8B,SAAA4P,GAAS3G,EAAA0G,EAAA1O,EAAAsI,GAEzC,MAAAwE,EAAA4B,EAAA9wC,IAAAmjB,MAMA,MAAAif,GAAA,MAAA8M,IAAA9M,EAAAiN,GAAAH,EAAA/rB,OCzEA,IAAAge,EAAA,G;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;kgCCAA,IAAArc,EAAAssB,I,GAAAtsB,E,GAqJeN,OAAA57B,OAAA,IAAAk8B,EAAcJ,aAAQ,G,EAClCF,OAAA70B,KAAAyhD,GAJDtsB,EAAmBJ,aAA+BE,GAAAwsB,G,GAAnBtsB,G,mBAAuBA,GAKvD,MAAAusB,EAAAvsB,EAAAN,OAAA6J,MrDvJDvJ,EAAAJ,aAAAE,GAAAysB,GA+BIvsB,EAAYN,OAAQ57B,OAAW,IAAAk8B,EAAAJ,aAAA,E;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;uhBb6G9B,iBAAA/3B,eAAA,WAAAA,OAAA,yBmElHI2kD,OAAA,6FACiB,E,4uBhE+jBV3+B,EAAA4+B,G,QACA5+B,EAAQjpB,W,6BAEKupB,E,o4B0D9WlBo9B,EAAaC,GAAMT,EAAAnpB,G,GAEjB2pB,EAAG,C,WAZCA,G,qBAaXlN,EAAAxf,GAAA8sB,EAAAntB,GAmCLkuB,EAAAzO,GAAA0O,WAAA3G,GAGK,OAAA4F,GAAiBb,EACnBY,EAFK,IAAAjQ,GAAkBV,GAAAnZ,GAAAwc,EAAAqO,GAM1B,CAED,Q,2HH2yDwB3B,EACZvsB,EACNwnB,G,MAIH0G,EAAAzO,GAAA0O,WAAA3G,GACF,OAAAiF,GAAAF,EAAA,IAAArP,GT1jDG,CACAT,UAAA,EACAO,YAAM,EACN3Z,QAAQ,K,QACN,GSsjDLrD,EAAAkuB,GAED,C;;;;;;;;;;;;;;;;kT7D5qDkB,oBAAN7kD,QAAMA,OAAAwpB,UAAAxpB,OAAAwpB,SAAAlE,WAAA,IAAAtlB,OAAAwpB,SAAAlE,SAAAQ,QAAA,WAAAvC,GAAA,6F;;;;;;;;;;;;;;;;;weekkBfoT,GAEO,IAAA3B,EAAA,G,IACN,IAAAh5B,EAAA26B,EAAAR,UAAAn6B,EAAI26B,EAAAP,QAAAn6B,OAAAD,IAAiD,KAAnB26B,EAAAP,QAAap6B,KAAMg5B,GAAa,IAAA+vB,mBAAAnmD,OAAA+3B,EAAAP,QAAAp6B,M,OAClEg5B,GAAK,G,mvB8CnMqBxe,GAC5BgK,IAAsB4hC,GAAwC,mDAC9DA,GAAoB5rC,C,eAy/BhBA,GAKHgK,IAAA6hC,GAAA,mDA5BDA,GAEgC7rC,C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;YhEzsDhCqI,GNvBS,S;;;;;;;;;;;;;;;;MgF3CXmmC,eAAiB,CACfC,YAAa,wCAGf,MAAMC,GAAMvnC,GAAcqnC,iBAI1B,SAAuBG,EAAQz/C,EAAM0/C,GACnC,MAAMjrC,EAAKkrC,GAAYH,IACvBxhD,QAAQC,IAAIwW,GAEZmrC,GAAIC,GAAIprC,EAAI,SAAWgrC,GAAS,CAC9BK,SAAU9/C,EACV0/C,MAAOA,G,CAIXK,CACE,+BACA,OACA,8BAkBF,SAASC,GAAW9jD,GACJrD,SAASC,cAAc,oBAC/BqB,MAAMyqB,QAAU,M,CAGxB,SAASq7B,GAAgB/jD,GACvBA,EAAEC,kBA6BJ,SAAkCujD,EAAO78B,GAChC1nB,MACL,oHACA,CACEyV,OAAQ,OACRqR,KAAMprB,KAAK4G,UAAU,C,MACnBiiD,E,SACA78B,EACAq9B,mBAAmB,IAErB13B,QAAS,CACP,eAAgB,sBAInBptB,MAAKk7B,GAAOA,EAAI96B,SAChBJ,MAAKU,IACJkC,QAAQC,IAAInC,EAAK,G,CA1CrBqkD,CAHctnD,SAASunD,eAAe,SAAS12C,MAC9B7Q,SAASunD,eAAe,YAAY12C,M,CAvBvC7Q,SAASC,cAAc,aAC/BQ,iBAAiB,SAEzB,WACE,MAAM+mD,EAAQxnD,SAASC,cAAc,oBACrCunD,EAAMlmD,MAAMyqB,QAAU,QACtBy7B,EAAMtjD,UAuBC,mwBAtBPlE,SACGunD,eAAe,aACf9mD,iBAAiB,SAAU2mD,GAAiB,CAAEj9C,MAAM,IACvDnK,SACGC,cAAc,sBACdQ,iBAAiB,QAAS0mD,G","sources":["node_modules/@parcel/runtime-js/lib/helpers/bundle-manifest.js","node_modules/@parcel/runtime-js/lib/runtime-b0520059e25b2595.js","node_modules/@parcel/runtime-js/lib/runtime-235f18115fe0f525.js","node_modules/@parcel/runtime-js/lib/runtime-f76010fd07ac1420.js","node_modules/@parcel/runtime-js/lib/runtime-a4f445d543be2cd8.js","node_modules/@parcel/runtime-js/lib/runtime-328ffd4eaea21f9e.js","node_modules/@parcel/runtime-js/lib/runtime-8622252ff6dbe9dc.js","node_modules/@parcel/runtime-js/lib/runtime-d84f211c5369fa29.js","node_modules/@parcel/runtime-js/lib/runtime-7e145d9c0236e64c.js","node_modules/@parcel/runtime-js/lib/runtime-ebf890fa0c00dda1.js","node_modules/@parcel/runtime-js/lib/runtime-2408f76825ad4172.js","node_modules/@parcel/runtime-js/lib/runtime-7fbf2e3753ab3517.js","node_modules/@parcel/runtime-js/lib/runtime-3398cdbafceaf935.js","node_modules/@parcel/runtime-js/lib/runtime-7577423c14945f0d.js","node_modules/@parcel/runtime-js/lib/runtime-54eabefdef3e6670.js","node_modules/@parcel/runtime-js/lib/runtime-4eaeead55b77730b.js","node_modules/@parcel/runtime-js/lib/runtime-a44e90bf1446c390.js","node_modules/@parcel/runtime-js/lib/runtime-39fd2dff3786b309.js","node_modules/@parcel/runtime-js/lib/runtime-5dda941c1991bcc7.js","node_modules/@parcel/runtime-js/lib/runtime-b9ea08008c2775e5.js","src/js/home__support.js","src/js/books-api.js","src/js/home-category.js","src/js/books-container.js","src/js/dark-theme.js","src/js/modal-window/modal.js","src/js/header.js","node_modules/process/browser.js","node_modules/@firebase/util/src/crypt.ts","node_modules/@firebase/util/src/deepCopy.ts","node_modules/@firebase/util/src/global.ts","node_modules/@firebase/util/src/defaults.ts","node_modules/@firebase/util/src/deferred.ts","node_modules/@firebase/util/src/emulator.ts","node_modules/@firebase/util/src/environment.ts","node_modules/@firebase/util/src/errors.ts","node_modules/@firebase/util/src/json.ts","node_modules/@firebase/util/src/jwt.ts","node_modules/@firebase/util/src/obj.ts","node_modules/@firebase/util/src/promise.ts","node_modules/@firebase/util/src/query.ts","node_modules/@firebase/util/src/sha1.ts","node_modules/@firebase/util/src/subscribe.ts","node_modules/@firebase/util/src/validation.ts","node_modules/@firebase/util/src/utf8.ts","node_modules/@firebase/util/src/uuid.ts","node_modules/@firebase/util/src/exponential_backoff.ts","node_modules/@firebase/util/src/formatters.ts","node_modules/@firebase/util/src/compat.ts","node_modules/@firebase/component/src/component.ts","node_modules/@firebase/component/src/constants.ts","node_modules/@firebase/component/src/provider.ts","node_modules/@firebase/component/src/component_container.ts","node_modules/@firebase/logger/src/logger.ts","node_modules/idb/build/wrap-idb-value.js","node_modules/idb/build/index.js","node_modules/@firebase/app/src/platformLoggerService.ts","node_modules/@firebase/app/src/logger.ts","node_modules/@firebase/app/src/constants.ts","node_modules/@firebase/app/src/internal.ts","node_modules/@firebase/app/src/errors.ts","node_modules/@firebase/app/src/firebaseApp.ts","node_modules/@firebase/app/src/api.ts","node_modules/@firebase/app/src/indexeddb.ts","node_modules/@firebase/app/src/heartbeatService.ts","node_modules/@firebase/database/src/core/storage/DOMStorageWrapper.ts","node_modules/@firebase/database/src/core/storage/MemoryStorage.ts","node_modules/@firebase/database/src/core/storage/storage.ts","node_modules/@firebase/database/src/core/util/util.ts","node_modules/@firebase/database/src/core/AppCheckTokenProvider.ts","node_modules/@firebase/database/src/core/AuthTokenProvider.ts","node_modules/@firebase/database/src/core/RepoInfo.ts","node_modules/@firebase/database/src/core/stats/StatsManager.ts","node_modules/@firebase/database/src/realtime/polling/PacketReceiver.ts","node_modules/@firebase/database/src/realtime/BrowserPollConnection.ts","node_modules/@firebase/database/src/realtime/WebSocketConnection.ts","node_modules/@firebase/database/src/realtime/TransportManager.ts","node_modules/@firebase/database/src/realtime/Connection.ts","node_modules/@firebase/database/src/core/ServerActions.ts","node_modules/@firebase/database/src/core/util/EventEmitter.ts","node_modules/@firebase/database/src/core/util/OnlineMonitor.ts","node_modules/@firebase/database/src/core/util/Path.ts","node_modules/@firebase/database/src/core/util/VisibilityMonitor.ts","node_modules/@firebase/database/src/core/PersistentConnection.ts","node_modules/@firebase/database/src/core/snap/indexes/Index.ts","node_modules/@firebase/database/src/core/snap/indexes/KeyIndex.ts","node_modules/@firebase/database/src/core/util/SortedMap.ts","node_modules/@firebase/database/src/core/snap/comparators.ts","node_modules/@firebase/database/src/core/snap/snap.ts","node_modules/@firebase/database/src/core/snap/LeafNode.ts","node_modules/@firebase/database/src/core/snap/indexes/PriorityIndex.ts","node_modules/@firebase/database/src/core/snap/childSet.ts","node_modules/@firebase/database/src/core/snap/IndexMap.ts","node_modules/@firebase/database/src/core/snap/ChildrenNode.ts","node_modules/@firebase/database/src/core/snap/nodeFromJSON.ts","node_modules/@firebase/database/src/core/snap/indexes/PathIndex.ts","node_modules/@firebase/database/src/core/snap/indexes/ValueIndex.ts","node_modules/@firebase/database/src/core/view/Change.ts","node_modules/@firebase/database/src/core/view/filter/IndexedFilter.ts","node_modules/@firebase/database/src/core/view/filter/RangedFilter.ts","node_modules/@firebase/database/src/core/view/filter/LimitedFilter.ts","node_modules/@firebase/database/src/core/view/QueryParams.ts","node_modules/@firebase/database/src/core/ReadonlyRestClient.ts","node_modules/@firebase/database/src/core/SparseSnapshotTree.ts","node_modules/@firebase/database/src/core/SnapshotHolder.ts","node_modules/@firebase/database/src/core/stats/StatsListener.ts","node_modules/@firebase/database/src/core/stats/StatsReporter.ts","node_modules/@firebase/database/src/core/operation/Operation.ts","node_modules/@firebase/database/src/core/operation/ListenComplete.ts","node_modules/@firebase/database/src/core/operation/Overwrite.ts","node_modules/@firebase/database/src/core/operation/Merge.ts","node_modules/@firebase/database/src/core/view/CacheNode.ts","node_modules/@firebase/database/src/core/view/EventGenerator.ts","node_modules/@firebase/database/src/core/view/ViewCache.ts","node_modules/@firebase/database/src/core/util/ImmutableTree.ts","node_modules/@firebase/database/src/core/CompoundWrite.ts","node_modules/@firebase/database/src/core/WriteTree.ts","node_modules/@firebase/database/src/core/view/ViewProcessor.ts","node_modules/@firebase/database/src/core/view/View.ts","node_modules/@firebase/database/src/core/SyncPoint.ts","node_modules/@firebase/database/src/core/SyncTree.ts","node_modules/@firebase/database/src/core/util/ServerValues.ts","node_modules/@firebase/database/src/core/util/Tree.ts","node_modules/@firebase/database/src/core/util/validation.ts","node_modules/@firebase/database/src/core/view/EventQueue.ts","node_modules/@firebase/database/src/core/Repo.ts","node_modules/@firebase/database/src/core/util/libs/parser.ts","node_modules/@firebase/database/src/core/view/Event.ts","node_modules/@firebase/database/src/core/view/EventRegistration.ts","node_modules/@firebase/database/src/api/Reference_impl.ts","node_modules/@firebase/database/src/api/OnDisconnect.ts","node_modules/@firebase/database/src/core/util/NextPushId.ts","node_modules/@firebase/database/src/api/Database.ts","node_modules/@firebase/database/src/api/ServerValue.ts","node_modules/@firebase/database/src/api/Transaction.ts","node_modules/@firebase/database/src/api/test_access.ts","node_modules/@firebase/database/src/index.ts","node_modules/@firebase/database/src/core/snap/Node.ts","node_modules/@firebase/database/src/core/stats/StatsCollection.ts","src/js/auth.js"],"sourcesContent":["\"use strict\";\n\nvar mapping = {};\n\nfunction register(pairs) {\n  var keys = Object.keys(pairs);\n\n  for (var i = 0; i < keys.length; i++) {\n    mapping[keys[i]] = pairs[keys[i]];\n  }\n}\n\nfunction resolve(id) {\n  var resolved = mapping[id];\n\n  if (resolved == null) {\n    throw new Error('Could not resolve bundle with id ' + id);\n  }\n\n  return resolved;\n}\n\nmodule.exports.register = register;\nmodule.exports.resolve = resolve;","require('./helpers/bundle-manifest').register(JSON.parse(\"{\\\"7bk21\\\":\\\"index.8c9125d9.js\\\",\\\"ljMJW\\\":\\\"save-the-children.afa9e55b.png\\\",\\\"gY1tF\\\":\\\"project-hope.6b951dc9.png\\\",\\\"ibwo6\\\":\\\"international-medical-corps.38e7f653.png\\\",\\\"8dNy0\\\":\\\"razom.61fc7ccd.png\\\",\\\"ft6U1\\\":\\\"action-against-hunger.2a8c3c0d.png\\\",\\\"3PaSI\\\":\\\"serhiy-prytula.69cae55e.png\\\",\\\"hMNVA\\\":\\\"united24.7e58352b.png\\\",\\\"eK3Ks\\\":\\\"medecins-sans-frontieres.9cc61963.png\\\",\\\"kFlNH\\\":\\\"world-vision.544fa60d.png\\\",\\\"cZUbX\\\":\\\"save-the-children2x.688b6dc7.png\\\",\\\"dZnsA\\\":\\\"project-hope2x.ee6ab1e6.png\\\",\\\"bwGiv\\\":\\\"international-medical-corps2x.2c438457.png\\\",\\\"e2COv\\\":\\\"razom2x.49347143.png\\\",\\\"8DGUa\\\":\\\"action-against-hunger2x.68b93551.png\\\",\\\"bACnJ\\\":\\\"serhiy-prytula2x.b3afcdef.png\\\",\\\"iBcPS\\\":\\\"united24-2x.d41967f5.png\\\",\\\"bhhC2\\\":\\\"medecins-sans-frontieres2x.b0544e06.png\\\",\\\"3Dl6E\\\":\\\"world-vision2x.01220224.png\\\"}\"));","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"ljMJW\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"gY1tF\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"ibwo6\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"8dNy0\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"ft6U1\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"3PaSI\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"hMNVA\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"eK3Ks\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"kFlNH\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"cZUbX\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"dZnsA\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"bwGiv\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"e2COv\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"8DGUa\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"bACnJ\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"iBcPS\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"bhhC2\")).toString();","module.exports = new __parcel__URL__(require('./helpers/bundle-manifest').resolve(\"3Dl6E\")).toString();","const supportArray = [\n  {\n    title: 'Save the Children',\n    url: 'https://www.savethechildren.net/what-we-do/emergencies/ukraine-crisis',\n    img: caveTheChildren,\n    img2x: caveTheChildren2x,\n  },\n  {\n    title: 'Project HOPE',\n    url: 'https://www.projecthope.org/country/ukraine/',\n    img: projectHope,\n    img2x: projectHope2x,\n  },\n  {\n    title: 'International Medical Corps',\n    url: 'https://internationalmedicalcorps.org/country/ukraine/',\n    img: internationalMedicalCorps,\n    img2x: internationalMedicalCorps2x,\n  },\n  {\n    title: 'RAZOM',\n    url: 'https://www.razomforukraine.org/',\n    img: razom,\n    img2x: razom2x,\n  },\n  {\n    title: 'Action against hunger',\n    url: 'https://www.actionagainsthunger.org/location/europe/ukraine/',\n    img: actionAgainstHunger,\n    img2x: actionAgainstHunger2x,\n  },\n  {\n    title: 'Serhiy Prytula Charity Foundation',\n    url: 'https://prytulafoundation.org/en',\n    img: serhiyPrytulaCharityFoundation,\n    img2x: serhiyPrytulaCharityFoundation2x,\n  },\n  {\n    title: 'UNITED24',\n    url: 'https://u24.gov.ua/uk',\n    img: united,\n    img2x: united2x,\n  },\n  {\n    title: 'Medecins Sans Frontieres',\n    url: 'https://www.msf.org/ukraine',\n    img: medecinsSansFrontieres,\n    img2x: medecinsSansFrontieres2x,\n  },\n  {\n    title: 'World vision',\n    url: 'https://www.wvi.org/emergencies/ukraine',\n    img: worldVision,\n    img2x: worldVision2x,\n  },\n];\n\nimport caveTheChildren from '../images/support-ua/save-the-children.png';\nimport projectHope from '../images/support-ua/project-hope.png';\nimport internationalMedicalCorps from '../images/support-ua/international-medical-corps.png';\nimport razom from '../images/support-ua/razom.png';\nimport actionAgainstHunger from '../images/support-ua/action-against-hunger.png';\nimport serhiyPrytulaCharityFoundation from '../images/support-ua/serhiy-prytula.png';\nimport united from '../images/support-ua/united24.png';\nimport medecinsSansFrontieres from '../images/support-ua/medecins-sans-frontieres.png';\nimport worldVision from '../images/support-ua/world-vision.png';\nimport caveTheChildren2x from '../images/support-ua/save-the-children2x.png';\nimport projectHope2x from '../images/support-ua/project-hope2x.png';\nimport internationalMedicalCorps2x from '../images/support-ua/international-medical-corps2x.png';\nimport razom2x from '../images/support-ua/razom2x.png';\nimport actionAgainstHunger2x from '../images/support-ua/action-against-hunger2x.png';\nimport serhiyPrytulaCharityFoundation2x from '../images/support-ua/serhiy-prytula2x.png';\nimport united2x from '../images/support-ua/united24-2x.png';\nimport medecinsSansFrontieres2x from '../images/support-ua/medecins-sans-frontieres2x.png';\nimport worldVision2x from '../images/support-ua/world-vision2x.png';\n\nconst supportList = document.querySelector('.js-support');\nconst markup = createImageCardMarkup(supportArray);\n\nsupportList.insertAdjacentHTML('beforeend', markup);\nsupportList.addEventListener('click', onClick);\n\nfunction createImageCardMarkup(supportArray) {\n\n  return supportArray\n    .map(({ title, url, img, img2x }, ind) => {\n      let num = String(ind + 1).padStart(2, '0');\n      return `<li class=\"support-link js-support\">\n        <a class=\"js-target\" href=\"${url}\" target=\"_blank\">\n          <span class=\"support-number\">${num}\n          <img class=\"support__img\" srcset=\"${img} 1x, ${img2x} 2x\"\n          src=\"${img}\" alt=\"${title}\"/></span>\n        </a>\n      </li>`;\n    })\n    .join('');\n}\n\nfunction onClick(evt) {\n  if (!evt.target.classList.contains('js-support')) {\n    return;\n  }\n}\n\nlet position = 0;\nlet slidesToShow = 6;\nlet slidesToScroll = 1;\n\nconst container = document.querySelector('.slider-container');\nconst list = document.querySelector('.support-list');\nconst sliderButton = document.querySelector('.slider-button');\nconst itemsSupport = document.querySelectorAll('.support-link');\nlet itemsCount = itemsSupport.length;\nconst sliderItemHeight = 32;\nconst movePosition = slidesToScroll * sliderItemHeight;\n\nitemsSupport.forEach((item) => {\n  item.style.minHeight = `${sliderItemHeight}px`;\n});\n\nsliderButton.addEventListener('click', () => {\n  const itemsBottom = getItemsBottom();\n\n  if (itemsBottom >= slidesToScroll) {\n    position -= movePosition;\n  } else {\n    position = 0;\n  }\n\n\n  list.style.transition = 'transform 0.3s ease-out';\n  setPosition();\n\n  setTimeout(() => {\n    list.style.transition = '';\n  }, 300);\n});\n\nwindow.addEventListener('resize', () => {\n  itemsCount = itemsSupport.length;\n  setPosition();\n});\n\nconst setPosition = () => {\n  list.style.transform = `translateY(${position}px)`;\n};\n\nfunction getItemsBottom() {\n  const windowWidth = window.innerWidth;\n\n  if (windowWidth >= 1440) {\n    return itemsCount - (Math.abs(position) + slidesToShow * sliderItemHeight) / 39;\n  } else if (windowWidth >= 768) {\n    return itemsCount - (Math.abs(position) + slidesToShow * sliderItemHeight) / 40;\n  } else {\n    return itemsCount - (Math.abs(position) + slidesToShow * sliderItemHeight) / 55;\n  }\n}","const API_URL = `https://books-backend.p.goit.global/`;\n\nconst fetchBookCategories = () => {\n    const url = `${API_URL}books/category-list`;\n    return fetch(url).then(response => {\n        if (!response.ok) {\n            throw new Error(response.status);\n        }\n        return response.json();\n    });\n};\n\nconst fetchTopBooks = () => {\n    const url = `${API_URL}books/top-books`;\n    return fetch(url).then(response => {\n        if (!response.ok) {\n            throw new Error(response.status);\n        }\n        return response.json();\n    });\n};\n\nconst fetchBookByCategory = bookCategory => {\n    const url = `${API_URL}books/category?category=${bookCategory}`;\n    return fetch(url).then(response => {\n        if (!response.ok) {\n            throw new Error(response.status);\n        } else {\n            return response.json();\n        }\n    });\n};\n\nconst fetchBookID = (bookId) => {\n    const url = `${API_URL}books/${bookId}`;\n    return fetch(url).then(response => {\n        if (!response.ok) {\n            throw new Error(response.status);\n        }\n        return response.json();\n    });\n};\n\nexport { fetchBookCategories, fetchTopBooks, fetchBookByCategory, fetchBookID };","import { fetchBookCategories, fetchBookByCategory, fetchTopBooks , renderAllCards  } from './books-api';\nconst refs = {\n  divEl: document.querySelector('.category-list'),\n  allcategory: document.querySelector('.all-category'),\n  onecategoryEl: document.querySelector('.category-link'),\n  categoriesList: document.querySelector('.books-in-categories-list'),\n};\n\nfetchBookCategories().then(data => {\n  data.map(book => {\n    const markup = `<li class=\"list category-item\">\n        <a class=\"category-link\" href=\"#\">${book.list_name}</a>\n      </li>`;\n    refs.divEl.insertAdjacentHTML('beforeend', markup);\n  });\n});\nrefs.divEl.addEventListener('click', onCategoryClick);\n\nfunction onCategoryClick(e) {\n  if (!e.target.classList.contains('category-link')) {\n    return;\n  }\n  e.preventDefault();\n\n  let activeBook = document.querySelector('.is-active');\n\n  if (activeBook) {\n    activeBook.classList.remove('is-active');\n  }\n\n  e.target.classList.add('is-active');\n\n  let titleCategory = document.querySelector('.booklist-title');\n  let titleTextContent = e.target.textContent;\n  titleCategory.textContent = titleTextContent;\n\n  refs.categoriesList.classList.add('render-category');\n\n  fetchBookByCategory(e.target.textContent).then(data => renderMarkupBooksByCategory(takeBookMarkupByCategory(data)))\n\n}\n\n\nfunction takeBookMarkupByCategory(books) { \n  let markup = books.map(({ author, title, book_image, _id }) => {\n  \n    return `\n      <li class=\"book-card render-item-card\" data-id=\"${_id}\">\n        <div class=\"thumb\">\n          <img class=\"book-cover\" src=\"${book_image}\" alt=\"${title}\" loading=\"lazy\" />\n        </div>\n        <h4 class=\"render-title\">${title}</h4>\n        <p class=\"render-author\">${author}</p>\n      </li>`;\n    \n  }).join('');\n  return markup;\n};\n\nfunction renderMarkupBooksByCategory(markup) { \n  refs.categoriesList.innerHTML = markup;\n};","import { fetchTopBooks } from './books-api';\nconst refs = {\n  categoriesList: document.querySelector('.books-in-categories-list'),\n};\nfetchTopBooks().then(renderAllCards);\nasync function renderAllCards(data) {\n  let booksArr = [];\n\n  data.forEach(category => {\n    let markup_base = `<li class=\"category-item\">\n    <h3>${category.books[0].list_name}</h3>\n    <ul class=\"bookslist\">`;\n    let markup = ``;\n\n    category.books.map(book => {\n      booksArr.push(book);\n      markup =\n        markup +\n        `\n      <li class=\"book-card\" data-id=\"${book._id}\">\n        <div class=\"thumb\">\n          <img class=\"book-cover\" src=\"${book.book_image}\" alt=\"${book.title}\" loading=\"lazy\" />\n        </div>\n        <h4 class=\"book-title\">${book.title}</h4>\n        <p>${book.author}</p>\n      </li>`;\n    });\n    markup_base =\n      markup_base +\n      markup +\n      `</ul><div class=\"button-container\" ><button class=\"books-by-category\" data-category-name=\"${category.books[0].list_name}\">See more</button></div></li>`;\n    refs.categoriesList.insertAdjacentHTML('beforeend', markup_base);\n  });\n\n  localStorage.setItem('books', JSON.stringify(booksArr));\n}\n\nrefs.categoriesList.addEventListener('click', onMoreBtnClick);\n\nfunction onMoreBtnClick(e) {\n  if (e.target.nodeName !== \"BUTTON\") {\n    return;\n  }\n  //console.log(e.target.getAttribute('data-category-name'))\n}","document.addEventListener('DOMContentLoaded', () => {\n  const switchInput = document.querySelector('.switch input');\n  switchInput.checked = localStorage.getItem('theme') === 'dark';\n\n  document.querySelector('.switch').addEventListener('click', event => {\n    const theme = switchInput.checked ? 'dark' : '';\n    if (theme === 'dark') {\n      localStorage.setItem('theme', 'dark');\n    } else {\n      localStorage.removeItem('theme');\n    }\n\n    addDarkClassToHTML();\n  });\n\n  function addDarkClassToHTML() {\n    try {\n      if (localStorage.getItem('theme') === 'dark') {\n        document.querySelector('body').classList.toggle('dark-theme');\n      } else {\n        document.querySelector('body').classList.remove('dark-theme');\n      }\n    } catch (error) {\n      console.log(error);\n    }\n  }\n\n  function updateSliderClass() {\n    const slider = document.querySelector('.slider');\n    if (localStorage.getItem('theme') === 'dark') {\n      slider.classList.add('dark-theme');\n    } else {\n      slider.classList.remove('dark-theme');\n    }\n  }\n\n  addDarkClassToHTML();\n  updateSliderClass();\n});\n","import { fetchBookID } from '../books-api'\n// import { createMarkup } from \"./modal-markup\";\n\nlet modalBody = document.querySelector(\"body\")\nlet modalOpenWindow = document.querySelector(\".modal_window\")\nlet modalMain = document.querySelector(\".modal-main\")\nconst bookCover = document.querySelector(\".modal-cover\")\nconst modalTitle = document.querySelector(\".modal-title\")\nconst modalAuthor = document.querySelector(\".modal-author\")\nconst modalDescription = document.querySelector(\".modal-description\")\nconst amazon = document.querySelector(\".amazon\")\nconst apple = document.querySelector(\".apple\")\nconst bookShop = document.querySelector(\".bookshop\")\n\nmodalBody.addEventListener('click', currentBook)\n\nfunction currentBook() {  \n    const bookCards = document.querySelectorAll('[data-id]');\n    bookCards.forEach(card => {    \n        card.addEventListener('click', () => {\n            const bookId = card.dataset.id;\n            modalBody.removeEventListener('click', currentBook)\n            fetchBookID(bookId).then(data => {\n\ncreateMarkup(data)\n                // modalOpenWindow.innerHTML = createMarkup(data)\n                blockScroll()\n                eventListeners()\n            }).catch((error) => {\n      console.log('Error:', error);\n    });\n        });\n    });\n}\n\nfunction createMarkup(data) {\n                modalOpenWindow.classList.add(\"overlay\")\n                modalMain.style.visibility = \"visible\"\n                modalMain.style.opacity = \"1\"\n                bookCover.src = data.book_image\n                bookCover.alt = data.title\n                modalTitle.textContent = data.title\n                modalAuthor.textContent = data.author\n    modalDescription.textContent = data.description\n    topBookShopLink(data)\n}\n\nfunction topBookShopLink({buy_links}) {\n    return buy_links.map(arr => {\n        if (arr.name === \"Amazon\") {amazon.href = arr.url}\n        if (arr.name === \"Bookshop\") {bookShop.href =  arr.url}\n        if (arr.name === \"Apple Books\") {apple.href =  arr.url}\n    })\n}\n    \nfunction eventListeners() {\n    const buttonClose = document.querySelector(\".modal_btn_close\")\n    buttonClose.addEventListener(\"click\", closeModal)\n    modalBody.addEventListener('click', onOverlayCloseModal)\n    modalBody.addEventListener('keydown', onEscCloseModal)\n    modalBody.addEventListener(\"scroll\", (e) => { e.preventDefault() })\n}\n\nfunction blockScroll() {\n    modalBody.classList.add(\"no_scroll\")\n}\n\nfunction closeModal() {\n    modalBody.classList.remove(\"no_scroll\")\n    modalOpenWindow.classList.remove(\"overlay\")\n                    modalMain.style.visibility = \"hidden\"\n                modalMain.style.opacity = \"0\"\n    // modalOpenWindow.innerHTML = \"\"\n    modalBody.removeEventListener('click', onOverlayCloseModal)\n    modalBody.removeEventListener('keydown', onEscCloseModal)\n}\n\nfunction onOverlayCloseModal(e) {\n    if (e.target !== modalOpenWindow) {\n        return\n    }\n    closeModal()\n}\n\nfunction onEscCloseModal(e) {\n    if (e.code !== \"Escape\") {\n        return\n    }\n    closeModal()\n}\n\n","const menuOpen = document.querySelector('.icon-menu-open');\nconst iconBurger = document.querySelector('.header-icon-open');\nconst iconClose = document.querySelector('.header-icon-close');\nmenuOpen.addEventListener('click', onClick);\nfunction onClick(e) {\n  iconBurger.classList.toggle('icon-display-none');\n  iconClose.classList.toggle('icon-display-none');\n}\n","// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst stringToByteArray = function (str: string): number[] {\n  // TODO(user): Use native implementations if/when available\n  const out: number[] = [];\n  let p = 0;\n  for (let i = 0; i < str.length; i++) {\n    let c = str.charCodeAt(i);\n    if (c < 128) {\n      out[p++] = c;\n    } else if (c < 2048) {\n      out[p++] = (c >> 6) | 192;\n      out[p++] = (c & 63) | 128;\n    } else if (\n      (c & 0xfc00) === 0xd800 &&\n      i + 1 < str.length &&\n      (str.charCodeAt(i + 1) & 0xfc00) === 0xdc00\n    ) {\n      // Surrogate Pair\n      c = 0x10000 + ((c & 0x03ff) << 10) + (str.charCodeAt(++i) & 0x03ff);\n      out[p++] = (c >> 18) | 240;\n      out[p++] = ((c >> 12) & 63) | 128;\n      out[p++] = ((c >> 6) & 63) | 128;\n      out[p++] = (c & 63) | 128;\n    } else {\n      out[p++] = (c >> 12) | 224;\n      out[p++] = ((c >> 6) & 63) | 128;\n      out[p++] = (c & 63) | 128;\n    }\n  }\n  return out;\n};\n\n/**\n * Turns an array of numbers into the string given by the concatenation of the\n * characters to which the numbers correspond.\n * @param bytes Array of numbers representing characters.\n * @return Stringification of the array.\n */\nconst byteArrayToString = function (bytes: number[]): string {\n  // TODO(user): Use native implementations if/when available\n  const out: string[] = [];\n  let pos = 0,\n    c = 0;\n  while (pos < bytes.length) {\n    const c1 = bytes[pos++];\n    if (c1 < 128) {\n      out[c++] = String.fromCharCode(c1);\n    } else if (c1 > 191 && c1 < 224) {\n      const c2 = bytes[pos++];\n      out[c++] = String.fromCharCode(((c1 & 31) << 6) | (c2 & 63));\n    } else if (c1 > 239 && c1 < 365) {\n      // Surrogate Pair\n      const c2 = bytes[pos++];\n      const c3 = bytes[pos++];\n      const c4 = bytes[pos++];\n      const u =\n        (((c1 & 7) << 18) | ((c2 & 63) << 12) | ((c3 & 63) << 6) | (c4 & 63)) -\n        0x10000;\n      out[c++] = String.fromCharCode(0xd800 + (u >> 10));\n      out[c++] = String.fromCharCode(0xdc00 + (u & 1023));\n    } else {\n      const c2 = bytes[pos++];\n      const c3 = bytes[pos++];\n      out[c++] = String.fromCharCode(\n        ((c1 & 15) << 12) | ((c2 & 63) << 6) | (c3 & 63)\n      );\n    }\n  }\n  return out.join('');\n};\n\ninterface Base64 {\n  byteToCharMap_: { [key: number]: string } | null;\n  charToByteMap_: { [key: string]: number } | null;\n  byteToCharMapWebSafe_: { [key: number]: string } | null;\n  charToByteMapWebSafe_: { [key: string]: number } | null;\n  ENCODED_VALS_BASE: string;\n  readonly ENCODED_VALS: string;\n  readonly ENCODED_VALS_WEBSAFE: string;\n  HAS_NATIVE_SUPPORT: boolean;\n  encodeByteArray(input: number[] | Uint8Array, webSafe?: boolean): string;\n  encodeString(input: string, webSafe?: boolean): string;\n  decodeString(input: string, webSafe: boolean): string;\n  decodeStringToByteArray(input: string, webSafe: boolean): number[];\n  init_(): void;\n}\n\n// We define it as an object literal instead of a class because a class compiled down to es5 can't\n// be treeshaked. https://github.com/rollup/rollup/issues/1691\n// Static lookup maps, lazily populated by init_()\nexport const base64: Base64 = {\n  /**\n   * Maps bytes to characters.\n   */\n  byteToCharMap_: null,\n\n  /**\n   * Maps characters to bytes.\n   */\n  charToByteMap_: null,\n\n  /**\n   * Maps bytes to websafe characters.\n   * @private\n   */\n  byteToCharMapWebSafe_: null,\n\n  /**\n   * Maps websafe characters to bytes.\n   * @private\n   */\n  charToByteMapWebSafe_: null,\n\n  /**\n   * Our default alphabet, shared between\n   * ENCODED_VALS and ENCODED_VALS_WEBSAFE\n   */\n  ENCODED_VALS_BASE:\n    'ABCDEFGHIJKLMNOPQRSTUVWXYZ' + 'abcdefghijklmnopqrstuvwxyz' + '0123456789',\n\n  /**\n   * Our default alphabet. Value 64 (=) is special; it means \"nothing.\"\n   */\n  get ENCODED_VALS() {\n    return this.ENCODED_VALS_BASE + '+/=';\n  },\n\n  /**\n   * Our websafe alphabet.\n   */\n  get ENCODED_VALS_WEBSAFE() {\n    return this.ENCODED_VALS_BASE + '-_.';\n  },\n\n  /**\n   * Whether this browser supports the atob and btoa functions. This extension\n   * started at Mozilla but is now implemented by many browsers. We use the\n   * ASSUME_* variables to avoid pulling in the full useragent detection library\n   * but still allowing the standard per-browser compilations.\n   *\n   */\n  HAS_NATIVE_SUPPORT: typeof atob === 'function',\n\n  /**\n   * Base64-encode an array of bytes.\n   *\n   * @param input An array of bytes (numbers with\n   *     value in [0, 255]) to encode.\n   * @param webSafe Boolean indicating we should use the\n   *     alternative alphabet.\n   * @return The base64 encoded string.\n   */\n  encodeByteArray(input: number[] | Uint8Array, webSafe?: boolean): string {\n    if (!Array.isArray(input)) {\n      throw Error('encodeByteArray takes an array as a parameter');\n    }\n\n    this.init_();\n\n    const byteToCharMap = webSafe\n      ? this.byteToCharMapWebSafe_!\n      : this.byteToCharMap_!;\n\n    const output = [];\n\n    for (let i = 0; i < input.length; i += 3) {\n      const byte1 = input[i];\n      const haveByte2 = i + 1 < input.length;\n      const byte2 = haveByte2 ? input[i + 1] : 0;\n      const haveByte3 = i + 2 < input.length;\n      const byte3 = haveByte3 ? input[i + 2] : 0;\n\n      const outByte1 = byte1 >> 2;\n      const outByte2 = ((byte1 & 0x03) << 4) | (byte2 >> 4);\n      let outByte3 = ((byte2 & 0x0f) << 2) | (byte3 >> 6);\n      let outByte4 = byte3 & 0x3f;\n\n      if (!haveByte3) {\n        outByte4 = 64;\n\n        if (!haveByte2) {\n          outByte3 = 64;\n        }\n      }\n\n      output.push(\n        byteToCharMap[outByte1],\n        byteToCharMap[outByte2],\n        byteToCharMap[outByte3],\n        byteToCharMap[outByte4]\n      );\n    }\n\n    return output.join('');\n  },\n\n  /**\n   * Base64-encode a string.\n   *\n   * @param input A string to encode.\n   * @param webSafe If true, we should use the\n   *     alternative alphabet.\n   * @return The base64 encoded string.\n   */\n  encodeString(input: string, webSafe?: boolean): string {\n    // Shortcut for Mozilla browsers that implement\n    // a native base64 encoder in the form of \"btoa/atob\"\n    if (this.HAS_NATIVE_SUPPORT && !webSafe) {\n      return btoa(input);\n    }\n    return this.encodeByteArray(stringToByteArray(input), webSafe);\n  },\n\n  /**\n   * Base64-decode a string.\n   *\n   * @param input to decode.\n   * @param webSafe True if we should use the\n   *     alternative alphabet.\n   * @return string representing the decoded value.\n   */\n  decodeString(input: string, webSafe: boolean): string {\n    // Shortcut for Mozilla browsers that implement\n    // a native base64 encoder in the form of \"btoa/atob\"\n    if (this.HAS_NATIVE_SUPPORT && !webSafe) {\n      return atob(input);\n    }\n    return byteArrayToString(this.decodeStringToByteArray(input, webSafe));\n  },\n\n  /**\n   * Base64-decode a string.\n   *\n   * In base-64 decoding, groups of four characters are converted into three\n   * bytes.  If the encoder did not apply padding, the input length may not\n   * be a multiple of 4.\n   *\n   * In this case, the last group will have fewer than 4 characters, and\n   * padding will be inferred.  If the group has one or two characters, it decodes\n   * to one byte.  If the group has three characters, it decodes to two bytes.\n   *\n   * @param input Input to decode.\n   * @param webSafe True if we should use the web-safe alphabet.\n   * @return bytes representing the decoded value.\n   */\n  decodeStringToByteArray(input: string, webSafe: boolean): number[] {\n    this.init_();\n\n    const charToByteMap = webSafe\n      ? this.charToByteMapWebSafe_!\n      : this.charToByteMap_!;\n\n    const output: number[] = [];\n\n    for (let i = 0; i < input.length; ) {\n      const byte1 = charToByteMap[input.charAt(i++)];\n\n      const haveByte2 = i < input.length;\n      const byte2 = haveByte2 ? charToByteMap[input.charAt(i)] : 0;\n      ++i;\n\n      const haveByte3 = i < input.length;\n      const byte3 = haveByte3 ? charToByteMap[input.charAt(i)] : 64;\n      ++i;\n\n      const haveByte4 = i < input.length;\n      const byte4 = haveByte4 ? charToByteMap[input.charAt(i)] : 64;\n      ++i;\n\n      if (byte1 == null || byte2 == null || byte3 == null || byte4 == null) {\n        throw new DecodeBase64StringError();\n      }\n\n      const outByte1 = (byte1 << 2) | (byte2 >> 4);\n      output.push(outByte1);\n\n      if (byte3 !== 64) {\n        const outByte2 = ((byte2 << 4) & 0xf0) | (byte3 >> 2);\n        output.push(outByte2);\n\n        if (byte4 !== 64) {\n          const outByte3 = ((byte3 << 6) & 0xc0) | byte4;\n          output.push(outByte3);\n        }\n      }\n    }\n\n    return output;\n  },\n\n  /**\n   * Lazy static initialization function. Called before\n   * accessing any of the static map variables.\n   * @private\n   */\n  init_() {\n    if (!this.byteToCharMap_) {\n      this.byteToCharMap_ = {};\n      this.charToByteMap_ = {};\n      this.byteToCharMapWebSafe_ = {};\n      this.charToByteMapWebSafe_ = {};\n\n      // We want quick mappings back and forth, so we precompute two maps.\n      for (let i = 0; i < this.ENCODED_VALS.length; i++) {\n        this.byteToCharMap_[i] = this.ENCODED_VALS.charAt(i);\n        this.charToByteMap_[this.byteToCharMap_[i]] = i;\n        this.byteToCharMapWebSafe_[i] = this.ENCODED_VALS_WEBSAFE.charAt(i);\n        this.charToByteMapWebSafe_[this.byteToCharMapWebSafe_[i]] = i;\n\n        // Be forgiving when decoding and correctly decode both encodings.\n        if (i >= this.ENCODED_VALS_BASE.length) {\n          this.charToByteMap_[this.ENCODED_VALS_WEBSAFE.charAt(i)] = i;\n          this.charToByteMapWebSafe_[this.ENCODED_VALS.charAt(i)] = i;\n        }\n      }\n    }\n  }\n};\n\n/**\n * An error encountered while decoding base64 string.\n */\nexport class DecodeBase64StringError extends Error {\n  readonly name = 'DecodeBase64StringError';\n}\n\n/**\n * URL-safe base64 encoding\n */\nexport const base64Encode = function (str: string): string {\n  const utf8Bytes = stringToByteArray(str);\n  return base64.encodeByteArray(utf8Bytes, true);\n};\n\n/**\n * URL-safe base64 encoding (without \".\" padding in the end).\n * e.g. Used in JSON Web Token (JWT) parts.\n */\nexport const base64urlEncodeWithoutPadding = function (str: string): string {\n  // Use base64url encoding and remove padding in the end (dot characters).\n  return base64Encode(str).replace(/\\./g, '');\n};\n\n/**\n * URL-safe base64 decoding\n *\n * NOTE: DO NOT use the global atob() function - it does NOT support the\n * base64Url variant encoding.\n *\n * @param str To be decoded\n * @return Decoded result, if possible\n */\nexport const base64Decode = function (str: string): string | null {\n  try {\n    return base64.decodeString(str, true);\n  } catch (e) {\n    console.error('base64Decode failed: ', e);\n  }\n  return null;\n};\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Do a deep-copy of basic JavaScript Objects or Arrays.\n */\nexport function deepCopy<T>(value: T): T {\n  return deepExtend(undefined, value) as T;\n}\n\n/**\n * Copy properties from source to target (recursively allows extension\n * of Objects and Arrays).  Scalar values in the target are over-written.\n * If target is undefined, an object of the appropriate type will be created\n * (and returned).\n *\n * We recursively copy all child properties of plain Objects in the source- so\n * that namespace- like dictionaries are merged.\n *\n * Note that the target can be a function, in which case the properties in\n * the source Object are copied onto it as static properties of the Function.\n *\n * Note: we don't merge __proto__ to prevent prototype pollution\n */\nexport function deepExtend(target: unknown, source: unknown): unknown {\n  if (!(source instanceof Object)) {\n    return source;\n  }\n\n  switch (source.constructor) {\n    case Date:\n      // Treat Dates like scalars; if the target date object had any child\n      // properties - they will be lost!\n      const dateValue = source as Date;\n      return new Date(dateValue.getTime());\n\n    case Object:\n      if (target === undefined) {\n        target = {};\n      }\n      break;\n    case Array:\n      // Always copy the array source and overwrite the target.\n      target = [];\n      break;\n\n    default:\n      // Not a plain Object - treat it as a scalar.\n      return source;\n  }\n\n  for (const prop in source) {\n    // use isValidKey to guard against prototype pollution. See https://snyk.io/vuln/SNYK-JS-LODASH-450202\n    if (!source.hasOwnProperty(prop) || !isValidKey(prop)) {\n      continue;\n    }\n    (target as Record<string, unknown>)[prop] = deepExtend(\n      (target as Record<string, unknown>)[prop],\n      (source as Record<string, unknown>)[prop]\n    );\n  }\n\n  return target;\n}\n\nfunction isValidKey(key: string): boolean {\n  return key !== '__proto__';\n}\n","/**\n * @license\n * Copyright 2022 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Polyfill for `globalThis` object.\n * @returns the `globalThis` object for the given environment.\n * @public\n */\nexport function getGlobal(): typeof globalThis {\n  if (typeof self !== 'undefined') {\n    return self;\n  }\n  if (typeof window !== 'undefined') {\n    return window;\n  }\n  if (typeof global !== 'undefined') {\n    return global;\n  }\n  throw new Error('Unable to locate global object.');\n}\n","/**\n * @license\n * Copyright 2022 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { base64Decode } from './crypt';\nimport { getGlobal } from './global';\n\n/**\n * Keys for experimental properties on the `FirebaseDefaults` object.\n * @public\n */\nexport type ExperimentalKey = 'authTokenSyncURL' | 'authIdTokenMaxAge';\n\n/**\n * An object that can be injected into the environment as __FIREBASE_DEFAULTS__,\n * either as a property of globalThis, a shell environment variable, or a\n * cookie.\n *\n * This object can be used to automatically configure and initialize\n * a Firebase app as well as any emulators.\n *\n * @public\n */\nexport interface FirebaseDefaults {\n  config?: Record<string, string>;\n  emulatorHosts?: Record<string, string>;\n  _authTokenSyncURL?: string;\n  _authIdTokenMaxAge?: number;\n  /**\n   * Override Firebase's runtime environment detection and\n   * force the SDK to act as if it were in the specified environment.\n   */\n  forceEnvironment?: 'browser' | 'node';\n  [key: string]: unknown;\n}\n\ndeclare global {\n  // Need `var` for this to work.\n  // eslint-disable-next-line no-var\n  var __FIREBASE_DEFAULTS__: FirebaseDefaults | undefined;\n}\n\nconst getDefaultsFromGlobal = (): FirebaseDefaults | undefined =>\n  getGlobal().__FIREBASE_DEFAULTS__;\n\n/**\n * Attempt to read defaults from a JSON string provided to\n * process(.)env(.)__FIREBASE_DEFAULTS__ or a JSON file whose path is in\n * process(.)env(.)__FIREBASE_DEFAULTS_PATH__\n * The dots are in parens because certain compilers (Vite?) cannot\n * handle seeing that variable in comments.\n * See https://github.com/firebase/firebase-js-sdk/issues/6838\n */\nconst getDefaultsFromEnvVariable = (): FirebaseDefaults | undefined => {\n  if (typeof process === 'undefined' || typeof process.env === 'undefined') {\n    return;\n  }\n  const defaultsJsonString = process.env.__FIREBASE_DEFAULTS__;\n  if (defaultsJsonString) {\n    return JSON.parse(defaultsJsonString);\n  }\n};\n\nconst getDefaultsFromCookie = (): FirebaseDefaults | undefined => {\n  if (typeof document === 'undefined') {\n    return;\n  }\n  let match;\n  try {\n    match = document.cookie.match(/__FIREBASE_DEFAULTS__=([^;]+)/);\n  } catch (e) {\n    // Some environments such as Angular Universal SSR have a\n    // `document` object but error on accessing `document.cookie`.\n    return;\n  }\n  const decoded = match && base64Decode(match[1]);\n  return decoded && JSON.parse(decoded);\n};\n\n/**\n * Get the __FIREBASE_DEFAULTS__ object. It checks in order:\n * (1) if such an object exists as a property of `globalThis`\n * (2) if such an object was provided on a shell environment variable\n * (3) if such an object exists in a cookie\n * @public\n */\nexport const getDefaults = (): FirebaseDefaults | undefined => {\n  try {\n    return (\n      getDefaultsFromGlobal() ||\n      getDefaultsFromEnvVariable() ||\n      getDefaultsFromCookie()\n    );\n  } catch (e) {\n    /**\n     * Catch-all for being unable to get __FIREBASE_DEFAULTS__ due\n     * to any environment case we have not accounted for. Log to\n     * info instead of swallowing so we can find these unknown cases\n     * and add paths for them if needed.\n     */\n    console.info(`Unable to get __FIREBASE_DEFAULTS__ due to: ${e}`);\n    return;\n  }\n};\n\n/**\n * Returns emulator host stored in the __FIREBASE_DEFAULTS__ object\n * for the given product.\n * @returns a URL host formatted like `127.0.0.1:9999` or `[::1]:4000` if available\n * @public\n */\nexport const getDefaultEmulatorHost = (\n  productName: string\n): string | undefined => getDefaults()?.emulatorHosts?.[productName];\n\n/**\n * Returns emulator hostname and port stored in the __FIREBASE_DEFAULTS__ object\n * for the given product.\n * @returns a pair of hostname and port like `[\"::1\", 4000]` if available\n * @public\n */\nexport const getDefaultEmulatorHostnameAndPort = (\n  productName: string\n): [hostname: string, port: number] | undefined => {\n  const host = getDefaultEmulatorHost(productName);\n  if (!host) {\n    return undefined;\n  }\n  const separatorIndex = host.lastIndexOf(':'); // Finding the last since IPv6 addr also has colons.\n  if (separatorIndex <= 0 || separatorIndex + 1 === host.length) {\n    throw new Error(`Invalid host ${host} with no separate hostname and port!`);\n  }\n  // eslint-disable-next-line no-restricted-globals\n  const port = parseInt(host.substring(separatorIndex + 1), 10);\n  if (host[0] === '[') {\n    // Bracket-quoted `[ipv6addr]:port` => return \"ipv6addr\" (without brackets).\n    return [host.substring(1, separatorIndex - 1), port];\n  } else {\n    return [host.substring(0, separatorIndex), port];\n  }\n};\n\n/**\n * Returns Firebase app config stored in the __FIREBASE_DEFAULTS__ object.\n * @public\n */\nexport const getDefaultAppConfig = (): Record<string, string> | undefined =>\n  getDefaults()?.config;\n\n/**\n * Returns an experimental setting on the __FIREBASE_DEFAULTS__ object (properties\n * prefixed by \"_\")\n * @public\n */\nexport const getExperimentalSetting = <T extends ExperimentalKey>(\n  name: T\n): FirebaseDefaults[`_${T}`] =>\n  getDefaults()?.[`_${name}`] as FirebaseDefaults[`_${T}`];\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport class Deferred<R> {\n  promise: Promise<R>;\n  reject: (value?: unknown) => void = () => {};\n  resolve: (value?: unknown) => void = () => {};\n  constructor() {\n    this.promise = new Promise((resolve, reject) => {\n      this.resolve = resolve as (value?: unknown) => void;\n      this.reject = reject as (value?: unknown) => void;\n    });\n  }\n\n  /**\n   * Our API internals are not promiseified and cannot because our callback APIs have subtle expectations around\n   * invoking promises inline, which Promises are forbidden to do. This method accepts an optional node-style callback\n   * and returns a node-style callback which will resolve or reject the Deferred's promise.\n   */\n  wrapCallback(\n    callback?: (error?: unknown, value?: unknown) => void\n  ): (error: unknown, value?: unknown) => void {\n    return (error, value?) => {\n      if (error) {\n        this.reject(error);\n      } else {\n        this.resolve(value);\n      }\n      if (typeof callback === 'function') {\n        // Attaching noop handler just in case developer wasn't expecting\n        // promises\n        this.promise.catch(() => {});\n\n        // Some of our callbacks don't expect a value and our own tests\n        // assert that the parameter length is 1\n        if (callback.length === 1) {\n          callback(error);\n        } else {\n          callback(error, value);\n        }\n      }\n    };\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { base64urlEncodeWithoutPadding } from './crypt';\n\n// Firebase Auth tokens contain snake_case claims following the JWT standard / convention.\n/* eslint-disable camelcase */\n\nexport type FirebaseSignInProvider =\n  | 'custom'\n  | 'email'\n  | 'password'\n  | 'phone'\n  | 'anonymous'\n  | 'google.com'\n  | 'facebook.com'\n  | 'github.com'\n  | 'twitter.com'\n  | 'microsoft.com'\n  | 'apple.com';\n\ninterface FirebaseIdToken {\n  // Always set to https://securetoken.google.com/PROJECT_ID\n  iss: string;\n\n  // Always set to PROJECT_ID\n  aud: string;\n\n  // The user's unique ID\n  sub: string;\n\n  // The token issue time, in seconds since epoch\n  iat: number;\n\n  // The token expiry time, normally 'iat' + 3600\n  exp: number;\n\n  // The user's unique ID. Must be equal to 'sub'\n  user_id: string;\n\n  // The time the user authenticated, normally 'iat'\n  auth_time: number;\n\n  // The sign in provider, only set when the provider is 'anonymous'\n  provider_id?: 'anonymous';\n\n  // The user's primary email\n  email?: string;\n\n  // The user's email verification status\n  email_verified?: boolean;\n\n  // The user's primary phone number\n  phone_number?: string;\n\n  // The user's display name\n  name?: string;\n\n  // The user's profile photo URL\n  picture?: string;\n\n  // Information on all identities linked to this user\n  firebase: {\n    // The primary sign-in provider\n    sign_in_provider: FirebaseSignInProvider;\n\n    // A map of providers to the user's list of unique identifiers from\n    // each provider\n    identities?: { [provider in FirebaseSignInProvider]?: string[] };\n  };\n\n  // Custom claims set by the developer\n  [claim: string]: unknown;\n\n  uid?: never; // Try to catch a common mistake of \"uid\" (should be \"sub\" instead).\n}\n\nexport type EmulatorMockTokenOptions = ({ user_id: string } | { sub: string }) &\n  Partial<FirebaseIdToken>;\n\nexport function createMockUserToken(\n  token: EmulatorMockTokenOptions,\n  projectId?: string\n): string {\n  if (token.uid) {\n    throw new Error(\n      'The \"uid\" field is no longer supported by mockUserToken. Please use \"sub\" instead for Firebase Auth User ID.'\n    );\n  }\n  // Unsecured JWTs use \"none\" as the algorithm.\n  const header = {\n    alg: 'none',\n    type: 'JWT'\n  };\n\n  const project = projectId || 'demo-project';\n  const iat = token.iat || 0;\n  const sub = token.sub || token.user_id;\n  if (!sub) {\n    throw new Error(\"mockUserToken must contain 'sub' or 'user_id' field!\");\n  }\n\n  const payload: FirebaseIdToken = {\n    // Set all required fields to decent defaults\n    iss: `https://securetoken.google.com/${project}`,\n    aud: project,\n    iat,\n    exp: iat + 3600,\n    auth_time: iat,\n    sub,\n    user_id: sub,\n    firebase: {\n      sign_in_provider: 'custom',\n      identities: {}\n    },\n\n    // Override with user options\n    ...token\n  };\n\n  // Unsecured JWTs use the empty string as a signature.\n  const signature = '';\n  return [\n    base64urlEncodeWithoutPadding(JSON.stringify(header)),\n    base64urlEncodeWithoutPadding(JSON.stringify(payload)),\n    signature\n  ].join('.');\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { CONSTANTS } from './constants';\nimport { getDefaults } from './defaults';\n\n/**\n * Returns navigator.userAgent string or '' if it's not defined.\n * @return user agent string\n */\nexport function getUA(): string {\n  if (\n    typeof navigator !== 'undefined' &&\n    typeof navigator['userAgent'] === 'string'\n  ) {\n    return navigator['userAgent'];\n  } else {\n    return '';\n  }\n}\n\n/**\n * Detect Cordova / PhoneGap / Ionic frameworks on a mobile device.\n *\n * Deliberately does not rely on checking `file://` URLs (as this fails PhoneGap\n * in the Ripple emulator) nor Cordova `onDeviceReady`, which would normally\n * wait for a callback.\n */\nexport function isMobileCordova(): boolean {\n  return (\n    typeof window !== 'undefined' &&\n    // @ts-ignore Setting up an broadly applicable index signature for Window\n    // just to deal with this case would probably be a bad idea.\n    !!(window['cordova'] || window['phonegap'] || window['PhoneGap']) &&\n    /ios|iphone|ipod|ipad|android|blackberry|iemobile/i.test(getUA())\n  );\n}\n\n/**\n * Detect Node.js.\n *\n * @return true if Node.js environment is detected or specified.\n */\n// Node detection logic from: https://github.com/iliakan/detect-node/\nexport function isNode(): boolean {\n  const forceEnvironment = getDefaults()?.forceEnvironment;\n  if (forceEnvironment === 'node') {\n    return true;\n  } else if (forceEnvironment === 'browser') {\n    return false;\n  }\n\n  try {\n    return (\n      Object.prototype.toString.call(global.process) === '[object process]'\n    );\n  } catch (e) {\n    return false;\n  }\n}\n\n/**\n * Detect Browser Environment\n */\nexport function isBrowser(): boolean {\n  return typeof self === 'object' && self.self === self;\n}\n\n/**\n * Detect browser extensions (Chrome and Firefox at least).\n */\ninterface BrowserRuntime {\n  id?: unknown;\n}\ndeclare const chrome: { runtime?: BrowserRuntime };\ndeclare const browser: { runtime?: BrowserRuntime };\nexport function isBrowserExtension(): boolean {\n  const runtime =\n    typeof chrome === 'object'\n      ? chrome.runtime\n      : typeof browser === 'object'\n      ? browser.runtime\n      : undefined;\n  return typeof runtime === 'object' && runtime.id !== undefined;\n}\n\n/**\n * Detect React Native.\n *\n * @return true if ReactNative environment is detected.\n */\nexport function isReactNative(): boolean {\n  return (\n    typeof navigator === 'object' && navigator['product'] === 'ReactNative'\n  );\n}\n\n/** Detects Electron apps. */\nexport function isElectron(): boolean {\n  return getUA().indexOf('Electron/') >= 0;\n}\n\n/** Detects Internet Explorer. */\nexport function isIE(): boolean {\n  const ua = getUA();\n  return ua.indexOf('MSIE ') >= 0 || ua.indexOf('Trident/') >= 0;\n}\n\n/** Detects Universal Windows Platform apps. */\nexport function isUWP(): boolean {\n  return getUA().indexOf('MSAppHost/') >= 0;\n}\n\n/**\n * Detect whether the current SDK build is the Node version.\n *\n * @return true if it's the Node SDK build.\n */\nexport function isNodeSdk(): boolean {\n  return CONSTANTS.NODE_CLIENT === true || CONSTANTS.NODE_ADMIN === true;\n}\n\n/** Returns true if we are running in Safari. */\nexport function isSafari(): boolean {\n  return (\n    !isNode() &&\n    navigator.userAgent.includes('Safari') &&\n    !navigator.userAgent.includes('Chrome')\n  );\n}\n\n/**\n * This method checks if indexedDB is supported by current browser/service worker context\n * @return true if indexedDB is supported by current browser/service worker context\n */\nexport function isIndexedDBAvailable(): boolean {\n  try {\n    return typeof indexedDB === 'object';\n  } catch (e) {\n    return false;\n  }\n}\n\n/**\n * This method validates browser/sw context for indexedDB by opening a dummy indexedDB database and reject\n * if errors occur during the database open operation.\n *\n * @throws exception if current browser/sw context can't run idb.open (ex: Safari iframe, Firefox\n * private browsing)\n */\nexport function validateIndexedDBOpenable(): Promise<boolean> {\n  return new Promise((resolve, reject) => {\n    try {\n      let preExist: boolean = true;\n      const DB_CHECK_NAME =\n        'validate-browser-context-for-indexeddb-analytics-module';\n      const request = self.indexedDB.open(DB_CHECK_NAME);\n      request.onsuccess = () => {\n        request.result.close();\n        // delete database only when it doesn't pre-exist\n        if (!preExist) {\n          self.indexedDB.deleteDatabase(DB_CHECK_NAME);\n        }\n        resolve(true);\n      };\n      request.onupgradeneeded = () => {\n        preExist = false;\n      };\n\n      request.onerror = () => {\n        reject(request.error?.message || '');\n      };\n    } catch (error) {\n      reject(error);\n    }\n  });\n}\n\n/**\n *\n * This method checks whether cookie is enabled within current browser\n * @return true if cookie is enabled within current browser\n */\nexport function areCookiesEnabled(): boolean {\n  if (typeof navigator === 'undefined' || !navigator.cookieEnabled) {\n    return false;\n  }\n  return true;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * @fileoverview Standardized Firebase Error.\n *\n * Usage:\n *\n *   // Typescript string literals for type-safe codes\n *   type Err =\n *     'unknown' |\n *     'object-not-found'\n *     ;\n *\n *   // Closure enum for type-safe error codes\n *   // at-enum {string}\n *   var Err = {\n *     UNKNOWN: 'unknown',\n *     OBJECT_NOT_FOUND: 'object-not-found',\n *   }\n *\n *   let errors: Map<Err, string> = {\n *     'generic-error': \"Unknown error\",\n *     'file-not-found': \"Could not find file: {$file}\",\n *   };\n *\n *   // Type-safe function - must pass a valid error code as param.\n *   let error = new ErrorFactory<Err>('service', 'Service', errors);\n *\n *   ...\n *   throw error.create(Err.GENERIC);\n *   ...\n *   throw error.create(Err.FILE_NOT_FOUND, {'file': fileName});\n *   ...\n *   // Service: Could not file file: foo.txt (service/file-not-found).\n *\n *   catch (e) {\n *     assert(e.message === \"Could not find file: foo.txt.\");\n *     if ((e as FirebaseError)?.code === 'service/file-not-found') {\n *       console.log(\"Could not read file: \" + e['file']);\n *     }\n *   }\n */\n\nexport type ErrorMap<ErrorCode extends string> = {\n  readonly [K in ErrorCode]: string;\n};\n\nconst ERROR_NAME = 'FirebaseError';\n\nexport interface StringLike {\n  toString(): string;\n}\n\nexport interface ErrorData {\n  [key: string]: unknown;\n}\n\n// Based on code from:\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Error#Custom_Error_Types\nexport class FirebaseError extends Error {\n  /** The custom name for all FirebaseErrors. */\n  readonly name: string = ERROR_NAME;\n\n  constructor(\n    /** The error code for this error. */\n    readonly code: string,\n    message: string,\n    /** Custom data for this error. */\n    public customData?: Record<string, unknown>\n  ) {\n    super(message);\n\n    // Fix For ES5\n    // https://github.com/Microsoft/TypeScript-wiki/blob/master/Breaking-Changes.md#extending-built-ins-like-error-array-and-map-may-no-longer-work\n    Object.setPrototypeOf(this, FirebaseError.prototype);\n\n    // Maintains proper stack trace for where our error was thrown.\n    // Only available on V8.\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, ErrorFactory.prototype.create);\n    }\n  }\n}\n\nexport class ErrorFactory<\n  ErrorCode extends string,\n  ErrorParams extends { readonly [K in ErrorCode]?: ErrorData } = {}\n> {\n  constructor(\n    private readonly service: string,\n    private readonly serviceName: string,\n    private readonly errors: ErrorMap<ErrorCode>\n  ) {}\n\n  create<K extends ErrorCode>(\n    code: K,\n    ...data: K extends keyof ErrorParams ? [ErrorParams[K]] : []\n  ): FirebaseError {\n    const customData = (data[0] as ErrorData) || {};\n    const fullCode = `${this.service}/${code}`;\n    const template = this.errors[code];\n\n    const message = template ? replaceTemplate(template, customData) : 'Error';\n    // Service Name: Error message (service/code).\n    const fullMessage = `${this.serviceName}: ${message} (${fullCode}).`;\n\n    const error = new FirebaseError(fullCode, fullMessage, customData);\n\n    return error;\n  }\n}\n\nfunction replaceTemplate(template: string, data: ErrorData): string {\n  return template.replace(PATTERN, (_, key) => {\n    const value = data[key];\n    return value != null ? String(value) : `<${key}?>`;\n  });\n}\n\nconst PATTERN = /\\{\\$([^}]+)}/g;\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Evaluates a JSON string into a javascript object.\n *\n * @param {string} str A string containing JSON.\n * @return {*} The javascript object representing the specified JSON.\n */\nexport function jsonEval(str: string): unknown {\n  return JSON.parse(str);\n}\n\n/**\n * Returns JSON representing a javascript object.\n * @param {*} data Javascript object to be stringified.\n * @return {string} The JSON contents of the object.\n */\nexport function stringify(data: unknown): string {\n  return JSON.stringify(data);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { base64Decode } from './crypt';\nimport { jsonEval } from './json';\n\ninterface Claims {\n  [key: string]: {};\n}\n\ninterface DecodedToken {\n  header: object;\n  claims: Claims;\n  data: object;\n  signature: string;\n}\n\n/**\n * Decodes a Firebase auth. token into constituent parts.\n *\n * Notes:\n * - May return with invalid / incomplete claims if there's no native base64 decoding support.\n * - Doesn't check if the token is actually valid.\n */\nexport const decode = function (token: string): DecodedToken {\n  let header = {},\n    claims: Claims = {},\n    data = {},\n    signature = '';\n\n  try {\n    const parts = token.split('.');\n    header = jsonEval(base64Decode(parts[0]) || '') as object;\n    claims = jsonEval(base64Decode(parts[1]) || '') as Claims;\n    signature = parts[2];\n    data = claims['d'] || {};\n    delete claims['d'];\n  } catch (e) {}\n\n  return {\n    header,\n    claims,\n    data,\n    signature\n  };\n};\n\ninterface DecodedToken {\n  header: object;\n  claims: Claims;\n  data: object;\n  signature: string;\n}\n\n/**\n * Decodes a Firebase auth. token and checks the validity of its time-based claims. Will return true if the\n * token is within the time window authorized by the 'nbf' (not-before) and 'iat' (issued-at) claims.\n *\n * Notes:\n * - May return a false negative if there's no native base64 decoding support.\n * - Doesn't check if the token is actually valid.\n */\nexport const isValidTimestamp = function (token: string): boolean {\n  const claims: Claims = decode(token).claims;\n  const now: number = Math.floor(new Date().getTime() / 1000);\n  let validSince: number = 0,\n    validUntil: number = 0;\n\n  if (typeof claims === 'object') {\n    if (claims.hasOwnProperty('nbf')) {\n      validSince = claims['nbf'] as number;\n    } else if (claims.hasOwnProperty('iat')) {\n      validSince = claims['iat'] as number;\n    }\n\n    if (claims.hasOwnProperty('exp')) {\n      validUntil = claims['exp'] as number;\n    } else {\n      // token will expire after 24h by default\n      validUntil = validSince + 86400;\n    }\n  }\n\n  return (\n    !!now &&\n    !!validSince &&\n    !!validUntil &&\n    now >= validSince &&\n    now <= validUntil\n  );\n};\n\n/**\n * Decodes a Firebase auth. token and returns its issued at time if valid, null otherwise.\n *\n * Notes:\n * - May return null if there's no native base64 decoding support.\n * - Doesn't check if the token is actually valid.\n */\nexport const issuedAtTime = function (token: string): number | null {\n  const claims: Claims = decode(token).claims;\n  if (typeof claims === 'object' && claims.hasOwnProperty('iat')) {\n    return claims['iat'] as number;\n  }\n  return null;\n};\n\n/**\n * Decodes a Firebase auth. token and checks the validity of its format. Expects a valid issued-at time.\n *\n * Notes:\n * - May return a false negative if there's no native base64 decoding support.\n * - Doesn't check if the token is actually valid.\n */\nexport const isValidFormat = function (token: string): boolean {\n  const decoded = decode(token),\n    claims = decoded.claims;\n\n  return !!claims && typeof claims === 'object' && claims.hasOwnProperty('iat');\n};\n\n/**\n * Attempts to peer into an auth token and determine if it's an admin auth token by looking at the claims portion.\n *\n * Notes:\n * - May return a false negative if there's no native base64 decoding support.\n * - Doesn't check if the token is actually valid.\n */\nexport const isAdmin = function (token: string): boolean {\n  const claims: Claims = decode(token).claims;\n  return typeof claims === 'object' && claims['admin'] === true;\n};\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport function contains<T extends object>(obj: T, key: string): boolean {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\nexport function safeGet<T extends object, K extends keyof T>(\n  obj: T,\n  key: K\n): T[K] | undefined {\n  if (Object.prototype.hasOwnProperty.call(obj, key)) {\n    return obj[key];\n  } else {\n    return undefined;\n  }\n}\n\nexport function isEmpty(obj: object): obj is {} {\n  for (const key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function map<K extends string, V, U>(\n  obj: { [key in K]: V },\n  fn: (value: V, key: K, obj: { [key in K]: V }) => U,\n  contextObj?: unknown\n): { [key in K]: U } {\n  const res: Partial<{ [key in K]: U }> = {};\n  for (const key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      res[key] = fn.call(contextObj, obj[key], key, obj);\n    }\n  }\n  return res as { [key in K]: U };\n}\n\n/**\n * Deep equal two objects. Support Arrays and Objects.\n */\nexport function deepEqual(a: object, b: object): boolean {\n  if (a === b) {\n    return true;\n  }\n\n  const aKeys = Object.keys(a);\n  const bKeys = Object.keys(b);\n  for (const k of aKeys) {\n    if (!bKeys.includes(k)) {\n      return false;\n    }\n\n    const aProp = (a as Record<string, unknown>)[k];\n    const bProp = (b as Record<string, unknown>)[k];\n    if (isObject(aProp) && isObject(bProp)) {\n      if (!deepEqual(aProp, bProp)) {\n        return false;\n      }\n    } else if (aProp !== bProp) {\n      return false;\n    }\n  }\n\n  for (const k of bKeys) {\n    if (!aKeys.includes(k)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nfunction isObject(thing: unknown): thing is object {\n  return thing !== null && typeof thing === 'object';\n}\n","/**\n * @license\n * Copyright 2022 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Deferred } from './deferred';\n\n/**\n * Rejects if the given promise doesn't resolve in timeInMS milliseconds.\n * @internal\n */\nexport function promiseWithTimeout<T>(\n  promise: Promise<T>,\n  timeInMS = 2000\n): Promise<T> {\n  const deferredPromise = new Deferred<T>();\n  setTimeout(() => deferredPromise.reject('timeout!'), timeInMS);\n  promise.then(deferredPromise.resolve, deferredPromise.reject);\n  return deferredPromise.promise;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Returns a querystring-formatted string (e.g. &arg=val&arg2=val2) from a\n * params object (e.g. {arg: 'val', arg2: 'val2'})\n * Note: You must prepend it with ? when adding it to a URL.\n */\nexport function querystring(querystringParams: {\n  [key: string]: string | number;\n}): string {\n  const params = [];\n  for (const [key, value] of Object.entries(querystringParams)) {\n    if (Array.isArray(value)) {\n      value.forEach(arrayVal => {\n        params.push(\n          encodeURIComponent(key) + '=' + encodeURIComponent(arrayVal)\n        );\n      });\n    } else {\n      params.push(encodeURIComponent(key) + '=' + encodeURIComponent(value));\n    }\n  }\n  return params.length ? '&' + params.join('&') : '';\n}\n\n/**\n * Decodes a querystring (e.g. ?arg=val&arg2=val2) into a params object\n * (e.g. {arg: 'val', arg2: 'val2'})\n */\nexport function querystringDecode(querystring: string): Record<string, string> {\n  const obj: Record<string, string> = {};\n  const tokens = querystring.replace(/^\\?/, '').split('&');\n\n  tokens.forEach(token => {\n    if (token) {\n      const [key, value] = token.split('=');\n      obj[decodeURIComponent(key)] = decodeURIComponent(value);\n    }\n  });\n  return obj;\n}\n\n/**\n * Extract the query string part of a URL, including the leading question mark (if present).\n */\nexport function extractQuerystring(url: string): string {\n  const queryStart = url.indexOf('?');\n  if (!queryStart) {\n    return '';\n  }\n  const fragmentStart = url.indexOf('#', queryStart);\n  return url.substring(\n    queryStart,\n    fragmentStart > 0 ? fragmentStart : undefined\n  );\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * @fileoverview SHA-1 cryptographic hash.\n * Variable names follow the notation in FIPS PUB 180-3:\n * http://csrc.nist.gov/publications/fips/fips180-3/fips180-3_final.pdf.\n *\n * Usage:\n *   var sha1 = new sha1();\n *   sha1.update(bytes);\n *   var hash = sha1.digest();\n *\n * Performance:\n *   Chrome 23:   ~400 Mbit/s\n *   Firefox 16:  ~250 Mbit/s\n *\n */\n\n/**\n * SHA-1 cryptographic hash constructor.\n *\n * The properties declared here are discussed in the above algorithm document.\n * @constructor\n * @final\n * @struct\n */\nexport class Sha1 {\n  /**\n   * Holds the previous values of accumulated variables a-e in the compress_\n   * function.\n   * @private\n   */\n  private chain_: number[] = [];\n\n  /**\n   * A buffer holding the partially computed hash result.\n   * @private\n   */\n  private buf_: number[] = [];\n\n  /**\n   * An array of 80 bytes, each a part of the message to be hashed.  Referred to\n   * as the message schedule in the docs.\n   * @private\n   */\n  private W_: number[] = [];\n\n  /**\n   * Contains data needed to pad messages less than 64 bytes.\n   * @private\n   */\n  private pad_: number[] = [];\n\n  /**\n   * @private {number}\n   */\n  private inbuf_: number = 0;\n\n  /**\n   * @private {number}\n   */\n  private total_: number = 0;\n\n  blockSize: number;\n\n  constructor() {\n    this.blockSize = 512 / 8;\n\n    this.pad_[0] = 128;\n    for (let i = 1; i < this.blockSize; ++i) {\n      this.pad_[i] = 0;\n    }\n\n    this.reset();\n  }\n\n  reset(): void {\n    this.chain_[0] = 0x67452301;\n    this.chain_[1] = 0xefcdab89;\n    this.chain_[2] = 0x98badcfe;\n    this.chain_[3] = 0x10325476;\n    this.chain_[4] = 0xc3d2e1f0;\n\n    this.inbuf_ = 0;\n    this.total_ = 0;\n  }\n\n  /**\n   * Internal compress helper function.\n   * @param buf Block to compress.\n   * @param offset Offset of the block in the buffer.\n   * @private\n   */\n  compress_(buf: number[] | Uint8Array | string, offset?: number): void {\n    if (!offset) {\n      offset = 0;\n    }\n\n    const W = this.W_;\n\n    // get 16 big endian words\n    if (typeof buf === 'string') {\n      for (let i = 0; i < 16; i++) {\n        // TODO(user): [bug 8140122] Recent versions of Safari for Mac OS and iOS\n        // have a bug that turns the post-increment ++ operator into pre-increment\n        // during JIT compilation.  We have code that depends heavily on SHA-1 for\n        // correctness and which is affected by this bug, so I've removed all uses\n        // of post-increment ++ in which the result value is used.  We can revert\n        // this change once the Safari bug\n        // (https://bugs.webkit.org/show_bug.cgi?id=109036) has been fixed and\n        // most clients have been updated.\n        W[i] =\n          (buf.charCodeAt(offset) << 24) |\n          (buf.charCodeAt(offset + 1) << 16) |\n          (buf.charCodeAt(offset + 2) << 8) |\n          buf.charCodeAt(offset + 3);\n        offset += 4;\n      }\n    } else {\n      for (let i = 0; i < 16; i++) {\n        W[i] =\n          (buf[offset] << 24) |\n          (buf[offset + 1] << 16) |\n          (buf[offset + 2] << 8) |\n          buf[offset + 3];\n        offset += 4;\n      }\n    }\n\n    // expand to 80 words\n    for (let i = 16; i < 80; i++) {\n      const t = W[i - 3] ^ W[i - 8] ^ W[i - 14] ^ W[i - 16];\n      W[i] = ((t << 1) | (t >>> 31)) & 0xffffffff;\n    }\n\n    let a = this.chain_[0];\n    let b = this.chain_[1];\n    let c = this.chain_[2];\n    let d = this.chain_[3];\n    let e = this.chain_[4];\n    let f, k;\n\n    // TODO(user): Try to unroll this loop to speed up the computation.\n    for (let i = 0; i < 80; i++) {\n      if (i < 40) {\n        if (i < 20) {\n          f = d ^ (b & (c ^ d));\n          k = 0x5a827999;\n        } else {\n          f = b ^ c ^ d;\n          k = 0x6ed9eba1;\n        }\n      } else {\n        if (i < 60) {\n          f = (b & c) | (d & (b | c));\n          k = 0x8f1bbcdc;\n        } else {\n          f = b ^ c ^ d;\n          k = 0xca62c1d6;\n        }\n      }\n\n      const t = (((a << 5) | (a >>> 27)) + f + e + k + W[i]) & 0xffffffff;\n      e = d;\n      d = c;\n      c = ((b << 30) | (b >>> 2)) & 0xffffffff;\n      b = a;\n      a = t;\n    }\n\n    this.chain_[0] = (this.chain_[0] + a) & 0xffffffff;\n    this.chain_[1] = (this.chain_[1] + b) & 0xffffffff;\n    this.chain_[2] = (this.chain_[2] + c) & 0xffffffff;\n    this.chain_[3] = (this.chain_[3] + d) & 0xffffffff;\n    this.chain_[4] = (this.chain_[4] + e) & 0xffffffff;\n  }\n\n  update(bytes?: number[] | Uint8Array | string, length?: number): void {\n    // TODO(johnlenz): tighten the function signature and remove this check\n    if (bytes == null) {\n      return;\n    }\n\n    if (length === undefined) {\n      length = bytes.length;\n    }\n\n    const lengthMinusBlock = length - this.blockSize;\n    let n = 0;\n    // Using local instead of member variables gives ~5% speedup on Firefox 16.\n    const buf = this.buf_;\n    let inbuf = this.inbuf_;\n\n    // The outer while loop should execute at most twice.\n    while (n < length) {\n      // When we have no data in the block to top up, we can directly process the\n      // input buffer (assuming it contains sufficient data). This gives ~25%\n      // speedup on Chrome 23 and ~15% speedup on Firefox 16, but requires that\n      // the data is provided in large chunks (or in multiples of 64 bytes).\n      if (inbuf === 0) {\n        while (n <= lengthMinusBlock) {\n          this.compress_(bytes, n);\n          n += this.blockSize;\n        }\n      }\n\n      if (typeof bytes === 'string') {\n        while (n < length) {\n          buf[inbuf] = bytes.charCodeAt(n);\n          ++inbuf;\n          ++n;\n          if (inbuf === this.blockSize) {\n            this.compress_(buf);\n            inbuf = 0;\n            // Jump to the outer loop so we use the full-block optimization.\n            break;\n          }\n        }\n      } else {\n        while (n < length) {\n          buf[inbuf] = bytes[n];\n          ++inbuf;\n          ++n;\n          if (inbuf === this.blockSize) {\n            this.compress_(buf);\n            inbuf = 0;\n            // Jump to the outer loop so we use the full-block optimization.\n            break;\n          }\n        }\n      }\n    }\n\n    this.inbuf_ = inbuf;\n    this.total_ += length;\n  }\n\n  /** @override */\n  digest(): number[] {\n    const digest: number[] = [];\n    let totalBits = this.total_ * 8;\n\n    // Add pad 0x80 0x00*.\n    if (this.inbuf_ < 56) {\n      this.update(this.pad_, 56 - this.inbuf_);\n    } else {\n      this.update(this.pad_, this.blockSize - (this.inbuf_ - 56));\n    }\n\n    // Add # bits.\n    for (let i = this.blockSize - 1; i >= 56; i--) {\n      this.buf_[i] = totalBits & 255;\n      totalBits /= 256; // Don't use bit-shifting here!\n    }\n\n    this.compress_(this.buf_);\n\n    let n = 0;\n    for (let i = 0; i < 5; i++) {\n      for (let j = 24; j >= 0; j -= 8) {\n        digest[n] = (this.chain_[i] >> j) & 255;\n        ++n;\n      }\n    }\n    return digest;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nexport type NextFn<T> = (value: T) => void;\nexport type ErrorFn = (error: Error) => void;\nexport type CompleteFn = () => void;\n\nexport interface Observer<T> {\n  // Called once for each value in a stream of values.\n  next: NextFn<T>;\n\n  // A stream terminates by a single call to EITHER error() or complete().\n  error: ErrorFn;\n\n  // No events will be sent to next() once complete() is called.\n  complete: CompleteFn;\n}\n\nexport type PartialObserver<T> = Partial<Observer<T>>;\n\n// TODO: Support also Unsubscribe.unsubscribe?\nexport type Unsubscribe = () => void;\n\n/**\n * The Subscribe interface has two forms - passing the inline function\n * callbacks, or a object interface with callback properties.\n */\nexport interface Subscribe<T> {\n  (next?: NextFn<T>, error?: ErrorFn, complete?: CompleteFn): Unsubscribe;\n  (observer: PartialObserver<T>): Unsubscribe;\n}\n\nexport interface Observable<T> {\n  // Subscribe method\n  subscribe: Subscribe<T>;\n}\n\nexport type Executor<T> = (observer: Observer<T>) => void;\n\n/**\n * Helper to make a Subscribe function (just like Promise helps make a\n * Thenable).\n *\n * @param executor Function which can make calls to a single Observer\n *     as a proxy.\n * @param onNoObservers Callback when count of Observers goes to zero.\n */\nexport function createSubscribe<T>(\n  executor: Executor<T>,\n  onNoObservers?: Executor<T>\n): Subscribe<T> {\n  const proxy = new ObserverProxy<T>(executor, onNoObservers);\n  return proxy.subscribe.bind(proxy);\n}\n\n/**\n * Implement fan-out for any number of Observers attached via a subscribe\n * function.\n */\nclass ObserverProxy<T> implements Observer<T> {\n  private observers: Array<Observer<T>> | undefined = [];\n  private unsubscribes: Unsubscribe[] = [];\n  private onNoObservers: Executor<T> | undefined;\n  private observerCount = 0;\n  // Micro-task scheduling by calling task.then().\n  private task = Promise.resolve();\n  private finalized = false;\n  private finalError?: Error;\n\n  /**\n   * @param executor Function which can make calls to a single Observer\n   *     as a proxy.\n   * @param onNoObservers Callback when count of Observers goes to zero.\n   */\n  constructor(executor: Executor<T>, onNoObservers?: Executor<T>) {\n    this.onNoObservers = onNoObservers;\n    // Call the executor asynchronously so subscribers that are called\n    // synchronously after the creation of the subscribe function\n    // can still receive the very first value generated in the executor.\n    this.task\n      .then(() => {\n        executor(this);\n      })\n      .catch(e => {\n        this.error(e);\n      });\n  }\n\n  next(value: T): void {\n    this.forEachObserver((observer: Observer<T>) => {\n      observer.next(value);\n    });\n  }\n\n  error(error: Error): void {\n    this.forEachObserver((observer: Observer<T>) => {\n      observer.error(error);\n    });\n    this.close(error);\n  }\n\n  complete(): void {\n    this.forEachObserver((observer: Observer<T>) => {\n      observer.complete();\n    });\n    this.close();\n  }\n\n  /**\n   * Subscribe function that can be used to add an Observer to the fan-out list.\n   *\n   * - We require that no event is sent to a subscriber sychronously to their\n   *   call to subscribe().\n   */\n  subscribe(\n    nextOrObserver?: NextFn<T> | PartialObserver<T>,\n    error?: ErrorFn,\n    complete?: CompleteFn\n  ): Unsubscribe {\n    let observer: Observer<T>;\n\n    if (\n      nextOrObserver === undefined &&\n      error === undefined &&\n      complete === undefined\n    ) {\n      throw new Error('Missing Observer.');\n    }\n\n    // Assemble an Observer object when passed as callback functions.\n    if (\n      implementsAnyMethods(nextOrObserver as { [key: string]: unknown }, [\n        'next',\n        'error',\n        'complete'\n      ])\n    ) {\n      observer = nextOrObserver as Observer<T>;\n    } else {\n      observer = {\n        next: nextOrObserver as NextFn<T>,\n        error,\n        complete\n      } as Observer<T>;\n    }\n\n    if (observer.next === undefined) {\n      observer.next = noop as NextFn<T>;\n    }\n    if (observer.error === undefined) {\n      observer.error = noop as ErrorFn;\n    }\n    if (observer.complete === undefined) {\n      observer.complete = noop as CompleteFn;\n    }\n\n    const unsub = this.unsubscribeOne.bind(this, this.observers!.length);\n\n    // Attempt to subscribe to a terminated Observable - we\n    // just respond to the Observer with the final error or complete\n    // event.\n    if (this.finalized) {\n      // eslint-disable-next-line @typescript-eslint/no-floating-promises\n      this.task.then(() => {\n        try {\n          if (this.finalError) {\n            observer.error(this.finalError);\n          } else {\n            observer.complete();\n          }\n        } catch (e) {\n          // nothing\n        }\n        return;\n      });\n    }\n\n    this.observers!.push(observer as Observer<T>);\n\n    return unsub;\n  }\n\n  // Unsubscribe is synchronous - we guarantee that no events are sent to\n  // any unsubscribed Observer.\n  private unsubscribeOne(i: number): void {\n    if (this.observers === undefined || this.observers[i] === undefined) {\n      return;\n    }\n\n    delete this.observers[i];\n\n    this.observerCount -= 1;\n    if (this.observerCount === 0 && this.onNoObservers !== undefined) {\n      this.onNoObservers(this);\n    }\n  }\n\n  private forEachObserver(fn: (observer: Observer<T>) => void): void {\n    if (this.finalized) {\n      // Already closed by previous event....just eat the additional values.\n      return;\n    }\n\n    // Since sendOne calls asynchronously - there is no chance that\n    // this.observers will become undefined.\n    for (let i = 0; i < this.observers!.length; i++) {\n      this.sendOne(i, fn);\n    }\n  }\n\n  // Call the Observer via one of it's callback function. We are careful to\n  // confirm that the observe has not been unsubscribed since this asynchronous\n  // function had been queued.\n  private sendOne(i: number, fn: (observer: Observer<T>) => void): void {\n    // Execute the callback asynchronously\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n    this.task.then(() => {\n      if (this.observers !== undefined && this.observers[i] !== undefined) {\n        try {\n          fn(this.observers[i]);\n        } catch (e) {\n          // Ignore exceptions raised in Observers or missing methods of an\n          // Observer.\n          // Log error to console. b/31404806\n          if (typeof console !== 'undefined' && console.error) {\n            console.error(e);\n          }\n        }\n      }\n    });\n  }\n\n  private close(err?: Error): void {\n    if (this.finalized) {\n      return;\n    }\n    this.finalized = true;\n    if (err !== undefined) {\n      this.finalError = err;\n    }\n    // Proxy is no longer needed - garbage collect references\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n    this.task.then(() => {\n      this.observers = undefined;\n      this.onNoObservers = undefined;\n    });\n  }\n}\n\n/** Turn synchronous function into one called asynchronously. */\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport function async(fn: Function, onError?: ErrorFn): Function {\n  return (...args: unknown[]) => {\n    Promise.resolve(true)\n      .then(() => {\n        fn(...args);\n      })\n      .catch((error: Error) => {\n        if (onError) {\n          onError(error);\n        }\n      });\n  };\n}\n\n/**\n * Return true if the object passed in implements any of the named methods.\n */\nfunction implementsAnyMethods(\n  obj: { [key: string]: unknown },\n  methods: string[]\n): boolean {\n  if (typeof obj !== 'object' || obj === null) {\n    return false;\n  }\n\n  for (const method of methods) {\n    if (method in obj && typeof obj[method] === 'function') {\n      return true;\n    }\n  }\n\n  return false;\n}\n\nfunction noop(): void {\n  // do nothing\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Check to make sure the appropriate number of arguments are provided for a public function.\n * Throws an error if it fails.\n *\n * @param fnName The function name\n * @param minCount The minimum number of arguments to allow for the function call\n * @param maxCount The maximum number of argument to allow for the function call\n * @param argCount The actual number of arguments provided.\n */\nexport const validateArgCount = function (\n  fnName: string,\n  minCount: number,\n  maxCount: number,\n  argCount: number\n): void {\n  let argError;\n  if (argCount < minCount) {\n    argError = 'at least ' + minCount;\n  } else if (argCount > maxCount) {\n    argError = maxCount === 0 ? 'none' : 'no more than ' + maxCount;\n  }\n  if (argError) {\n    const error =\n      fnName +\n      ' failed: Was called with ' +\n      argCount +\n      (argCount === 1 ? ' argument.' : ' arguments.') +\n      ' Expects ' +\n      argError +\n      '.';\n    throw new Error(error);\n  }\n};\n\n/**\n * Generates a string to prefix an error message about failed argument validation\n *\n * @param fnName The function name\n * @param argName The name of the argument\n * @return The prefix to add to the error thrown for validation.\n */\nexport function errorPrefix(fnName: string, argName: string): string {\n  return `${fnName} failed: ${argName} argument `;\n}\n\n/**\n * @param fnName\n * @param argumentNumber\n * @param namespace\n * @param optional\n */\nexport function validateNamespace(\n  fnName: string,\n  namespace: string,\n  optional: boolean\n): void {\n  if (optional && !namespace) {\n    return;\n  }\n  if (typeof namespace !== 'string') {\n    //TODO: I should do more validation here. We only allow certain chars in namespaces.\n    throw new Error(\n      errorPrefix(fnName, 'namespace') + 'must be a valid firebase namespace.'\n    );\n  }\n}\n\nexport function validateCallback(\n  fnName: string,\n  argumentName: string,\n  // eslint-disable-next-line @typescript-eslint/ban-types\n  callback: Function,\n  optional: boolean\n): void {\n  if (optional && !callback) {\n    return;\n  }\n  if (typeof callback !== 'function') {\n    throw new Error(\n      errorPrefix(fnName, argumentName) + 'must be a valid function.'\n    );\n  }\n}\n\nexport function validateContextObject(\n  fnName: string,\n  argumentName: string,\n  context: unknown,\n  optional: boolean\n): void {\n  if (optional && !context) {\n    return;\n  }\n  if (typeof context !== 'object' || context === null) {\n    throw new Error(\n      errorPrefix(fnName, argumentName) + 'must be a valid context object.'\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from './assert';\n\n// Code originally came from goog.crypt.stringToUtf8ByteArray, but for some reason they\n// automatically replaced '\\r\\n' with '\\n', and they didn't handle surrogate pairs,\n// so it's been modified.\n\n// Note that not all Unicode characters appear as single characters in JavaScript strings.\n// fromCharCode returns the UTF-16 encoding of a character - so some Unicode characters\n// use 2 characters in Javascript.  All 4-byte UTF-8 characters begin with a first\n// character in the range 0xD800 - 0xDBFF (the first character of a so-called surrogate\n// pair).\n// See http://www.ecma-international.org/ecma-262/5.1/#sec-15.1.3\n\n/**\n * @param {string} str\n * @return {Array}\n */\nexport const stringToByteArray = function (str: string): number[] {\n  const out: number[] = [];\n  let p = 0;\n  for (let i = 0; i < str.length; i++) {\n    let c = str.charCodeAt(i);\n\n    // Is this the lead surrogate in a surrogate pair?\n    if (c >= 0xd800 && c <= 0xdbff) {\n      const high = c - 0xd800; // the high 10 bits.\n      i++;\n      assert(i < str.length, 'Surrogate pair missing trail surrogate.');\n      const low = str.charCodeAt(i) - 0xdc00; // the low 10 bits.\n      c = 0x10000 + (high << 10) + low;\n    }\n\n    if (c < 128) {\n      out[p++] = c;\n    } else if (c < 2048) {\n      out[p++] = (c >> 6) | 192;\n      out[p++] = (c & 63) | 128;\n    } else if (c < 65536) {\n      out[p++] = (c >> 12) | 224;\n      out[p++] = ((c >> 6) & 63) | 128;\n      out[p++] = (c & 63) | 128;\n    } else {\n      out[p++] = (c >> 18) | 240;\n      out[p++] = ((c >> 12) & 63) | 128;\n      out[p++] = ((c >> 6) & 63) | 128;\n      out[p++] = (c & 63) | 128;\n    }\n  }\n  return out;\n};\n\n/**\n * Calculate length without actually converting; useful for doing cheaper validation.\n * @param {string} str\n * @return {number}\n */\nexport const stringLength = function (str: string): number {\n  let p = 0;\n  for (let i = 0; i < str.length; i++) {\n    const c = str.charCodeAt(i);\n    if (c < 128) {\n      p++;\n    } else if (c < 2048) {\n      p += 2;\n    } else if (c >= 0xd800 && c <= 0xdbff) {\n      // Lead surrogate of a surrogate pair.  The pair together will take 4 bytes to represent.\n      p += 4;\n      i++; // skip trail surrogate.\n    } else {\n      p += 3;\n    }\n  }\n  return p;\n};\n","/**\n * @license\n * Copyright 2022 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Copied from https://stackoverflow.com/a/2117523\n * Generates a new uuid.\n * @public\n */\nexport const uuidv4 = function (): string {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, c => {\n    const r = (Math.random() * 16) | 0,\n      v = c === 'x' ? r : (r & 0x3) | 0x8;\n    return v.toString(16);\n  });\n};\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * The amount of milliseconds to exponentially increase.\n */\nconst DEFAULT_INTERVAL_MILLIS = 1000;\n\n/**\n * The factor to backoff by.\n * Should be a number greater than 1.\n */\nconst DEFAULT_BACKOFF_FACTOR = 2;\n\n/**\n * The maximum milliseconds to increase to.\n *\n * <p>Visible for testing\n */\nexport const MAX_VALUE_MILLIS = 4 * 60 * 60 * 1000; // Four hours, like iOS and Android.\n\n/**\n * The percentage of backoff time to randomize by.\n * See\n * http://go/safe-client-behavior#step-1-determine-the-appropriate-retry-interval-to-handle-spike-traffic\n * for context.\n *\n * <p>Visible for testing\n */\nexport const RANDOM_FACTOR = 0.5;\n\n/**\n * Based on the backoff method from\n * https://github.com/google/closure-library/blob/master/closure/goog/math/exponentialbackoff.js.\n * Extracted here so we don't need to pass metadata and a stateful ExponentialBackoff object around.\n */\nexport function calculateBackoffMillis(\n  backoffCount: number,\n  intervalMillis: number = DEFAULT_INTERVAL_MILLIS,\n  backoffFactor: number = DEFAULT_BACKOFF_FACTOR\n): number {\n  // Calculates an exponentially increasing value.\n  // Deviation: calculates value from count and a constant interval, so we only need to save value\n  // and count to restore state.\n  const currBaseValue = intervalMillis * Math.pow(backoffFactor, backoffCount);\n\n  // A random \"fuzz\" to avoid waves of retries.\n  // Deviation: randomFactor is required.\n  const randomWait = Math.round(\n    // A fraction of the backoff value to add/subtract.\n    // Deviation: changes multiplication order to improve readability.\n    RANDOM_FACTOR *\n      currBaseValue *\n      // A random float (rounded to int by Math.round above) in the range [-1, 1]. Determines\n      // if we add or subtract.\n      (Math.random() - 0.5) *\n      2\n  );\n\n  // Limits backoff to max to avoid effectively permanent backoff.\n  return Math.min(MAX_VALUE_MILLIS, currBaseValue + randomWait);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Provide English ordinal letters after a number\n */\nexport function ordinal(i: number): string {\n  if (!Number.isFinite(i)) {\n    return `${i}`;\n  }\n  return i + indicator(i);\n}\n\nfunction indicator(i: number): string {\n  i = Math.abs(i);\n  const cent = i % 100;\n  if (cent >= 10 && cent <= 20) {\n    return 'th';\n  }\n  const dec = i % 10;\n  if (dec === 1) {\n    return 'st';\n  }\n  if (dec === 2) {\n    return 'nd';\n  }\n  if (dec === 3) {\n    return 'rd';\n  }\n  return 'th';\n}\n","/**\n * @license\n * Copyright 2021 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport interface Compat<T> {\n  _delegate: T;\n}\n\nexport function getModularInstance<ExpService>(\n  service: Compat<ExpService> | ExpService\n): ExpService {\n  if (service && (service as Compat<ExpService>)._delegate) {\n    return (service as Compat<ExpService>)._delegate;\n  } else {\n    return service as ExpService;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport {\n  InstantiationMode,\n  InstanceFactory,\n  ComponentType,\n  Dictionary,\n  Name,\n  onInstanceCreatedCallback\n} from './types';\n\n/**\n * Component for service name T, e.g. `auth`, `auth-internal`\n */\nexport class Component<T extends Name = Name> {\n  multipleInstances = false;\n  /**\n   * Properties to be added to the service namespace\n   */\n  serviceProps: Dictionary = {};\n\n  instantiationMode = InstantiationMode.LAZY;\n\n  onInstanceCreated: onInstanceCreatedCallback<T> | null = null;\n\n  /**\n   *\n   * @param name The public service name, e.g. app, auth, firestore, database\n   * @param instanceFactory Service factory responsible for creating the public interface\n   * @param type whether the service provided by the component is public or private\n   */\n  constructor(\n    readonly name: T,\n    readonly instanceFactory: InstanceFactory<T>,\n    readonly type: ComponentType\n  ) {}\n\n  setInstantiationMode(mode: InstantiationMode): this {\n    this.instantiationMode = mode;\n    return this;\n  }\n\n  setMultipleInstances(multipleInstances: boolean): this {\n    this.multipleInstances = multipleInstances;\n    return this;\n  }\n\n  setServiceProps(props: Dictionary): this {\n    this.serviceProps = props;\n    return this;\n  }\n\n  setInstanceCreatedCallback(callback: onInstanceCreatedCallback<T>): this {\n    this.onInstanceCreated = callback;\n    return this;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport const DEFAULT_ENTRY_NAME = '[DEFAULT]';\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Deferred } from '@firebase/util';\nimport { ComponentContainer } from './component_container';\nimport { DEFAULT_ENTRY_NAME } from './constants';\nimport {\n  InitializeOptions,\n  InstantiationMode,\n  Name,\n  NameServiceMapping,\n  OnInitCallBack\n} from './types';\nimport { Component } from './component';\n\n/**\n * Provider for instance for service name T, e.g. 'auth', 'auth-internal'\n * NameServiceMapping[T] is an alias for the type of the instance\n */\nexport class Provider<T extends Name> {\n  private component: Component<T> | null = null;\n  private readonly instances: Map<string, NameServiceMapping[T]> = new Map();\n  private readonly instancesDeferred: Map<\n    string,\n    Deferred<NameServiceMapping[T]>\n  > = new Map();\n  private readonly instancesOptions: Map<string, Record<string, unknown>> =\n    new Map();\n  private onInitCallbacks: Map<string, Set<OnInitCallBack<T>>> = new Map();\n\n  constructor(\n    private readonly name: T,\n    private readonly container: ComponentContainer\n  ) {}\n\n  /**\n   * @param identifier A provider can provide mulitple instances of a service\n   * if this.component.multipleInstances is true.\n   */\n  get(identifier?: string): Promise<NameServiceMapping[T]> {\n    // if multipleInstances is not supported, use the default name\n    const normalizedIdentifier = this.normalizeInstanceIdentifier(identifier);\n\n    if (!this.instancesDeferred.has(normalizedIdentifier)) {\n      const deferred = new Deferred<NameServiceMapping[T]>();\n      this.instancesDeferred.set(normalizedIdentifier, deferred);\n\n      if (\n        this.isInitialized(normalizedIdentifier) ||\n        this.shouldAutoInitialize()\n      ) {\n        // initialize the service if it can be auto-initialized\n        try {\n          const instance = this.getOrInitializeService({\n            instanceIdentifier: normalizedIdentifier\n          });\n          if (instance) {\n            deferred.resolve(instance);\n          }\n        } catch (e) {\n          // when the instance factory throws an exception during get(), it should not cause\n          // a fatal error. We just return the unresolved promise in this case.\n        }\n      }\n    }\n\n    return this.instancesDeferred.get(normalizedIdentifier)!.promise;\n  }\n\n  /**\n   *\n   * @param options.identifier A provider can provide mulitple instances of a service\n   * if this.component.multipleInstances is true.\n   * @param options.optional If optional is false or not provided, the method throws an error when\n   * the service is not immediately available.\n   * If optional is true, the method returns null if the service is not immediately available.\n   */\n  getImmediate(options: {\n    identifier?: string;\n    optional: true;\n  }): NameServiceMapping[T] | null;\n  getImmediate(options?: {\n    identifier?: string;\n    optional?: false;\n  }): NameServiceMapping[T];\n  getImmediate(options?: {\n    identifier?: string;\n    optional?: boolean;\n  }): NameServiceMapping[T] | null {\n    // if multipleInstances is not supported, use the default name\n    const normalizedIdentifier = this.normalizeInstanceIdentifier(\n      options?.identifier\n    );\n    const optional = options?.optional ?? false;\n\n    if (\n      this.isInitialized(normalizedIdentifier) ||\n      this.shouldAutoInitialize()\n    ) {\n      try {\n        return this.getOrInitializeService({\n          instanceIdentifier: normalizedIdentifier\n        });\n      } catch (e) {\n        if (optional) {\n          return null;\n        } else {\n          throw e;\n        }\n      }\n    } else {\n      // In case a component is not initialized and should/can not be auto-initialized at the moment, return null if the optional flag is set, or throw\n      if (optional) {\n        return null;\n      } else {\n        throw Error(`Service ${this.name} is not available`);\n      }\n    }\n  }\n\n  getComponent(): Component<T> | null {\n    return this.component;\n  }\n\n  setComponent(component: Component<T>): void {\n    if (component.name !== this.name) {\n      throw Error(\n        `Mismatching Component ${component.name} for Provider ${this.name}.`\n      );\n    }\n\n    if (this.component) {\n      throw Error(`Component for ${this.name} has already been provided`);\n    }\n\n    this.component = component;\n\n    // return early without attempting to initialize the component if the component requires explicit initialization (calling `Provider.initialize()`)\n    if (!this.shouldAutoInitialize()) {\n      return;\n    }\n\n    // if the service is eager, initialize the default instance\n    if (isComponentEager(component)) {\n      try {\n        this.getOrInitializeService({ instanceIdentifier: DEFAULT_ENTRY_NAME });\n      } catch (e) {\n        // when the instance factory for an eager Component throws an exception during the eager\n        // initialization, it should not cause a fatal error.\n        // TODO: Investigate if we need to make it configurable, because some component may want to cause\n        // a fatal error in this case?\n      }\n    }\n\n    // Create service instances for the pending promises and resolve them\n    // NOTE: if this.multipleInstances is false, only the default instance will be created\n    // and all promises with resolve with it regardless of the identifier.\n    for (const [\n      instanceIdentifier,\n      instanceDeferred\n    ] of this.instancesDeferred.entries()) {\n      const normalizedIdentifier =\n        this.normalizeInstanceIdentifier(instanceIdentifier);\n\n      try {\n        // `getOrInitializeService()` should always return a valid instance since a component is guaranteed. use ! to make typescript happy.\n        const instance = this.getOrInitializeService({\n          instanceIdentifier: normalizedIdentifier\n        })!;\n        instanceDeferred.resolve(instance);\n      } catch (e) {\n        // when the instance factory throws an exception, it should not cause\n        // a fatal error. We just leave the promise unresolved.\n      }\n    }\n  }\n\n  clearInstance(identifier: string = DEFAULT_ENTRY_NAME): void {\n    this.instancesDeferred.delete(identifier);\n    this.instancesOptions.delete(identifier);\n    this.instances.delete(identifier);\n  }\n\n  // app.delete() will call this method on every provider to delete the services\n  // TODO: should we mark the provider as deleted?\n  async delete(): Promise<void> {\n    const services = Array.from(this.instances.values());\n\n    await Promise.all([\n      ...services\n        .filter(service => 'INTERNAL' in service) // legacy services\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        .map(service => (service as any).INTERNAL!.delete()),\n      ...services\n        .filter(service => '_delete' in service) // modularized services\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        .map(service => (service as any)._delete())\n    ]);\n  }\n\n  isComponentSet(): boolean {\n    return this.component != null;\n  }\n\n  isInitialized(identifier: string = DEFAULT_ENTRY_NAME): boolean {\n    return this.instances.has(identifier);\n  }\n\n  getOptions(identifier: string = DEFAULT_ENTRY_NAME): Record<string, unknown> {\n    return this.instancesOptions.get(identifier) || {};\n  }\n\n  initialize(opts: InitializeOptions = {}): NameServiceMapping[T] {\n    const { options = {} } = opts;\n    const normalizedIdentifier = this.normalizeInstanceIdentifier(\n      opts.instanceIdentifier\n    );\n    if (this.isInitialized(normalizedIdentifier)) {\n      throw Error(\n        `${this.name}(${normalizedIdentifier}) has already been initialized`\n      );\n    }\n\n    if (!this.isComponentSet()) {\n      throw Error(`Component ${this.name} has not been registered yet`);\n    }\n\n    const instance = this.getOrInitializeService({\n      instanceIdentifier: normalizedIdentifier,\n      options\n    })!;\n\n    // resolve any pending promise waiting for the service instance\n    for (const [\n      instanceIdentifier,\n      instanceDeferred\n    ] of this.instancesDeferred.entries()) {\n      const normalizedDeferredIdentifier =\n        this.normalizeInstanceIdentifier(instanceIdentifier);\n      if (normalizedIdentifier === normalizedDeferredIdentifier) {\n        instanceDeferred.resolve(instance);\n      }\n    }\n\n    return instance;\n  }\n\n  /**\n   *\n   * @param callback - a function that will be invoked  after the provider has been initialized by calling provider.initialize().\n   * The function is invoked SYNCHRONOUSLY, so it should not execute any longrunning tasks in order to not block the program.\n   *\n   * @param identifier An optional instance identifier\n   * @returns a function to unregister the callback\n   */\n  onInit(callback: OnInitCallBack<T>, identifier?: string): () => void {\n    const normalizedIdentifier = this.normalizeInstanceIdentifier(identifier);\n    const existingCallbacks =\n      this.onInitCallbacks.get(normalizedIdentifier) ??\n      new Set<OnInitCallBack<T>>();\n    existingCallbacks.add(callback);\n    this.onInitCallbacks.set(normalizedIdentifier, existingCallbacks);\n\n    const existingInstance = this.instances.get(normalizedIdentifier);\n    if (existingInstance) {\n      callback(existingInstance, normalizedIdentifier);\n    }\n\n    return () => {\n      existingCallbacks.delete(callback);\n    };\n  }\n\n  /**\n   * Invoke onInit callbacks synchronously\n   * @param instance the service instance`\n   */\n  private invokeOnInitCallbacks(\n    instance: NameServiceMapping[T],\n    identifier: string\n  ): void {\n    const callbacks = this.onInitCallbacks.get(identifier);\n    if (!callbacks) {\n      return;\n    }\n    for (const callback of callbacks) {\n      try {\n        callback(instance, identifier);\n      } catch {\n        // ignore errors in the onInit callback\n      }\n    }\n  }\n\n  private getOrInitializeService({\n    instanceIdentifier,\n    options = {}\n  }: {\n    instanceIdentifier: string;\n    options?: Record<string, unknown>;\n  }): NameServiceMapping[T] | null {\n    let instance = this.instances.get(instanceIdentifier);\n    if (!instance && this.component) {\n      instance = this.component.instanceFactory(this.container, {\n        instanceIdentifier: normalizeIdentifierForFactory(instanceIdentifier),\n        options\n      });\n      this.instances.set(instanceIdentifier, instance);\n      this.instancesOptions.set(instanceIdentifier, options);\n\n      /**\n       * Invoke onInit listeners.\n       * Note this.component.onInstanceCreated is different, which is used by the component creator,\n       * while onInit listeners are registered by consumers of the provider.\n       */\n      this.invokeOnInitCallbacks(instance, instanceIdentifier);\n\n      /**\n       * Order is important\n       * onInstanceCreated() should be called after this.instances.set(instanceIdentifier, instance); which\n       * makes `isInitialized()` return true.\n       */\n      if (this.component.onInstanceCreated) {\n        try {\n          this.component.onInstanceCreated(\n            this.container,\n            instanceIdentifier,\n            instance\n          );\n        } catch {\n          // ignore errors in the onInstanceCreatedCallback\n        }\n      }\n    }\n\n    return instance || null;\n  }\n\n  private normalizeInstanceIdentifier(\n    identifier: string = DEFAULT_ENTRY_NAME\n  ): string {\n    if (this.component) {\n      return this.component.multipleInstances ? identifier : DEFAULT_ENTRY_NAME;\n    } else {\n      return identifier; // assume multiple instances are supported before the component is provided.\n    }\n  }\n\n  private shouldAutoInitialize(): boolean {\n    return (\n      !!this.component &&\n      this.component.instantiationMode !== InstantiationMode.EXPLICIT\n    );\n  }\n}\n\n// undefined should be passed to the service factory for the default instance\nfunction normalizeIdentifierForFactory(identifier: string): string | undefined {\n  return identifier === DEFAULT_ENTRY_NAME ? undefined : identifier;\n}\n\nfunction isComponentEager<T extends Name>(component: Component<T>): boolean {\n  return component.instantiationMode === InstantiationMode.EAGER;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Provider } from './provider';\nimport { Component } from './component';\nimport { Name } from './types';\n\n/**\n * ComponentContainer that provides Providers for service name T, e.g. `auth`, `auth-internal`\n */\nexport class ComponentContainer {\n  private readonly providers = new Map<string, Provider<Name>>();\n\n  constructor(private readonly name: string) {}\n\n  /**\n   *\n   * @param component Component being added\n   * @param overwrite When a component with the same name has already been registered,\n   * if overwrite is true: overwrite the existing component with the new component and create a new\n   * provider with the new component. It can be useful in tests where you want to use different mocks\n   * for different tests.\n   * if overwrite is false: throw an exception\n   */\n  addComponent<T extends Name>(component: Component<T>): void {\n    const provider = this.getProvider(component.name);\n    if (provider.isComponentSet()) {\n      throw new Error(\n        `Component ${component.name} has already been registered with ${this.name}`\n      );\n    }\n\n    provider.setComponent(component);\n  }\n\n  addOrOverwriteComponent<T extends Name>(component: Component<T>): void {\n    const provider = this.getProvider(component.name);\n    if (provider.isComponentSet()) {\n      // delete the existing provider from the container, so we can register the new component\n      this.providers.delete(component.name);\n    }\n\n    this.addComponent(component);\n  }\n\n  /**\n   * getProvider provides a type safe interface where it can only be called with a field name\n   * present in NameServiceMapping interface.\n   *\n   * Firebase SDKs providing services should extend NameServiceMapping interface to register\n   * themselves.\n   */\n  getProvider<T extends Name>(name: T): Provider<T> {\n    if (this.providers.has(name)) {\n      return this.providers.get(name) as unknown as Provider<T>;\n    }\n\n    // create a Provider for a service that hasn't registered with Firebase\n    const provider = new Provider<T>(name, this);\n    this.providers.set(name, provider as unknown as Provider<Name>);\n\n    return provider as Provider<T>;\n  }\n\n  getProviders(): Array<Provider<Name>> {\n    return Array.from(this.providers.values());\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport type LogLevelString =\n  | 'debug'\n  | 'verbose'\n  | 'info'\n  | 'warn'\n  | 'error'\n  | 'silent';\n\nexport interface LogOptions {\n  level: LogLevelString;\n}\n\nexport type LogCallback = (callbackParams: LogCallbackParams) => void;\n\nexport interface LogCallbackParams {\n  level: LogLevelString;\n  message: string;\n  args: unknown[];\n  type: string;\n}\n\n/**\n * A container for all of the Logger instances\n */\nexport const instances: Logger[] = [];\n\n/**\n * The JS SDK supports 5 log levels and also allows a user the ability to\n * silence the logs altogether.\n *\n * The order is a follows:\n * DEBUG < VERBOSE < INFO < WARN < ERROR\n *\n * All of the log types above the current log level will be captured (i.e. if\n * you set the log level to `INFO`, errors will still be logged, but `DEBUG` and\n * `VERBOSE` logs will not)\n */\nexport enum LogLevel {\n  DEBUG,\n  VERBOSE,\n  INFO,\n  WARN,\n  ERROR,\n  SILENT\n}\n\nconst levelStringToEnum: { [key in LogLevelString]: LogLevel } = {\n  'debug': LogLevel.DEBUG,\n  'verbose': LogLevel.VERBOSE,\n  'info': LogLevel.INFO,\n  'warn': LogLevel.WARN,\n  'error': LogLevel.ERROR,\n  'silent': LogLevel.SILENT\n};\n\n/**\n * The default log level\n */\nconst defaultLogLevel: LogLevel = LogLevel.INFO;\n\n/**\n * We allow users the ability to pass their own log handler. We will pass the\n * type of log, the current log level, and any other arguments passed (i.e. the\n * messages that the user wants to log) to this function.\n */\nexport type LogHandler = (\n  loggerInstance: Logger,\n  logType: LogLevel,\n  ...args: unknown[]\n) => void;\n\n/**\n * By default, `console.debug` is not displayed in the developer console (in\n * chrome). To avoid forcing users to have to opt-in to these logs twice\n * (i.e. once for firebase, and once in the console), we are sending `DEBUG`\n * logs to the `console.log` function.\n */\nconst ConsoleMethod = {\n  [LogLevel.DEBUG]: 'log',\n  [LogLevel.VERBOSE]: 'log',\n  [LogLevel.INFO]: 'info',\n  [LogLevel.WARN]: 'warn',\n  [LogLevel.ERROR]: 'error'\n};\n\n/**\n * The default log handler will forward DEBUG, VERBOSE, INFO, WARN, and ERROR\n * messages on to their corresponding console counterparts (if the log method\n * is supported by the current log level)\n */\nconst defaultLogHandler: LogHandler = (instance, logType, ...args): void => {\n  if (logType < instance.logLevel) {\n    return;\n  }\n  const now = new Date().toISOString();\n  const method = ConsoleMethod[logType as keyof typeof ConsoleMethod];\n  if (method) {\n    console[method as 'log' | 'info' | 'warn' | 'error'](\n      `[${now}]  ${instance.name}:`,\n      ...args\n    );\n  } else {\n    throw new Error(\n      `Attempted to log a message with an invalid logType (value: ${logType})`\n    );\n  }\n};\n\nexport class Logger {\n  /**\n   * Gives you an instance of a Logger to capture messages according to\n   * Firebase's logging scheme.\n   *\n   * @param name The name that the logs will be associated with\n   */\n  constructor(public name: string) {\n    /**\n     * Capture the current instance for later use\n     */\n    instances.push(this);\n  }\n\n  /**\n   * The log level of the given Logger instance.\n   */\n  private _logLevel = defaultLogLevel;\n\n  get logLevel(): LogLevel {\n    return this._logLevel;\n  }\n\n  set logLevel(val: LogLevel) {\n    if (!(val in LogLevel)) {\n      throw new TypeError(`Invalid value \"${val}\" assigned to \\`logLevel\\``);\n    }\n    this._logLevel = val;\n  }\n\n  // Workaround for setter/getter having to be the same type.\n  setLogLevel(val: LogLevel | LogLevelString): void {\n    this._logLevel = typeof val === 'string' ? levelStringToEnum[val] : val;\n  }\n\n  /**\n   * The main (internal) log handler for the Logger instance.\n   * Can be set to a new function in internal package code but not by user.\n   */\n  private _logHandler: LogHandler = defaultLogHandler;\n  get logHandler(): LogHandler {\n    return this._logHandler;\n  }\n  set logHandler(val: LogHandler) {\n    if (typeof val !== 'function') {\n      throw new TypeError('Value assigned to `logHandler` must be a function');\n    }\n    this._logHandler = val;\n  }\n\n  /**\n   * The optional, additional, user-defined log handler for the Logger instance.\n   */\n  private _userLogHandler: LogHandler | null = null;\n  get userLogHandler(): LogHandler | null {\n    return this._userLogHandler;\n  }\n  set userLogHandler(val: LogHandler | null) {\n    this._userLogHandler = val;\n  }\n\n  /**\n   * The functions below are all based on the `console` interface\n   */\n\n  debug(...args: unknown[]): void {\n    this._userLogHandler && this._userLogHandler(this, LogLevel.DEBUG, ...args);\n    this._logHandler(this, LogLevel.DEBUG, ...args);\n  }\n  log(...args: unknown[]): void {\n    this._userLogHandler &&\n      this._userLogHandler(this, LogLevel.VERBOSE, ...args);\n    this._logHandler(this, LogLevel.VERBOSE, ...args);\n  }\n  info(...args: unknown[]): void {\n    this._userLogHandler && this._userLogHandler(this, LogLevel.INFO, ...args);\n    this._logHandler(this, LogLevel.INFO, ...args);\n  }\n  warn(...args: unknown[]): void {\n    this._userLogHandler && this._userLogHandler(this, LogLevel.WARN, ...args);\n    this._logHandler(this, LogLevel.WARN, ...args);\n  }\n  error(...args: unknown[]): void {\n    this._userLogHandler && this._userLogHandler(this, LogLevel.ERROR, ...args);\n    this._logHandler(this, LogLevel.ERROR, ...args);\n  }\n}\n\nexport function setLogLevel(level: LogLevelString | LogLevel): void {\n  instances.forEach(inst => {\n    inst.setLogLevel(level);\n  });\n}\n\nexport function setUserLogHandler(\n  logCallback: LogCallback | null,\n  options?: LogOptions\n): void {\n  for (const instance of instances) {\n    let customLogLevel: LogLevel | null = null;\n    if (options && options.level) {\n      customLogLevel = levelStringToEnum[options.level];\n    }\n    if (logCallback === null) {\n      instance.userLogHandler = null;\n    } else {\n      instance.userLogHandler = (\n        instance: Logger,\n        level: LogLevel,\n        ...args: unknown[]\n      ) => {\n        const message = args\n          .map(arg => {\n            if (arg == null) {\n              return null;\n            } else if (typeof arg === 'string') {\n              return arg;\n            } else if (typeof arg === 'number' || typeof arg === 'boolean') {\n              return arg.toString();\n            } else if (arg instanceof Error) {\n              return arg.message;\n            } else {\n              try {\n                return JSON.stringify(arg);\n              } catch (ignored) {\n                return null;\n              }\n            }\n          })\n          .filter(arg => arg)\n          .join(' ');\n        if (level >= (customLogLevel ?? instance.logLevel)) {\n          logCallback({\n            level: LogLevel[level].toLowerCase() as LogLevelString,\n            message,\n            args,\n            type: instance.name\n          });\n        }\n      };\n    }\n  }\n}\n","const instanceOfAny = (object, constructors) => constructors.some((c) => object instanceof c);\n\nlet idbProxyableTypes;\nlet cursorAdvanceMethods;\n// This is a function to prevent it throwing up in node environments.\nfunction getIdbProxyableTypes() {\n    return (idbProxyableTypes ||\n        (idbProxyableTypes = [\n            IDBDatabase,\n            IDBObjectStore,\n            IDBIndex,\n            IDBCursor,\n            IDBTransaction,\n        ]));\n}\n// This is a function to prevent it throwing up in node environments.\nfunction getCursorAdvanceMethods() {\n    return (cursorAdvanceMethods ||\n        (cursorAdvanceMethods = [\n            IDBCursor.prototype.advance,\n            IDBCursor.prototype.continue,\n            IDBCursor.prototype.continuePrimaryKey,\n        ]));\n}\nconst cursorRequestMap = new WeakMap();\nconst transactionDoneMap = new WeakMap();\nconst transactionStoreNamesMap = new WeakMap();\nconst transformCache = new WeakMap();\nconst reverseTransformCache = new WeakMap();\nfunction promisifyRequest(request) {\n    const promise = new Promise((resolve, reject) => {\n        const unlisten = () => {\n            request.removeEventListener('success', success);\n            request.removeEventListener('error', error);\n        };\n        const success = () => {\n            resolve(wrap(request.result));\n            unlisten();\n        };\n        const error = () => {\n            reject(request.error);\n            unlisten();\n        };\n        request.addEventListener('success', success);\n        request.addEventListener('error', error);\n    });\n    promise\n        .then((value) => {\n        // Since cursoring reuses the IDBRequest (*sigh*), we cache it for later retrieval\n        // (see wrapFunction).\n        if (value instanceof IDBCursor) {\n            cursorRequestMap.set(value, request);\n        }\n        // Catching to avoid \"Uncaught Promise exceptions\"\n    })\n        .catch(() => { });\n    // This mapping exists in reverseTransformCache but doesn't doesn't exist in transformCache. This\n    // is because we create many promises from a single IDBRequest.\n    reverseTransformCache.set(promise, request);\n    return promise;\n}\nfunction cacheDonePromiseForTransaction(tx) {\n    // Early bail if we've already created a done promise for this transaction.\n    if (transactionDoneMap.has(tx))\n        return;\n    const done = new Promise((resolve, reject) => {\n        const unlisten = () => {\n            tx.removeEventListener('complete', complete);\n            tx.removeEventListener('error', error);\n            tx.removeEventListener('abort', error);\n        };\n        const complete = () => {\n            resolve();\n            unlisten();\n        };\n        const error = () => {\n            reject(tx.error || new DOMException('AbortError', 'AbortError'));\n            unlisten();\n        };\n        tx.addEventListener('complete', complete);\n        tx.addEventListener('error', error);\n        tx.addEventListener('abort', error);\n    });\n    // Cache it for later retrieval.\n    transactionDoneMap.set(tx, done);\n}\nlet idbProxyTraps = {\n    get(target, prop, receiver) {\n        if (target instanceof IDBTransaction) {\n            // Special handling for transaction.done.\n            if (prop === 'done')\n                return transactionDoneMap.get(target);\n            // Polyfill for objectStoreNames because of Edge.\n            if (prop === 'objectStoreNames') {\n                return target.objectStoreNames || transactionStoreNamesMap.get(target);\n            }\n            // Make tx.store return the only store in the transaction, or undefined if there are many.\n            if (prop === 'store') {\n                return receiver.objectStoreNames[1]\n                    ? undefined\n                    : receiver.objectStore(receiver.objectStoreNames[0]);\n            }\n        }\n        // Else transform whatever we get back.\n        return wrap(target[prop]);\n    },\n    set(target, prop, value) {\n        target[prop] = value;\n        return true;\n    },\n    has(target, prop) {\n        if (target instanceof IDBTransaction &&\n            (prop === 'done' || prop === 'store')) {\n            return true;\n        }\n        return prop in target;\n    },\n};\nfunction replaceTraps(callback) {\n    idbProxyTraps = callback(idbProxyTraps);\n}\nfunction wrapFunction(func) {\n    // Due to expected object equality (which is enforced by the caching in `wrap`), we\n    // only create one new func per func.\n    // Edge doesn't support objectStoreNames (booo), so we polyfill it here.\n    if (func === IDBDatabase.prototype.transaction &&\n        !('objectStoreNames' in IDBTransaction.prototype)) {\n        return function (storeNames, ...args) {\n            const tx = func.call(unwrap(this), storeNames, ...args);\n            transactionStoreNamesMap.set(tx, storeNames.sort ? storeNames.sort() : [storeNames]);\n            return wrap(tx);\n        };\n    }\n    // Cursor methods are special, as the behaviour is a little more different to standard IDB. In\n    // IDB, you advance the cursor and wait for a new 'success' on the IDBRequest that gave you the\n    // cursor. It's kinda like a promise that can resolve with many values. That doesn't make sense\n    // with real promises, so each advance methods returns a new promise for the cursor object, or\n    // undefined if the end of the cursor has been reached.\n    if (getCursorAdvanceMethods().includes(func)) {\n        return function (...args) {\n            // Calling the original function with the proxy as 'this' causes ILLEGAL INVOCATION, so we use\n            // the original object.\n            func.apply(unwrap(this), args);\n            return wrap(cursorRequestMap.get(this));\n        };\n    }\n    return function (...args) {\n        // Calling the original function with the proxy as 'this' causes ILLEGAL INVOCATION, so we use\n        // the original object.\n        return wrap(func.apply(unwrap(this), args));\n    };\n}\nfunction transformCachableValue(value) {\n    if (typeof value === 'function')\n        return wrapFunction(value);\n    // This doesn't return, it just creates a 'done' promise for the transaction,\n    // which is later returned for transaction.done (see idbObjectHandler).\n    if (value instanceof IDBTransaction)\n        cacheDonePromiseForTransaction(value);\n    if (instanceOfAny(value, getIdbProxyableTypes()))\n        return new Proxy(value, idbProxyTraps);\n    // Return the same value back if we're not going to transform it.\n    return value;\n}\nfunction wrap(value) {\n    // We sometimes generate multiple promises from a single IDBRequest (eg when cursoring), because\n    // IDB is weird and a single IDBRequest can yield many responses, so these can't be cached.\n    if (value instanceof IDBRequest)\n        return promisifyRequest(value);\n    // If we've already transformed this value before, reuse the transformed value.\n    // This is faster, but it also provides object equality.\n    if (transformCache.has(value))\n        return transformCache.get(value);\n    const newValue = transformCachableValue(value);\n    // Not all types are transformed.\n    // These may be primitive types, so they can't be WeakMap keys.\n    if (newValue !== value) {\n        transformCache.set(value, newValue);\n        reverseTransformCache.set(newValue, value);\n    }\n    return newValue;\n}\nconst unwrap = (value) => reverseTransformCache.get(value);\n\nexport { reverseTransformCache as a, instanceOfAny as i, replaceTraps as r, unwrap as u, wrap as w };\n","import { w as wrap, r as replaceTraps } from './wrap-idb-value.js';\nexport { u as unwrap, w as wrap } from './wrap-idb-value.js';\n\n/**\n * Open a database.\n *\n * @param name Name of the database.\n * @param version Schema version.\n * @param callbacks Additional callbacks.\n */\nfunction openDB(name, version, { blocked, upgrade, blocking, terminated } = {}) {\n    const request = indexedDB.open(name, version);\n    const openPromise = wrap(request);\n    if (upgrade) {\n        request.addEventListener('upgradeneeded', (event) => {\n            upgrade(wrap(request.result), event.oldVersion, event.newVersion, wrap(request.transaction), event);\n        });\n    }\n    if (blocked) {\n        request.addEventListener('blocked', (event) => blocked(\n        // Casting due to https://github.com/microsoft/TypeScript-DOM-lib-generator/pull/1405\n        event.oldVersion, event.newVersion, event));\n    }\n    openPromise\n        .then((db) => {\n        if (terminated)\n            db.addEventListener('close', () => terminated());\n        if (blocking) {\n            db.addEventListener('versionchange', (event) => blocking(event.oldVersion, event.newVersion, event));\n        }\n    })\n        .catch(() => { });\n    return openPromise;\n}\n/**\n * Delete a database.\n *\n * @param name Name of the database.\n */\nfunction deleteDB(name, { blocked } = {}) {\n    const request = indexedDB.deleteDatabase(name);\n    if (blocked) {\n        request.addEventListener('blocked', (event) => blocked(\n        // Casting due to https://github.com/microsoft/TypeScript-DOM-lib-generator/pull/1405\n        event.oldVersion, event));\n    }\n    return wrap(request).then(() => undefined);\n}\n\nconst readMethods = ['get', 'getKey', 'getAll', 'getAllKeys', 'count'];\nconst writeMethods = ['put', 'add', 'delete', 'clear'];\nconst cachedMethods = new Map();\nfunction getMethod(target, prop) {\n    if (!(target instanceof IDBDatabase &&\n        !(prop in target) &&\n        typeof prop === 'string')) {\n        return;\n    }\n    if (cachedMethods.get(prop))\n        return cachedMethods.get(prop);\n    const targetFuncName = prop.replace(/FromIndex$/, '');\n    const useIndex = prop !== targetFuncName;\n    const isWrite = writeMethods.includes(targetFuncName);\n    if (\n    // Bail if the target doesn't exist on the target. Eg, getAll isn't in Edge.\n    !(targetFuncName in (useIndex ? IDBIndex : IDBObjectStore).prototype) ||\n        !(isWrite || readMethods.includes(targetFuncName))) {\n        return;\n    }\n    const method = async function (storeName, ...args) {\n        // isWrite ? 'readwrite' : undefined gzipps better, but fails in Edge :(\n        const tx = this.transaction(storeName, isWrite ? 'readwrite' : 'readonly');\n        let target = tx.store;\n        if (useIndex)\n            target = target.index(args.shift());\n        // Must reject if op rejects.\n        // If it's a write operation, must reject if tx.done rejects.\n        // Must reject with op rejection first.\n        // Must resolve with op value.\n        // Must handle both promises (no unhandled rejections)\n        return (await Promise.all([\n            target[targetFuncName](...args),\n            isWrite && tx.done,\n        ]))[0];\n    };\n    cachedMethods.set(prop, method);\n    return method;\n}\nreplaceTraps((oldTraps) => ({\n    ...oldTraps,\n    get: (target, prop, receiver) => getMethod(target, prop) || oldTraps.get(target, prop, receiver),\n    has: (target, prop) => !!getMethod(target, prop) || oldTraps.has(target, prop),\n}));\n\nexport { deleteDB, openDB };\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ComponentContainer,\n  ComponentType,\n  Provider,\n  Name\n} from '@firebase/component';\nimport { PlatformLoggerService, VersionService } from './types';\n\nexport class PlatformLoggerServiceImpl implements PlatformLoggerService {\n  constructor(private readonly container: ComponentContainer) {}\n  // In initial implementation, this will be called by installations on\n  // auth token refresh, and installations will send this string.\n  getPlatformInfoString(): string {\n    const providers = this.container.getProviders();\n    // Loop through providers and get library/version pairs from any that are\n    // version components.\n    return providers\n      .map(provider => {\n        if (isVersionServiceProvider(provider)) {\n          const service = provider.getImmediate() as VersionService;\n          return `${service.library}/${service.version}`;\n        } else {\n          return null;\n        }\n      })\n      .filter(logString => logString)\n      .join(' ');\n  }\n}\n/**\n *\n * @param provider check if this provider provides a VersionService\n *\n * NOTE: Using Provider<'app-version'> is a hack to indicate that the provider\n * provides VersionService. The provider is not necessarily a 'app-version'\n * provider.\n */\nfunction isVersionServiceProvider(provider: Provider<Name>): boolean {\n  const component = provider.getComponent();\n  return component?.type === ComponentType.VERSION;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Logger } from '@firebase/logger';\n\nexport const logger = new Logger('@firebase/app');\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { name as appName } from '../package.json';\nimport { name as appCompatName } from '../../app-compat/package.json';\nimport { name as analyticsCompatName } from '../../../packages/analytics-compat/package.json';\nimport { name as analyticsName } from '../../../packages/analytics/package.json';\nimport { name as appCheckCompatName } from '../../../packages/app-check-compat/package.json';\nimport { name as appCheckName } from '../../../packages/app-check/package.json';\nimport { name as authName } from '../../../packages/auth/package.json';\nimport { name as authCompatName } from '../../../packages/auth-compat/package.json';\nimport { name as databaseName } from '../../../packages/database/package.json';\nimport { name as databaseCompatName } from '../../../packages/database-compat/package.json';\nimport { name as functionsName } from '../../../packages/functions/package.json';\nimport { name as functionsCompatName } from '../../../packages/functions-compat/package.json';\nimport { name as installationsName } from '../../../packages/installations/package.json';\nimport { name as installationsCompatName } from '../../../packages/installations-compat/package.json';\nimport { name as messagingName } from '../../../packages/messaging/package.json';\nimport { name as messagingCompatName } from '../../../packages/messaging-compat/package.json';\nimport { name as performanceName } from '../../../packages/performance/package.json';\nimport { name as performanceCompatName } from '../../../packages/performance-compat/package.json';\nimport { name as remoteConfigName } from '../../../packages/remote-config/package.json';\nimport { name as remoteConfigCompatName } from '../../../packages/remote-config-compat/package.json';\nimport { name as storageName } from '../../../packages/storage/package.json';\nimport { name as storageCompatName } from '../../../packages/storage-compat/package.json';\nimport { name as firestoreName } from '../../../packages/firestore/package.json';\nimport { name as firestoreCompatName } from '../../../packages/firestore-compat/package.json';\nimport { name as packageName } from '../../../packages/firebase/package.json';\n\n/**\n * The default app name\n *\n * @internal\n */\nexport const DEFAULT_ENTRY_NAME = '[DEFAULT]';\n\nexport const PLATFORM_LOG_STRING = {\n  [appName]: 'fire-core',\n  [appCompatName]: 'fire-core-compat',\n  [analyticsName]: 'fire-analytics',\n  [analyticsCompatName]: 'fire-analytics-compat',\n  [appCheckName]: 'fire-app-check',\n  [appCheckCompatName]: 'fire-app-check-compat',\n  [authName]: 'fire-auth',\n  [authCompatName]: 'fire-auth-compat',\n  [databaseName]: 'fire-rtdb',\n  [databaseCompatName]: 'fire-rtdb-compat',\n  [functionsName]: 'fire-fn',\n  [functionsCompatName]: 'fire-fn-compat',\n  [installationsName]: 'fire-iid',\n  [installationsCompatName]: 'fire-iid-compat',\n  [messagingName]: 'fire-fcm',\n  [messagingCompatName]: 'fire-fcm-compat',\n  [performanceName]: 'fire-perf',\n  [performanceCompatName]: 'fire-perf-compat',\n  [remoteConfigName]: 'fire-rc',\n  [remoteConfigCompatName]: 'fire-rc-compat',\n  [storageName]: 'fire-gcs',\n  [storageCompatName]: 'fire-gcs-compat',\n  [firestoreName]: 'fire-fst',\n  [firestoreCompatName]: 'fire-fst-compat',\n  'fire-js': 'fire-js', // Platform identifier for JS SDK.\n  [packageName]: 'fire-js-all'\n} as const;\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseApp } from './public-types';\nimport { Component, Provider, Name } from '@firebase/component';\nimport { logger } from './logger';\nimport { DEFAULT_ENTRY_NAME } from './constants';\nimport { FirebaseAppImpl } from './firebaseApp';\n\n/**\n * @internal\n */\nexport const _apps = new Map<string, FirebaseApp>();\n\n/**\n * Registered components.\n *\n * @internal\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nexport const _components = new Map<string, Component<any>>();\n\n/**\n * @param component - the component being added to this app's container\n *\n * @internal\n */\nexport function _addComponent<T extends Name>(\n  app: FirebaseApp,\n  component: Component<T>\n): void {\n  try {\n    (app as FirebaseAppImpl).container.addComponent(component);\n  } catch (e) {\n    logger.debug(\n      `Component ${component.name} failed to register with FirebaseApp ${app.name}`,\n      e\n    );\n  }\n}\n\n/**\n *\n * @internal\n */\nexport function _addOrOverwriteComponent(\n  app: FirebaseApp,\n  component: Component\n): void {\n  (app as FirebaseAppImpl).container.addOrOverwriteComponent(component);\n}\n\n/**\n *\n * @param component - the component to register\n * @returns whether or not the component is registered successfully\n *\n * @internal\n */\nexport function _registerComponent<T extends Name>(\n  component: Component<T>\n): boolean {\n  const componentName = component.name;\n  if (_components.has(componentName)) {\n    logger.debug(\n      `There were multiple attempts to register component ${componentName}.`\n    );\n\n    return false;\n  }\n\n  _components.set(componentName, component);\n\n  // add the component to existing app instances\n  for (const app of _apps.values()) {\n    _addComponent(app as FirebaseAppImpl, component);\n  }\n\n  return true;\n}\n\n/**\n *\n * @param app - FirebaseApp instance\n * @param name - service name\n *\n * @returns the provider for the service with the matching name\n *\n * @internal\n */\nexport function _getProvider<T extends Name>(\n  app: FirebaseApp,\n  name: T\n): Provider<T> {\n  const heartbeatController = (app as FirebaseAppImpl).container\n    .getProvider('heartbeat')\n    .getImmediate({ optional: true });\n  if (heartbeatController) {\n    void heartbeatController.triggerHeartbeat();\n  }\n  return (app as FirebaseAppImpl).container.getProvider(name);\n}\n\n/**\n *\n * @param app - FirebaseApp instance\n * @param name - service name\n * @param instanceIdentifier - service instance identifier in case the service supports multiple instances\n *\n * @internal\n */\nexport function _removeServiceInstance<T extends Name>(\n  app: FirebaseApp,\n  name: T,\n  instanceIdentifier: string = DEFAULT_ENTRY_NAME\n): void {\n  _getProvider(app, name).clearInstance(instanceIdentifier);\n}\n\n/**\n * Test only\n *\n * @internal\n */\nexport function _clearComponents(): void {\n  _components.clear();\n}\n\n/**\n * Exported in order to be used in app-compat package\n */\nexport { DEFAULT_ENTRY_NAME as _DEFAULT_ENTRY_NAME };\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ErrorFactory, ErrorMap } from '@firebase/util';\n\nexport const enum AppError {\n  NO_APP = 'no-app',\n  BAD_APP_NAME = 'bad-app-name',\n  DUPLICATE_APP = 'duplicate-app',\n  APP_DELETED = 'app-deleted',\n  NO_OPTIONS = 'no-options',\n  INVALID_APP_ARGUMENT = 'invalid-app-argument',\n  INVALID_LOG_ARGUMENT = 'invalid-log-argument',\n  IDB_OPEN = 'idb-open',\n  IDB_GET = 'idb-get',\n  IDB_WRITE = 'idb-set',\n  IDB_DELETE = 'idb-delete'\n}\n\nconst ERRORS: ErrorMap<AppError> = {\n  [AppError.NO_APP]:\n    \"No Firebase App '{$appName}' has been created - \" +\n    'call initializeApp() first',\n  [AppError.BAD_APP_NAME]: \"Illegal App name: '{$appName}\",\n  [AppError.DUPLICATE_APP]:\n    \"Firebase App named '{$appName}' already exists with different options or config\",\n  [AppError.APP_DELETED]: \"Firebase App named '{$appName}' already deleted\",\n  [AppError.NO_OPTIONS]:\n    'Need to provide options, when not being deployed to hosting via source.',\n  [AppError.INVALID_APP_ARGUMENT]:\n    'firebase.{$appName}() takes either no argument or a ' +\n    'Firebase App instance.',\n  [AppError.INVALID_LOG_ARGUMENT]:\n    'First argument to `onLog` must be null or a function.',\n  [AppError.IDB_OPEN]:\n    'Error thrown when opening IndexedDB. Original error: {$originalErrorMessage}.',\n  [AppError.IDB_GET]:\n    'Error thrown when reading from IndexedDB. Original error: {$originalErrorMessage}.',\n  [AppError.IDB_WRITE]:\n    'Error thrown when writing to IndexedDB. Original error: {$originalErrorMessage}.',\n  [AppError.IDB_DELETE]:\n    'Error thrown when deleting from IndexedDB. Original error: {$originalErrorMessage}.'\n};\n\ninterface ErrorParams {\n  [AppError.NO_APP]: { appName: string };\n  [AppError.BAD_APP_NAME]: { appName: string };\n  [AppError.DUPLICATE_APP]: { appName: string };\n  [AppError.APP_DELETED]: { appName: string };\n  [AppError.INVALID_APP_ARGUMENT]: { appName: string };\n  [AppError.IDB_OPEN]: { originalErrorMessage?: string };\n  [AppError.IDB_GET]: { originalErrorMessage?: string };\n  [AppError.IDB_WRITE]: { originalErrorMessage?: string };\n  [AppError.IDB_DELETE]: { originalErrorMessage?: string };\n}\n\nexport const ERROR_FACTORY = new ErrorFactory<AppError, ErrorParams>(\n  'app',\n  'Firebase',\n  ERRORS\n);\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  FirebaseApp,\n  FirebaseOptions,\n  FirebaseAppSettings\n} from './public-types';\nimport {\n  ComponentContainer,\n  Component,\n  ComponentType\n} from '@firebase/component';\nimport { ERROR_FACTORY, AppError } from './errors';\n\nexport class FirebaseAppImpl implements FirebaseApp {\n  private readonly _options: FirebaseOptions;\n  private readonly _name: string;\n  /**\n   * Original config values passed in as a constructor parameter.\n   * It is only used to compare with another config object to support idempotent initializeApp().\n   *\n   * Updating automaticDataCollectionEnabled on the App instance will not change its value in _config.\n   */\n  private readonly _config: Required<FirebaseAppSettings>;\n  private _automaticDataCollectionEnabled: boolean;\n  private _isDeleted = false;\n  private readonly _container: ComponentContainer;\n\n  constructor(\n    options: FirebaseOptions,\n    config: Required<FirebaseAppSettings>,\n    container: ComponentContainer\n  ) {\n    this._options = { ...options };\n    this._config = { ...config };\n    this._name = config.name;\n    this._automaticDataCollectionEnabled =\n      config.automaticDataCollectionEnabled;\n    this._container = container;\n    this.container.addComponent(\n      new Component('app', () => this, ComponentType.PUBLIC)\n    );\n  }\n\n  get automaticDataCollectionEnabled(): boolean {\n    this.checkDestroyed();\n    return this._automaticDataCollectionEnabled;\n  }\n\n  set automaticDataCollectionEnabled(val: boolean) {\n    this.checkDestroyed();\n    this._automaticDataCollectionEnabled = val;\n  }\n\n  get name(): string {\n    this.checkDestroyed();\n    return this._name;\n  }\n\n  get options(): FirebaseOptions {\n    this.checkDestroyed();\n    return this._options;\n  }\n\n  get config(): Required<FirebaseAppSettings> {\n    this.checkDestroyed();\n    return this._config;\n  }\n\n  get container(): ComponentContainer {\n    return this._container;\n  }\n\n  get isDeleted(): boolean {\n    return this._isDeleted;\n  }\n\n  set isDeleted(val: boolean) {\n    this._isDeleted = val;\n  }\n\n  /**\n   * This function will throw an Error if the App has already been deleted -\n   * use before performing API actions on the App.\n   */\n  private checkDestroyed(): void {\n    if (this.isDeleted) {\n      throw ERROR_FACTORY.create(AppError.APP_DELETED, { appName: this._name });\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  FirebaseApp,\n  FirebaseOptions,\n  FirebaseAppSettings\n} from './public-types';\nimport { DEFAULT_ENTRY_NAME, PLATFORM_LOG_STRING } from './constants';\nimport { ERROR_FACTORY, AppError } from './errors';\nimport {\n  ComponentContainer,\n  Component,\n  Name,\n  ComponentType\n} from '@firebase/component';\nimport { version } from '../../firebase/package.json';\nimport { FirebaseAppImpl } from './firebaseApp';\nimport { _apps, _components, _registerComponent } from './internal';\nimport { logger } from './logger';\nimport {\n  LogLevelString,\n  setLogLevel as setLogLevelImpl,\n  LogCallback,\n  LogOptions,\n  setUserLogHandler\n} from '@firebase/logger';\nimport { deepEqual, getDefaultAppConfig } from '@firebase/util';\n\nexport { FirebaseError } from '@firebase/util';\n\n/**\n * The current SDK version.\n *\n * @public\n */\nexport const SDK_VERSION = version;\n\n/**\n * Creates and initializes a {@link @firebase/app#FirebaseApp} instance.\n *\n * See\n * {@link\n *   https://firebase.google.com/docs/web/setup#add_firebase_to_your_app\n *   | Add Firebase to your app} and\n * {@link\n *   https://firebase.google.com/docs/web/setup#multiple-projects\n *   | Initialize multiple projects} for detailed documentation.\n *\n * @example\n * ```javascript\n *\n * // Initialize default app\n * // Retrieve your own options values by adding a web app on\n * // https://console.firebase.google.com\n * initializeApp({\n *   apiKey: \"AIza....\",                             // Auth / General Use\n *   authDomain: \"YOUR_APP.firebaseapp.com\",         // Auth with popup/redirect\n *   databaseURL: \"https://YOUR_APP.firebaseio.com\", // Realtime Database\n *   storageBucket: \"YOUR_APP.appspot.com\",          // Storage\n *   messagingSenderId: \"123456789\"                  // Cloud Messaging\n * });\n * ```\n *\n * @example\n * ```javascript\n *\n * // Initialize another app\n * const otherApp = initializeApp({\n *   databaseURL: \"https://<OTHER_DATABASE_NAME>.firebaseio.com\",\n *   storageBucket: \"<OTHER_STORAGE_BUCKET>.appspot.com\"\n * }, \"otherApp\");\n * ```\n *\n * @param options - Options to configure the app's services.\n * @param name - Optional name of the app to initialize. If no name\n *   is provided, the default is `\"[DEFAULT]\"`.\n *\n * @returns The initialized app.\n *\n * @public\n */\nexport function initializeApp(\n  options: FirebaseOptions,\n  name?: string\n): FirebaseApp;\n/**\n * Creates and initializes a FirebaseApp instance.\n *\n * @param options - Options to configure the app's services.\n * @param config - FirebaseApp Configuration\n *\n * @public\n */\nexport function initializeApp(\n  options: FirebaseOptions,\n  config?: FirebaseAppSettings\n): FirebaseApp;\n/**\n * Creates and initializes a FirebaseApp instance.\n *\n * @public\n */\nexport function initializeApp(): FirebaseApp;\nexport function initializeApp(\n  _options?: FirebaseOptions,\n  rawConfig = {}\n): FirebaseApp {\n  let options = _options;\n\n  if (typeof rawConfig !== 'object') {\n    const name = rawConfig;\n    rawConfig = { name };\n  }\n\n  const config: Required<FirebaseAppSettings> = {\n    name: DEFAULT_ENTRY_NAME,\n    automaticDataCollectionEnabled: false,\n    ...rawConfig\n  };\n  const name = config.name;\n\n  if (typeof name !== 'string' || !name) {\n    throw ERROR_FACTORY.create(AppError.BAD_APP_NAME, {\n      appName: String(name)\n    });\n  }\n\n  options ||= getDefaultAppConfig();\n\n  if (!options) {\n    throw ERROR_FACTORY.create(AppError.NO_OPTIONS);\n  }\n\n  const existingApp = _apps.get(name) as FirebaseAppImpl;\n  if (existingApp) {\n    // return the existing app if options and config deep equal the ones in the existing app.\n    if (\n      deepEqual(options, existingApp.options) &&\n      deepEqual(config, existingApp.config)\n    ) {\n      return existingApp;\n    } else {\n      throw ERROR_FACTORY.create(AppError.DUPLICATE_APP, { appName: name });\n    }\n  }\n\n  const container = new ComponentContainer(name);\n  for (const component of _components.values()) {\n    container.addComponent(component);\n  }\n\n  const newApp = new FirebaseAppImpl(options, config, container);\n\n  _apps.set(name, newApp);\n\n  return newApp;\n}\n\n/**\n * Retrieves a {@link @firebase/app#FirebaseApp} instance.\n *\n * When called with no arguments, the default app is returned. When an app name\n * is provided, the app corresponding to that name is returned.\n *\n * An exception is thrown if the app being retrieved has not yet been\n * initialized.\n *\n * @example\n * ```javascript\n * // Return the default app\n * const app = getApp();\n * ```\n *\n * @example\n * ```javascript\n * // Return a named app\n * const otherApp = getApp(\"otherApp\");\n * ```\n *\n * @param name - Optional name of the app to return. If no name is\n *   provided, the default is `\"[DEFAULT]\"`.\n *\n * @returns The app corresponding to the provided app name.\n *   If no app name is provided, the default app is returned.\n *\n * @public\n */\nexport function getApp(name: string = DEFAULT_ENTRY_NAME): FirebaseApp {\n  const app = _apps.get(name);\n  if (!app && name === DEFAULT_ENTRY_NAME && getDefaultAppConfig()) {\n    return initializeApp();\n  }\n  if (!app) {\n    throw ERROR_FACTORY.create(AppError.NO_APP, { appName: name });\n  }\n\n  return app;\n}\n\n/**\n * A (read-only) array of all initialized apps.\n * @public\n */\nexport function getApps(): FirebaseApp[] {\n  return Array.from(_apps.values());\n}\n\n/**\n * Renders this app unusable and frees the resources of all associated\n * services.\n *\n * @example\n * ```javascript\n * deleteApp(app)\n *   .then(function() {\n *     console.log(\"App deleted successfully\");\n *   })\n *   .catch(function(error) {\n *     console.log(\"Error deleting app:\", error);\n *   });\n * ```\n *\n * @public\n */\nexport async function deleteApp(app: FirebaseApp): Promise<void> {\n  const name = app.name;\n  if (_apps.has(name)) {\n    _apps.delete(name);\n    await Promise.all(\n      (app as FirebaseAppImpl).container\n        .getProviders()\n        .map(provider => provider.delete())\n    );\n    (app as FirebaseAppImpl).isDeleted = true;\n  }\n}\n\n/**\n * Registers a library's name and version for platform logging purposes.\n * @param library - Name of 1p or 3p library (e.g. firestore, angularfire)\n * @param version - Current version of that library.\n * @param variant - Bundle variant, e.g., node, rn, etc.\n *\n * @public\n */\nexport function registerVersion(\n  libraryKeyOrName: string,\n  version: string,\n  variant?: string\n): void {\n  // TODO: We can use this check to whitelist strings when/if we set up\n  // a good whitelist system.\n  let library = PLATFORM_LOG_STRING[libraryKeyOrName] ?? libraryKeyOrName;\n  if (variant) {\n    library += `-${variant}`;\n  }\n  const libraryMismatch = library.match(/\\s|\\//);\n  const versionMismatch = version.match(/\\s|\\//);\n  if (libraryMismatch || versionMismatch) {\n    const warning = [\n      `Unable to register library \"${library}\" with version \"${version}\":`\n    ];\n    if (libraryMismatch) {\n      warning.push(\n        `library name \"${library}\" contains illegal characters (whitespace or \"/\")`\n      );\n    }\n    if (libraryMismatch && versionMismatch) {\n      warning.push('and');\n    }\n    if (versionMismatch) {\n      warning.push(\n        `version name \"${version}\" contains illegal characters (whitespace or \"/\")`\n      );\n    }\n    logger.warn(warning.join(' '));\n    return;\n  }\n  _registerComponent(\n    new Component(\n      `${library}-version` as Name,\n      () => ({ library, version }),\n      ComponentType.VERSION\n    )\n  );\n}\n\n/**\n * Sets log handler for all Firebase SDKs.\n * @param logCallback - An optional custom log handler that executes user code whenever\n * the Firebase SDK makes a logging call.\n *\n * @public\n */\nexport function onLog(\n  logCallback: LogCallback | null,\n  options?: LogOptions\n): void {\n  if (logCallback !== null && typeof logCallback !== 'function') {\n    throw ERROR_FACTORY.create(AppError.INVALID_LOG_ARGUMENT);\n  }\n  setUserLogHandler(logCallback, options);\n}\n\n/**\n * Sets log level for all Firebase SDKs.\n *\n * All of the log types above the current log level are captured (i.e. if\n * you set the log level to `info`, errors are logged, but `debug` and\n * `verbose` logs are not).\n *\n * @public\n */\nexport function setLogLevel(logLevel: LogLevelString): void {\n  setLogLevelImpl(logLevel);\n}\n","/**\n * @license\n * Copyright 2021 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseError } from '@firebase/util';\nimport { DBSchema, openDB, IDBPDatabase } from 'idb';\nimport { AppError, ERROR_FACTORY } from './errors';\nimport { FirebaseApp } from './public-types';\nimport { HeartbeatsInIndexedDB } from './types';\nimport { logger } from './logger';\n\nconst DB_NAME = 'firebase-heartbeat-database';\nconst DB_VERSION = 1;\nconst STORE_NAME = 'firebase-heartbeat-store';\n\ninterface AppDB extends DBSchema {\n  'firebase-heartbeat-store': {\n    key: string;\n    value: HeartbeatsInIndexedDB;\n  };\n}\n\nlet dbPromise: Promise<IDBPDatabase<AppDB>> | null = null;\nfunction getDbPromise(): Promise<IDBPDatabase<AppDB>> {\n  if (!dbPromise) {\n    dbPromise = openDB<AppDB>(DB_NAME, DB_VERSION, {\n      upgrade: (db, oldVersion) => {\n        // We don't use 'break' in this switch statement, the fall-through\n        // behavior is what we want, because if there are multiple versions between\n        // the old version and the current version, we want ALL the migrations\n        // that correspond to those versions to run, not only the last one.\n        // eslint-disable-next-line default-case\n        switch (oldVersion) {\n          case 0:\n            db.createObjectStore(STORE_NAME);\n        }\n      }\n    }).catch(e => {\n      throw ERROR_FACTORY.create(AppError.IDB_OPEN, {\n        originalErrorMessage: e.message\n      });\n    });\n  }\n  return dbPromise;\n}\n\nexport async function readHeartbeatsFromIndexedDB(\n  app: FirebaseApp\n): Promise<HeartbeatsInIndexedDB | undefined> {\n  try {\n    const db = await getDbPromise();\n    const result = await db\n      .transaction(STORE_NAME)\n      .objectStore(STORE_NAME)\n      .get(computeKey(app));\n    return result;\n  } catch (e) {\n    if (e instanceof FirebaseError) {\n      logger.warn(e.message);\n    } else {\n      const idbGetError = ERROR_FACTORY.create(AppError.IDB_GET, {\n        originalErrorMessage: (e as Error)?.message\n      });\n      logger.warn(idbGetError.message);\n    }\n  }\n}\n\nexport async function writeHeartbeatsToIndexedDB(\n  app: FirebaseApp,\n  heartbeatObject: HeartbeatsInIndexedDB\n): Promise<void> {\n  try {\n    const db = await getDbPromise();\n    const tx = db.transaction(STORE_NAME, 'readwrite');\n    const objectStore = tx.objectStore(STORE_NAME);\n    await objectStore.put(heartbeatObject, computeKey(app));\n    await tx.done;\n  } catch (e) {\n    if (e instanceof FirebaseError) {\n      logger.warn(e.message);\n    } else {\n      const idbGetError = ERROR_FACTORY.create(AppError.IDB_WRITE, {\n        originalErrorMessage: (e as Error)?.message\n      });\n      logger.warn(idbGetError.message);\n    }\n  }\n}\n\nfunction computeKey(app: FirebaseApp): string {\n  return `${app.name}!${app.options.appId}`;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ComponentContainer } from '@firebase/component';\nimport {\n  base64urlEncodeWithoutPadding,\n  isIndexedDBAvailable,\n  validateIndexedDBOpenable\n} from '@firebase/util';\nimport {\n  readHeartbeatsFromIndexedDB,\n  writeHeartbeatsToIndexedDB\n} from './indexeddb';\nimport { FirebaseApp } from './public-types';\nimport {\n  HeartbeatsByUserAgent,\n  HeartbeatService,\n  HeartbeatsInIndexedDB,\n  HeartbeatStorage,\n  SingleDateHeartbeat\n} from './types';\n\nconst MAX_HEADER_BYTES = 1024;\n// 30 days\nconst STORED_HEARTBEAT_RETENTION_MAX_MILLIS = 30 * 24 * 60 * 60 * 1000;\n\nexport class HeartbeatServiceImpl implements HeartbeatService {\n  /**\n   * The persistence layer for heartbeats\n   * Leave public for easier testing.\n   */\n  _storage: HeartbeatStorageImpl;\n\n  /**\n   * In-memory cache for heartbeats, used by getHeartbeatsHeader() to generate\n   * the header string.\n   * Stores one record per date. This will be consolidated into the standard\n   * format of one record per user agent string before being sent as a header.\n   * Populated from indexedDB when the controller is instantiated and should\n   * be kept in sync with indexedDB.\n   * Leave public for easier testing.\n   */\n  _heartbeatsCache: HeartbeatsInIndexedDB | null = null;\n\n  /**\n   * the initialization promise for populating heartbeatCache.\n   * If getHeartbeatsHeader() is called before the promise resolves\n   * (hearbeatsCache == null), it should wait for this promise\n   * Leave public for easier testing.\n   */\n  _heartbeatsCachePromise: Promise<HeartbeatsInIndexedDB>;\n  constructor(private readonly container: ComponentContainer) {\n    const app = this.container.getProvider('app').getImmediate();\n    this._storage = new HeartbeatStorageImpl(app);\n    this._heartbeatsCachePromise = this._storage.read().then(result => {\n      this._heartbeatsCache = result;\n      return result;\n    });\n  }\n\n  /**\n   * Called to report a heartbeat. The function will generate\n   * a HeartbeatsByUserAgent object, update heartbeatsCache, and persist it\n   * to IndexedDB.\n   * Note that we only store one heartbeat per day. So if a heartbeat for today is\n   * already logged, subsequent calls to this function in the same day will be ignored.\n   */\n  async triggerHeartbeat(): Promise<void> {\n    const platformLogger = this.container\n      .getProvider('platform-logger')\n      .getImmediate();\n\n    // This is the \"Firebase user agent\" string from the platform logger\n    // service, not the browser user agent.\n    const agent = platformLogger.getPlatformInfoString();\n    const date = getUTCDateString();\n    if (this._heartbeatsCache === null) {\n      this._heartbeatsCache = await this._heartbeatsCachePromise;\n    }\n    // Do not store a heartbeat if one is already stored for this day\n    // or if a header has already been sent today.\n    if (\n      this._heartbeatsCache.lastSentHeartbeatDate === date ||\n      this._heartbeatsCache.heartbeats.some(\n        singleDateHeartbeat => singleDateHeartbeat.date === date\n      )\n    ) {\n      return;\n    } else {\n      // There is no entry for this date. Create one.\n      this._heartbeatsCache.heartbeats.push({ date, agent });\n    }\n    // Remove entries older than 30 days.\n    this._heartbeatsCache.heartbeats = this._heartbeatsCache.heartbeats.filter(\n      singleDateHeartbeat => {\n        const hbTimestamp = new Date(singleDateHeartbeat.date).valueOf();\n        const now = Date.now();\n        return now - hbTimestamp <= STORED_HEARTBEAT_RETENTION_MAX_MILLIS;\n      }\n    );\n    return this._storage.overwrite(this._heartbeatsCache);\n  }\n\n  /**\n   * Returns a base64 encoded string which can be attached to the heartbeat-specific header directly.\n   * It also clears all heartbeats from memory as well as in IndexedDB.\n   *\n   * NOTE: Consuming product SDKs should not send the header if this method\n   * returns an empty string.\n   */\n  async getHeartbeatsHeader(): Promise<string> {\n    if (this._heartbeatsCache === null) {\n      await this._heartbeatsCachePromise;\n    }\n    // If it's still null or the array is empty, there is no data to send.\n    if (\n      this._heartbeatsCache === null ||\n      this._heartbeatsCache.heartbeats.length === 0\n    ) {\n      return '';\n    }\n    const date = getUTCDateString();\n    // Extract as many heartbeats from the cache as will fit under the size limit.\n    const { heartbeatsToSend, unsentEntries } = extractHeartbeatsForHeader(\n      this._heartbeatsCache.heartbeats\n    );\n    const headerString = base64urlEncodeWithoutPadding(\n      JSON.stringify({ version: 2, heartbeats: heartbeatsToSend })\n    );\n    // Store last sent date to prevent another being logged/sent for the same day.\n    this._heartbeatsCache.lastSentHeartbeatDate = date;\n    if (unsentEntries.length > 0) {\n      // Store any unsent entries if they exist.\n      this._heartbeatsCache.heartbeats = unsentEntries;\n      // This seems more likely than emptying the array (below) to lead to some odd state\n      // since the cache isn't empty and this will be called again on the next request,\n      // and is probably safest if we await it.\n      await this._storage.overwrite(this._heartbeatsCache);\n    } else {\n      this._heartbeatsCache.heartbeats = [];\n      // Do not wait for this, to reduce latency.\n      void this._storage.overwrite(this._heartbeatsCache);\n    }\n    return headerString;\n  }\n}\n\nfunction getUTCDateString(): string {\n  const today = new Date();\n  // Returns date format 'YYYY-MM-DD'\n  return today.toISOString().substring(0, 10);\n}\n\nexport function extractHeartbeatsForHeader(\n  heartbeatsCache: SingleDateHeartbeat[],\n  maxSize = MAX_HEADER_BYTES\n): {\n  heartbeatsToSend: HeartbeatsByUserAgent[];\n  unsentEntries: SingleDateHeartbeat[];\n} {\n  // Heartbeats grouped by user agent in the standard format to be sent in\n  // the header.\n  const heartbeatsToSend: HeartbeatsByUserAgent[] = [];\n  // Single date format heartbeats that are not sent.\n  let unsentEntries = heartbeatsCache.slice();\n  for (const singleDateHeartbeat of heartbeatsCache) {\n    // Look for an existing entry with the same user agent.\n    const heartbeatEntry = heartbeatsToSend.find(\n      hb => hb.agent === singleDateHeartbeat.agent\n    );\n    if (!heartbeatEntry) {\n      // If no entry for this user agent exists, create one.\n      heartbeatsToSend.push({\n        agent: singleDateHeartbeat.agent,\n        dates: [singleDateHeartbeat.date]\n      });\n      if (countBytes(heartbeatsToSend) > maxSize) {\n        // If the header would exceed max size, remove the added heartbeat\n        // entry and stop adding to the header.\n        heartbeatsToSend.pop();\n        break;\n      }\n    } else {\n      heartbeatEntry.dates.push(singleDateHeartbeat.date);\n      // If the header would exceed max size, remove the added date\n      // and stop adding to the header.\n      if (countBytes(heartbeatsToSend) > maxSize) {\n        heartbeatEntry.dates.pop();\n        break;\n      }\n    }\n    // Pop unsent entry from queue. (Skipped if adding the entry exceeded\n    // quota and the loop breaks early.)\n    unsentEntries = unsentEntries.slice(1);\n  }\n  return {\n    heartbeatsToSend,\n    unsentEntries\n  };\n}\n\nexport class HeartbeatStorageImpl implements HeartbeatStorage {\n  private _canUseIndexedDBPromise: Promise<boolean>;\n  constructor(public app: FirebaseApp) {\n    this._canUseIndexedDBPromise = this.runIndexedDBEnvironmentCheck();\n  }\n  async runIndexedDBEnvironmentCheck(): Promise<boolean> {\n    if (!isIndexedDBAvailable()) {\n      return false;\n    } else {\n      return validateIndexedDBOpenable()\n        .then(() => true)\n        .catch(() => false);\n    }\n  }\n  /**\n   * Read all heartbeats.\n   */\n  async read(): Promise<HeartbeatsInIndexedDB> {\n    const canUseIndexedDB = await this._canUseIndexedDBPromise;\n    if (!canUseIndexedDB) {\n      return { heartbeats: [] };\n    } else {\n      const idbHeartbeatObject = await readHeartbeatsFromIndexedDB(this.app);\n      return idbHeartbeatObject || { heartbeats: [] };\n    }\n  }\n  // overwrite the storage with the provided heartbeats\n  async overwrite(heartbeatsObject: HeartbeatsInIndexedDB): Promise<void> {\n    const canUseIndexedDB = await this._canUseIndexedDBPromise;\n    if (!canUseIndexedDB) {\n      return;\n    } else {\n      const existingHeartbeatsObject = await this.read();\n      return writeHeartbeatsToIndexedDB(this.app, {\n        lastSentHeartbeatDate:\n          heartbeatsObject.lastSentHeartbeatDate ??\n          existingHeartbeatsObject.lastSentHeartbeatDate,\n        heartbeats: heartbeatsObject.heartbeats\n      });\n    }\n  }\n  // add heartbeats\n  async add(heartbeatsObject: HeartbeatsInIndexedDB): Promise<void> {\n    const canUseIndexedDB = await this._canUseIndexedDBPromise;\n    if (!canUseIndexedDB) {\n      return;\n    } else {\n      const existingHeartbeatsObject = await this.read();\n      return writeHeartbeatsToIndexedDB(this.app, {\n        lastSentHeartbeatDate:\n          heartbeatsObject.lastSentHeartbeatDate ??\n          existingHeartbeatsObject.lastSentHeartbeatDate,\n        heartbeats: [\n          ...existingHeartbeatsObject.heartbeats,\n          ...heartbeatsObject.heartbeats\n        ]\n      });\n    }\n  }\n}\n\n/**\n * Calculate bytes of a HeartbeatsByUserAgent array after being wrapped\n * in a platform logging header JSON object, stringified, and converted\n * to base 64.\n */\nexport function countBytes(heartbeatsCache: HeartbeatsByUserAgent[]): number {\n  // base64 has a restricted set of characters, all of which should be 1 byte.\n  return base64urlEncodeWithoutPadding(\n    // heartbeatsCache wrapper properties\n    JSON.stringify({ version: 2, heartbeats: heartbeatsCache })\n  ).length;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { jsonEval, stringify } from '@firebase/util';\n\n/**\n * Wraps a DOM Storage object and:\n * - automatically encode objects as JSON strings before storing them to allow us to store arbitrary types.\n * - prefixes names with \"firebase:\" to avoid collisions with app data.\n *\n * We automatically (see storage.js) create two such wrappers, one for sessionStorage,\n * and one for localStorage.\n *\n */\nexport class DOMStorageWrapper {\n  // Use a prefix to avoid collisions with other stuff saved by the app.\n  private prefix_ = 'firebase:';\n\n  /**\n   * @param domStorage_ - The underlying storage object (e.g. localStorage or sessionStorage)\n   */\n  constructor(private domStorage_: Storage) {}\n\n  /**\n   * @param key - The key to save the value under\n   * @param value - The value being stored, or null to remove the key.\n   */\n  set(key: string, value: unknown | null) {\n    if (value == null) {\n      this.domStorage_.removeItem(this.prefixedName_(key));\n    } else {\n      this.domStorage_.setItem(this.prefixedName_(key), stringify(value));\n    }\n  }\n\n  /**\n   * @returns The value that was stored under this key, or null\n   */\n  get(key: string): unknown {\n    const storedVal = this.domStorage_.getItem(this.prefixedName_(key));\n    if (storedVal == null) {\n      return null;\n    } else {\n      return jsonEval(storedVal);\n    }\n  }\n\n  remove(key: string) {\n    this.domStorage_.removeItem(this.prefixedName_(key));\n  }\n\n  isInMemoryStorage: boolean;\n\n  prefixedName_(name: string): string {\n    return this.prefix_ + name;\n  }\n\n  toString(): string {\n    return this.domStorage_.toString();\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { contains } from '@firebase/util';\n\n/**\n * An in-memory storage implementation that matches the API of DOMStorageWrapper\n * (TODO: create interface for both to implement).\n */\nexport class MemoryStorage {\n  private cache_: { [k: string]: unknown } = {};\n\n  set(key: string, value: unknown | null) {\n    if (value == null) {\n      delete this.cache_[key];\n    } else {\n      this.cache_[key] = value;\n    }\n  }\n\n  get(key: string): unknown {\n    if (contains(this.cache_, key)) {\n      return this.cache_[key];\n    }\n    return null;\n  }\n\n  remove(key: string) {\n    delete this.cache_[key];\n  }\n\n  isInMemoryStorage = true;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DOMStorageWrapper } from './DOMStorageWrapper';\nimport { MemoryStorage } from './MemoryStorage';\n\ndeclare const window: Window;\n\n/**\n * Helper to create a DOMStorageWrapper or else fall back to MemoryStorage.\n * TODO: Once MemoryStorage and DOMStorageWrapper have a shared interface this method annotation should change\n * to reflect this type\n *\n * @param domStorageName - Name of the underlying storage object\n *   (e.g. 'localStorage' or 'sessionStorage').\n * @returns Turning off type information until a common interface is defined.\n */\nconst createStoragefor = function (\n  domStorageName: string\n): DOMStorageWrapper | MemoryStorage {\n  try {\n    // NOTE: just accessing \"localStorage\" or \"window['localStorage']\" may throw a security exception,\n    // so it must be inside the try/catch.\n    if (\n      typeof window !== 'undefined' &&\n      typeof window[domStorageName] !== 'undefined'\n    ) {\n      // Need to test cache. Just because it's here doesn't mean it works\n      const domStorage = window[domStorageName];\n      domStorage.setItem('firebase:sentinel', 'cache');\n      domStorage.removeItem('firebase:sentinel');\n      return new DOMStorageWrapper(domStorage);\n    }\n  } catch (e) {}\n\n  // Failed to create wrapper.  Just return in-memory storage.\n  // TODO: log?\n  return new MemoryStorage();\n};\n\n/** A storage object that lasts across sessions */\nexport const PersistentStorage = createStoragefor('localStorage');\n\n/** A storage object that only lasts one session */\nexport const SessionStorage = createStoragefor('sessionStorage');\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Logger, LogLevel } from '@firebase/logger';\nimport {\n  assert,\n  base64,\n  Sha1,\n  stringToByteArray,\n  stringify,\n  isNodeSdk\n} from '@firebase/util';\n\nimport { SessionStorage } from '../storage/storage';\nimport { QueryContext } from '../view/EventRegistration';\n\ndeclare const window: Window;\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\ndeclare const Windows: any;\n\nconst logClient = new Logger('@firebase/database');\n\n/**\n * Returns a locally-unique ID (generated by just incrementing up from 0 each time its called).\n */\nexport const LUIDGenerator: () => number = (function () {\n  let id = 1;\n  return function () {\n    return id++;\n  };\n})();\n\n/**\n * Sha1 hash of the input string\n * @param str - The string to hash\n * @returns {!string} The resulting hash\n */\nexport const sha1 = function (str: string): string {\n  const utf8Bytes = stringToByteArray(str);\n  const sha1 = new Sha1();\n  sha1.update(utf8Bytes);\n  const sha1Bytes = sha1.digest();\n  return base64.encodeByteArray(sha1Bytes);\n};\n\nconst buildLogMessage_ = function (...varArgs: unknown[]): string {\n  let message = '';\n  for (let i = 0; i < varArgs.length; i++) {\n    const arg = varArgs[i];\n    if (\n      Array.isArray(arg) ||\n      (arg &&\n        typeof arg === 'object' &&\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        typeof (arg as any).length === 'number')\n    ) {\n      message += buildLogMessage_.apply(null, arg);\n    } else if (typeof arg === 'object') {\n      message += stringify(arg);\n    } else {\n      message += arg;\n    }\n    message += ' ';\n  }\n\n  return message;\n};\n\n/**\n * Use this for all debug messages in Firebase.\n */\nexport let logger: ((a: string) => void) | null = null;\n\n/**\n * Flag to check for log availability on first log message\n */\nlet firstLog_ = true;\n\n/**\n * The implementation of Firebase.enableLogging (defined here to break dependencies)\n * @param logger_ - A flag to turn on logging, or a custom logger\n * @param persistent - Whether or not to persist logging settings across refreshes\n */\nexport const enableLogging = function (\n  logger_?: boolean | ((a: string) => void) | null,\n  persistent?: boolean\n) {\n  assert(\n    !persistent || logger_ === true || logger_ === false,\n    \"Can't turn on custom loggers persistently.\"\n  );\n  if (logger_ === true) {\n    logClient.logLevel = LogLevel.VERBOSE;\n    logger = logClient.log.bind(logClient);\n    if (persistent) {\n      SessionStorage.set('logging_enabled', true);\n    }\n  } else if (typeof logger_ === 'function') {\n    logger = logger_;\n  } else {\n    logger = null;\n    SessionStorage.remove('logging_enabled');\n  }\n};\n\nexport const log = function (...varArgs: unknown[]) {\n  if (firstLog_ === true) {\n    firstLog_ = false;\n    if (logger === null && SessionStorage.get('logging_enabled') === true) {\n      enableLogging(true);\n    }\n  }\n\n  if (logger) {\n    const message = buildLogMessage_.apply(null, varArgs);\n    logger(message);\n  }\n};\n\nexport const logWrapper = function (\n  prefix: string\n): (...varArgs: unknown[]) => void {\n  return function (...varArgs: unknown[]) {\n    log(prefix, ...varArgs);\n  };\n};\n\nexport const error = function (...varArgs: string[]) {\n  const message = 'FIREBASE INTERNAL ERROR: ' + buildLogMessage_(...varArgs);\n  logClient.error(message);\n};\n\nexport const fatal = function (...varArgs: string[]) {\n  const message = `FIREBASE FATAL ERROR: ${buildLogMessage_(...varArgs)}`;\n  logClient.error(message);\n  throw new Error(message);\n};\n\nexport const warn = function (...varArgs: unknown[]) {\n  const message = 'FIREBASE WARNING: ' + buildLogMessage_(...varArgs);\n  logClient.warn(message);\n};\n\n/**\n * Logs a warning if the containing page uses https. Called when a call to new Firebase\n * does not use https.\n */\nexport const warnIfPageIsSecure = function () {\n  // Be very careful accessing browser globals. Who knows what may or may not exist.\n  if (\n    typeof window !== 'undefined' &&\n    window.location &&\n    window.location.protocol &&\n    window.location.protocol.indexOf('https:') !== -1\n  ) {\n    warn(\n      'Insecure Firebase access from a secure page. ' +\n        'Please use https in calls to new Firebase().'\n    );\n  }\n};\n\nexport const warnAboutUnsupportedMethod = function (methodName: string) {\n  warn(\n    methodName +\n      ' is unsupported and will likely change soon.  ' +\n      'Please do not use.'\n  );\n};\n\n/**\n * Returns true if data is NaN, or +/- Infinity.\n */\nexport const isInvalidJSONNumber = function (data: unknown): boolean {\n  return (\n    typeof data === 'number' &&\n    (data !== data || // NaN\n      data === Number.POSITIVE_INFINITY ||\n      data === Number.NEGATIVE_INFINITY)\n  );\n};\n\nexport const executeWhenDOMReady = function (fn: () => void) {\n  if (isNodeSdk() || document.readyState === 'complete') {\n    fn();\n  } else {\n    // Modeled after jQuery. Try DOMContentLoaded and onreadystatechange (which\n    // fire before onload), but fall back to onload.\n\n    let called = false;\n    const wrappedFn = function () {\n      if (!document.body) {\n        setTimeout(wrappedFn, Math.floor(10));\n        return;\n      }\n\n      if (!called) {\n        called = true;\n        fn();\n      }\n    };\n\n    if (document.addEventListener) {\n      document.addEventListener('DOMContentLoaded', wrappedFn, false);\n      // fallback to onload.\n      window.addEventListener('load', wrappedFn, false);\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    } else if ((document as any).attachEvent) {\n      // IE.\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      (document as any).attachEvent('onreadystatechange', () => {\n        if (document.readyState === 'complete') {\n          wrappedFn();\n        }\n      });\n      // fallback to onload.\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      (window as any).attachEvent('onload', wrappedFn);\n\n      // jQuery has an extra hack for IE that we could employ (based on\n      // http://javascript.nwbox.com/IEContentLoaded/) But it looks really old.\n      // I'm hoping we don't need it.\n    }\n  }\n};\n\n/**\n * Minimum key name. Invalid for actual data, used as a marker to sort before any valid names\n */\nexport const MIN_NAME = '[MIN_NAME]';\n\n/**\n * Maximum key name. Invalid for actual data, used as a marker to sort above any valid names\n */\nexport const MAX_NAME = '[MAX_NAME]';\n\n/**\n * Compares valid Firebase key names, plus min and max name\n */\nexport const nameCompare = function (a: string, b: string): number {\n  if (a === b) {\n    return 0;\n  } else if (a === MIN_NAME || b === MAX_NAME) {\n    return -1;\n  } else if (b === MIN_NAME || a === MAX_NAME) {\n    return 1;\n  } else {\n    const aAsInt = tryParseInt(a),\n      bAsInt = tryParseInt(b);\n\n    if (aAsInt !== null) {\n      if (bAsInt !== null) {\n        return aAsInt - bAsInt === 0 ? a.length - b.length : aAsInt - bAsInt;\n      } else {\n        return -1;\n      }\n    } else if (bAsInt !== null) {\n      return 1;\n    } else {\n      return a < b ? -1 : 1;\n    }\n  }\n};\n\n/**\n * @returns {!number} comparison result.\n */\nexport const stringCompare = function (a: string, b: string): number {\n  if (a === b) {\n    return 0;\n  } else if (a < b) {\n    return -1;\n  } else {\n    return 1;\n  }\n};\n\nexport const requireKey = function (\n  key: string,\n  obj: { [k: string]: unknown }\n): unknown {\n  if (obj && key in obj) {\n    return obj[key];\n  } else {\n    throw new Error(\n      'Missing required key (' + key + ') in object: ' + stringify(obj)\n    );\n  }\n};\n\nexport const ObjectToUniqueKey = function (obj: unknown): string {\n  if (typeof obj !== 'object' || obj === null) {\n    return stringify(obj);\n  }\n\n  const keys = [];\n  // eslint-disable-next-line guard-for-in\n  for (const k in obj) {\n    keys.push(k);\n  }\n\n  // Export as json, but with the keys sorted.\n  keys.sort();\n  let key = '{';\n  for (let i = 0; i < keys.length; i++) {\n    if (i !== 0) {\n      key += ',';\n    }\n    key += stringify(keys[i]);\n    key += ':';\n    key += ObjectToUniqueKey(obj[keys[i]]);\n  }\n\n  key += '}';\n  return key;\n};\n\n/**\n * Splits a string into a number of smaller segments of maximum size\n * @param str - The string\n * @param segsize - The maximum number of chars in the string.\n * @returns The string, split into appropriately-sized chunks\n */\nexport const splitStringBySize = function (\n  str: string,\n  segsize: number\n): string[] {\n  const len = str.length;\n\n  if (len <= segsize) {\n    return [str];\n  }\n\n  const dataSegs = [];\n  for (let c = 0; c < len; c += segsize) {\n    if (c + segsize > len) {\n      dataSegs.push(str.substring(c, len));\n    } else {\n      dataSegs.push(str.substring(c, c + segsize));\n    }\n  }\n  return dataSegs;\n};\n\n/**\n * Apply a function to each (key, value) pair in an object or\n * apply a function to each (index, value) pair in an array\n * @param obj - The object or array to iterate over\n * @param fn - The function to apply\n */\nexport function each(obj: object, fn: (k: string, v: unknown) => void) {\n  for (const key in obj) {\n    if (obj.hasOwnProperty(key)) {\n      fn(key, obj[key]);\n    }\n  }\n}\n\n/**\n * Like goog.bind, but doesn't bother to create a closure if opt_context is null/undefined.\n * @param callback - Callback function.\n * @param context - Optional context to bind to.\n *\n */\nexport const bindCallback = function (\n  callback: (a: unknown) => void,\n  context?: object | null\n): (a: unknown) => void {\n  return context ? callback.bind(context) : callback;\n};\n\n/**\n * Borrowed from http://hg.secondlife.com/llsd/src/tip/js/typedarray.js (MIT License)\n * I made one modification at the end and removed the NaN / Infinity\n * handling (since it seemed broken [caused an overflow] and we don't need it).  See MJL comments.\n * @param v - A double\n *\n */\nexport const doubleToIEEE754String = function (v: number): string {\n  assert(!isInvalidJSONNumber(v), 'Invalid JSON number'); // MJL\n\n  const ebits = 11,\n    fbits = 52;\n  const bias = (1 << (ebits - 1)) - 1;\n  let s, e, f, ln, i;\n\n  // Compute sign, exponent, fraction\n  // Skip NaN / Infinity handling --MJL.\n  if (v === 0) {\n    e = 0;\n    f = 0;\n    s = 1 / v === -Infinity ? 1 : 0;\n  } else {\n    s = v < 0;\n    v = Math.abs(v);\n\n    if (v >= Math.pow(2, 1 - bias)) {\n      // Normalized\n      ln = Math.min(Math.floor(Math.log(v) / Math.LN2), bias);\n      e = ln + bias;\n      f = Math.round(v * Math.pow(2, fbits - ln) - Math.pow(2, fbits));\n    } else {\n      // Denormalized\n      e = 0;\n      f = Math.round(v / Math.pow(2, 1 - bias - fbits));\n    }\n  }\n\n  // Pack sign, exponent, fraction\n  const bits = [];\n  for (i = fbits; i; i -= 1) {\n    bits.push(f % 2 ? 1 : 0);\n    f = Math.floor(f / 2);\n  }\n  for (i = ebits; i; i -= 1) {\n    bits.push(e % 2 ? 1 : 0);\n    e = Math.floor(e / 2);\n  }\n  bits.push(s ? 1 : 0);\n  bits.reverse();\n  const str = bits.join('');\n\n  // Return the data as a hex string. --MJL\n  let hexByteString = '';\n  for (i = 0; i < 64; i += 8) {\n    let hexByte = parseInt(str.substr(i, 8), 2).toString(16);\n    if (hexByte.length === 1) {\n      hexByte = '0' + hexByte;\n    }\n    hexByteString = hexByteString + hexByte;\n  }\n  return hexByteString.toLowerCase();\n};\n\n/**\n * Used to detect if we're in a Chrome content script (which executes in an\n * isolated environment where long-polling doesn't work).\n */\nexport const isChromeExtensionContentScript = function (): boolean {\n  return !!(\n    typeof window === 'object' &&\n    window['chrome'] &&\n    window['chrome']['extension'] &&\n    !/^chrome/.test(window.location.href)\n  );\n};\n\n/**\n * Used to detect if we're in a Windows 8 Store app.\n */\nexport const isWindowsStoreApp = function (): boolean {\n  // Check for the presence of a couple WinRT globals\n  return typeof Windows === 'object' && typeof Windows.UI === 'object';\n};\n\n/**\n * Converts a server error code to a Javascript Error\n */\nexport function errorForServerCode(code: string, query: QueryContext): Error {\n  let reason = 'Unknown Error';\n  if (code === 'too_big') {\n    reason =\n      'The data requested exceeds the maximum size ' +\n      'that can be accessed with a single request.';\n  } else if (code === 'permission_denied') {\n    reason = \"Client doesn't have permission to access the desired data.\";\n  } else if (code === 'unavailable') {\n    reason = 'The service is unavailable';\n  }\n\n  const error = new Error(\n    code + ' at ' + query._path.toString() + ': ' + reason\n  );\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  (error as any).code = code.toUpperCase();\n  return error;\n}\n\n/**\n * Used to test for integer-looking strings\n */\nexport const INTEGER_REGEXP_ = new RegExp('^-?(0*)\\\\d{1,10}$');\n\n/**\n * For use in keys, the minimum possible 32-bit integer.\n */\nexport const INTEGER_32_MIN = -2147483648;\n\n/**\n * For use in kyes, the maximum possible 32-bit integer.\n */\nexport const INTEGER_32_MAX = 2147483647;\n\n/**\n * If the string contains a 32-bit integer, return it.  Else return null.\n */\nexport const tryParseInt = function (str: string): number | null {\n  if (INTEGER_REGEXP_.test(str)) {\n    const intVal = Number(str);\n    if (intVal >= INTEGER_32_MIN && intVal <= INTEGER_32_MAX) {\n      return intVal;\n    }\n  }\n  return null;\n};\n\n/**\n * Helper to run some code but catch any exceptions and re-throw them later.\n * Useful for preventing user callbacks from breaking internal code.\n *\n * Re-throwing the exception from a setTimeout is a little evil, but it's very\n * convenient (we don't have to try to figure out when is a safe point to\n * re-throw it), and the behavior seems reasonable:\n *\n * * If you aren't pausing on exceptions, you get an error in the console with\n *   the correct stack trace.\n * * If you're pausing on all exceptions, the debugger will pause on your\n *   exception and then again when we rethrow it.\n * * If you're only pausing on uncaught exceptions, the debugger will only pause\n *   on us re-throwing it.\n *\n * @param fn - The code to guard.\n */\nexport const exceptionGuard = function (fn: () => void) {\n  try {\n    fn();\n  } catch (e) {\n    // Re-throw exception when it's safe.\n    setTimeout(() => {\n      // It used to be that \"throw e\" would result in a good console error with\n      // relevant context, but as of Chrome 39, you just get the firebase.js\n      // file/line number where we re-throw it, which is useless. So we log\n      // e.stack explicitly.\n      const stack = e.stack || '';\n      warn('Exception was thrown by user callback.', stack);\n      throw e;\n    }, Math.floor(0));\n  }\n};\n\n/**\n * Helper function to safely call opt_callback with the specified arguments.  It:\n * 1. Turns into a no-op if opt_callback is null or undefined.\n * 2. Wraps the call inside exceptionGuard to prevent exceptions from breaking our state.\n *\n * @param callback - Optional onComplete callback.\n * @param varArgs - Arbitrary args to be passed to opt_onComplete\n */\nexport const callUserCallback = function (\n  // eslint-disable-next-line @typescript-eslint/ban-types\n  callback?: Function | null,\n  ...varArgs: unknown[]\n) {\n  if (typeof callback === 'function') {\n    exceptionGuard(() => {\n      callback(...varArgs);\n    });\n  }\n};\n\n/**\n * @returns {boolean} true if we think we're currently being crawled.\n */\nexport const beingCrawled = function (): boolean {\n  const userAgent =\n    (typeof window === 'object' &&\n      window['navigator'] &&\n      window['navigator']['userAgent']) ||\n    '';\n\n  // For now we whitelist the most popular crawlers.  We should refine this to be the set of crawlers we\n  // believe to support JavaScript/AJAX rendering.\n  // NOTE: Google Webmaster Tools doesn't really belong, but their \"This is how a visitor to your website\n  // would have seen the page\" is flaky if we don't treat it as a crawler.\n  return (\n    userAgent.search(\n      /googlebot|google webmaster tools|bingbot|yahoo! slurp|baiduspider|yandexbot|duckduckbot/i\n    ) >= 0\n  );\n};\n\n/**\n * Export a property of an object using a getter function.\n */\nexport const exportPropGetter = function (\n  object: object,\n  name: string,\n  fnGet: () => unknown\n) {\n  Object.defineProperty(object, name, { get: fnGet });\n};\n\n/**\n * Same as setTimeout() except on Node.JS it will /not/ prevent the process from exiting.\n *\n * It is removed with clearTimeout() as normal.\n *\n * @param fn - Function to run.\n * @param time - Milliseconds to wait before running.\n * @returns The setTimeout() return value.\n */\nexport const setTimeoutNonBlocking = function (\n  fn: () => void,\n  time: number\n): number | object {\n  const timeout: number | object = setTimeout(fn, time);\n  // Note: at the time of this comment, unrefTimer is under the unstable set of APIs. Run with --unstable to enable the API.\n  if (\n    typeof timeout === 'number' &&\n    // @ts-ignore Is only defined in Deno environments.\n    typeof Deno !== 'undefined' &&\n    // @ts-ignore Deno and unrefTimer are only defined in Deno environments.\n    Deno['unrefTimer']\n  ) {\n    // @ts-ignore Deno and unrefTimer are only defined in Deno environments.\n    Deno.unrefTimer(timeout);\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  } else if (typeof timeout === 'object' && (timeout as any)['unref']) {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    (timeout as any)['unref']();\n  }\n\n  return timeout;\n};\n","/**\n * @license\n * Copyright 2021 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AppCheckInternalComponentName,\n  AppCheckTokenListener,\n  AppCheckTokenResult,\n  FirebaseAppCheckInternal\n} from '@firebase/app-check-interop-types';\nimport { Provider } from '@firebase/component';\n\nimport { warn } from './util/util';\n\n/**\n * Abstraction around AppCheck's token fetching capabilities.\n */\nexport class AppCheckTokenProvider {\n  private appCheck?: FirebaseAppCheckInternal;\n  constructor(\n    private appName_: string,\n    private appCheckProvider?: Provider<AppCheckInternalComponentName>\n  ) {\n    this.appCheck = appCheckProvider?.getImmediate({ optional: true });\n    if (!this.appCheck) {\n      appCheckProvider?.get().then(appCheck => (this.appCheck = appCheck));\n    }\n  }\n\n  getToken(forceRefresh?: boolean): Promise<AppCheckTokenResult> {\n    if (!this.appCheck) {\n      return new Promise<AppCheckTokenResult>((resolve, reject) => {\n        // Support delayed initialization of FirebaseAppCheck. This allows our\n        // customers to initialize the RTDB SDK before initializing Firebase\n        // AppCheck and ensures that all requests are authenticated if a token\n        // becomes available before the timoeout below expires.\n        setTimeout(() => {\n          if (this.appCheck) {\n            this.getToken(forceRefresh).then(resolve, reject);\n          } else {\n            resolve(null);\n          }\n        }, 0);\n      });\n    }\n    return this.appCheck.getToken(forceRefresh);\n  }\n\n  addTokenChangeListener(listener: AppCheckTokenListener) {\n    this.appCheckProvider\n      ?.get()\n      .then(appCheck => appCheck.addTokenListener(listener));\n  }\n\n  notifyForInvalidToken(): void {\n    warn(\n      `Provided AppCheck credentials for the app named \"${this.appName_}\" ` +\n        'are invalid. This usually indicates your app was not initialized correctly.'\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseAuthTokenData } from '@firebase/app-types/private';\nimport {\n  FirebaseAuthInternal,\n  FirebaseAuthInternalName\n} from '@firebase/auth-interop-types';\nimport { Provider } from '@firebase/component';\n\nimport { log, warn } from './util/util';\n\nexport interface AuthTokenProvider {\n  getToken(forceRefresh: boolean): Promise<FirebaseAuthTokenData>;\n  addTokenChangeListener(listener: (token: string | null) => void): void;\n  removeTokenChangeListener(listener: (token: string | null) => void): void;\n  notifyForInvalidToken(): void;\n}\n\n/**\n * Abstraction around FirebaseApp's token fetching capabilities.\n */\nexport class FirebaseAuthTokenProvider implements AuthTokenProvider {\n  private auth_: FirebaseAuthInternal | null = null;\n\n  constructor(\n    private appName_: string,\n    private firebaseOptions_: object,\n    private authProvider_: Provider<FirebaseAuthInternalName>\n  ) {\n    this.auth_ = authProvider_.getImmediate({ optional: true });\n    if (!this.auth_) {\n      authProvider_.onInit(auth => (this.auth_ = auth));\n    }\n  }\n\n  getToken(forceRefresh: boolean): Promise<FirebaseAuthTokenData> {\n    if (!this.auth_) {\n      return new Promise<FirebaseAuthTokenData>((resolve, reject) => {\n        // Support delayed initialization of FirebaseAuth. This allows our\n        // customers to initialize the RTDB SDK before initializing Firebase\n        // Auth and ensures that all requests are authenticated if a token\n        // becomes available before the timoeout below expires.\n        setTimeout(() => {\n          if (this.auth_) {\n            this.getToken(forceRefresh).then(resolve, reject);\n          } else {\n            resolve(null);\n          }\n        }, 0);\n      });\n    }\n\n    return this.auth_.getToken(forceRefresh).catch(error => {\n      // TODO: Need to figure out all the cases this is raised and whether\n      // this makes sense.\n      if (error && error.code === 'auth/token-not-initialized') {\n        log('Got auth/token-not-initialized error.  Treating as null token.');\n        return null;\n      } else {\n        return Promise.reject(error);\n      }\n    });\n  }\n\n  addTokenChangeListener(listener: (token: string | null) => void): void {\n    // TODO: We might want to wrap the listener and call it with no args to\n    // avoid a leaky abstraction, but that makes removing the listener harder.\n    if (this.auth_) {\n      this.auth_.addAuthTokenListener(listener);\n    } else {\n      this.authProvider_\n        .get()\n        .then(auth => auth.addAuthTokenListener(listener));\n    }\n  }\n\n  removeTokenChangeListener(listener: (token: string | null) => void): void {\n    this.authProvider_\n      .get()\n      .then(auth => auth.removeAuthTokenListener(listener));\n  }\n\n  notifyForInvalidToken(): void {\n    let errorMessage =\n      'Provided authentication credentials for the app named \"' +\n      this.appName_ +\n      '\" are invalid. This usually indicates your app was not ' +\n      'initialized correctly. ';\n    if ('credential' in this.firebaseOptions_) {\n      errorMessage +=\n        'Make sure the \"credential\" property provided to initializeApp() ' +\n        'is authorized to access the specified \"databaseURL\" and is from the correct ' +\n        'project.';\n    } else if ('serviceAccount' in this.firebaseOptions_) {\n      errorMessage +=\n        'Make sure the \"serviceAccount\" property provided to initializeApp() ' +\n        'is authorized to access the specified \"databaseURL\" and is from the correct ' +\n        'project.';\n    } else {\n      errorMessage +=\n        'Make sure the \"apiKey\" and \"databaseURL\" properties provided to ' +\n        'initializeApp() match the values provided for your app at ' +\n        'https://console.firebase.google.com/.';\n    }\n    warn(errorMessage);\n  }\n}\n\n/* AuthTokenProvider that supplies a constant token. Used by Admin SDK or mockUserToken with emulators. */\nexport class EmulatorTokenProvider implements AuthTokenProvider {\n  /** A string that is treated as an admin access token by the RTDB emulator. Used by Admin SDK. */\n  static OWNER = 'owner';\n\n  constructor(private accessToken: string) {}\n\n  getToken(forceRefresh: boolean): Promise<FirebaseAuthTokenData> {\n    return Promise.resolve({\n      accessToken: this.accessToken\n    });\n  }\n\n  addTokenChangeListener(listener: (token: string | null) => void): void {\n    // Invoke the listener immediately to match the behavior in Firebase Auth\n    // (see packages/auth/src/auth.js#L1807)\n    listener(this.accessToken);\n  }\n\n  removeTokenChangeListener(listener: (token: string | null) => void): void {}\n\n  notifyForInvalidToken(): void {}\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { LONG_POLLING, WEBSOCKET } from '../realtime/Constants';\n\nimport { PersistentStorage } from './storage/storage';\nimport { each } from './util/util';\n\n/**\n * A class that holds metadata about a Repo object\n */\nexport class RepoInfo {\n  private _host: string;\n  private _domain: string;\n  internalHost: string;\n\n  /**\n   * @param host - Hostname portion of the url for the repo\n   * @param secure - Whether or not this repo is accessed over ssl\n   * @param namespace - The namespace represented by the repo\n   * @param webSocketOnly - Whether to prefer websockets over all other transports (used by Nest).\n   * @param nodeAdmin - Whether this instance uses Admin SDK credentials\n   * @param persistenceKey - Override the default session persistence storage key\n   */\n  constructor(\n    host: string,\n    public readonly secure: boolean,\n    public readonly namespace: string,\n    public readonly webSocketOnly: boolean,\n    public readonly nodeAdmin: boolean = false,\n    public readonly persistenceKey: string = '',\n    public readonly includeNamespaceInQueryParams: boolean = false,\n    public readonly isUsingEmulator: boolean = false\n  ) {\n    this._host = host.toLowerCase();\n    this._domain = this._host.substr(this._host.indexOf('.') + 1);\n    this.internalHost =\n      (PersistentStorage.get('host:' + host) as string) || this._host;\n  }\n\n  isCacheableHost(): boolean {\n    return this.internalHost.substr(0, 2) === 's-';\n  }\n\n  isCustomHost() {\n    return (\n      this._domain !== 'firebaseio.com' &&\n      this._domain !== 'firebaseio-demo.com'\n    );\n  }\n\n  get host() {\n    return this._host;\n  }\n\n  set host(newHost: string) {\n    if (newHost !== this.internalHost) {\n      this.internalHost = newHost;\n      if (this.isCacheableHost()) {\n        PersistentStorage.set('host:' + this._host, this.internalHost);\n      }\n    }\n  }\n\n  toString(): string {\n    let str = this.toURLString();\n    if (this.persistenceKey) {\n      str += '<' + this.persistenceKey + '>';\n    }\n    return str;\n  }\n\n  toURLString(): string {\n    const protocol = this.secure ? 'https://' : 'http://';\n    const query = this.includeNamespaceInQueryParams\n      ? `?ns=${this.namespace}`\n      : '';\n    return `${protocol}${this.host}/${query}`;\n  }\n}\n\nfunction repoInfoNeedsQueryParam(repoInfo: RepoInfo): boolean {\n  return (\n    repoInfo.host !== repoInfo.internalHost ||\n    repoInfo.isCustomHost() ||\n    repoInfo.includeNamespaceInQueryParams\n  );\n}\n\n/**\n * Returns the websocket URL for this repo\n * @param repoInfo - RepoInfo object\n * @param type - of connection\n * @param params - list\n * @returns The URL for this repo\n */\nexport function repoInfoConnectionURL(\n  repoInfo: RepoInfo,\n  type: string,\n  params: { [k: string]: string }\n): string {\n  assert(typeof type === 'string', 'typeof type must == string');\n  assert(typeof params === 'object', 'typeof params must == object');\n\n  let connURL: string;\n  if (type === WEBSOCKET) {\n    connURL =\n      (repoInfo.secure ? 'wss://' : 'ws://') + repoInfo.internalHost + '/.ws?';\n  } else if (type === LONG_POLLING) {\n    connURL =\n      (repoInfo.secure ? 'https://' : 'http://') +\n      repoInfo.internalHost +\n      '/.lp?';\n  } else {\n    throw new Error('Unknown connection type: ' + type);\n  }\n  if (repoInfoNeedsQueryParam(repoInfo)) {\n    params['ns'] = repoInfo.namespace;\n  }\n\n  const pairs: string[] = [];\n\n  each(params, (key: string, value: string) => {\n    pairs.push(key + '=' + value);\n  });\n\n  return connURL + pairs.join('&');\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { RepoInfo } from '../RepoInfo';\n\nimport { StatsCollection } from './StatsCollection';\n\nconst collections: { [k: string]: StatsCollection } = {};\nconst reporters: { [k: string]: unknown } = {};\n\nexport function statsManagerGetCollection(repoInfo: RepoInfo): StatsCollection {\n  const hashString = repoInfo.toString();\n\n  if (!collections[hashString]) {\n    collections[hashString] = new StatsCollection();\n  }\n\n  return collections[hashString];\n}\n\nexport function statsManagerGetOrCreateReporter<T>(\n  repoInfo: RepoInfo,\n  creatorFunction: () => T\n): T {\n  const hashString = repoInfo.toString();\n\n  if (!reporters[hashString]) {\n    reporters[hashString] = creatorFunction();\n  }\n\n  return reporters[hashString] as T;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { exceptionGuard } from '../../core/util/util';\n\n/**\n * This class ensures the packets from the server arrive in order\n * This class takes data from the server and ensures it gets passed into the callbacks in order.\n */\nexport class PacketReceiver {\n  pendingResponses: unknown[] = [];\n  currentResponseNum = 0;\n  closeAfterResponse = -1;\n  onClose: (() => void) | null = null;\n\n  /**\n   * @param onMessage_\n   */\n  constructor(private onMessage_: (a: {}) => void) {}\n\n  closeAfter(responseNum: number, callback: () => void) {\n    this.closeAfterResponse = responseNum;\n    this.onClose = callback;\n    if (this.closeAfterResponse < this.currentResponseNum) {\n      this.onClose();\n      this.onClose = null;\n    }\n  }\n\n  /**\n   * Each message from the server comes with a response number, and an array of data. The responseNumber\n   * allows us to ensure that we process them in the right order, since we can't be guaranteed that all\n   * browsers will respond in the same order as the requests we sent\n   */\n  handleResponse(requestNum: number, data: unknown[]) {\n    this.pendingResponses[requestNum] = data;\n    while (this.pendingResponses[this.currentResponseNum]) {\n      const toProcess = this.pendingResponses[\n        this.currentResponseNum\n      ] as unknown[];\n      delete this.pendingResponses[this.currentResponseNum];\n      for (let i = 0; i < toProcess.length; ++i) {\n        if (toProcess[i]) {\n          exceptionGuard(() => {\n            this.onMessage_(toProcess[i]);\n          });\n        }\n      }\n      if (this.currentResponseNum === this.closeAfterResponse) {\n        if (this.onClose) {\n          this.onClose();\n          this.onClose = null;\n        }\n        break;\n      }\n      this.currentResponseNum++;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { base64Encode, isNodeSdk, stringify } from '@firebase/util';\n\nimport { RepoInfo, repoInfoConnectionURL } from '../core/RepoInfo';\nimport { StatsCollection } from '../core/stats/StatsCollection';\nimport { statsManagerGetCollection } from '../core/stats/StatsManager';\nimport {\n  executeWhenDOMReady,\n  isChromeExtensionContentScript,\n  isWindowsStoreApp,\n  log,\n  logWrapper,\n  LUIDGenerator,\n  splitStringBySize\n} from '../core/util/util';\n\nimport {\n  APP_CHECK_TOKEN_PARAM,\n  APPLICATION_ID_PARAM,\n  FORGE_DOMAIN_RE,\n  FORGE_REF,\n  LAST_SESSION_PARAM,\n  LONG_POLLING,\n  PROTOCOL_VERSION,\n  REFERER_PARAM,\n  TRANSPORT_SESSION_PARAM,\n  VERSION_PARAM\n} from './Constants';\nimport { PacketReceiver } from './polling/PacketReceiver';\nimport { Transport } from './Transport';\n\n// URL query parameters associated with longpolling\nexport const FIREBASE_LONGPOLL_START_PARAM = 'start';\nexport const FIREBASE_LONGPOLL_CLOSE_COMMAND = 'close';\nexport const FIREBASE_LONGPOLL_COMMAND_CB_NAME = 'pLPCommand';\nexport const FIREBASE_LONGPOLL_DATA_CB_NAME = 'pRTLPCB';\nexport const FIREBASE_LONGPOLL_ID_PARAM = 'id';\nexport const FIREBASE_LONGPOLL_PW_PARAM = 'pw';\nexport const FIREBASE_LONGPOLL_SERIAL_PARAM = 'ser';\nexport const FIREBASE_LONGPOLL_CALLBACK_ID_PARAM = 'cb';\nexport const FIREBASE_LONGPOLL_SEGMENT_NUM_PARAM = 'seg';\nexport const FIREBASE_LONGPOLL_SEGMENTS_IN_PACKET = 'ts';\nexport const FIREBASE_LONGPOLL_DATA_PARAM = 'd';\nexport const FIREBASE_LONGPOLL_DISCONN_FRAME_PARAM = 'disconn';\nexport const FIREBASE_LONGPOLL_DISCONN_FRAME_REQUEST_PARAM = 'dframe';\n\n//Data size constants.\n//TODO: Perf: the maximum length actually differs from browser to browser.\n// We should check what browser we're on and set accordingly.\nconst MAX_URL_DATA_SIZE = 1870;\nconst SEG_HEADER_SIZE = 30; //ie: &seg=8299234&ts=982389123&d=\nconst MAX_PAYLOAD_SIZE = MAX_URL_DATA_SIZE - SEG_HEADER_SIZE;\n\n/**\n * Keepalive period\n * send a fresh request at minimum every 25 seconds. Opera has a maximum request\n * length of 30 seconds that we can't exceed.\n */\nconst KEEPALIVE_REQUEST_INTERVAL = 25000;\n\n/**\n * How long to wait before aborting a long-polling connection attempt.\n */\nconst LP_CONNECT_TIMEOUT = 30000;\n\n/**\n * This class manages a single long-polling connection.\n */\nexport class BrowserPollConnection implements Transport {\n  bytesSent = 0;\n  bytesReceived = 0;\n  urlFn: (params: object) => string;\n  scriptTagHolder: FirebaseIFrameScriptHolder;\n  myDisconnFrame: HTMLIFrameElement;\n  curSegmentNum: number;\n  myPacketOrderer: PacketReceiver;\n  id: string;\n  password: string;\n  private log_: (...a: unknown[]) => void;\n  private stats_: StatsCollection;\n  private everConnected_ = false;\n  private isClosed_: boolean;\n  private connectTimeoutTimer_: number | null;\n  private onDisconnect_: ((a?: boolean) => void) | null;\n\n  /**\n   * @param connId An identifier for this connection, used for logging\n   * @param repoInfo The info for the endpoint to send data to.\n   * @param applicationId The Firebase App ID for this project.\n   * @param appCheckToken The AppCheck token for this client.\n   * @param authToken The AuthToken to use for this connection.\n   * @param transportSessionId Optional transportSessionid if we are\n   * reconnecting for an existing transport session\n   * @param lastSessionId Optional lastSessionId if the PersistentConnection has\n   * already created a connection previously\n   */\n  constructor(\n    public connId: string,\n    public repoInfo: RepoInfo,\n    private applicationId?: string,\n    private appCheckToken?: string,\n    private authToken?: string,\n    public transportSessionId?: string,\n    public lastSessionId?: string\n  ) {\n    this.log_ = logWrapper(connId);\n    this.stats_ = statsManagerGetCollection(repoInfo);\n    this.urlFn = (params: { [k: string]: string }) => {\n      // Always add the token if we have one.\n      if (this.appCheckToken) {\n        params[APP_CHECK_TOKEN_PARAM] = this.appCheckToken;\n      }\n      return repoInfoConnectionURL(repoInfo, LONG_POLLING, params);\n    };\n  }\n\n  /**\n   * @param onMessage - Callback when messages arrive\n   * @param onDisconnect - Callback with connection lost.\n   */\n  open(onMessage: (msg: {}) => void, onDisconnect: (a?: boolean) => void) {\n    this.curSegmentNum = 0;\n    this.onDisconnect_ = onDisconnect;\n    this.myPacketOrderer = new PacketReceiver(onMessage);\n    this.isClosed_ = false;\n\n    this.connectTimeoutTimer_ = setTimeout(() => {\n      this.log_('Timed out trying to connect.');\n      // Make sure we clear the host cache\n      this.onClosed_();\n      this.connectTimeoutTimer_ = null;\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    }, Math.floor(LP_CONNECT_TIMEOUT)) as any;\n\n    // Ensure we delay the creation of the iframe until the DOM is loaded.\n    executeWhenDOMReady(() => {\n      if (this.isClosed_) {\n        return;\n      }\n\n      //Set up a callback that gets triggered once a connection is set up.\n      this.scriptTagHolder = new FirebaseIFrameScriptHolder(\n        (...args) => {\n          const [command, arg1, arg2, arg3, arg4] = args;\n          this.incrementIncomingBytes_(args);\n          if (!this.scriptTagHolder) {\n            return; // we closed the connection.\n          }\n\n          if (this.connectTimeoutTimer_) {\n            clearTimeout(this.connectTimeoutTimer_);\n            this.connectTimeoutTimer_ = null;\n          }\n          this.everConnected_ = true;\n          if (command === FIREBASE_LONGPOLL_START_PARAM) {\n            this.id = arg1 as string;\n            this.password = arg2 as string;\n          } else if (command === FIREBASE_LONGPOLL_CLOSE_COMMAND) {\n            // Don't clear the host cache. We got a response from the server, so we know it's reachable\n            if (arg1) {\n              // We aren't expecting any more data (other than what the server's already in the process of sending us\n              // through our already open polls), so don't send any more.\n              this.scriptTagHolder.sendNewPolls = false;\n\n              // arg1 in this case is the last response number sent by the server. We should try to receive\n              // all of the responses up to this one before closing\n              this.myPacketOrderer.closeAfter(arg1 as number, () => {\n                this.onClosed_();\n              });\n            } else {\n              this.onClosed_();\n            }\n          } else {\n            throw new Error('Unrecognized command received: ' + command);\n          }\n        },\n        (...args) => {\n          const [pN, data] = args;\n          this.incrementIncomingBytes_(args);\n          this.myPacketOrderer.handleResponse(pN as number, data as unknown[]);\n        },\n        () => {\n          this.onClosed_();\n        },\n        this.urlFn\n      );\n\n      //Send the initial request to connect. The serial number is simply to keep the browser from pulling previous results\n      //from cache.\n      const urlParams: { [k: string]: string | number } = {};\n      urlParams[FIREBASE_LONGPOLL_START_PARAM] = 't';\n      urlParams[FIREBASE_LONGPOLL_SERIAL_PARAM] = Math.floor(\n        Math.random() * 100000000\n      );\n      if (this.scriptTagHolder.uniqueCallbackIdentifier) {\n        urlParams[FIREBASE_LONGPOLL_CALLBACK_ID_PARAM] =\n          this.scriptTagHolder.uniqueCallbackIdentifier;\n      }\n      urlParams[VERSION_PARAM] = PROTOCOL_VERSION;\n      if (this.transportSessionId) {\n        urlParams[TRANSPORT_SESSION_PARAM] = this.transportSessionId;\n      }\n      if (this.lastSessionId) {\n        urlParams[LAST_SESSION_PARAM] = this.lastSessionId;\n      }\n      if (this.applicationId) {\n        urlParams[APPLICATION_ID_PARAM] = this.applicationId;\n      }\n      if (this.appCheckToken) {\n        urlParams[APP_CHECK_TOKEN_PARAM] = this.appCheckToken;\n      }\n      if (\n        typeof location !== 'undefined' &&\n        location.hostname &&\n        FORGE_DOMAIN_RE.test(location.hostname)\n      ) {\n        urlParams[REFERER_PARAM] = FORGE_REF;\n      }\n      const connectURL = this.urlFn(urlParams);\n      this.log_('Connecting via long-poll to ' + connectURL);\n      this.scriptTagHolder.addTag(connectURL, () => {\n        /* do nothing */\n      });\n    });\n  }\n\n  /**\n   * Call this when a handshake has completed successfully and we want to consider the connection established\n   */\n  start() {\n    this.scriptTagHolder.startLongPoll(this.id, this.password);\n    this.addDisconnectPingFrame(this.id, this.password);\n  }\n\n  static forceAllow_: boolean;\n\n  /**\n   * Forces long polling to be considered as a potential transport\n   */\n  static forceAllow() {\n    BrowserPollConnection.forceAllow_ = true;\n  }\n\n  static forceDisallow_: boolean;\n\n  /**\n   * Forces longpolling to not be considered as a potential transport\n   */\n  static forceDisallow() {\n    BrowserPollConnection.forceDisallow_ = true;\n  }\n\n  // Static method, use string literal so it can be accessed in a generic way\n  static isAvailable() {\n    if (isNodeSdk()) {\n      return false;\n    } else if (BrowserPollConnection.forceAllow_) {\n      return true;\n    } else {\n      // NOTE: In React-Native there's normally no 'document', but if you debug a React-Native app in\n      // the Chrome debugger, 'document' is defined, but document.createElement is null (2015/06/08).\n      return (\n        !BrowserPollConnection.forceDisallow_ &&\n        typeof document !== 'undefined' &&\n        document.createElement != null &&\n        !isChromeExtensionContentScript() &&\n        !isWindowsStoreApp()\n      );\n    }\n  }\n\n  /**\n   * No-op for polling\n   */\n  markConnectionHealthy() {}\n\n  /**\n   * Stops polling and cleans up the iframe\n   */\n  private shutdown_() {\n    this.isClosed_ = true;\n\n    if (this.scriptTagHolder) {\n      this.scriptTagHolder.close();\n      this.scriptTagHolder = null;\n    }\n\n    //remove the disconnect frame, which will trigger an XHR call to the server to tell it we're leaving.\n    if (this.myDisconnFrame) {\n      document.body.removeChild(this.myDisconnFrame);\n      this.myDisconnFrame = null;\n    }\n\n    if (this.connectTimeoutTimer_) {\n      clearTimeout(this.connectTimeoutTimer_);\n      this.connectTimeoutTimer_ = null;\n    }\n  }\n\n  /**\n   * Triggered when this transport is closed\n   */\n  private onClosed_() {\n    if (!this.isClosed_) {\n      this.log_('Longpoll is closing itself');\n      this.shutdown_();\n\n      if (this.onDisconnect_) {\n        this.onDisconnect_(this.everConnected_);\n        this.onDisconnect_ = null;\n      }\n    }\n  }\n\n  /**\n   * External-facing close handler. RealTime has requested we shut down. Kill our connection and tell the server\n   * that we've left.\n   */\n  close() {\n    if (!this.isClosed_) {\n      this.log_('Longpoll is being closed.');\n      this.shutdown_();\n    }\n  }\n\n  /**\n   * Send the JSON object down to the server. It will need to be stringified, base64 encoded, and then\n   * broken into chunks (since URLs have a small maximum length).\n   * @param data - The JSON data to transmit.\n   */\n  send(data: {}) {\n    const dataStr = stringify(data);\n    this.bytesSent += dataStr.length;\n    this.stats_.incrementCounter('bytes_sent', dataStr.length);\n\n    //first, lets get the base64-encoded data\n    const base64data = base64Encode(dataStr);\n\n    //We can only fit a certain amount in each URL, so we need to split this request\n    //up into multiple pieces if it doesn't fit in one request.\n    const dataSegs = splitStringBySize(base64data, MAX_PAYLOAD_SIZE);\n\n    //Enqueue each segment for transmission. We assign each chunk a sequential ID and a total number\n    //of segments so that we can reassemble the packet on the server.\n    for (let i = 0; i < dataSegs.length; i++) {\n      this.scriptTagHolder.enqueueSegment(\n        this.curSegmentNum,\n        dataSegs.length,\n        dataSegs[i]\n      );\n      this.curSegmentNum++;\n    }\n  }\n\n  /**\n   * This is how we notify the server that we're leaving.\n   * We aren't able to send requests with DHTML on a window close event, but we can\n   * trigger XHR requests in some browsers (everything but Opera basically).\n   */\n  addDisconnectPingFrame(id: string, pw: string) {\n    if (isNodeSdk()) {\n      return;\n    }\n    this.myDisconnFrame = document.createElement('iframe');\n    const urlParams: { [k: string]: string } = {};\n    urlParams[FIREBASE_LONGPOLL_DISCONN_FRAME_REQUEST_PARAM] = 't';\n    urlParams[FIREBASE_LONGPOLL_ID_PARAM] = id;\n    urlParams[FIREBASE_LONGPOLL_PW_PARAM] = pw;\n    this.myDisconnFrame.src = this.urlFn(urlParams);\n    this.myDisconnFrame.style.display = 'none';\n\n    document.body.appendChild(this.myDisconnFrame);\n  }\n\n  /**\n   * Used to track the bytes received by this client\n   */\n  private incrementIncomingBytes_(args: unknown) {\n    // TODO: This is an annoying perf hit just to track the number of incoming bytes.  Maybe it should be opt-in.\n    const bytesReceived = stringify(args).length;\n    this.bytesReceived += bytesReceived;\n    this.stats_.incrementCounter('bytes_received', bytesReceived);\n  }\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport interface IFrameElement extends HTMLIFrameElement {\n  doc: Document;\n}\n\n/*********************************************************************************************\n * A wrapper around an iframe that is used as a long-polling script holder.\n *********************************************************************************************/\nexport class FirebaseIFrameScriptHolder {\n  //We maintain a count of all of the outstanding requests, because if we have too many active at once it can cause\n  //problems in some browsers.\n  outstandingRequests = new Set<number>();\n\n  //A queue of the pending segments waiting for transmission to the server.\n  pendingSegs: Array<{ seg: number; ts: number; d: unknown }> = [];\n\n  //A serial number. We use this for two things:\n  // 1) A way to ensure the browser doesn't cache responses to polls\n  // 2) A way to make the server aware when long-polls arrive in a different order than we started them. The\n  //    server needs to release both polls in this case or it will cause problems in Opera since Opera can only execute\n  //    JSONP code in the order it was added to the iframe.\n  currentSerial = Math.floor(Math.random() * 100000000);\n\n  // This gets set to false when we're \"closing down\" the connection (e.g. we're switching transports but there's still\n  // incoming data from the server that we're waiting for).\n  sendNewPolls = true;\n\n  uniqueCallbackIdentifier: number;\n  myIFrame: IFrameElement;\n  alive: boolean;\n  myID: string;\n  myPW: string;\n  commandCB: (command: string, ...args: unknown[]) => void;\n  onMessageCB: (...args: unknown[]) => void;\n\n  /**\n   * @param commandCB - The callback to be called when control commands are recevied from the server.\n   * @param onMessageCB - The callback to be triggered when responses arrive from the server.\n   * @param onDisconnect - The callback to be triggered when this tag holder is closed\n   * @param urlFn - A function that provides the URL of the endpoint to send data to.\n   */\n  constructor(\n    commandCB: (command: string, ...args: unknown[]) => void,\n    onMessageCB: (...args: unknown[]) => void,\n    public onDisconnect: () => void,\n    public urlFn: (a: object) => string\n  ) {\n    if (!isNodeSdk()) {\n      //Each script holder registers a couple of uniquely named callbacks with the window. These are called from the\n      //iframes where we put the long-polling script tags. We have two callbacks:\n      //   1) Command Callback - Triggered for control issues, like starting a connection.\n      //   2) Message Callback - Triggered when new data arrives.\n      this.uniqueCallbackIdentifier = LUIDGenerator();\n      window[\n        FIREBASE_LONGPOLL_COMMAND_CB_NAME + this.uniqueCallbackIdentifier\n      ] = commandCB;\n      window[FIREBASE_LONGPOLL_DATA_CB_NAME + this.uniqueCallbackIdentifier] =\n        onMessageCB;\n\n      //Create an iframe for us to add script tags to.\n      this.myIFrame = FirebaseIFrameScriptHolder.createIFrame_();\n\n      // Set the iframe's contents.\n      let script = '';\n      // if we set a javascript url, it's IE and we need to set the document domain. The javascript url is sufficient\n      // for ie9, but ie8 needs to do it again in the document itself.\n      if (\n        this.myIFrame.src &&\n        this.myIFrame.src.substr(0, 'javascript:'.length) === 'javascript:'\n      ) {\n        const currentDomain = document.domain;\n        script = '<script>document.domain=\"' + currentDomain + '\";</script>';\n      }\n      const iframeContents = '<html><body>' + script + '</body></html>';\n      try {\n        this.myIFrame.doc.open();\n        this.myIFrame.doc.write(iframeContents);\n        this.myIFrame.doc.close();\n      } catch (e) {\n        log('frame writing exception');\n        if (e.stack) {\n          log(e.stack);\n        }\n        log(e);\n      }\n    } else {\n      this.commandCB = commandCB;\n      this.onMessageCB = onMessageCB;\n    }\n  }\n\n  /**\n   * Each browser has its own funny way to handle iframes. Here we mush them all together into one object that I can\n   * actually use.\n   */\n  private static createIFrame_(): IFrameElement {\n    const iframe = document.createElement('iframe') as IFrameElement;\n    iframe.style.display = 'none';\n\n    // This is necessary in order to initialize the document inside the iframe\n    if (document.body) {\n      document.body.appendChild(iframe);\n      try {\n        // If document.domain has been modified in IE, this will throw an error, and we need to set the\n        // domain of the iframe's document manually. We can do this via a javascript: url as the src attribute\n        // Also note that we must do this *after* the iframe has been appended to the page. Otherwise it doesn't work.\n        const a = iframe.contentWindow.document;\n        if (!a) {\n          // Apologies for the log-spam, I need to do something to keep closure from optimizing out the assignment above.\n          log('No IE domain setting required');\n        }\n      } catch (e) {\n        const domain = document.domain;\n        iframe.src =\n          \"javascript:void((function(){document.open();document.domain='\" +\n          domain +\n          \"';document.close();})())\";\n      }\n    } else {\n      // LongPollConnection attempts to delay initialization until the document is ready, so hopefully this\n      // never gets hit.\n      throw 'Document body has not initialized. Wait to initialize Firebase until after the document is ready.';\n    }\n\n    // Get the document of the iframe in a browser-specific way.\n    if (iframe.contentDocument) {\n      iframe.doc = iframe.contentDocument; // Firefox, Opera, Safari\n    } else if (iframe.contentWindow) {\n      iframe.doc = iframe.contentWindow.document; // Internet Explorer\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    } else if ((iframe as any).document) {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      iframe.doc = (iframe as any).document; //others?\n    }\n\n    return iframe;\n  }\n\n  /**\n   * Cancel all outstanding queries and remove the frame.\n   */\n  close() {\n    //Mark this iframe as dead, so no new requests are sent.\n    this.alive = false;\n\n    if (this.myIFrame) {\n      //We have to actually remove all of the html inside this iframe before removing it from the\n      //window, or IE will continue loading and executing the script tags we've already added, which\n      //can lead to some errors being thrown. Setting textContent seems to be the safest way to do this.\n      this.myIFrame.doc.body.textContent = '';\n      setTimeout(() => {\n        if (this.myIFrame !== null) {\n          document.body.removeChild(this.myIFrame);\n          this.myIFrame = null;\n        }\n      }, Math.floor(0));\n    }\n\n    // Protect from being called recursively.\n    const onDisconnect = this.onDisconnect;\n    if (onDisconnect) {\n      this.onDisconnect = null;\n      onDisconnect();\n    }\n  }\n\n  /**\n   * Actually start the long-polling session by adding the first script tag(s) to the iframe.\n   * @param id - The ID of this connection\n   * @param pw - The password for this connection\n   */\n  startLongPoll(id: string, pw: string) {\n    this.myID = id;\n    this.myPW = pw;\n    this.alive = true;\n\n    //send the initial request. If there are requests queued, make sure that we transmit as many as we are currently able to.\n    while (this.newRequest_()) {}\n  }\n\n  /**\n   * This is called any time someone might want a script tag to be added. It adds a script tag when there aren't\n   * too many outstanding requests and we are still alive.\n   *\n   * If there are outstanding packet segments to send, it sends one. If there aren't, it sends a long-poll anyways if\n   * needed.\n   */\n  private newRequest_() {\n    // We keep one outstanding request open all the time to receive data, but if we need to send data\n    // (pendingSegs.length > 0) then we create a new request to send the data.  The server will automatically\n    // close the old request.\n    if (\n      this.alive &&\n      this.sendNewPolls &&\n      this.outstandingRequests.size < (this.pendingSegs.length > 0 ? 2 : 1)\n    ) {\n      //construct our url\n      this.currentSerial++;\n      const urlParams: { [k: string]: string | number } = {};\n      urlParams[FIREBASE_LONGPOLL_ID_PARAM] = this.myID;\n      urlParams[FIREBASE_LONGPOLL_PW_PARAM] = this.myPW;\n      urlParams[FIREBASE_LONGPOLL_SERIAL_PARAM] = this.currentSerial;\n      let theURL = this.urlFn(urlParams);\n      //Now add as much data as we can.\n      let curDataString = '';\n      let i = 0;\n\n      while (this.pendingSegs.length > 0) {\n        //first, lets see if the next segment will fit.\n        const nextSeg = this.pendingSegs[0];\n        if (\n          (nextSeg.d as unknown[]).length +\n            SEG_HEADER_SIZE +\n            curDataString.length <=\n          MAX_URL_DATA_SIZE\n        ) {\n          //great, the segment will fit. Lets append it.\n          const theSeg = this.pendingSegs.shift();\n          curDataString =\n            curDataString +\n            '&' +\n            FIREBASE_LONGPOLL_SEGMENT_NUM_PARAM +\n            i +\n            '=' +\n            theSeg.seg +\n            '&' +\n            FIREBASE_LONGPOLL_SEGMENTS_IN_PACKET +\n            i +\n            '=' +\n            theSeg.ts +\n            '&' +\n            FIREBASE_LONGPOLL_DATA_PARAM +\n            i +\n            '=' +\n            theSeg.d;\n          i++;\n        } else {\n          break;\n        }\n      }\n\n      theURL = theURL + curDataString;\n      this.addLongPollTag_(theURL, this.currentSerial);\n\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  /**\n   * Queue a packet for transmission to the server.\n   * @param segnum - A sequential id for this packet segment used for reassembly\n   * @param totalsegs - The total number of segments in this packet\n   * @param data - The data for this segment.\n   */\n  enqueueSegment(segnum: number, totalsegs: number, data: unknown) {\n    //add this to the queue of segments to send.\n    this.pendingSegs.push({ seg: segnum, ts: totalsegs, d: data });\n\n    //send the data immediately if there isn't already data being transmitted, unless\n    //startLongPoll hasn't been called yet.\n    if (this.alive) {\n      this.newRequest_();\n    }\n  }\n\n  /**\n   * Add a script tag for a regular long-poll request.\n   * @param url - The URL of the script tag.\n   * @param serial - The serial number of the request.\n   */\n  private addLongPollTag_(url: string, serial: number) {\n    //remember that we sent this request.\n    this.outstandingRequests.add(serial);\n\n    const doNewRequest = () => {\n      this.outstandingRequests.delete(serial);\n      this.newRequest_();\n    };\n\n    // If this request doesn't return on its own accord (by the server sending us some data), we'll\n    // create a new one after the KEEPALIVE interval to make sure we always keep a fresh request open.\n    const keepaliveTimeout = setTimeout(\n      doNewRequest,\n      Math.floor(KEEPALIVE_REQUEST_INTERVAL)\n    );\n\n    const readyStateCB = () => {\n      // Request completed.  Cancel the keepalive.\n      clearTimeout(keepaliveTimeout);\n\n      // Trigger a new request so we can continue receiving data.\n      doNewRequest();\n    };\n\n    this.addTag(url, readyStateCB);\n  }\n\n  /**\n   * Add an arbitrary script tag to the iframe.\n   * @param url - The URL for the script tag source.\n   * @param loadCB - A callback to be triggered once the script has loaded.\n   */\n  addTag(url: string, loadCB: () => void) {\n    if (isNodeSdk()) {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      (this as any).doNodeLongPoll(url, loadCB);\n    } else {\n      setTimeout(() => {\n        try {\n          // if we're already closed, don't add this poll\n          if (!this.sendNewPolls) {\n            return;\n          }\n          const newScript = this.myIFrame.doc.createElement('script');\n          newScript.type = 'text/javascript';\n          newScript.async = true;\n          newScript.src = url;\n          // eslint-disable-next-line @typescript-eslint/no-explicit-any\n          newScript.onload = (newScript as any).onreadystatechange =\n            function () {\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              const rstate = (newScript as any).readyState;\n              if (!rstate || rstate === 'loaded' || rstate === 'complete') {\n                // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                newScript.onload = (newScript as any).onreadystatechange = null;\n                if (newScript.parentNode) {\n                  newScript.parentNode.removeChild(newScript);\n                }\n                loadCB();\n              }\n            };\n          newScript.onerror = () => {\n            log('Long-poll script failed to load: ' + url);\n            this.sendNewPolls = false;\n            this.close();\n          };\n          this.myIFrame.doc.body.appendChild(newScript);\n        } catch (e) {\n          // TODO: we should make this error visible somehow\n        }\n      }, Math.floor(1));\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert, isNodeSdk, jsonEval, stringify } from '@firebase/util';\n\nimport { RepoInfo, repoInfoConnectionURL } from '../core/RepoInfo';\nimport { StatsCollection } from '../core/stats/StatsCollection';\nimport { statsManagerGetCollection } from '../core/stats/StatsManager';\nimport { PersistentStorage } from '../core/storage/storage';\nimport { logWrapper, splitStringBySize } from '../core/util/util';\nimport { SDK_VERSION } from '../core/version';\n\nimport {\n  APPLICATION_ID_PARAM,\n  APP_CHECK_TOKEN_PARAM,\n  FORGE_DOMAIN_RE,\n  FORGE_REF,\n  LAST_SESSION_PARAM,\n  PROTOCOL_VERSION,\n  REFERER_PARAM,\n  TRANSPORT_SESSION_PARAM,\n  VERSION_PARAM,\n  WEBSOCKET\n} from './Constants';\nimport { Transport } from './Transport';\n\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\ndeclare const MozWebSocket: any;\n\nconst WEBSOCKET_MAX_FRAME_SIZE = 16384;\nconst WEBSOCKET_KEEPALIVE_INTERVAL = 45000;\n\nlet WebSocketImpl = null;\nif (typeof MozWebSocket !== 'undefined') {\n  WebSocketImpl = MozWebSocket;\n} else if (typeof WebSocket !== 'undefined') {\n  WebSocketImpl = WebSocket;\n}\n\nexport function setWebSocketImpl(impl) {\n  WebSocketImpl = impl;\n}\n\n/**\n * Create a new websocket connection with the given callbacks.\n */\nexport class WebSocketConnection implements Transport {\n  keepaliveTimer: number | null = null;\n  frames: string[] | null = null;\n  totalFrames = 0;\n  bytesSent = 0;\n  bytesReceived = 0;\n  connURL: string;\n  onDisconnect: (a?: boolean) => void;\n  onMessage: (msg: {}) => void;\n  mySock: WebSocket | null;\n  private log_: (...a: unknown[]) => void;\n  private stats_: StatsCollection;\n  private everConnected_: boolean;\n  private isClosed_: boolean;\n  private nodeAdmin: boolean;\n\n  /**\n   * @param connId identifier for this transport\n   * @param repoInfo The info for the websocket endpoint.\n   * @param applicationId The Firebase App ID for this project.\n   * @param appCheckToken The App Check Token for this client.\n   * @param authToken The Auth Token for this client.\n   * @param transportSessionId Optional transportSessionId if this is connecting\n   * to an existing transport session\n   * @param lastSessionId Optional lastSessionId if there was a previous\n   * connection\n   */\n  constructor(\n    public connId: string,\n    repoInfo: RepoInfo,\n    private applicationId?: string,\n    private appCheckToken?: string,\n    private authToken?: string,\n    transportSessionId?: string,\n    lastSessionId?: string\n  ) {\n    this.log_ = logWrapper(this.connId);\n    this.stats_ = statsManagerGetCollection(repoInfo);\n    this.connURL = WebSocketConnection.connectionURL_(\n      repoInfo,\n      transportSessionId,\n      lastSessionId,\n      appCheckToken,\n      applicationId\n    );\n    this.nodeAdmin = repoInfo.nodeAdmin;\n  }\n\n  /**\n   * @param repoInfo - The info for the websocket endpoint.\n   * @param transportSessionId - Optional transportSessionId if this is connecting to an existing transport\n   *                                         session\n   * @param lastSessionId - Optional lastSessionId if there was a previous connection\n   * @returns connection url\n   */\n  private static connectionURL_(\n    repoInfo: RepoInfo,\n    transportSessionId?: string,\n    lastSessionId?: string,\n    appCheckToken?: string,\n    applicationId?: string\n  ): string {\n    const urlParams: { [k: string]: string } = {};\n    urlParams[VERSION_PARAM] = PROTOCOL_VERSION;\n\n    if (\n      !isNodeSdk() &&\n      typeof location !== 'undefined' &&\n      location.hostname &&\n      FORGE_DOMAIN_RE.test(location.hostname)\n    ) {\n      urlParams[REFERER_PARAM] = FORGE_REF;\n    }\n    if (transportSessionId) {\n      urlParams[TRANSPORT_SESSION_PARAM] = transportSessionId;\n    }\n    if (lastSessionId) {\n      urlParams[LAST_SESSION_PARAM] = lastSessionId;\n    }\n    if (appCheckToken) {\n      urlParams[APP_CHECK_TOKEN_PARAM] = appCheckToken;\n    }\n    if (applicationId) {\n      urlParams[APPLICATION_ID_PARAM] = applicationId;\n    }\n\n    return repoInfoConnectionURL(repoInfo, WEBSOCKET, urlParams);\n  }\n\n  /**\n   * @param onMessage - Callback when messages arrive\n   * @param onDisconnect - Callback with connection lost.\n   */\n  open(onMessage: (msg: {}) => void, onDisconnect: (a?: boolean) => void) {\n    this.onDisconnect = onDisconnect;\n    this.onMessage = onMessage;\n\n    this.log_('Websocket connecting to ' + this.connURL);\n\n    this.everConnected_ = false;\n    // Assume failure until proven otherwise.\n    PersistentStorage.set('previous_websocket_failure', true);\n\n    try {\n      let options: { [k: string]: object };\n      if (isNodeSdk()) {\n        const device = this.nodeAdmin ? 'AdminNode' : 'Node';\n        // UA Format: Firebase/<wire_protocol>/<sdk_version>/<platform>/<device>\n        options = {\n          headers: {\n            'User-Agent': `Firebase/${PROTOCOL_VERSION}/${SDK_VERSION}/${process.platform}/${device}`,\n            'X-Firebase-GMPID': this.applicationId || ''\n          }\n        };\n\n        // If using Node with admin creds, AppCheck-related checks are unnecessary.\n        // Note that we send the credentials here even if they aren't admin credentials, which is\n        // not a problem.\n        // Note that this header is just used to bypass appcheck, and the token should still be sent\n        // through the websocket connection once it is established.\n        if (this.authToken) {\n          options.headers['Authorization'] = `Bearer ${this.authToken}`;\n        }\n        if (this.appCheckToken) {\n          options.headers['X-Firebase-AppCheck'] = this.appCheckToken;\n        }\n\n        // Plumb appropriate http_proxy environment variable into faye-websocket if it exists.\n        const env = process['env'];\n        const proxy =\n          this.connURL.indexOf('wss://') === 0\n            ? env['HTTPS_PROXY'] || env['https_proxy']\n            : env['HTTP_PROXY'] || env['http_proxy'];\n\n        if (proxy) {\n          options['proxy'] = { origin: proxy };\n        }\n      }\n      this.mySock = new WebSocketImpl(this.connURL, [], options);\n    } catch (e) {\n      this.log_('Error instantiating WebSocket.');\n      const error = e.message || e.data;\n      if (error) {\n        this.log_(error);\n      }\n      this.onClosed_();\n      return;\n    }\n\n    this.mySock.onopen = () => {\n      this.log_('Websocket connected.');\n      this.everConnected_ = true;\n    };\n\n    this.mySock.onclose = () => {\n      this.log_('Websocket connection was disconnected.');\n      this.mySock = null;\n      this.onClosed_();\n    };\n\n    this.mySock.onmessage = m => {\n      this.handleIncomingFrame(m as {});\n    };\n\n    this.mySock.onerror = e => {\n      this.log_('WebSocket error.  Closing connection.');\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      const error = (e as any).message || (e as any).data;\n      if (error) {\n        this.log_(error);\n      }\n      this.onClosed_();\n    };\n  }\n\n  /**\n   * No-op for websockets, we don't need to do anything once the connection is confirmed as open\n   */\n  start() {}\n\n  static forceDisallow_: boolean;\n\n  static forceDisallow() {\n    WebSocketConnection.forceDisallow_ = true;\n  }\n\n  static isAvailable(): boolean {\n    let isOldAndroid = false;\n    if (typeof navigator !== 'undefined' && navigator.userAgent) {\n      const oldAndroidRegex = /Android ([0-9]{0,}\\.[0-9]{0,})/;\n      const oldAndroidMatch = navigator.userAgent.match(oldAndroidRegex);\n      if (oldAndroidMatch && oldAndroidMatch.length > 1) {\n        if (parseFloat(oldAndroidMatch[1]) < 4.4) {\n          isOldAndroid = true;\n        }\n      }\n    }\n\n    return (\n      !isOldAndroid &&\n      WebSocketImpl !== null &&\n      !WebSocketConnection.forceDisallow_\n    );\n  }\n\n  /**\n   * Number of response before we consider the connection \"healthy.\"\n   */\n  static responsesRequiredToBeHealthy = 2;\n\n  /**\n   * Time to wait for the connection te become healthy before giving up.\n   */\n  static healthyTimeout = 30000;\n\n  /**\n   * Returns true if we previously failed to connect with this transport.\n   */\n  static previouslyFailed(): boolean {\n    // If our persistent storage is actually only in-memory storage,\n    // we default to assuming that it previously failed to be safe.\n    return (\n      PersistentStorage.isInMemoryStorage ||\n      PersistentStorage.get('previous_websocket_failure') === true\n    );\n  }\n\n  markConnectionHealthy() {\n    PersistentStorage.remove('previous_websocket_failure');\n  }\n\n  private appendFrame_(data: string) {\n    this.frames.push(data);\n    if (this.frames.length === this.totalFrames) {\n      const fullMess = this.frames.join('');\n      this.frames = null;\n      const jsonMess = jsonEval(fullMess) as object;\n\n      //handle the message\n      this.onMessage(jsonMess);\n    }\n  }\n\n  /**\n   * @param frameCount - The number of frames we are expecting from the server\n   */\n  private handleNewFrameCount_(frameCount: number) {\n    this.totalFrames = frameCount;\n    this.frames = [];\n  }\n\n  /**\n   * Attempts to parse a frame count out of some text. If it can't, assumes a value of 1\n   * @returns Any remaining data to be process, or null if there is none\n   */\n  private extractFrameCount_(data: string): string | null {\n    assert(this.frames === null, 'We already have a frame buffer');\n    // TODO: The server is only supposed to send up to 9999 frames (i.e. length <= 4), but that isn't being enforced\n    // currently.  So allowing larger frame counts (length <= 6).  See https://app.asana.com/0/search/8688598998380/8237608042508\n    if (data.length <= 6) {\n      const frameCount = Number(data);\n      if (!isNaN(frameCount)) {\n        this.handleNewFrameCount_(frameCount);\n        return null;\n      }\n    }\n    this.handleNewFrameCount_(1);\n    return data;\n  }\n\n  /**\n   * Process a websocket frame that has arrived from the server.\n   * @param mess - The frame data\n   */\n  handleIncomingFrame(mess: { [k: string]: unknown }) {\n    if (this.mySock === null) {\n      return; // Chrome apparently delivers incoming packets even after we .close() the connection sometimes.\n    }\n    const data = mess['data'] as string;\n    this.bytesReceived += data.length;\n    this.stats_.incrementCounter('bytes_received', data.length);\n\n    this.resetKeepAlive();\n\n    if (this.frames !== null) {\n      // we're buffering\n      this.appendFrame_(data);\n    } else {\n      // try to parse out a frame count, otherwise, assume 1 and process it\n      const remainingData = this.extractFrameCount_(data);\n      if (remainingData !== null) {\n        this.appendFrame_(remainingData);\n      }\n    }\n  }\n\n  /**\n   * Send a message to the server\n   * @param data - The JSON object to transmit\n   */\n  send(data: {}) {\n    this.resetKeepAlive();\n\n    const dataStr = stringify(data);\n    this.bytesSent += dataStr.length;\n    this.stats_.incrementCounter('bytes_sent', dataStr.length);\n\n    //We can only fit a certain amount in each websocket frame, so we need to split this request\n    //up into multiple pieces if it doesn't fit in one request.\n\n    const dataSegs = splitStringBySize(dataStr, WEBSOCKET_MAX_FRAME_SIZE);\n\n    //Send the length header\n    if (dataSegs.length > 1) {\n      this.sendString_(String(dataSegs.length));\n    }\n\n    //Send the actual data in segments.\n    for (let i = 0; i < dataSegs.length; i++) {\n      this.sendString_(dataSegs[i]);\n    }\n  }\n\n  private shutdown_() {\n    this.isClosed_ = true;\n    if (this.keepaliveTimer) {\n      clearInterval(this.keepaliveTimer);\n      this.keepaliveTimer = null;\n    }\n\n    if (this.mySock) {\n      this.mySock.close();\n      this.mySock = null;\n    }\n  }\n\n  private onClosed_() {\n    if (!this.isClosed_) {\n      this.log_('WebSocket is closing itself');\n      this.shutdown_();\n\n      // since this is an internal close, trigger the close listener\n      if (this.onDisconnect) {\n        this.onDisconnect(this.everConnected_);\n        this.onDisconnect = null;\n      }\n    }\n  }\n\n  /**\n   * External-facing close handler.\n   * Close the websocket and kill the connection.\n   */\n  close() {\n    if (!this.isClosed_) {\n      this.log_('WebSocket is being closed');\n      this.shutdown_();\n    }\n  }\n\n  /**\n   * Kill the current keepalive timer and start a new one, to ensure that it always fires N seconds after\n   * the last activity.\n   */\n  resetKeepAlive() {\n    clearInterval(this.keepaliveTimer);\n    this.keepaliveTimer = setInterval(() => {\n      //If there has been no websocket activity for a while, send a no-op\n      if (this.mySock) {\n        this.sendString_('0');\n      }\n      this.resetKeepAlive();\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    }, Math.floor(WEBSOCKET_KEEPALIVE_INTERVAL)) as any;\n  }\n\n  /**\n   * Send a string over the websocket.\n   *\n   * @param str - String to send.\n   */\n  private sendString_(str: string) {\n    // Firefox seems to sometimes throw exceptions (NS_ERROR_UNEXPECTED) from websocket .send()\n    // calls for some unknown reason.  We treat these as an error and disconnect.\n    // See https://app.asana.com/0/58926111402292/68021340250410\n    try {\n      this.mySock.send(str);\n    } catch (e) {\n      this.log_(\n        'Exception thrown from WebSocket.send():',\n        e.message || e.data,\n        'Closing connection.'\n      );\n      setTimeout(this.onClosed_.bind(this), 0);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { RepoInfo } from '../core/RepoInfo';\nimport { warn } from '../core/util/util';\n\nimport { BrowserPollConnection } from './BrowserPollConnection';\nimport { TransportConstructor } from './Transport';\nimport { WebSocketConnection } from './WebSocketConnection';\n\n/**\n * Currently simplistic, this class manages what transport a Connection should use at various stages of its\n * lifecycle.\n *\n * It starts with longpolling in a browser, and httppolling on node. It then upgrades to websockets if\n * they are available.\n */\nexport class TransportManager {\n  private transports_: TransportConstructor[];\n\n  // Keeps track of whether the TransportManager has already chosen a transport to use\n  static globalTransportInitialized_ = false;\n\n  static get ALL_TRANSPORTS() {\n    return [BrowserPollConnection, WebSocketConnection];\n  }\n\n  /**\n   * Returns whether transport has been selected to ensure WebSocketConnection or BrowserPollConnection are not called after\n   * TransportManager has already set up transports_\n   */\n  static get IS_TRANSPORT_INITIALIZED() {\n    return this.globalTransportInitialized_;\n  }\n\n  /**\n   * @param repoInfo - Metadata around the namespace we're connecting to\n   */\n  constructor(repoInfo: RepoInfo) {\n    this.initTransports_(repoInfo);\n  }\n\n  private initTransports_(repoInfo: RepoInfo) {\n    const isWebSocketsAvailable: boolean =\n      WebSocketConnection && WebSocketConnection['isAvailable']();\n    let isSkipPollConnection =\n      isWebSocketsAvailable && !WebSocketConnection.previouslyFailed();\n\n    if (repoInfo.webSocketOnly) {\n      if (!isWebSocketsAvailable) {\n        warn(\n          \"wss:// URL used, but browser isn't known to support websockets.  Trying anyway.\"\n        );\n      }\n\n      isSkipPollConnection = true;\n    }\n\n    if (isSkipPollConnection) {\n      this.transports_ = [WebSocketConnection];\n    } else {\n      const transports = (this.transports_ = [] as TransportConstructor[]);\n      for (const transport of TransportManager.ALL_TRANSPORTS) {\n        if (transport && transport['isAvailable']()) {\n          transports.push(transport);\n        }\n      }\n      TransportManager.globalTransportInitialized_ = true;\n    }\n  }\n\n  /**\n   * @returns The constructor for the initial transport to use\n   */\n  initialTransport(): TransportConstructor {\n    if (this.transports_.length > 0) {\n      return this.transports_[0];\n    } else {\n      throw new Error('No transports available');\n    }\n  }\n\n  /**\n   * @returns The constructor for the next transport, or null\n   */\n  upgradeTransport(): TransportConstructor | null {\n    if (this.transports_.length > 1) {\n      return this.transports_[1];\n    } else {\n      return null;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { RepoInfo } from '../core/RepoInfo';\nimport { PersistentStorage } from '../core/storage/storage';\nimport { Indexable } from '../core/util/misc';\nimport {\n  error,\n  logWrapper,\n  requireKey,\n  setTimeoutNonBlocking,\n  warn\n} from '../core/util/util';\n\nimport { PROTOCOL_VERSION } from './Constants';\nimport { Transport, TransportConstructor } from './Transport';\nimport { TransportManager } from './TransportManager';\n\n// Abort upgrade attempt if it takes longer than 60s.\nconst UPGRADE_TIMEOUT = 60000;\n\n// For some transports (WebSockets), we need to \"validate\" the transport by exchanging a few requests and responses.\n// If we haven't sent enough requests within 5s, we'll start sending noop ping requests.\nconst DELAY_BEFORE_SENDING_EXTRA_REQUESTS = 5000;\n\n// If the initial data sent triggers a lot of bandwidth (i.e. it's a large put or a listen for a large amount of data)\n// then we may not be able to exchange our ping/pong requests within the healthy timeout.  So if we reach the timeout\n// but we've sent/received enough bytes, we don't cancel the connection.\nconst BYTES_SENT_HEALTHY_OVERRIDE = 10 * 1024;\nconst BYTES_RECEIVED_HEALTHY_OVERRIDE = 100 * 1024;\n\nconst enum RealtimeState {\n  CONNECTING,\n  CONNECTED,\n  DISCONNECTED\n}\n\nconst MESSAGE_TYPE = 't';\nconst MESSAGE_DATA = 'd';\nconst CONTROL_SHUTDOWN = 's';\nconst CONTROL_RESET = 'r';\nconst CONTROL_ERROR = 'e';\nconst CONTROL_PONG = 'o';\nconst SWITCH_ACK = 'a';\nconst END_TRANSMISSION = 'n';\nconst PING = 'p';\n\nconst SERVER_HELLO = 'h';\n\n/**\n * Creates a new real-time connection to the server using whichever method works\n * best in the current browser.\n */\nexport class Connection {\n  connectionCount = 0;\n  pendingDataMessages: unknown[] = [];\n  sessionId: string;\n\n  private conn_: Transport;\n  private healthyTimeout_: number;\n  private isHealthy_: boolean;\n  private log_: (...args: unknown[]) => void;\n  private primaryResponsesRequired_: number;\n  private rx_: Transport;\n  private secondaryConn_: Transport;\n  private secondaryResponsesRequired_: number;\n  private state_ = RealtimeState.CONNECTING;\n  private transportManager_: TransportManager;\n  private tx_: Transport;\n\n  /**\n   * @param id - an id for this connection\n   * @param repoInfo_ - the info for the endpoint to connect to\n   * @param applicationId_ - the Firebase App ID for this project\n   * @param appCheckToken_ - The App Check Token for this device.\n   * @param authToken_ - The auth token for this session.\n   * @param onMessage_ - the callback to be triggered when a server-push message arrives\n   * @param onReady_ - the callback to be triggered when this connection is ready to send messages.\n   * @param onDisconnect_ - the callback to be triggered when a connection was lost\n   * @param onKill_ - the callback to be triggered when this connection has permanently shut down.\n   * @param lastSessionId - last session id in persistent connection. is used to clean up old session in real-time server\n   */\n  constructor(\n    public id: string,\n    private repoInfo_: RepoInfo,\n    private applicationId_: string | undefined,\n    private appCheckToken_: string | undefined,\n    private authToken_: string | undefined,\n    private onMessage_: (a: {}) => void,\n    private onReady_: (a: number, b: string) => void,\n    private onDisconnect_: () => void,\n    private onKill_: (a: string) => void,\n    public lastSessionId?: string\n  ) {\n    this.log_ = logWrapper('c:' + this.id + ':');\n    this.transportManager_ = new TransportManager(repoInfo_);\n    this.log_('Connection created');\n    this.start_();\n  }\n\n  /**\n   * Starts a connection attempt\n   */\n  private start_(): void {\n    const conn = this.transportManager_.initialTransport();\n    this.conn_ = new conn(\n      this.nextTransportId_(),\n      this.repoInfo_,\n      this.applicationId_,\n      this.appCheckToken_,\n      this.authToken_,\n      null,\n      this.lastSessionId\n    );\n\n    // For certain transports (WebSockets), we need to send and receive several messages back and forth before we\n    // can consider the transport healthy.\n    this.primaryResponsesRequired_ = conn['responsesRequiredToBeHealthy'] || 0;\n\n    const onMessageReceived = this.connReceiver_(this.conn_);\n    const onConnectionLost = this.disconnReceiver_(this.conn_);\n    this.tx_ = this.conn_;\n    this.rx_ = this.conn_;\n    this.secondaryConn_ = null;\n    this.isHealthy_ = false;\n\n    /*\n     * Firefox doesn't like when code from one iframe tries to create another iframe by way of the parent frame.\n     * This can occur in the case of a redirect, i.e. we guessed wrong on what server to connect to and received a reset.\n     * Somehow, setTimeout seems to make this ok. That doesn't make sense from a security perspective, since you should\n     * still have the context of your originating frame.\n     */\n    setTimeout(() => {\n      // this.conn_ gets set to null in some of the tests. Check to make sure it still exists before using it\n      this.conn_ && this.conn_.open(onMessageReceived, onConnectionLost);\n    }, Math.floor(0));\n\n    const healthyTimeoutMS = conn['healthyTimeout'] || 0;\n    if (healthyTimeoutMS > 0) {\n      this.healthyTimeout_ = setTimeoutNonBlocking(() => {\n        this.healthyTimeout_ = null;\n        if (!this.isHealthy_) {\n          if (\n            this.conn_ &&\n            this.conn_.bytesReceived > BYTES_RECEIVED_HEALTHY_OVERRIDE\n          ) {\n            this.log_(\n              'Connection exceeded healthy timeout but has received ' +\n                this.conn_.bytesReceived +\n                ' bytes.  Marking connection healthy.'\n            );\n            this.isHealthy_ = true;\n            this.conn_.markConnectionHealthy();\n          } else if (\n            this.conn_ &&\n            this.conn_.bytesSent > BYTES_SENT_HEALTHY_OVERRIDE\n          ) {\n            this.log_(\n              'Connection exceeded healthy timeout but has sent ' +\n                this.conn_.bytesSent +\n                ' bytes.  Leaving connection alive.'\n            );\n            // NOTE: We don't want to mark it healthy, since we have no guarantee that the bytes have made it to\n            // the server.\n          } else {\n            this.log_('Closing unhealthy connection after timeout.');\n            this.close();\n          }\n        }\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      }, Math.floor(healthyTimeoutMS)) as any;\n    }\n  }\n\n  private nextTransportId_(): string {\n    return 'c:' + this.id + ':' + this.connectionCount++;\n  }\n\n  private disconnReceiver_(conn) {\n    return everConnected => {\n      if (conn === this.conn_) {\n        this.onConnectionLost_(everConnected);\n      } else if (conn === this.secondaryConn_) {\n        this.log_('Secondary connection lost.');\n        this.onSecondaryConnectionLost_();\n      } else {\n        this.log_('closing an old connection');\n      }\n    };\n  }\n\n  private connReceiver_(conn: Transport) {\n    return (message: Indexable) => {\n      if (this.state_ !== RealtimeState.DISCONNECTED) {\n        if (conn === this.rx_) {\n          this.onPrimaryMessageReceived_(message);\n        } else if (conn === this.secondaryConn_) {\n          this.onSecondaryMessageReceived_(message);\n        } else {\n          this.log_('message on old connection');\n        }\n      }\n    };\n  }\n\n  /**\n   * @param dataMsg - An arbitrary data message to be sent to the server\n   */\n  sendRequest(dataMsg: object) {\n    // wrap in a data message envelope and send it on\n    const msg = { t: 'd', d: dataMsg };\n    this.sendData_(msg);\n  }\n\n  tryCleanupConnection() {\n    if (this.tx_ === this.secondaryConn_ && this.rx_ === this.secondaryConn_) {\n      this.log_(\n        'cleaning up and promoting a connection: ' + this.secondaryConn_.connId\n      );\n      this.conn_ = this.secondaryConn_;\n      this.secondaryConn_ = null;\n      // the server will shutdown the old connection\n    }\n  }\n\n  private onSecondaryControl_(controlData: { [k: string]: unknown }) {\n    if (MESSAGE_TYPE in controlData) {\n      const cmd = controlData[MESSAGE_TYPE] as string;\n      if (cmd === SWITCH_ACK) {\n        this.upgradeIfSecondaryHealthy_();\n      } else if (cmd === CONTROL_RESET) {\n        // Most likely the session wasn't valid. Abandon the switch attempt\n        this.log_('Got a reset on secondary, closing it');\n        this.secondaryConn_.close();\n        // If we were already using this connection for something, than we need to fully close\n        if (\n          this.tx_ === this.secondaryConn_ ||\n          this.rx_ === this.secondaryConn_\n        ) {\n          this.close();\n        }\n      } else if (cmd === CONTROL_PONG) {\n        this.log_('got pong on secondary.');\n        this.secondaryResponsesRequired_--;\n        this.upgradeIfSecondaryHealthy_();\n      }\n    }\n  }\n\n  private onSecondaryMessageReceived_(parsedData: Indexable) {\n    const layer: string = requireKey('t', parsedData) as string;\n    const data: unknown = requireKey('d', parsedData);\n    if (layer === 'c') {\n      this.onSecondaryControl_(data as Indexable);\n    } else if (layer === 'd') {\n      // got a data message, but we're still second connection. Need to buffer it up\n      this.pendingDataMessages.push(data);\n    } else {\n      throw new Error('Unknown protocol layer: ' + layer);\n    }\n  }\n\n  private upgradeIfSecondaryHealthy_() {\n    if (this.secondaryResponsesRequired_ <= 0) {\n      this.log_('Secondary connection is healthy.');\n      this.isHealthy_ = true;\n      this.secondaryConn_.markConnectionHealthy();\n      this.proceedWithUpgrade_();\n    } else {\n      // Send a ping to make sure the connection is healthy.\n      this.log_('sending ping on secondary.');\n      this.secondaryConn_.send({ t: 'c', d: { t: PING, d: {} } });\n    }\n  }\n\n  private proceedWithUpgrade_() {\n    // tell this connection to consider itself open\n    this.secondaryConn_.start();\n    // send ack\n    this.log_('sending client ack on secondary');\n    this.secondaryConn_.send({ t: 'c', d: { t: SWITCH_ACK, d: {} } });\n\n    // send end packet on primary transport, switch to sending on this one\n    // can receive on this one, buffer responses until end received on primary transport\n    this.log_('Ending transmission on primary');\n    this.conn_.send({ t: 'c', d: { t: END_TRANSMISSION, d: {} } });\n    this.tx_ = this.secondaryConn_;\n\n    this.tryCleanupConnection();\n  }\n\n  private onPrimaryMessageReceived_(parsedData: { [k: string]: unknown }) {\n    // Must refer to parsedData properties in quotes, so closure doesn't touch them.\n    const layer: string = requireKey('t', parsedData) as string;\n    const data: unknown = requireKey('d', parsedData);\n    if (layer === 'c') {\n      this.onControl_(data as { [k: string]: unknown });\n    } else if (layer === 'd') {\n      this.onDataMessage_(data);\n    }\n  }\n\n  private onDataMessage_(message: unknown) {\n    this.onPrimaryResponse_();\n\n    // We don't do anything with data messages, just kick them up a level\n    this.onMessage_(message);\n  }\n\n  private onPrimaryResponse_() {\n    if (!this.isHealthy_) {\n      this.primaryResponsesRequired_--;\n      if (this.primaryResponsesRequired_ <= 0) {\n        this.log_('Primary connection is healthy.');\n        this.isHealthy_ = true;\n        this.conn_.markConnectionHealthy();\n      }\n    }\n  }\n\n  private onControl_(controlData: { [k: string]: unknown }) {\n    const cmd: string = requireKey(MESSAGE_TYPE, controlData) as string;\n    if (MESSAGE_DATA in controlData) {\n      const payload = controlData[MESSAGE_DATA];\n      if (cmd === SERVER_HELLO) {\n        const handshakePayload = {\n          ...(payload as {\n            ts: number;\n            v: string;\n            h: string;\n            s: string;\n          })\n        };\n        if (this.repoInfo_.isUsingEmulator) {\n          // Upon connecting, the emulator will pass the hostname that it's aware of, but we prefer the user's set hostname via `connectDatabaseEmulator` over what the emulator passes.\n          handshakePayload.h = this.repoInfo_.host;\n        }\n        this.onHandshake_(handshakePayload);\n      } else if (cmd === END_TRANSMISSION) {\n        this.log_('recvd end transmission on primary');\n        this.rx_ = this.secondaryConn_;\n        for (let i = 0; i < this.pendingDataMessages.length; ++i) {\n          this.onDataMessage_(this.pendingDataMessages[i]);\n        }\n        this.pendingDataMessages = [];\n        this.tryCleanupConnection();\n      } else if (cmd === CONTROL_SHUTDOWN) {\n        // This was previously the 'onKill' callback passed to the lower-level connection\n        // payload in this case is the reason for the shutdown. Generally a human-readable error\n        this.onConnectionShutdown_(payload as string);\n      } else if (cmd === CONTROL_RESET) {\n        // payload in this case is the host we should contact\n        this.onReset_(payload as string);\n      } else if (cmd === CONTROL_ERROR) {\n        error('Server Error: ' + payload);\n      } else if (cmd === CONTROL_PONG) {\n        this.log_('got pong on primary.');\n        this.onPrimaryResponse_();\n        this.sendPingOnPrimaryIfNecessary_();\n      } else {\n        error('Unknown control packet command: ' + cmd);\n      }\n    }\n  }\n\n  /**\n   * @param handshake - The handshake data returned from the server\n   */\n  private onHandshake_(handshake: {\n    ts: number;\n    v: string;\n    h: string;\n    s: string;\n  }): void {\n    const timestamp = handshake.ts;\n    const version = handshake.v;\n    const host = handshake.h;\n    this.sessionId = handshake.s;\n    this.repoInfo_.host = host;\n    // if we've already closed the connection, then don't bother trying to progress further\n    if (this.state_ === RealtimeState.CONNECTING) {\n      this.conn_.start();\n      this.onConnectionEstablished_(this.conn_, timestamp);\n      if (PROTOCOL_VERSION !== version) {\n        warn('Protocol version mismatch detected');\n      }\n      // TODO: do we want to upgrade? when? maybe a delay?\n      this.tryStartUpgrade_();\n    }\n  }\n\n  private tryStartUpgrade_() {\n    const conn = this.transportManager_.upgradeTransport();\n    if (conn) {\n      this.startUpgrade_(conn);\n    }\n  }\n\n  private startUpgrade_(conn: TransportConstructor) {\n    this.secondaryConn_ = new conn(\n      this.nextTransportId_(),\n      this.repoInfo_,\n      this.applicationId_,\n      this.appCheckToken_,\n      this.authToken_,\n      this.sessionId\n    );\n    // For certain transports (WebSockets), we need to send and receive several messages back and forth before we\n    // can consider the transport healthy.\n    this.secondaryResponsesRequired_ =\n      conn['responsesRequiredToBeHealthy'] || 0;\n\n    const onMessage = this.connReceiver_(this.secondaryConn_);\n    const onDisconnect = this.disconnReceiver_(this.secondaryConn_);\n    this.secondaryConn_.open(onMessage, onDisconnect);\n\n    // If we haven't successfully upgraded after UPGRADE_TIMEOUT, give up and kill the secondary.\n    setTimeoutNonBlocking(() => {\n      if (this.secondaryConn_) {\n        this.log_('Timed out trying to upgrade.');\n        this.secondaryConn_.close();\n      }\n    }, Math.floor(UPGRADE_TIMEOUT));\n  }\n\n  private onReset_(host: string) {\n    this.log_('Reset packet received.  New host: ' + host);\n    this.repoInfo_.host = host;\n    // TODO: if we're already \"connected\", we need to trigger a disconnect at the next layer up.\n    // We don't currently support resets after the connection has already been established\n    if (this.state_ === RealtimeState.CONNECTED) {\n      this.close();\n    } else {\n      // Close whatever connections we have open and start again.\n      this.closeConnections_();\n      this.start_();\n    }\n  }\n\n  private onConnectionEstablished_(conn: Transport, timestamp: number) {\n    this.log_('Realtime connection established.');\n    this.conn_ = conn;\n    this.state_ = RealtimeState.CONNECTED;\n\n    if (this.onReady_) {\n      this.onReady_(timestamp, this.sessionId);\n      this.onReady_ = null;\n    }\n\n    // If after 5 seconds we haven't sent enough requests to the server to get the connection healthy,\n    // send some pings.\n    if (this.primaryResponsesRequired_ === 0) {\n      this.log_('Primary connection is healthy.');\n      this.isHealthy_ = true;\n    } else {\n      setTimeoutNonBlocking(() => {\n        this.sendPingOnPrimaryIfNecessary_();\n      }, Math.floor(DELAY_BEFORE_SENDING_EXTRA_REQUESTS));\n    }\n  }\n\n  private sendPingOnPrimaryIfNecessary_() {\n    // If the connection isn't considered healthy yet, we'll send a noop ping packet request.\n    if (!this.isHealthy_ && this.state_ === RealtimeState.CONNECTED) {\n      this.log_('sending ping on primary.');\n      this.sendData_({ t: 'c', d: { t: PING, d: {} } });\n    }\n  }\n\n  private onSecondaryConnectionLost_() {\n    const conn = this.secondaryConn_;\n    this.secondaryConn_ = null;\n    if (this.tx_ === conn || this.rx_ === conn) {\n      // we are relying on this connection already in some capacity. Therefore, a failure is real\n      this.close();\n    }\n  }\n\n  /**\n   * @param everConnected - Whether or not the connection ever reached a server. Used to determine if\n   * we should flush the host cache\n   */\n  private onConnectionLost_(everConnected: boolean) {\n    this.conn_ = null;\n\n    // NOTE: IF you're seeing a Firefox error for this line, I think it might be because it's getting\n    // called on window close and RealtimeState.CONNECTING is no longer defined.  Just a guess.\n    if (!everConnected && this.state_ === RealtimeState.CONNECTING) {\n      this.log_('Realtime connection failed.');\n      // Since we failed to connect at all, clear any cached entry for this namespace in case the machine went away\n      if (this.repoInfo_.isCacheableHost()) {\n        PersistentStorage.remove('host:' + this.repoInfo_.host);\n        // reset the internal host to what we would show the user, i.e. <ns>.firebaseio.com\n        this.repoInfo_.internalHost = this.repoInfo_.host;\n      }\n    } else if (this.state_ === RealtimeState.CONNECTED) {\n      this.log_('Realtime connection lost.');\n    }\n\n    this.close();\n  }\n\n  private onConnectionShutdown_(reason: string) {\n    this.log_('Connection shutdown command received. Shutting down...');\n\n    if (this.onKill_) {\n      this.onKill_(reason);\n      this.onKill_ = null;\n    }\n\n    // We intentionally don't want to fire onDisconnect (kill is a different case),\n    // so clear the callback.\n    this.onDisconnect_ = null;\n\n    this.close();\n  }\n\n  private sendData_(data: object) {\n    if (this.state_ !== RealtimeState.CONNECTED) {\n      throw 'Connection is not connected';\n    } else {\n      this.tx_.send(data);\n    }\n  }\n\n  /**\n   * Cleans up this connection, calling the appropriate callbacks\n   */\n  close() {\n    if (this.state_ !== RealtimeState.DISCONNECTED) {\n      this.log_('Closing realtime connection.');\n      this.state_ = RealtimeState.DISCONNECTED;\n\n      this.closeConnections_();\n\n      if (this.onDisconnect_) {\n        this.onDisconnect_();\n        this.onDisconnect_ = null;\n      }\n    }\n  }\n\n  private closeConnections_() {\n    this.log_('Shutting down all connections');\n    if (this.conn_) {\n      this.conn_.close();\n      this.conn_ = null;\n    }\n\n    if (this.secondaryConn_) {\n      this.secondaryConn_.close();\n      this.secondaryConn_ = null;\n    }\n\n    if (this.healthyTimeout_) {\n      clearTimeout(this.healthyTimeout_);\n      this.healthyTimeout_ = null;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { QueryContext } from './view/EventRegistration';\n\n/**\n * Interface defining the set of actions that can be performed against the Firebase server\n * (basically corresponds to our wire protocol).\n *\n * @interface\n */\nexport abstract class ServerActions {\n  abstract listen(\n    query: QueryContext,\n    currentHashFn: () => string,\n    tag: number | null,\n    onComplete: (a: string, b: unknown) => void\n  ): void;\n\n  /**\n   * Remove a listen.\n   */\n  abstract unlisten(query: QueryContext, tag: number | null): void;\n\n  /**\n   * Get the server value satisfying this query.\n   */\n  abstract get(query: QueryContext): Promise<string>;\n\n  put(\n    pathString: string,\n    data: unknown,\n    onComplete?: (a: string, b: string) => void,\n    hash?: string\n  ) {}\n\n  merge(\n    pathString: string,\n    data: unknown,\n    onComplete: (a: string, b: string | null) => void,\n    hash?: string\n  ) {}\n\n  /**\n   * Refreshes the auth token for the current connection.\n   * @param token - The authentication token\n   */\n  refreshAuthToken(token: string) {}\n\n  /**\n   * Refreshes the app check token for the current connection.\n   * @param token The app check token\n   */\n  refreshAppCheckToken(token: string) {}\n\n  onDisconnectPut(\n    pathString: string,\n    data: unknown,\n    onComplete?: (a: string, b: string) => void\n  ) {}\n\n  onDisconnectMerge(\n    pathString: string,\n    data: unknown,\n    onComplete?: (a: string, b: string) => void\n  ) {}\n\n  onDisconnectCancel(\n    pathString: string,\n    onComplete?: (a: string, b: string) => void\n  ) {}\n\n  reportStats(stats: { [k: string]: unknown }) {}\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\n/**\n * Base class to be used if you want to emit events. Call the constructor with\n * the set of allowed event names.\n */\nexport abstract class EventEmitter {\n  private listeners_: {\n    [eventType: string]: Array<{\n      callback(...args: unknown[]): void;\n      context: unknown;\n    }>;\n  } = {};\n\n  constructor(private allowedEvents_: string[]) {\n    assert(\n      Array.isArray(allowedEvents_) && allowedEvents_.length > 0,\n      'Requires a non-empty array'\n    );\n  }\n\n  /**\n   * To be overridden by derived classes in order to fire an initial event when\n   * somebody subscribes for data.\n   *\n   * @returns {Array.<*>} Array of parameters to trigger initial event with.\n   */\n  abstract getInitialEvent(eventType: string): unknown[];\n\n  /**\n   * To be called by derived classes to trigger events.\n   */\n  protected trigger(eventType: string, ...varArgs: unknown[]) {\n    if (Array.isArray(this.listeners_[eventType])) {\n      // Clone the list, since callbacks could add/remove listeners.\n      const listeners = [...this.listeners_[eventType]];\n\n      for (let i = 0; i < listeners.length; i++) {\n        listeners[i].callback.apply(listeners[i].context, varArgs);\n      }\n    }\n  }\n\n  on(eventType: string, callback: (a: unknown) => void, context: unknown) {\n    this.validateEventType_(eventType);\n    this.listeners_[eventType] = this.listeners_[eventType] || [];\n    this.listeners_[eventType].push({ callback, context });\n\n    const eventData = this.getInitialEvent(eventType);\n    if (eventData) {\n      callback.apply(context, eventData);\n    }\n  }\n\n  off(eventType: string, callback: (a: unknown) => void, context: unknown) {\n    this.validateEventType_(eventType);\n    const listeners = this.listeners_[eventType] || [];\n    for (let i = 0; i < listeners.length; i++) {\n      if (\n        listeners[i].callback === callback &&\n        (!context || context === listeners[i].context)\n      ) {\n        listeners.splice(i, 1);\n        return;\n      }\n    }\n  }\n\n  private validateEventType_(eventType: string) {\n    assert(\n      this.allowedEvents_.find(et => {\n        return et === eventType;\n      }),\n      'Unknown event: ' + eventType\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert, isMobileCordova } from '@firebase/util';\n\nimport { EventEmitter } from './EventEmitter';\n\n/**\n * Monitors online state (as reported by window.online/offline events).\n *\n * The expectation is that this could have many false positives (thinks we are online\n * when we're not), but no false negatives.  So we can safely use it to determine when\n * we definitely cannot reach the internet.\n */\nexport class OnlineMonitor extends EventEmitter {\n  private online_ = true;\n\n  static getInstance() {\n    return new OnlineMonitor();\n  }\n\n  constructor() {\n    super(['online']);\n\n    // We've had repeated complaints that Cordova apps can get stuck \"offline\", e.g.\n    // https://forum.ionicframework.com/t/firebase-connection-is-lost-and-never-come-back/43810\n    // It would seem that the 'online' event does not always fire consistently. So we disable it\n    // for Cordova.\n    if (\n      typeof window !== 'undefined' &&\n      typeof window.addEventListener !== 'undefined' &&\n      !isMobileCordova()\n    ) {\n      window.addEventListener(\n        'online',\n        () => {\n          if (!this.online_) {\n            this.online_ = true;\n            this.trigger('online', true);\n          }\n        },\n        false\n      );\n\n      window.addEventListener(\n        'offline',\n        () => {\n          if (this.online_) {\n            this.online_ = false;\n            this.trigger('online', false);\n          }\n        },\n        false\n      );\n    }\n  }\n\n  getInitialEvent(eventType: string): boolean[] {\n    assert(eventType === 'online', 'Unknown event type: ' + eventType);\n    return [this.online_];\n  }\n\n  currentlyOnline(): boolean {\n    return this.online_;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { stringLength } from '@firebase/util';\n\nimport { nameCompare } from './util';\n\n/** Maximum key depth. */\nconst MAX_PATH_DEPTH = 32;\n\n/** Maximum number of (UTF8) bytes in a Firebase path. */\nconst MAX_PATH_LENGTH_BYTES = 768;\n\n/**\n * An immutable object representing a parsed path.  It's immutable so that you\n * can pass them around to other functions without worrying about them changing\n * it.\n */\n\nexport class Path {\n  pieces_: string[];\n  pieceNum_: number;\n\n  /**\n   * @param pathOrString - Path string to parse, or another path, or the raw\n   * tokens array\n   */\n  constructor(pathOrString: string | string[], pieceNum?: number) {\n    if (pieceNum === void 0) {\n      this.pieces_ = (pathOrString as string).split('/');\n\n      // Remove empty pieces.\n      let copyTo = 0;\n      for (let i = 0; i < this.pieces_.length; i++) {\n        if (this.pieces_[i].length > 0) {\n          this.pieces_[copyTo] = this.pieces_[i];\n          copyTo++;\n        }\n      }\n      this.pieces_.length = copyTo;\n\n      this.pieceNum_ = 0;\n    } else {\n      this.pieces_ = pathOrString as string[];\n      this.pieceNum_ = pieceNum;\n    }\n  }\n\n  toString(): string {\n    let pathString = '';\n    for (let i = this.pieceNum_; i < this.pieces_.length; i++) {\n      if (this.pieces_[i] !== '') {\n        pathString += '/' + this.pieces_[i];\n      }\n    }\n\n    return pathString || '/';\n  }\n}\n\nexport function newEmptyPath(): Path {\n  return new Path('');\n}\n\nexport function pathGetFront(path: Path): string | null {\n  if (path.pieceNum_ >= path.pieces_.length) {\n    return null;\n  }\n\n  return path.pieces_[path.pieceNum_];\n}\n\n/**\n * @returns The number of segments in this path\n */\nexport function pathGetLength(path: Path): number {\n  return path.pieces_.length - path.pieceNum_;\n}\n\nexport function pathPopFront(path: Path): Path {\n  let pieceNum = path.pieceNum_;\n  if (pieceNum < path.pieces_.length) {\n    pieceNum++;\n  }\n  return new Path(path.pieces_, pieceNum);\n}\n\nexport function pathGetBack(path: Path): string | null {\n  if (path.pieceNum_ < path.pieces_.length) {\n    return path.pieces_[path.pieces_.length - 1];\n  }\n\n  return null;\n}\n\nexport function pathToUrlEncodedString(path: Path): string {\n  let pathString = '';\n  for (let i = path.pieceNum_; i < path.pieces_.length; i++) {\n    if (path.pieces_[i] !== '') {\n      pathString += '/' + encodeURIComponent(String(path.pieces_[i]));\n    }\n  }\n\n  return pathString || '/';\n}\n\n/**\n * Shallow copy of the parts of the path.\n *\n */\nexport function pathSlice(path: Path, begin: number = 0): string[] {\n  return path.pieces_.slice(path.pieceNum_ + begin);\n}\n\nexport function pathParent(path: Path): Path | null {\n  if (path.pieceNum_ >= path.pieces_.length) {\n    return null;\n  }\n\n  const pieces = [];\n  for (let i = path.pieceNum_; i < path.pieces_.length - 1; i++) {\n    pieces.push(path.pieces_[i]);\n  }\n\n  return new Path(pieces, 0);\n}\n\nexport function pathChild(path: Path, childPathObj: string | Path): Path {\n  const pieces = [];\n  for (let i = path.pieceNum_; i < path.pieces_.length; i++) {\n    pieces.push(path.pieces_[i]);\n  }\n\n  if (childPathObj instanceof Path) {\n    for (let i = childPathObj.pieceNum_; i < childPathObj.pieces_.length; i++) {\n      pieces.push(childPathObj.pieces_[i]);\n    }\n  } else {\n    const childPieces = childPathObj.split('/');\n    for (let i = 0; i < childPieces.length; i++) {\n      if (childPieces[i].length > 0) {\n        pieces.push(childPieces[i]);\n      }\n    }\n  }\n\n  return new Path(pieces, 0);\n}\n\n/**\n * @returns True if there are no segments in this path\n */\nexport function pathIsEmpty(path: Path): boolean {\n  return path.pieceNum_ >= path.pieces_.length;\n}\n\n/**\n * @returns The path from outerPath to innerPath\n */\nexport function newRelativePath(outerPath: Path, innerPath: Path): Path {\n  const outer = pathGetFront(outerPath),\n    inner = pathGetFront(innerPath);\n  if (outer === null) {\n    return innerPath;\n  } else if (outer === inner) {\n    return newRelativePath(pathPopFront(outerPath), pathPopFront(innerPath));\n  } else {\n    throw new Error(\n      'INTERNAL ERROR: innerPath (' +\n        innerPath +\n        ') is not within ' +\n        'outerPath (' +\n        outerPath +\n        ')'\n    );\n  }\n}\n\n/**\n * @returns -1, 0, 1 if left is less, equal, or greater than the right.\n */\nexport function pathCompare(left: Path, right: Path): number {\n  const leftKeys = pathSlice(left, 0);\n  const rightKeys = pathSlice(right, 0);\n  for (let i = 0; i < leftKeys.length && i < rightKeys.length; i++) {\n    const cmp = nameCompare(leftKeys[i], rightKeys[i]);\n    if (cmp !== 0) {\n      return cmp;\n    }\n  }\n  if (leftKeys.length === rightKeys.length) {\n    return 0;\n  }\n  return leftKeys.length < rightKeys.length ? -1 : 1;\n}\n\n/**\n * @returns true if paths are the same.\n */\nexport function pathEquals(path: Path, other: Path): boolean {\n  if (pathGetLength(path) !== pathGetLength(other)) {\n    return false;\n  }\n\n  for (\n    let i = path.pieceNum_, j = other.pieceNum_;\n    i <= path.pieces_.length;\n    i++, j++\n  ) {\n    if (path.pieces_[i] !== other.pieces_[j]) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * @returns True if this path is a parent of (or the same as) other\n */\nexport function pathContains(path: Path, other: Path): boolean {\n  let i = path.pieceNum_;\n  let j = other.pieceNum_;\n  if (pathGetLength(path) > pathGetLength(other)) {\n    return false;\n  }\n  while (i < path.pieces_.length) {\n    if (path.pieces_[i] !== other.pieces_[j]) {\n      return false;\n    }\n    ++i;\n    ++j;\n  }\n  return true;\n}\n\n/**\n * Dynamic (mutable) path used to count path lengths.\n *\n * This class is used to efficiently check paths for valid\n * length (in UTF8 bytes) and depth (used in path validation).\n *\n * Throws Error exception if path is ever invalid.\n *\n * The definition of a path always begins with '/'.\n */\nexport class ValidationPath {\n  parts_: string[];\n  /** Initialize to number of '/' chars needed in path. */\n  byteLength_: number;\n\n  /**\n   * @param path - Initial Path.\n   * @param errorPrefix_ - Prefix for any error messages.\n   */\n  constructor(path: Path, public errorPrefix_: string) {\n    this.parts_ = pathSlice(path, 0);\n    /** Initialize to number of '/' chars needed in path. */\n    this.byteLength_ = Math.max(1, this.parts_.length);\n\n    for (let i = 0; i < this.parts_.length; i++) {\n      this.byteLength_ += stringLength(this.parts_[i]);\n    }\n    validationPathCheckValid(this);\n  }\n}\n\nexport function validationPathPush(\n  validationPath: ValidationPath,\n  child: string\n): void {\n  // Count the needed '/'\n  if (validationPath.parts_.length > 0) {\n    validationPath.byteLength_ += 1;\n  }\n  validationPath.parts_.push(child);\n  validationPath.byteLength_ += stringLength(child);\n  validationPathCheckValid(validationPath);\n}\n\nexport function validationPathPop(validationPath: ValidationPath): void {\n  const last = validationPath.parts_.pop();\n  validationPath.byteLength_ -= stringLength(last);\n  // Un-count the previous '/'\n  if (validationPath.parts_.length > 0) {\n    validationPath.byteLength_ -= 1;\n  }\n}\n\nfunction validationPathCheckValid(validationPath: ValidationPath): void {\n  if (validationPath.byteLength_ > MAX_PATH_LENGTH_BYTES) {\n    throw new Error(\n      validationPath.errorPrefix_ +\n        'has a key path longer than ' +\n        MAX_PATH_LENGTH_BYTES +\n        ' bytes (' +\n        validationPath.byteLength_ +\n        ').'\n    );\n  }\n  if (validationPath.parts_.length > MAX_PATH_DEPTH) {\n    throw new Error(\n      validationPath.errorPrefix_ +\n        'path specified exceeds the maximum depth that can be written (' +\n        MAX_PATH_DEPTH +\n        ') or object contains a cycle ' +\n        validationPathToErrorString(validationPath)\n    );\n  }\n}\n\n/**\n * String for use in error messages - uses '.' notation for path.\n */\nexport function validationPathToErrorString(\n  validationPath: ValidationPath\n): string {\n  if (validationPath.parts_.length === 0) {\n    return '';\n  }\n  return \"in property '\" + validationPath.parts_.join('.') + \"'\";\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { EventEmitter } from './EventEmitter';\n\ndeclare const document: Document;\n\nexport class VisibilityMonitor extends EventEmitter {\n  private visible_: boolean;\n\n  static getInstance() {\n    return new VisibilityMonitor();\n  }\n\n  constructor() {\n    super(['visible']);\n    let hidden: string;\n    let visibilityChange: string;\n    if (\n      typeof document !== 'undefined' &&\n      typeof document.addEventListener !== 'undefined'\n    ) {\n      if (typeof document['hidden'] !== 'undefined') {\n        // Opera 12.10 and Firefox 18 and later support\n        visibilityChange = 'visibilitychange';\n        hidden = 'hidden';\n      } else if (typeof document['mozHidden'] !== 'undefined') {\n        visibilityChange = 'mozvisibilitychange';\n        hidden = 'mozHidden';\n      } else if (typeof document['msHidden'] !== 'undefined') {\n        visibilityChange = 'msvisibilitychange';\n        hidden = 'msHidden';\n      } else if (typeof document['webkitHidden'] !== 'undefined') {\n        visibilityChange = 'webkitvisibilitychange';\n        hidden = 'webkitHidden';\n      }\n    }\n\n    // Initially, we always assume we are visible. This ensures that in browsers\n    // without page visibility support or in cases where we are never visible\n    // (e.g. chrome extension), we act as if we are visible, i.e. don't delay\n    // reconnects\n    this.visible_ = true;\n\n    if (visibilityChange) {\n      document.addEventListener(\n        visibilityChange,\n        () => {\n          const visible = !document[hidden];\n          if (visible !== this.visible_) {\n            this.visible_ = visible;\n            this.trigger('visible', visible);\n          }\n        },\n        false\n      );\n    }\n  }\n\n  getInitialEvent(eventType: string): boolean[] {\n    assert(eventType === 'visible', 'Unknown event type: ' + eventType);\n    return [this.visible_];\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  assert,\n  contains,\n  Deferred,\n  isEmpty,\n  isMobileCordova,\n  isNodeSdk,\n  isReactNative,\n  isValidFormat,\n  safeGet,\n  stringify,\n  isAdmin\n} from '@firebase/util';\n\nimport { Connection } from '../realtime/Connection';\n\nimport { AppCheckTokenProvider } from './AppCheckTokenProvider';\nimport { AuthTokenProvider } from './AuthTokenProvider';\nimport { RepoInfo } from './RepoInfo';\nimport { ServerActions } from './ServerActions';\nimport { OnlineMonitor } from './util/OnlineMonitor';\nimport { Path } from './util/Path';\nimport { error, log, logWrapper, warn, ObjectToUniqueKey } from './util/util';\nimport { VisibilityMonitor } from './util/VisibilityMonitor';\nimport { SDK_VERSION } from './version';\nimport { QueryContext } from './view/EventRegistration';\n\nconst RECONNECT_MIN_DELAY = 1000;\nconst RECONNECT_MAX_DELAY_DEFAULT = 60 * 5 * 1000; // 5 minutes in milliseconds (Case: 1858)\nconst RECONNECT_MAX_DELAY_FOR_ADMINS = 30 * 1000; // 30 seconds for admin clients (likely to be a backend server)\nconst RECONNECT_DELAY_MULTIPLIER = 1.3;\nconst RECONNECT_DELAY_RESET_TIMEOUT = 30000; // Reset delay back to MIN_DELAY after being connected for 30sec.\nconst SERVER_KILL_INTERRUPT_REASON = 'server_kill';\n\n// If auth fails repeatedly, we'll assume something is wrong and log a warning / back off.\nconst INVALID_TOKEN_THRESHOLD = 3;\n\ninterface ListenSpec {\n  onComplete(s: string, p?: unknown): void;\n\n  hashFn(): string;\n\n  query: QueryContext;\n  tag: number | null;\n}\n\ninterface OnDisconnectRequest {\n  pathString: string;\n  action: string;\n  data: unknown;\n  onComplete?: (a: string, b: string) => void;\n}\n\ninterface OutstandingPut {\n  action: string;\n  request: object;\n  queued?: boolean;\n  onComplete: (a: string, b?: string) => void;\n}\n\ninterface OutstandingGet {\n  request: object;\n  onComplete: (response: { [k: string]: unknown }) => void;\n}\n\n/**\n * Firebase connection.  Abstracts wire protocol and handles reconnecting.\n *\n * NOTE: All JSON objects sent to the realtime connection must have property names enclosed\n * in quotes to make sure the closure compiler does not minify them.\n */\nexport class PersistentConnection extends ServerActions {\n  // Used for diagnostic logging.\n  id = PersistentConnection.nextPersistentConnectionId_++;\n  private log_ = logWrapper('p:' + this.id + ':');\n\n  private interruptReasons_: { [reason: string]: boolean } = {};\n  private readonly listens: Map<\n    /* path */ string,\n    Map</* queryId */ string, ListenSpec>\n  > = new Map();\n  private outstandingPuts_: OutstandingPut[] = [];\n  private outstandingGets_: OutstandingGet[] = [];\n  private outstandingPutCount_ = 0;\n  private outstandingGetCount_ = 0;\n  private onDisconnectRequestQueue_: OnDisconnectRequest[] = [];\n  private connected_ = false;\n  private reconnectDelay_ = RECONNECT_MIN_DELAY;\n  private maxReconnectDelay_ = RECONNECT_MAX_DELAY_DEFAULT;\n  private securityDebugCallback_: ((a: object) => void) | null = null;\n  lastSessionId: string | null = null;\n\n  private establishConnectionTimer_: number | null = null;\n\n  private visible_: boolean = false;\n\n  // Before we get connected, we keep a queue of pending messages to send.\n  private requestCBHash_: { [k: number]: (a: unknown) => void } = {};\n  private requestNumber_ = 0;\n\n  private realtime_: {\n    sendRequest(a: object): void;\n    close(): void;\n  } | null = null;\n\n  private authToken_: string | null = null;\n  private appCheckToken_: string | null = null;\n  private forceTokenRefresh_ = false;\n  private invalidAuthTokenCount_ = 0;\n  private invalidAppCheckTokenCount_ = 0;\n\n  private firstConnection_ = true;\n  private lastConnectionAttemptTime_: number | null = null;\n  private lastConnectionEstablishedTime_: number | null = null;\n\n  private static nextPersistentConnectionId_ = 0;\n\n  /**\n   * Counter for number of connections created. Mainly used for tagging in the logs\n   */\n  private static nextConnectionId_ = 0;\n\n  /**\n   * @param repoInfo_ - Data about the namespace we are connecting to\n   * @param applicationId_ - The Firebase App ID for this project\n   * @param onDataUpdate_ - A callback for new data from the server\n   */\n  constructor(\n    private repoInfo_: RepoInfo,\n    private applicationId_: string,\n    private onDataUpdate_: (\n      a: string,\n      b: unknown,\n      c: boolean,\n      d: number | null\n    ) => void,\n    private onConnectStatus_: (a: boolean) => void,\n    private onServerInfoUpdate_: (a: unknown) => void,\n    private authTokenProvider_: AuthTokenProvider,\n    private appCheckTokenProvider_: AppCheckTokenProvider,\n    private authOverride_?: object | null\n  ) {\n    super();\n\n    if (authOverride_ && !isNodeSdk()) {\n      throw new Error(\n        'Auth override specified in options, but not supported on non Node.js platforms'\n      );\n    }\n\n    VisibilityMonitor.getInstance().on('visible', this.onVisible_, this);\n\n    if (repoInfo_.host.indexOf('fblocal') === -1) {\n      OnlineMonitor.getInstance().on('online', this.onOnline_, this);\n    }\n  }\n\n  protected sendRequest(\n    action: string,\n    body: unknown,\n    onResponse?: (a: unknown) => void\n  ) {\n    const curReqNum = ++this.requestNumber_;\n\n    const msg = { r: curReqNum, a: action, b: body };\n    this.log_(stringify(msg));\n    assert(\n      this.connected_,\n      \"sendRequest call when we're not connected not allowed.\"\n    );\n    this.realtime_.sendRequest(msg);\n    if (onResponse) {\n      this.requestCBHash_[curReqNum] = onResponse;\n    }\n  }\n\n  get(query: QueryContext): Promise<string> {\n    this.initConnection_();\n\n    const deferred = new Deferred<string>();\n    const request = {\n      p: query._path.toString(),\n      q: query._queryObject\n    };\n    const outstandingGet = {\n      action: 'g',\n      request,\n      onComplete: (message: { [k: string]: unknown }) => {\n        const payload = message['d'] as string;\n        if (message['s'] === 'ok') {\n          deferred.resolve(payload);\n        } else {\n          deferred.reject(payload);\n        }\n      }\n    };\n    this.outstandingGets_.push(outstandingGet);\n    this.outstandingGetCount_++;\n    const index = this.outstandingGets_.length - 1;\n\n    if (this.connected_) {\n      this.sendGet_(index);\n    }\n\n    return deferred.promise;\n  }\n\n  listen(\n    query: QueryContext,\n    currentHashFn: () => string,\n    tag: number | null,\n    onComplete: (a: string, b: unknown) => void\n  ) {\n    this.initConnection_();\n\n    const queryId = query._queryIdentifier;\n    const pathString = query._path.toString();\n    this.log_('Listen called for ' + pathString + ' ' + queryId);\n    if (!this.listens.has(pathString)) {\n      this.listens.set(pathString, new Map());\n    }\n    assert(\n      query._queryParams.isDefault() || !query._queryParams.loadsAllData(),\n      'listen() called for non-default but complete query'\n    );\n    assert(\n      !this.listens.get(pathString)!.has(queryId),\n      `listen() called twice for same path/queryId.`\n    );\n    const listenSpec: ListenSpec = {\n      onComplete,\n      hashFn: currentHashFn,\n      query,\n      tag\n    };\n    this.listens.get(pathString)!.set(queryId, listenSpec);\n\n    if (this.connected_) {\n      this.sendListen_(listenSpec);\n    }\n  }\n\n  private sendGet_(index: number) {\n    const get = this.outstandingGets_[index];\n    this.sendRequest('g', get.request, (message: { [k: string]: unknown }) => {\n      delete this.outstandingGets_[index];\n      this.outstandingGetCount_--;\n      if (this.outstandingGetCount_ === 0) {\n        this.outstandingGets_ = [];\n      }\n      if (get.onComplete) {\n        get.onComplete(message);\n      }\n    });\n  }\n\n  private sendListen_(listenSpec: ListenSpec) {\n    const query = listenSpec.query;\n    const pathString = query._path.toString();\n    const queryId = query._queryIdentifier;\n    this.log_('Listen on ' + pathString + ' for ' + queryId);\n    const req: { [k: string]: unknown } = { /*path*/ p: pathString };\n\n    const action = 'q';\n\n    // Only bother to send query if it's non-default.\n    if (listenSpec.tag) {\n      req['q'] = query._queryObject;\n      req['t'] = listenSpec.tag;\n    }\n\n    req[/*hash*/ 'h'] = listenSpec.hashFn();\n\n    this.sendRequest(action, req, (message: { [k: string]: unknown }) => {\n      const payload: unknown = message[/*data*/ 'd'];\n      const status = message[/*status*/ 's'] as string;\n\n      // print warnings in any case...\n      PersistentConnection.warnOnListenWarnings_(payload, query);\n\n      const currentListenSpec =\n        this.listens.get(pathString) &&\n        this.listens.get(pathString)!.get(queryId);\n      // only trigger actions if the listen hasn't been removed and readded\n      if (currentListenSpec === listenSpec) {\n        this.log_('listen response', message);\n\n        if (status !== 'ok') {\n          this.removeListen_(pathString, queryId);\n        }\n\n        if (listenSpec.onComplete) {\n          listenSpec.onComplete(status, payload);\n        }\n      }\n    });\n  }\n\n  private static warnOnListenWarnings_(payload: unknown, query: QueryContext) {\n    if (payload && typeof payload === 'object' && contains(payload, 'w')) {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      const warnings = safeGet(payload as any, 'w');\n      if (Array.isArray(warnings) && ~warnings.indexOf('no_index')) {\n        const indexSpec =\n          '\".indexOn\": \"' + query._queryParams.getIndex().toString() + '\"';\n        const indexPath = query._path.toString();\n        warn(\n          `Using an unspecified index. Your data will be downloaded and ` +\n            `filtered on the client. Consider adding ${indexSpec} at ` +\n            `${indexPath} to your security rules for better performance.`\n        );\n      }\n    }\n  }\n\n  refreshAuthToken(token: string) {\n    this.authToken_ = token;\n    this.log_('Auth token refreshed');\n    if (this.authToken_) {\n      this.tryAuth();\n    } else {\n      //If we're connected we want to let the server know to unauthenticate us. If we're not connected, simply delete\n      //the credential so we dont become authenticated next time we connect.\n      if (this.connected_) {\n        this.sendRequest('unauth', {}, () => {});\n      }\n    }\n\n    this.reduceReconnectDelayIfAdminCredential_(token);\n  }\n\n  private reduceReconnectDelayIfAdminCredential_(credential: string) {\n    // NOTE: This isn't intended to be bulletproof (a malicious developer can always just modify the client).\n    // Additionally, we don't bother resetting the max delay back to the default if auth fails / expires.\n    const isFirebaseSecret = credential && credential.length === 40;\n    if (isFirebaseSecret || isAdmin(credential)) {\n      this.log_(\n        'Admin auth credential detected.  Reducing max reconnect time.'\n      );\n      this.maxReconnectDelay_ = RECONNECT_MAX_DELAY_FOR_ADMINS;\n    }\n  }\n\n  refreshAppCheckToken(token: string | null) {\n    this.appCheckToken_ = token;\n    this.log_('App check token refreshed');\n    if (this.appCheckToken_) {\n      this.tryAppCheck();\n    } else {\n      //If we're connected we want to let the server know to unauthenticate us.\n      //If we're not connected, simply delete the credential so we dont become\n      // authenticated next time we connect.\n      if (this.connected_) {\n        this.sendRequest('unappeck', {}, () => {});\n      }\n    }\n  }\n\n  /**\n   * Attempts to authenticate with the given credentials. If the authentication attempt fails, it's triggered like\n   * a auth revoked (the connection is closed).\n   */\n  tryAuth() {\n    if (this.connected_ && this.authToken_) {\n      const token = this.authToken_;\n      const authMethod = isValidFormat(token) ? 'auth' : 'gauth';\n      const requestData: { [k: string]: unknown } = { cred: token };\n      if (this.authOverride_ === null) {\n        requestData['noauth'] = true;\n      } else if (typeof this.authOverride_ === 'object') {\n        requestData['authvar'] = this.authOverride_;\n      }\n      this.sendRequest(\n        authMethod,\n        requestData,\n        (res: { [k: string]: unknown }) => {\n          const status = res[/*status*/ 's'] as string;\n          const data = (res[/*data*/ 'd'] as string) || 'error';\n\n          if (this.authToken_ === token) {\n            if (status === 'ok') {\n              this.invalidAuthTokenCount_ = 0;\n            } else {\n              // Triggers reconnect and force refresh for auth token\n              this.onAuthRevoked_(status, data);\n            }\n          }\n        }\n      );\n    }\n  }\n\n  /**\n   * Attempts to authenticate with the given token. If the authentication\n   * attempt fails, it's triggered like the token was revoked (the connection is\n   * closed).\n   */\n  tryAppCheck() {\n    if (this.connected_ && this.appCheckToken_) {\n      this.sendRequest(\n        'appcheck',\n        { 'token': this.appCheckToken_ },\n        (res: { [k: string]: unknown }) => {\n          const status = res[/*status*/ 's'] as string;\n          const data = (res[/*data*/ 'd'] as string) || 'error';\n          if (status === 'ok') {\n            this.invalidAppCheckTokenCount_ = 0;\n          } else {\n            this.onAppCheckRevoked_(status, data);\n          }\n        }\n      );\n    }\n  }\n\n  /**\n   * @inheritDoc\n   */\n  unlisten(query: QueryContext, tag: number | null) {\n    const pathString = query._path.toString();\n    const queryId = query._queryIdentifier;\n\n    this.log_('Unlisten called for ' + pathString + ' ' + queryId);\n\n    assert(\n      query._queryParams.isDefault() || !query._queryParams.loadsAllData(),\n      'unlisten() called for non-default but complete query'\n    );\n    const listen = this.removeListen_(pathString, queryId);\n    if (listen && this.connected_) {\n      this.sendUnlisten_(pathString, queryId, query._queryObject, tag);\n    }\n  }\n\n  private sendUnlisten_(\n    pathString: string,\n    queryId: string,\n    queryObj: object,\n    tag: number | null\n  ) {\n    this.log_('Unlisten on ' + pathString + ' for ' + queryId);\n\n    const req: { [k: string]: unknown } = { /*path*/ p: pathString };\n    const action = 'n';\n    // Only bother sending queryId if it's non-default.\n    if (tag) {\n      req['q'] = queryObj;\n      req['t'] = tag;\n    }\n\n    this.sendRequest(action, req);\n  }\n\n  onDisconnectPut(\n    pathString: string,\n    data: unknown,\n    onComplete?: (a: string, b: string) => void\n  ) {\n    this.initConnection_();\n\n    if (this.connected_) {\n      this.sendOnDisconnect_('o', pathString, data, onComplete);\n    } else {\n      this.onDisconnectRequestQueue_.push({\n        pathString,\n        action: 'o',\n        data,\n        onComplete\n      });\n    }\n  }\n\n  onDisconnectMerge(\n    pathString: string,\n    data: unknown,\n    onComplete?: (a: string, b: string) => void\n  ) {\n    this.initConnection_();\n\n    if (this.connected_) {\n      this.sendOnDisconnect_('om', pathString, data, onComplete);\n    } else {\n      this.onDisconnectRequestQueue_.push({\n        pathString,\n        action: 'om',\n        data,\n        onComplete\n      });\n    }\n  }\n\n  onDisconnectCancel(\n    pathString: string,\n    onComplete?: (a: string, b: string) => void\n  ) {\n    this.initConnection_();\n\n    if (this.connected_) {\n      this.sendOnDisconnect_('oc', pathString, null, onComplete);\n    } else {\n      this.onDisconnectRequestQueue_.push({\n        pathString,\n        action: 'oc',\n        data: null,\n        onComplete\n      });\n    }\n  }\n\n  private sendOnDisconnect_(\n    action: string,\n    pathString: string,\n    data: unknown,\n    onComplete: (a: string, b: string) => void\n  ) {\n    const request = { /*path*/ p: pathString, /*data*/ d: data };\n    this.log_('onDisconnect ' + action, request);\n    this.sendRequest(action, request, (response: { [k: string]: unknown }) => {\n      if (onComplete) {\n        setTimeout(() => {\n          onComplete(\n            response[/*status*/ 's'] as string,\n            response[/* data */ 'd'] as string\n          );\n        }, Math.floor(0));\n      }\n    });\n  }\n\n  put(\n    pathString: string,\n    data: unknown,\n    onComplete?: (a: string, b: string) => void,\n    hash?: string\n  ) {\n    this.putInternal('p', pathString, data, onComplete, hash);\n  }\n\n  merge(\n    pathString: string,\n    data: unknown,\n    onComplete: (a: string, b: string | null) => void,\n    hash?: string\n  ) {\n    this.putInternal('m', pathString, data, onComplete, hash);\n  }\n\n  putInternal(\n    action: string,\n    pathString: string,\n    data: unknown,\n    onComplete: (a: string, b: string | null) => void,\n    hash?: string\n  ) {\n    this.initConnection_();\n\n    const request: { [k: string]: unknown } = {\n      /*path*/ p: pathString,\n      /*data*/ d: data\n    };\n\n    if (hash !== undefined) {\n      request[/*hash*/ 'h'] = hash;\n    }\n\n    // TODO: Only keep track of the most recent put for a given path?\n    this.outstandingPuts_.push({\n      action,\n      request,\n      onComplete\n    });\n\n    this.outstandingPutCount_++;\n    const index = this.outstandingPuts_.length - 1;\n\n    if (this.connected_) {\n      this.sendPut_(index);\n    } else {\n      this.log_('Buffering put: ' + pathString);\n    }\n  }\n\n  private sendPut_(index: number) {\n    const action = this.outstandingPuts_[index].action;\n    const request = this.outstandingPuts_[index].request;\n    const onComplete = this.outstandingPuts_[index].onComplete;\n    this.outstandingPuts_[index].queued = this.connected_;\n\n    this.sendRequest(action, request, (message: { [k: string]: unknown }) => {\n      this.log_(action + ' response', message);\n\n      delete this.outstandingPuts_[index];\n      this.outstandingPutCount_--;\n\n      // Clean up array occasionally.\n      if (this.outstandingPutCount_ === 0) {\n        this.outstandingPuts_ = [];\n      }\n\n      if (onComplete) {\n        onComplete(\n          message[/*status*/ 's'] as string,\n          message[/* data */ 'd'] as string\n        );\n      }\n    });\n  }\n\n  reportStats(stats: { [k: string]: unknown }) {\n    // If we're not connected, we just drop the stats.\n    if (this.connected_) {\n      const request = { /*counters*/ c: stats };\n      this.log_('reportStats', request);\n\n      this.sendRequest(/*stats*/ 's', request, result => {\n        const status = result[/*status*/ 's'];\n        if (status !== 'ok') {\n          const errorReason = result[/* data */ 'd'];\n          this.log_('reportStats', 'Error sending stats: ' + errorReason);\n        }\n      });\n    }\n  }\n\n  private onDataMessage_(message: { [k: string]: unknown }) {\n    if ('r' in message) {\n      // this is a response\n      this.log_('from server: ' + stringify(message));\n      const reqNum = message['r'] as string;\n      const onResponse = this.requestCBHash_[reqNum];\n      if (onResponse) {\n        delete this.requestCBHash_[reqNum];\n        onResponse(message[/*body*/ 'b']);\n      }\n    } else if ('error' in message) {\n      throw 'A server-side error has occurred: ' + message['error'];\n    } else if ('a' in message) {\n      // a and b are action and body, respectively\n      this.onDataPush_(message['a'] as string, message['b'] as {});\n    }\n  }\n\n  private onDataPush_(action: string, body: { [k: string]: unknown }) {\n    this.log_('handleServerMessage', action, body);\n    if (action === 'd') {\n      this.onDataUpdate_(\n        body[/*path*/ 'p'] as string,\n        body[/*data*/ 'd'],\n        /*isMerge*/ false,\n        body['t'] as number\n      );\n    } else if (action === 'm') {\n      this.onDataUpdate_(\n        body[/*path*/ 'p'] as string,\n        body[/*data*/ 'd'],\n        /*isMerge=*/ true,\n        body['t'] as number\n      );\n    } else if (action === 'c') {\n      this.onListenRevoked_(\n        body[/*path*/ 'p'] as string,\n        body[/*query*/ 'q'] as unknown[]\n      );\n    } else if (action === 'ac') {\n      this.onAuthRevoked_(\n        body[/*status code*/ 's'] as string,\n        body[/* explanation */ 'd'] as string\n      );\n    } else if (action === 'apc') {\n      this.onAppCheckRevoked_(\n        body[/*status code*/ 's'] as string,\n        body[/* explanation */ 'd'] as string\n      );\n    } else if (action === 'sd') {\n      this.onSecurityDebugPacket_(body);\n    } else {\n      error(\n        'Unrecognized action received from server: ' +\n          stringify(action) +\n          '\\nAre you using the latest client?'\n      );\n    }\n  }\n\n  private onReady_(timestamp: number, sessionId: string) {\n    this.log_('connection ready');\n    this.connected_ = true;\n    this.lastConnectionEstablishedTime_ = new Date().getTime();\n    this.handleTimestamp_(timestamp);\n    this.lastSessionId = sessionId;\n    if (this.firstConnection_) {\n      this.sendConnectStats_();\n    }\n    this.restoreState_();\n    this.firstConnection_ = false;\n    this.onConnectStatus_(true);\n  }\n\n  private scheduleConnect_(timeout: number) {\n    assert(\n      !this.realtime_,\n      \"Scheduling a connect when we're already connected/ing?\"\n    );\n\n    if (this.establishConnectionTimer_) {\n      clearTimeout(this.establishConnectionTimer_);\n    }\n\n    // NOTE: Even when timeout is 0, it's important to do a setTimeout to work around an infuriating \"Security Error\" in\n    // Firefox when trying to write to our long-polling iframe in some scenarios (e.g. Forge or our unit tests).\n\n    this.establishConnectionTimer_ = setTimeout(() => {\n      this.establishConnectionTimer_ = null;\n      this.establishConnection_();\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    }, Math.floor(timeout)) as any;\n  }\n\n  private initConnection_() {\n    if (!this.realtime_ && this.firstConnection_) {\n      this.scheduleConnect_(0);\n    }\n  }\n\n  private onVisible_(visible: boolean) {\n    // NOTE: Tabbing away and back to a window will defeat our reconnect backoff, but I think that's fine.\n    if (\n      visible &&\n      !this.visible_ &&\n      this.reconnectDelay_ === this.maxReconnectDelay_\n    ) {\n      this.log_('Window became visible.  Reducing delay.');\n      this.reconnectDelay_ = RECONNECT_MIN_DELAY;\n\n      if (!this.realtime_) {\n        this.scheduleConnect_(0);\n      }\n    }\n    this.visible_ = visible;\n  }\n\n  private onOnline_(online: boolean) {\n    if (online) {\n      this.log_('Browser went online.');\n      this.reconnectDelay_ = RECONNECT_MIN_DELAY;\n      if (!this.realtime_) {\n        this.scheduleConnect_(0);\n      }\n    } else {\n      this.log_('Browser went offline.  Killing connection.');\n      if (this.realtime_) {\n        this.realtime_.close();\n      }\n    }\n  }\n\n  private onRealtimeDisconnect_() {\n    this.log_('data client disconnected');\n    this.connected_ = false;\n    this.realtime_ = null;\n\n    // Since we don't know if our sent transactions succeeded or not, we need to cancel them.\n    this.cancelSentTransactions_();\n\n    // Clear out the pending requests.\n    this.requestCBHash_ = {};\n\n    if (this.shouldReconnect_()) {\n      if (!this.visible_) {\n        this.log_(\"Window isn't visible.  Delaying reconnect.\");\n        this.reconnectDelay_ = this.maxReconnectDelay_;\n        this.lastConnectionAttemptTime_ = new Date().getTime();\n      } else if (this.lastConnectionEstablishedTime_) {\n        // If we've been connected long enough, reset reconnect delay to minimum.\n        const timeSinceLastConnectSucceeded =\n          new Date().getTime() - this.lastConnectionEstablishedTime_;\n        if (timeSinceLastConnectSucceeded > RECONNECT_DELAY_RESET_TIMEOUT) {\n          this.reconnectDelay_ = RECONNECT_MIN_DELAY;\n        }\n        this.lastConnectionEstablishedTime_ = null;\n      }\n\n      const timeSinceLastConnectAttempt =\n        new Date().getTime() - this.lastConnectionAttemptTime_;\n      let reconnectDelay = Math.max(\n        0,\n        this.reconnectDelay_ - timeSinceLastConnectAttempt\n      );\n      reconnectDelay = Math.random() * reconnectDelay;\n\n      this.log_('Trying to reconnect in ' + reconnectDelay + 'ms');\n      this.scheduleConnect_(reconnectDelay);\n\n      // Adjust reconnect delay for next time.\n      this.reconnectDelay_ = Math.min(\n        this.maxReconnectDelay_,\n        this.reconnectDelay_ * RECONNECT_DELAY_MULTIPLIER\n      );\n    }\n    this.onConnectStatus_(false);\n  }\n\n  private async establishConnection_() {\n    if (this.shouldReconnect_()) {\n      this.log_('Making a connection attempt');\n      this.lastConnectionAttemptTime_ = new Date().getTime();\n      this.lastConnectionEstablishedTime_ = null;\n      const onDataMessage = this.onDataMessage_.bind(this);\n      const onReady = this.onReady_.bind(this);\n      const onDisconnect = this.onRealtimeDisconnect_.bind(this);\n      const connId = this.id + ':' + PersistentConnection.nextConnectionId_++;\n      const lastSessionId = this.lastSessionId;\n      let canceled = false;\n      let connection: Connection | null = null;\n      const closeFn = function () {\n        if (connection) {\n          connection.close();\n        } else {\n          canceled = true;\n          onDisconnect();\n        }\n      };\n      const sendRequestFn = function (msg: object) {\n        assert(\n          connection,\n          \"sendRequest call when we're not connected not allowed.\"\n        );\n        connection.sendRequest(msg);\n      };\n\n      this.realtime_ = {\n        close: closeFn,\n        sendRequest: sendRequestFn\n      };\n\n      const forceRefresh = this.forceTokenRefresh_;\n      this.forceTokenRefresh_ = false;\n\n      try {\n        // First fetch auth and app check token, and establish connection after\n        // fetching the token was successful\n        const [authToken, appCheckToken] = await Promise.all([\n          this.authTokenProvider_.getToken(forceRefresh),\n          this.appCheckTokenProvider_.getToken(forceRefresh)\n        ]);\n\n        if (!canceled) {\n          log('getToken() completed. Creating connection.');\n          this.authToken_ = authToken && authToken.accessToken;\n          this.appCheckToken_ = appCheckToken && appCheckToken.token;\n          connection = new Connection(\n            connId,\n            this.repoInfo_,\n            this.applicationId_,\n            this.appCheckToken_,\n            this.authToken_,\n            onDataMessage,\n            onReady,\n            onDisconnect,\n            /* onKill= */ reason => {\n              warn(reason + ' (' + this.repoInfo_.toString() + ')');\n              this.interrupt(SERVER_KILL_INTERRUPT_REASON);\n            },\n            lastSessionId\n          );\n        } else {\n          log('getToken() completed but was canceled');\n        }\n      } catch (error) {\n        this.log_('Failed to get token: ' + error);\n        if (!canceled) {\n          if (this.repoInfo_.nodeAdmin) {\n            // This may be a critical error for the Admin Node.js SDK, so log a warning.\n            // But getToken() may also just have temporarily failed, so we still want to\n            // continue retrying.\n            warn(error);\n          }\n          closeFn();\n        }\n      }\n    }\n  }\n\n  interrupt(reason: string) {\n    log('Interrupting connection for reason: ' + reason);\n    this.interruptReasons_[reason] = true;\n    if (this.realtime_) {\n      this.realtime_.close();\n    } else {\n      if (this.establishConnectionTimer_) {\n        clearTimeout(this.establishConnectionTimer_);\n        this.establishConnectionTimer_ = null;\n      }\n      if (this.connected_) {\n        this.onRealtimeDisconnect_();\n      }\n    }\n  }\n\n  resume(reason: string) {\n    log('Resuming connection for reason: ' + reason);\n    delete this.interruptReasons_[reason];\n    if (isEmpty(this.interruptReasons_)) {\n      this.reconnectDelay_ = RECONNECT_MIN_DELAY;\n      if (!this.realtime_) {\n        this.scheduleConnect_(0);\n      }\n    }\n  }\n\n  private handleTimestamp_(timestamp: number) {\n    const delta = timestamp - new Date().getTime();\n    this.onServerInfoUpdate_({ serverTimeOffset: delta });\n  }\n\n  private cancelSentTransactions_() {\n    for (let i = 0; i < this.outstandingPuts_.length; i++) {\n      const put = this.outstandingPuts_[i];\n      if (put && /*hash*/ 'h' in put.request && put.queued) {\n        if (put.onComplete) {\n          put.onComplete('disconnect');\n        }\n\n        delete this.outstandingPuts_[i];\n        this.outstandingPutCount_--;\n      }\n    }\n\n    // Clean up array occasionally.\n    if (this.outstandingPutCount_ === 0) {\n      this.outstandingPuts_ = [];\n    }\n  }\n\n  private onListenRevoked_(pathString: string, query?: unknown[]) {\n    // Remove the listen and manufacture a \"permission_denied\" error for the failed listen.\n    let queryId;\n    if (!query) {\n      queryId = 'default';\n    } else {\n      queryId = query.map(q => ObjectToUniqueKey(q)).join('$');\n    }\n    const listen = this.removeListen_(pathString, queryId);\n    if (listen && listen.onComplete) {\n      listen.onComplete('permission_denied');\n    }\n  }\n\n  private removeListen_(pathString: string, queryId: string): ListenSpec {\n    const normalizedPathString = new Path(pathString).toString(); // normalize path.\n    let listen;\n    if (this.listens.has(normalizedPathString)) {\n      const map = this.listens.get(normalizedPathString)!;\n      listen = map.get(queryId);\n      map.delete(queryId);\n      if (map.size === 0) {\n        this.listens.delete(normalizedPathString);\n      }\n    } else {\n      // all listens for this path has already been removed\n      listen = undefined;\n    }\n    return listen;\n  }\n\n  private onAuthRevoked_(statusCode: string, explanation: string) {\n    log('Auth token revoked: ' + statusCode + '/' + explanation);\n    this.authToken_ = null;\n    this.forceTokenRefresh_ = true;\n    this.realtime_.close();\n    if (statusCode === 'invalid_token' || statusCode === 'permission_denied') {\n      // We'll wait a couple times before logging the warning / increasing the\n      // retry period since oauth tokens will report as \"invalid\" if they're\n      // just expired. Plus there may be transient issues that resolve themselves.\n      this.invalidAuthTokenCount_++;\n      if (this.invalidAuthTokenCount_ >= INVALID_TOKEN_THRESHOLD) {\n        // Set a long reconnect delay because recovery is unlikely\n        this.reconnectDelay_ = RECONNECT_MAX_DELAY_FOR_ADMINS;\n\n        // Notify the auth token provider that the token is invalid, which will log\n        // a warning\n        this.authTokenProvider_.notifyForInvalidToken();\n      }\n    }\n  }\n\n  private onAppCheckRevoked_(statusCode: string, explanation: string) {\n    log('App check token revoked: ' + statusCode + '/' + explanation);\n    this.appCheckToken_ = null;\n    this.forceTokenRefresh_ = true;\n    // Note: We don't close the connection as the developer may not have\n    // enforcement enabled. The backend closes connections with enforcements.\n    if (statusCode === 'invalid_token' || statusCode === 'permission_denied') {\n      // We'll wait a couple times before logging the warning / increasing the\n      // retry period since oauth tokens will report as \"invalid\" if they're\n      // just expired. Plus there may be transient issues that resolve themselves.\n      this.invalidAppCheckTokenCount_++;\n      if (this.invalidAppCheckTokenCount_ >= INVALID_TOKEN_THRESHOLD) {\n        this.appCheckTokenProvider_.notifyForInvalidToken();\n      }\n    }\n  }\n\n  private onSecurityDebugPacket_(body: { [k: string]: unknown }) {\n    if (this.securityDebugCallback_) {\n      this.securityDebugCallback_(body);\n    } else {\n      if ('msg' in body) {\n        console.log(\n          'FIREBASE: ' + (body['msg'] as string).replace('\\n', '\\nFIREBASE: ')\n        );\n      }\n    }\n  }\n\n  private restoreState_() {\n    //Re-authenticate ourselves if we have a credential stored.\n    this.tryAuth();\n    this.tryAppCheck();\n\n    // Puts depend on having received the corresponding data update from the server before they complete, so we must\n    // make sure to send listens before puts.\n    for (const queries of this.listens.values()) {\n      for (const listenSpec of queries.values()) {\n        this.sendListen_(listenSpec);\n      }\n    }\n\n    for (let i = 0; i < this.outstandingPuts_.length; i++) {\n      if (this.outstandingPuts_[i]) {\n        this.sendPut_(i);\n      }\n    }\n\n    while (this.onDisconnectRequestQueue_.length) {\n      const request = this.onDisconnectRequestQueue_.shift();\n      this.sendOnDisconnect_(\n        request.action,\n        request.pathString,\n        request.data,\n        request.onComplete\n      );\n    }\n\n    for (let i = 0; i < this.outstandingGets_.length; i++) {\n      if (this.outstandingGets_[i]) {\n        this.sendGet_(i);\n      }\n    }\n  }\n\n  /**\n   * Sends client stats for first connection\n   */\n  private sendConnectStats_() {\n    const stats: { [k: string]: number } = {};\n\n    let clientName = 'js';\n    if (isNodeSdk()) {\n      if (this.repoInfo_.nodeAdmin) {\n        clientName = 'admin_node';\n      } else {\n        clientName = 'node';\n      }\n    }\n\n    stats['sdk.' + clientName + '.' + SDK_VERSION.replace(/\\./g, '-')] = 1;\n\n    if (isMobileCordova()) {\n      stats['framework.cordova'] = 1;\n    } else if (isReactNative()) {\n      stats['framework.reactnative'] = 1;\n    }\n    this.reportStats(stats);\n  }\n\n  private shouldReconnect_(): boolean {\n    const online = OnlineMonitor.getInstance().currentlyOnline();\n    return isEmpty(this.interruptReasons_) && online;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Comparator } from '../../util/SortedMap';\nimport { MIN_NAME } from '../../util/util';\nimport { Node, NamedNode } from '../Node';\n\nexport abstract class Index {\n  abstract compare(a: NamedNode, b: NamedNode): number;\n\n  abstract isDefinedOn(node: Node): boolean;\n\n  /**\n   * @returns A standalone comparison function for\n   * this index\n   */\n  getCompare(): Comparator<NamedNode> {\n    return this.compare.bind(this);\n  }\n\n  /**\n   * Given a before and after value for a node, determine if the indexed value has changed. Even if they are different,\n   * it's possible that the changes are isolated to parts of the snapshot that are not indexed.\n   *\n   *\n   * @returns True if the portion of the snapshot being indexed changed between oldNode and newNode\n   */\n  indexedValueChanged(oldNode: Node, newNode: Node): boolean {\n    const oldWrapped = new NamedNode(MIN_NAME, oldNode);\n    const newWrapped = new NamedNode(MIN_NAME, newNode);\n    return this.compare(oldWrapped, newWrapped) !== 0;\n  }\n\n  /**\n   * @returns a node wrapper that will sort equal to or less than\n   * any other node wrapper, using this index\n   */\n  minPost(): NamedNode {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return (NamedNode as any).MIN;\n  }\n\n  /**\n   * @returns a node wrapper that will sort greater than or equal to\n   * any other node wrapper, using this index\n   */\n  abstract maxPost(): NamedNode;\n\n  abstract makePost(indexValue: unknown, name: string): NamedNode;\n\n  /**\n   * @returns String representation for inclusion in a query spec\n   */\n  abstract toString(): string;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert, assertionError } from '@firebase/util';\n\nimport { nameCompare, MAX_NAME } from '../../util/util';\nimport { ChildrenNode } from '../ChildrenNode';\nimport { Node, NamedNode } from '../Node';\n\nimport { Index } from './Index';\n\nlet __EMPTY_NODE: ChildrenNode;\n\nexport class KeyIndex extends Index {\n  static get __EMPTY_NODE() {\n    return __EMPTY_NODE;\n  }\n\n  static set __EMPTY_NODE(val) {\n    __EMPTY_NODE = val;\n  }\n  compare(a: NamedNode, b: NamedNode): number {\n    return nameCompare(a.name, b.name);\n  }\n  isDefinedOn(node: Node): boolean {\n    // We could probably return true here (since every node has a key), but it's never called\n    // so just leaving unimplemented for now.\n    throw assertionError('KeyIndex.isDefinedOn not expected to be called.');\n  }\n  indexedValueChanged(oldNode: Node, newNode: Node): boolean {\n    return false; // The key for a node never changes.\n  }\n  minPost() {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return (NamedNode as any).MIN;\n  }\n  maxPost(): NamedNode {\n    // TODO: This should really be created once and cached in a static property, but\n    // NamedNode isn't defined yet, so I can't use it in a static.  Bleh.\n    return new NamedNode(MAX_NAME, __EMPTY_NODE);\n  }\n\n  makePost(indexValue: string, name: string): NamedNode {\n    assert(\n      typeof indexValue === 'string',\n      'KeyIndex indexValue must always be a string.'\n    );\n    // We just use empty node, but it'll never be compared, since our comparator only looks at name.\n    return new NamedNode(indexValue, __EMPTY_NODE);\n  }\n\n  /**\n   * @returns String representation for inclusion in a query spec\n   */\n  toString(): string {\n    return '.key';\n  }\n}\n\nexport const KEY_INDEX = new KeyIndex();\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * @fileoverview Implementation of an immutable SortedMap using a Left-leaning\n * Red-Black Tree, adapted from the implementation in Mugs\n * (http://mads379.github.com/mugs/) by Mads Hartmann Jensen\n * (mads379\\@gmail.com).\n *\n * Original paper on Left-leaning Red-Black Trees:\n *   http://www.cs.princeton.edu/~rs/talks/LLRB/LLRB.pdf\n *\n * Invariant 1: No red node has a red child\n * Invariant 2: Every leaf path has the same number of black nodes\n * Invariant 3: Only the left child can be red (left leaning)\n */\n\n// TODO: There are some improvements I'd like to make to improve memory / perf:\n//  * Create two prototypes, LLRedNode and LLBlackNode, instead of storing a\n//    color property in every node.\n// TODO: It would also be good (and possibly necessary) to create a base\n// interface for LLRBNode and LLRBEmptyNode.\n\nexport type Comparator<K> = (key1: K, key2: K) => number;\n\n/**\n * An iterator over an LLRBNode.\n */\nexport class SortedMapIterator<K, V, T> {\n  private nodeStack_: Array<LLRBNode<K, V> | LLRBEmptyNode<K, V>> = [];\n\n  /**\n   * @param node - Node to iterate.\n   * @param isReverse_ - Whether or not to iterate in reverse\n   */\n  constructor(\n    node: LLRBNode<K, V> | LLRBEmptyNode<K, V>,\n    startKey: K | null,\n    comparator: Comparator<K>,\n    private isReverse_: boolean,\n    private resultGenerator_: ((k: K, v: V) => T) | null = null\n  ) {\n    let cmp = 1;\n    while (!node.isEmpty()) {\n      node = node as LLRBNode<K, V>;\n      cmp = startKey ? comparator(node.key, startKey) : 1;\n      // flip the comparison if we're going in reverse\n      if (isReverse_) {\n        cmp *= -1;\n      }\n\n      if (cmp < 0) {\n        // This node is less than our start key. ignore it\n        if (this.isReverse_) {\n          node = node.left;\n        } else {\n          node = node.right;\n        }\n      } else if (cmp === 0) {\n        // This node is exactly equal to our start key. Push it on the stack, but stop iterating;\n        this.nodeStack_.push(node);\n        break;\n      } else {\n        // This node is greater than our start key, add it to the stack and move to the next one\n        this.nodeStack_.push(node);\n        if (this.isReverse_) {\n          node = node.right;\n        } else {\n          node = node.left;\n        }\n      }\n    }\n  }\n\n  getNext(): T {\n    if (this.nodeStack_.length === 0) {\n      return null;\n    }\n\n    let node = this.nodeStack_.pop();\n    let result: T;\n    if (this.resultGenerator_) {\n      result = this.resultGenerator_(node.key, node.value);\n    } else {\n      result = { key: node.key, value: node.value } as unknown as T;\n    }\n\n    if (this.isReverse_) {\n      node = node.left;\n      while (!node.isEmpty()) {\n        this.nodeStack_.push(node);\n        node = node.right;\n      }\n    } else {\n      node = node.right;\n      while (!node.isEmpty()) {\n        this.nodeStack_.push(node);\n        node = node.left;\n      }\n    }\n\n    return result;\n  }\n\n  hasNext(): boolean {\n    return this.nodeStack_.length > 0;\n  }\n\n  peek(): T {\n    if (this.nodeStack_.length === 0) {\n      return null;\n    }\n\n    const node = this.nodeStack_[this.nodeStack_.length - 1];\n    if (this.resultGenerator_) {\n      return this.resultGenerator_(node.key, node.value);\n    } else {\n      return { key: node.key, value: node.value } as unknown as T;\n    }\n  }\n}\n\n/**\n * Represents a node in a Left-leaning Red-Black tree.\n */\nexport class LLRBNode<K, V> {\n  color: boolean;\n  left: LLRBNode<K, V> | LLRBEmptyNode<K, V>;\n  right: LLRBNode<K, V> | LLRBEmptyNode<K, V>;\n\n  /**\n   * @param key - Key associated with this node.\n   * @param value - Value associated with this node.\n   * @param color - Whether this node is red.\n   * @param left - Left child.\n   * @param right - Right child.\n   */\n  constructor(\n    public key: K,\n    public value: V,\n    color: boolean | null,\n    left?: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null,\n    right?: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null\n  ) {\n    this.color = color != null ? color : LLRBNode.RED;\n    this.left =\n      left != null ? left : (SortedMap.EMPTY_NODE as LLRBEmptyNode<K, V>);\n    this.right =\n      right != null ? right : (SortedMap.EMPTY_NODE as LLRBEmptyNode<K, V>);\n  }\n\n  static RED = true;\n  static BLACK = false;\n\n  /**\n   * Returns a copy of the current node, optionally replacing pieces of it.\n   *\n   * @param key - New key for the node, or null.\n   * @param value - New value for the node, or null.\n   * @param color - New color for the node, or null.\n   * @param left - New left child for the node, or null.\n   * @param right - New right child for the node, or null.\n   * @returns The node copy.\n   */\n  copy(\n    key: K | null,\n    value: V | null,\n    color: boolean | null,\n    left: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null,\n    right: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null\n  ): LLRBNode<K, V> {\n    return new LLRBNode(\n      key != null ? key : this.key,\n      value != null ? value : this.value,\n      color != null ? color : this.color,\n      left != null ? left : this.left,\n      right != null ? right : this.right\n    );\n  }\n\n  /**\n   * @returns The total number of nodes in the tree.\n   */\n  count(): number {\n    return this.left.count() + 1 + this.right.count();\n  }\n\n  /**\n   * @returns True if the tree is empty.\n   */\n  isEmpty(): boolean {\n    return false;\n  }\n\n  /**\n   * Traverses the tree in key order and calls the specified action function\n   * for each node.\n   *\n   * @param action - Callback function to be called for each\n   *   node.  If it returns true, traversal is aborted.\n   * @returns The first truthy value returned by action, or the last falsey\n   *   value returned by action\n   */\n  inorderTraversal(action: (k: K, v: V) => unknown): boolean {\n    return (\n      this.left.inorderTraversal(action) ||\n      !!action(this.key, this.value) ||\n      this.right.inorderTraversal(action)\n    );\n  }\n\n  /**\n   * Traverses the tree in reverse key order and calls the specified action function\n   * for each node.\n   *\n   * @param action - Callback function to be called for each\n   * node.  If it returns true, traversal is aborted.\n   * @returns True if traversal was aborted.\n   */\n  reverseTraversal(action: (k: K, v: V) => void): boolean {\n    return (\n      this.right.reverseTraversal(action) ||\n      action(this.key, this.value) ||\n      this.left.reverseTraversal(action)\n    );\n  }\n\n  /**\n   * @returns The minimum node in the tree.\n   */\n  private min_(): LLRBNode<K, V> {\n    if (this.left.isEmpty()) {\n      return this;\n    } else {\n      return (this.left as LLRBNode<K, V>).min_();\n    }\n  }\n\n  /**\n   * @returns The maximum key in the tree.\n   */\n  minKey(): K {\n    return this.min_().key;\n  }\n\n  /**\n   * @returns The maximum key in the tree.\n   */\n  maxKey(): K {\n    if (this.right.isEmpty()) {\n      return this.key;\n    } else {\n      return this.right.maxKey();\n    }\n  }\n\n  /**\n   * @param key - Key to insert.\n   * @param value - Value to insert.\n   * @param comparator - Comparator.\n   * @returns New tree, with the key/value added.\n   */\n  insert(key: K, value: V, comparator: Comparator<K>): LLRBNode<K, V> {\n    let n: LLRBNode<K, V> = this;\n    const cmp = comparator(key, n.key);\n    if (cmp < 0) {\n      n = n.copy(null, null, null, n.left.insert(key, value, comparator), null);\n    } else if (cmp === 0) {\n      n = n.copy(null, value, null, null, null);\n    } else {\n      n = n.copy(\n        null,\n        null,\n        null,\n        null,\n        n.right.insert(key, value, comparator)\n      );\n    }\n    return n.fixUp_();\n  }\n\n  /**\n   * @returns New tree, with the minimum key removed.\n   */\n  private removeMin_(): LLRBNode<K, V> | LLRBEmptyNode<K, V> {\n    if (this.left.isEmpty()) {\n      return SortedMap.EMPTY_NODE as LLRBEmptyNode<K, V>;\n    }\n    let n: LLRBNode<K, V> = this;\n    if (!n.left.isRed_() && !n.left.left.isRed_()) {\n      n = n.moveRedLeft_();\n    }\n    n = n.copy(null, null, null, (n.left as LLRBNode<K, V>).removeMin_(), null);\n    return n.fixUp_();\n  }\n\n  /**\n   * @param key - The key of the item to remove.\n   * @param comparator - Comparator.\n   * @returns New tree, with the specified item removed.\n   */\n  remove(\n    key: K,\n    comparator: Comparator<K>\n  ): LLRBNode<K, V> | LLRBEmptyNode<K, V> {\n    let n, smallest;\n    n = this;\n    if (comparator(key, n.key) < 0) {\n      if (!n.left.isEmpty() && !n.left.isRed_() && !n.left.left.isRed_()) {\n        n = n.moveRedLeft_();\n      }\n      n = n.copy(null, null, null, n.left.remove(key, comparator), null);\n    } else {\n      if (n.left.isRed_()) {\n        n = n.rotateRight_();\n      }\n      if (!n.right.isEmpty() && !n.right.isRed_() && !n.right.left.isRed_()) {\n        n = n.moveRedRight_();\n      }\n      if (comparator(key, n.key) === 0) {\n        if (n.right.isEmpty()) {\n          return SortedMap.EMPTY_NODE as LLRBEmptyNode<K, V>;\n        } else {\n          smallest = (n.right as LLRBNode<K, V>).min_();\n          n = n.copy(\n            smallest.key,\n            smallest.value,\n            null,\n            null,\n            (n.right as LLRBNode<K, V>).removeMin_()\n          );\n        }\n      }\n      n = n.copy(null, null, null, null, n.right.remove(key, comparator));\n    }\n    return n.fixUp_();\n  }\n\n  /**\n   * @returns Whether this is a RED node.\n   */\n  isRed_(): boolean {\n    return this.color;\n  }\n\n  /**\n   * @returns New tree after performing any needed rotations.\n   */\n  private fixUp_(): LLRBNode<K, V> {\n    let n: LLRBNode<K, V> = this;\n    if (n.right.isRed_() && !n.left.isRed_()) {\n      n = n.rotateLeft_();\n    }\n    if (n.left.isRed_() && n.left.left.isRed_()) {\n      n = n.rotateRight_();\n    }\n    if (n.left.isRed_() && n.right.isRed_()) {\n      n = n.colorFlip_();\n    }\n    return n;\n  }\n\n  /**\n   * @returns New tree, after moveRedLeft.\n   */\n  private moveRedLeft_(): LLRBNode<K, V> {\n    let n = this.colorFlip_();\n    if (n.right.left.isRed_()) {\n      n = n.copy(\n        null,\n        null,\n        null,\n        null,\n        (n.right as LLRBNode<K, V>).rotateRight_()\n      );\n      n = n.rotateLeft_();\n      n = n.colorFlip_();\n    }\n    return n;\n  }\n\n  /**\n   * @returns New tree, after moveRedRight.\n   */\n  private moveRedRight_(): LLRBNode<K, V> {\n    let n = this.colorFlip_();\n    if (n.left.left.isRed_()) {\n      n = n.rotateRight_();\n      n = n.colorFlip_();\n    }\n    return n;\n  }\n\n  /**\n   * @returns New tree, after rotateLeft.\n   */\n  private rotateLeft_(): LLRBNode<K, V> {\n    const nl = this.copy(null, null, LLRBNode.RED, null, this.right.left);\n    return this.right.copy(null, null, this.color, nl, null) as LLRBNode<K, V>;\n  }\n\n  /**\n   * @returns New tree, after rotateRight.\n   */\n  private rotateRight_(): LLRBNode<K, V> {\n    const nr = this.copy(null, null, LLRBNode.RED, this.left.right, null);\n    return this.left.copy(null, null, this.color, null, nr) as LLRBNode<K, V>;\n  }\n\n  /**\n   * @returns Newt ree, after colorFlip.\n   */\n  private colorFlip_(): LLRBNode<K, V> {\n    const left = this.left.copy(null, null, !this.left.color, null, null);\n    const right = this.right.copy(null, null, !this.right.color, null, null);\n    return this.copy(null, null, !this.color, left, right);\n  }\n\n  /**\n   * For testing.\n   *\n   * @returns True if all is well.\n   */\n  private checkMaxDepth_(): boolean {\n    const blackDepth = this.check_();\n    return Math.pow(2.0, blackDepth) <= this.count() + 1;\n  }\n\n  check_(): number {\n    if (this.isRed_() && this.left.isRed_()) {\n      throw new Error(\n        'Red node has red child(' + this.key + ',' + this.value + ')'\n      );\n    }\n    if (this.right.isRed_()) {\n      throw new Error(\n        'Right child of (' + this.key + ',' + this.value + ') is red'\n      );\n    }\n    const blackDepth = this.left.check_();\n    if (blackDepth !== this.right.check_()) {\n      throw new Error('Black depths differ');\n    } else {\n      return blackDepth + (this.isRed_() ? 0 : 1);\n    }\n  }\n}\n\n/**\n * Represents an empty node (a leaf node in the Red-Black Tree).\n */\nexport class LLRBEmptyNode<K, V> {\n  key: K;\n  value: V;\n  left: LLRBNode<K, V> | LLRBEmptyNode<K, V>;\n  right: LLRBNode<K, V> | LLRBEmptyNode<K, V>;\n  color: boolean;\n\n  /**\n   * Returns a copy of the current node.\n   *\n   * @returns The node copy.\n   */\n  copy(\n    key: K | null,\n    value: V | null,\n    color: boolean | null,\n    left: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null,\n    right: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null\n  ): LLRBEmptyNode<K, V> {\n    return this;\n  }\n\n  /**\n   * Returns a copy of the tree, with the specified key/value added.\n   *\n   * @param key - Key to be added.\n   * @param value - Value to be added.\n   * @param comparator - Comparator.\n   * @returns New tree, with item added.\n   */\n  insert(key: K, value: V, comparator: Comparator<K>): LLRBNode<K, V> {\n    return new LLRBNode(key, value, null);\n  }\n\n  /**\n   * Returns a copy of the tree, with the specified key removed.\n   *\n   * @param key - The key to remove.\n   * @param comparator - Comparator.\n   * @returns New tree, with item removed.\n   */\n  remove(key: K, comparator: Comparator<K>): LLRBEmptyNode<K, V> {\n    return this;\n  }\n\n  /**\n   * @returns The total number of nodes in the tree.\n   */\n  count(): number {\n    return 0;\n  }\n\n  /**\n   * @returns True if the tree is empty.\n   */\n  isEmpty(): boolean {\n    return true;\n  }\n\n  /**\n   * Traverses the tree in key order and calls the specified action function\n   * for each node.\n   *\n   * @param action - Callback function to be called for each\n   * node.  If it returns true, traversal is aborted.\n   * @returns True if traversal was aborted.\n   */\n  inorderTraversal(action: (k: K, v: V) => unknown): boolean {\n    return false;\n  }\n\n  /**\n   * Traverses the tree in reverse key order and calls the specified action function\n   * for each node.\n   *\n   * @param action - Callback function to be called for each\n   * node.  If it returns true, traversal is aborted.\n   * @returns True if traversal was aborted.\n   */\n  reverseTraversal(action: (k: K, v: V) => void): boolean {\n    return false;\n  }\n\n  minKey(): null {\n    return null;\n  }\n\n  maxKey(): null {\n    return null;\n  }\n\n  check_(): number {\n    return 0;\n  }\n\n  /**\n   * @returns Whether this node is red.\n   */\n  isRed_() {\n    return false;\n  }\n}\n\n/**\n * An immutable sorted map implementation, based on a Left-leaning Red-Black\n * tree.\n */\nexport class SortedMap<K, V> {\n  /**\n   * Always use the same empty node, to reduce memory.\n   */\n  static EMPTY_NODE = new LLRBEmptyNode();\n\n  /**\n   * @param comparator_ - Key comparator.\n   * @param root_ - Optional root node for the map.\n   */\n  constructor(\n    private comparator_: Comparator<K>,\n    private root_:\n      | LLRBNode<K, V>\n      | LLRBEmptyNode<K, V> = SortedMap.EMPTY_NODE as LLRBEmptyNode<K, V>\n  ) {}\n\n  /**\n   * Returns a copy of the map, with the specified key/value added or replaced.\n   * (TODO: We should perhaps rename this method to 'put')\n   *\n   * @param key - Key to be added.\n   * @param value - Value to be added.\n   * @returns New map, with item added.\n   */\n  insert(key: K, value: V): SortedMap<K, V> {\n    return new SortedMap(\n      this.comparator_,\n      this.root_\n        .insert(key, value, this.comparator_)\n        .copy(null, null, LLRBNode.BLACK, null, null)\n    );\n  }\n\n  /**\n   * Returns a copy of the map, with the specified key removed.\n   *\n   * @param key - The key to remove.\n   * @returns New map, with item removed.\n   */\n  remove(key: K): SortedMap<K, V> {\n    return new SortedMap(\n      this.comparator_,\n      this.root_\n        .remove(key, this.comparator_)\n        .copy(null, null, LLRBNode.BLACK, null, null)\n    );\n  }\n\n  /**\n   * Returns the value of the node with the given key, or null.\n   *\n   * @param key - The key to look up.\n   * @returns The value of the node with the given key, or null if the\n   * key doesn't exist.\n   */\n  get(key: K): V | null {\n    let cmp;\n    let node = this.root_;\n    while (!node.isEmpty()) {\n      cmp = this.comparator_(key, node.key);\n      if (cmp === 0) {\n        return node.value;\n      } else if (cmp < 0) {\n        node = node.left;\n      } else if (cmp > 0) {\n        node = node.right;\n      }\n    }\n    return null;\n  }\n\n  /**\n   * Returns the key of the item *before* the specified key, or null if key is the first item.\n   * @param key - The key to find the predecessor of\n   * @returns The predecessor key.\n   */\n  getPredecessorKey(key: K): K | null {\n    let cmp,\n      node = this.root_,\n      rightParent = null;\n    while (!node.isEmpty()) {\n      cmp = this.comparator_(key, node.key);\n      if (cmp === 0) {\n        if (!node.left.isEmpty()) {\n          node = node.left;\n          while (!node.right.isEmpty()) {\n            node = node.right;\n          }\n          return node.key;\n        } else if (rightParent) {\n          return rightParent.key;\n        } else {\n          return null; // first item.\n        }\n      } else if (cmp < 0) {\n        node = node.left;\n      } else if (cmp > 0) {\n        rightParent = node;\n        node = node.right;\n      }\n    }\n\n    throw new Error(\n      'Attempted to find predecessor key for a nonexistent key.  What gives?'\n    );\n  }\n\n  /**\n   * @returns True if the map is empty.\n   */\n  isEmpty(): boolean {\n    return this.root_.isEmpty();\n  }\n\n  /**\n   * @returns The total number of nodes in the map.\n   */\n  count(): number {\n    return this.root_.count();\n  }\n\n  /**\n   * @returns The minimum key in the map.\n   */\n  minKey(): K | null {\n    return this.root_.minKey();\n  }\n\n  /**\n   * @returns The maximum key in the map.\n   */\n  maxKey(): K | null {\n    return this.root_.maxKey();\n  }\n\n  /**\n   * Traverses the map in key order and calls the specified action function\n   * for each key/value pair.\n   *\n   * @param action - Callback function to be called\n   * for each key/value pair.  If action returns true, traversal is aborted.\n   * @returns The first truthy value returned by action, or the last falsey\n   *   value returned by action\n   */\n  inorderTraversal(action: (k: K, v: V) => unknown): boolean {\n    return this.root_.inorderTraversal(action);\n  }\n\n  /**\n   * Traverses the map in reverse key order and calls the specified action function\n   * for each key/value pair.\n   *\n   * @param action - Callback function to be called\n   * for each key/value pair.  If action returns true, traversal is aborted.\n   * @returns True if the traversal was aborted.\n   */\n  reverseTraversal(action: (k: K, v: V) => void): boolean {\n    return this.root_.reverseTraversal(action);\n  }\n\n  /**\n   * Returns an iterator over the SortedMap.\n   * @returns The iterator.\n   */\n  getIterator<T>(\n    resultGenerator?: (k: K, v: V) => T\n  ): SortedMapIterator<K, V, T> {\n    return new SortedMapIterator(\n      this.root_,\n      null,\n      this.comparator_,\n      false,\n      resultGenerator\n    );\n  }\n\n  getIteratorFrom<T>(\n    key: K,\n    resultGenerator?: (k: K, v: V) => T\n  ): SortedMapIterator<K, V, T> {\n    return new SortedMapIterator(\n      this.root_,\n      key,\n      this.comparator_,\n      false,\n      resultGenerator\n    );\n  }\n\n  getReverseIteratorFrom<T>(\n    key: K,\n    resultGenerator?: (k: K, v: V) => T\n  ): SortedMapIterator<K, V, T> {\n    return new SortedMapIterator(\n      this.root_,\n      key,\n      this.comparator_,\n      true,\n      resultGenerator\n    );\n  }\n\n  getReverseIterator<T>(\n    resultGenerator?: (k: K, v: V) => T\n  ): SortedMapIterator<K, V, T> {\n    return new SortedMapIterator(\n      this.root_,\n      null,\n      this.comparator_,\n      true,\n      resultGenerator\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { nameCompare } from '../util/util';\n\nimport { NamedNode } from './Node';\n\nexport function NAME_ONLY_COMPARATOR(left: NamedNode, right: NamedNode) {\n  return nameCompare(left.name, right.name);\n}\n\nexport function NAME_COMPARATOR(left: string, right: string) {\n  return nameCompare(left, right);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert, contains } from '@firebase/util';\n\nimport { Indexable } from '../util/misc';\nimport { doubleToIEEE754String } from '../util/util';\n\nimport { Node } from './Node';\n\nlet MAX_NODE: Node;\n\nexport function setMaxNode(val: Node) {\n  MAX_NODE = val;\n}\n\nexport const priorityHashText = function (priority: string | number): string {\n  if (typeof priority === 'number') {\n    return 'number:' + doubleToIEEE754String(priority);\n  } else {\n    return 'string:' + priority;\n  }\n};\n\n/**\n * Validates that a priority snapshot Node is valid.\n */\nexport const validatePriorityNode = function (priorityNode: Node) {\n  if (priorityNode.isLeafNode()) {\n    const val = priorityNode.val();\n    assert(\n      typeof val === 'string' ||\n        typeof val === 'number' ||\n        (typeof val === 'object' && contains(val as Indexable, '.sv')),\n      'Priority must be a string or number.'\n    );\n  } else {\n    assert(\n      priorityNode === MAX_NODE || priorityNode.isEmpty(),\n      'priority of unexpected type.'\n    );\n  }\n  // Don't call getPriority() on MAX_NODE to avoid hitting assertion.\n  assert(\n    priorityNode === MAX_NODE || priorityNode.getPriority().isEmpty(),\n    \"Priority nodes can't have a priority of their own.\"\n  );\n};\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { Indexable } from '../util/misc';\nimport {\n  Path,\n  pathGetFront,\n  pathGetLength,\n  pathIsEmpty,\n  pathPopFront\n} from '../util/Path';\nimport { doubleToIEEE754String, sha1 } from '../util/util';\n\nimport { ChildrenNodeConstructor } from './ChildrenNode';\nimport { Index } from './indexes/Index';\nimport { Node } from './Node';\nimport { priorityHashText, validatePriorityNode } from './snap';\n\nlet __childrenNodeConstructor: ChildrenNodeConstructor;\n\n/**\n * LeafNode is a class for storing leaf nodes in a DataSnapshot.  It\n * implements Node and stores the value of the node (a string,\n * number, or boolean) accessible via getValue().\n */\nexport class LeafNode implements Node {\n  static set __childrenNodeConstructor(val: ChildrenNodeConstructor) {\n    __childrenNodeConstructor = val;\n  }\n\n  static get __childrenNodeConstructor() {\n    return __childrenNodeConstructor;\n  }\n\n  /**\n   * The sort order for comparing leaf nodes of different types. If two leaf nodes have\n   * the same type, the comparison falls back to their value\n   */\n  static VALUE_TYPE_ORDER = ['object', 'boolean', 'number', 'string'];\n\n  private lazyHash_: string | null = null;\n\n  /**\n   * @param value_ - The value to store in this leaf node. The object type is\n   * possible in the event of a deferred value\n   * @param priorityNode_ - The priority of this node.\n   */\n  constructor(\n    private readonly value_: string | number | boolean | Indexable,\n    private priorityNode_: Node = LeafNode.__childrenNodeConstructor.EMPTY_NODE\n  ) {\n    assert(\n      this.value_ !== undefined && this.value_ !== null,\n      \"LeafNode shouldn't be created with null/undefined value.\"\n    );\n\n    validatePriorityNode(this.priorityNode_);\n  }\n\n  /** @inheritDoc */\n  isLeafNode(): boolean {\n    return true;\n  }\n\n  /** @inheritDoc */\n  getPriority(): Node {\n    return this.priorityNode_;\n  }\n\n  /** @inheritDoc */\n  updatePriority(newPriorityNode: Node): Node {\n    return new LeafNode(this.value_, newPriorityNode);\n  }\n\n  /** @inheritDoc */\n  getImmediateChild(childName: string): Node {\n    // Hack to treat priority as a regular child\n    if (childName === '.priority') {\n      return this.priorityNode_;\n    } else {\n      return LeafNode.__childrenNodeConstructor.EMPTY_NODE;\n    }\n  }\n\n  /** @inheritDoc */\n  getChild(path: Path): Node {\n    if (pathIsEmpty(path)) {\n      return this;\n    } else if (pathGetFront(path) === '.priority') {\n      return this.priorityNode_;\n    } else {\n      return LeafNode.__childrenNodeConstructor.EMPTY_NODE;\n    }\n  }\n  hasChild(): boolean {\n    return false;\n  }\n\n  /** @inheritDoc */\n  getPredecessorChildName(childName: string, childNode: Node): null {\n    return null;\n  }\n\n  /** @inheritDoc */\n  updateImmediateChild(childName: string, newChildNode: Node): Node {\n    if (childName === '.priority') {\n      return this.updatePriority(newChildNode);\n    } else if (newChildNode.isEmpty() && childName !== '.priority') {\n      return this;\n    } else {\n      return LeafNode.__childrenNodeConstructor.EMPTY_NODE.updateImmediateChild(\n        childName,\n        newChildNode\n      ).updatePriority(this.priorityNode_);\n    }\n  }\n\n  /** @inheritDoc */\n  updateChild(path: Path, newChildNode: Node): Node {\n    const front = pathGetFront(path);\n    if (front === null) {\n      return newChildNode;\n    } else if (newChildNode.isEmpty() && front !== '.priority') {\n      return this;\n    } else {\n      assert(\n        front !== '.priority' || pathGetLength(path) === 1,\n        '.priority must be the last token in a path'\n      );\n\n      return this.updateImmediateChild(\n        front,\n        LeafNode.__childrenNodeConstructor.EMPTY_NODE.updateChild(\n          pathPopFront(path),\n          newChildNode\n        )\n      );\n    }\n  }\n\n  /** @inheritDoc */\n  isEmpty(): boolean {\n    return false;\n  }\n\n  /** @inheritDoc */\n  numChildren(): number {\n    return 0;\n  }\n\n  /** @inheritDoc */\n  forEachChild(index: Index, action: (s: string, n: Node) => void): boolean {\n    return false;\n  }\n  val(exportFormat?: boolean): {} {\n    if (exportFormat && !this.getPriority().isEmpty()) {\n      return {\n        '.value': this.getValue(),\n        '.priority': this.getPriority().val()\n      };\n    } else {\n      return this.getValue();\n    }\n  }\n\n  /** @inheritDoc */\n  hash(): string {\n    if (this.lazyHash_ === null) {\n      let toHash = '';\n      if (!this.priorityNode_.isEmpty()) {\n        toHash +=\n          'priority:' +\n          priorityHashText(this.priorityNode_.val() as number | string) +\n          ':';\n      }\n\n      const type = typeof this.value_;\n      toHash += type + ':';\n      if (type === 'number') {\n        toHash += doubleToIEEE754String(this.value_ as number);\n      } else {\n        toHash += this.value_;\n      }\n      this.lazyHash_ = sha1(toHash);\n    }\n    return this.lazyHash_;\n  }\n\n  /**\n   * Returns the value of the leaf node.\n   * @returns The value of the node.\n   */\n  getValue(): Indexable | string | number | boolean {\n    return this.value_;\n  }\n  compareTo(other: Node): number {\n    if (other === LeafNode.__childrenNodeConstructor.EMPTY_NODE) {\n      return 1;\n    } else if (other instanceof LeafNode.__childrenNodeConstructor) {\n      return -1;\n    } else {\n      assert(other.isLeafNode(), 'Unknown node type');\n      return this.compareToLeafNode_(other as LeafNode);\n    }\n  }\n\n  /**\n   * Comparison specifically for two leaf nodes\n   */\n  private compareToLeafNode_(otherLeaf: LeafNode): number {\n    const otherLeafType = typeof otherLeaf.value_;\n    const thisLeafType = typeof this.value_;\n    const otherIndex = LeafNode.VALUE_TYPE_ORDER.indexOf(otherLeafType);\n    const thisIndex = LeafNode.VALUE_TYPE_ORDER.indexOf(thisLeafType);\n    assert(otherIndex >= 0, 'Unknown leaf type: ' + otherLeafType);\n    assert(thisIndex >= 0, 'Unknown leaf type: ' + thisLeafType);\n    if (otherIndex === thisIndex) {\n      // Same type, compare values\n      if (thisLeafType === 'object') {\n        // Deferred value nodes are all equal, but we should also never get to this point...\n        return 0;\n      } else {\n        // Note that this works because true > false, all others are number or string comparisons\n        if (this.value_ < otherLeaf.value_) {\n          return -1;\n        } else if (this.value_ === otherLeaf.value_) {\n          return 0;\n        } else {\n          return 1;\n        }\n      }\n    } else {\n      return thisIndex - otherIndex;\n    }\n  }\n  withIndex(): Node {\n    return this;\n  }\n  isIndexed(): boolean {\n    return true;\n  }\n  equals(other: Node): boolean {\n    if (other === this) {\n      return true;\n    } else if (other.isLeafNode()) {\n      const otherLeaf = other as LeafNode;\n      return (\n        this.value_ === otherLeaf.value_ &&\n        this.priorityNode_.equals(otherLeaf.priorityNode_)\n      );\n    } else {\n      return false;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { nameCompare, MAX_NAME } from '../../util/util';\nimport { LeafNode } from '../LeafNode';\nimport { NamedNode, Node } from '../Node';\n\nimport { Index } from './Index';\n\nlet nodeFromJSON: (a: unknown) => Node;\nlet MAX_NODE: Node;\n\nexport function setNodeFromJSON(val: (a: unknown) => Node) {\n  nodeFromJSON = val;\n}\n\nexport function setMaxNode(val: Node) {\n  MAX_NODE = val;\n}\n\nexport class PriorityIndex extends Index {\n  compare(a: NamedNode, b: NamedNode): number {\n    const aPriority = a.node.getPriority();\n    const bPriority = b.node.getPriority();\n    const indexCmp = aPriority.compareTo(bPriority);\n    if (indexCmp === 0) {\n      return nameCompare(a.name, b.name);\n    } else {\n      return indexCmp;\n    }\n  }\n  isDefinedOn(node: Node): boolean {\n    return !node.getPriority().isEmpty();\n  }\n  indexedValueChanged(oldNode: Node, newNode: Node): boolean {\n    return !oldNode.getPriority().equals(newNode.getPriority());\n  }\n  minPost(): NamedNode {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return (NamedNode as any).MIN;\n  }\n  maxPost(): NamedNode {\n    return new NamedNode(MAX_NAME, new LeafNode('[PRIORITY-POST]', MAX_NODE));\n  }\n\n  makePost(indexValue: unknown, name: string): NamedNode {\n    const priorityNode = nodeFromJSON(indexValue);\n    return new NamedNode(name, new LeafNode('[PRIORITY-POST]', priorityNode));\n  }\n\n  /**\n   * @returns String representation for inclusion in a query spec\n   */\n  toString(): string {\n    return '.priority';\n  }\n}\n\nexport const PRIORITY_INDEX = new PriorityIndex();\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { LLRBNode, SortedMap } from '../util/SortedMap';\n\nimport { NamedNode } from './Node';\n\nconst LOG_2 = Math.log(2);\n\nclass Base12Num {\n  count: number;\n  private current_: number;\n  private bits_: number;\n\n  constructor(length: number) {\n    const logBase2 = (num: number) =>\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      parseInt((Math.log(num) / LOG_2) as any, 10);\n    const bitMask = (bits: number) => parseInt(Array(bits + 1).join('1'), 2);\n    this.count = logBase2(length + 1);\n    this.current_ = this.count - 1;\n    const mask = bitMask(this.count);\n    this.bits_ = (length + 1) & mask;\n  }\n\n  nextBitIsOne(): boolean {\n    //noinspection JSBitwiseOperatorUsage\n    const result = !(this.bits_ & (0x1 << this.current_));\n    this.current_--;\n    return result;\n  }\n}\n\n/**\n * Takes a list of child nodes and constructs a SortedSet using the given comparison\n * function\n *\n * Uses the algorithm described in the paper linked here:\n * http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.1458\n *\n * @param childList - Unsorted list of children\n * @param cmp - The comparison method to be used\n * @param keyFn - An optional function to extract K from a node wrapper, if K's\n * type is not NamedNode\n * @param mapSortFn - An optional override for comparator used by the generated sorted map\n */\nexport const buildChildSet = function <K, V>(\n  childList: NamedNode[],\n  cmp: (a: NamedNode, b: NamedNode) => number,\n  keyFn?: (a: NamedNode) => K,\n  mapSortFn?: (a: K, b: K) => number\n): SortedMap<K, V> {\n  childList.sort(cmp);\n\n  const buildBalancedTree = function (\n    low: number,\n    high: number\n  ): LLRBNode<K, V> | null {\n    const length = high - low;\n    let namedNode: NamedNode;\n    let key: K;\n    if (length === 0) {\n      return null;\n    } else if (length === 1) {\n      namedNode = childList[low];\n      key = keyFn ? keyFn(namedNode) : (namedNode as unknown as K);\n      return new LLRBNode(\n        key,\n        namedNode.node as unknown as V,\n        LLRBNode.BLACK,\n        null,\n        null\n      );\n    } else {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      const middle = parseInt((length / 2) as any, 10) + low;\n      const left = buildBalancedTree(low, middle);\n      const right = buildBalancedTree(middle + 1, high);\n      namedNode = childList[middle];\n      key = keyFn ? keyFn(namedNode) : (namedNode as unknown as K);\n      return new LLRBNode(\n        key,\n        namedNode.node as unknown as V,\n        LLRBNode.BLACK,\n        left,\n        right\n      );\n    }\n  };\n\n  const buildFrom12Array = function (base12: Base12Num): LLRBNode<K, V> {\n    let node: LLRBNode<K, V> = null;\n    let root = null;\n    let index = childList.length;\n\n    const buildPennant = function (chunkSize: number, color: boolean) {\n      const low = index - chunkSize;\n      const high = index;\n      index -= chunkSize;\n      const childTree = buildBalancedTree(low + 1, high);\n      const namedNode = childList[low];\n      const key: K = keyFn ? keyFn(namedNode) : (namedNode as unknown as K);\n      attachPennant(\n        new LLRBNode(\n          key,\n          namedNode.node as unknown as V,\n          color,\n          null,\n          childTree\n        )\n      );\n    };\n\n    const attachPennant = function (pennant: LLRBNode<K, V>) {\n      if (node) {\n        node.left = pennant;\n        node = pennant;\n      } else {\n        root = pennant;\n        node = pennant;\n      }\n    };\n\n    for (let i = 0; i < base12.count; ++i) {\n      const isOne = base12.nextBitIsOne();\n      // The number of nodes taken in each slice is 2^(arr.length - (i + 1))\n      const chunkSize = Math.pow(2, base12.count - (i + 1));\n      if (isOne) {\n        buildPennant(chunkSize, LLRBNode.BLACK);\n      } else {\n        // current == 2\n        buildPennant(chunkSize, LLRBNode.BLACK);\n        buildPennant(chunkSize, LLRBNode.RED);\n      }\n    }\n    return root;\n  };\n\n  const base12 = new Base12Num(childList.length);\n  const root = buildFrom12Array(base12);\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  return new SortedMap<K, V>(mapSortFn || (cmp as any), root);\n};\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert, contains, map, safeGet } from '@firebase/util';\n\nimport { SortedMap } from '../util/SortedMap';\n\nimport { buildChildSet } from './childSet';\nimport { Index } from './indexes/Index';\nimport { KEY_INDEX } from './indexes/KeyIndex';\nimport { PRIORITY_INDEX } from './indexes/PriorityIndex';\nimport { NamedNode, Node } from './Node';\n\nlet _defaultIndexMap: IndexMap;\n\nconst fallbackObject = {};\n\nexport class IndexMap {\n  /**\n   * The default IndexMap for nodes without a priority\n   */\n  static get Default(): IndexMap {\n    assert(\n      fallbackObject && PRIORITY_INDEX,\n      'ChildrenNode.ts has not been loaded'\n    );\n    _defaultIndexMap =\n      _defaultIndexMap ||\n      new IndexMap(\n        { '.priority': fallbackObject },\n        { '.priority': PRIORITY_INDEX }\n      );\n    return _defaultIndexMap;\n  }\n\n  constructor(\n    private indexes_: {\n      [k: string]: SortedMap<NamedNode, Node> | /*FallbackType*/ object;\n    },\n    private indexSet_: { [k: string]: Index }\n  ) {}\n\n  get(indexKey: string): SortedMap<NamedNode, Node> | null {\n    const sortedMap = safeGet(this.indexes_, indexKey);\n    if (!sortedMap) {\n      throw new Error('No index defined for ' + indexKey);\n    }\n\n    if (sortedMap instanceof SortedMap) {\n      return sortedMap;\n    } else {\n      // The index exists, but it falls back to just name comparison. Return null so that the calling code uses the\n      // regular child map\n      return null;\n    }\n  }\n\n  hasIndex(indexDefinition: Index): boolean {\n    return contains(this.indexSet_, indexDefinition.toString());\n  }\n\n  addIndex(\n    indexDefinition: Index,\n    existingChildren: SortedMap<string, Node>\n  ): IndexMap {\n    assert(\n      indexDefinition !== KEY_INDEX,\n      \"KeyIndex always exists and isn't meant to be added to the IndexMap.\"\n    );\n    const childList = [];\n    let sawIndexedValue = false;\n    const iter = existingChildren.getIterator(NamedNode.Wrap);\n    let next = iter.getNext();\n    while (next) {\n      sawIndexedValue =\n        sawIndexedValue || indexDefinition.isDefinedOn(next.node);\n      childList.push(next);\n      next = iter.getNext();\n    }\n    let newIndex;\n    if (sawIndexedValue) {\n      newIndex = buildChildSet(childList, indexDefinition.getCompare());\n    } else {\n      newIndex = fallbackObject;\n    }\n    const indexName = indexDefinition.toString();\n    const newIndexSet = { ...this.indexSet_ };\n    newIndexSet[indexName] = indexDefinition;\n    const newIndexes = { ...this.indexes_ };\n    newIndexes[indexName] = newIndex;\n    return new IndexMap(newIndexes, newIndexSet);\n  }\n\n  /**\n   * Ensure that this node is properly tracked in any indexes that we're maintaining\n   */\n  addToIndexes(\n    namedNode: NamedNode,\n    existingChildren: SortedMap<string, Node>\n  ): IndexMap {\n    const newIndexes = map(\n      this.indexes_,\n      (indexedChildren: SortedMap<NamedNode, Node>, indexName: string) => {\n        const index = safeGet(this.indexSet_, indexName);\n        assert(index, 'Missing index implementation for ' + indexName);\n        if (indexedChildren === fallbackObject) {\n          // Check to see if we need to index everything\n          if (index.isDefinedOn(namedNode.node)) {\n            // We need to build this index\n            const childList = [];\n            const iter = existingChildren.getIterator(NamedNode.Wrap);\n            let next = iter.getNext();\n            while (next) {\n              if (next.name !== namedNode.name) {\n                childList.push(next);\n              }\n              next = iter.getNext();\n            }\n            childList.push(namedNode);\n            return buildChildSet(childList, index.getCompare());\n          } else {\n            // No change, this remains a fallback\n            return fallbackObject;\n          }\n        } else {\n          const existingSnap = existingChildren.get(namedNode.name);\n          let newChildren = indexedChildren;\n          if (existingSnap) {\n            newChildren = newChildren.remove(\n              new NamedNode(namedNode.name, existingSnap)\n            );\n          }\n          return newChildren.insert(namedNode, namedNode.node);\n        }\n      }\n    );\n    return new IndexMap(newIndexes, this.indexSet_);\n  }\n\n  /**\n   * Create a new IndexMap instance with the given value removed\n   */\n  removeFromIndexes(\n    namedNode: NamedNode,\n    existingChildren: SortedMap<string, Node>\n  ): IndexMap {\n    const newIndexes = map(\n      this.indexes_,\n      (indexedChildren: SortedMap<NamedNode, Node>) => {\n        if (indexedChildren === fallbackObject) {\n          // This is the fallback. Just return it, nothing to do in this case\n          return indexedChildren;\n        } else {\n          const existingSnap = existingChildren.get(namedNode.name);\n          if (existingSnap) {\n            return indexedChildren.remove(\n              new NamedNode(namedNode.name, existingSnap)\n            );\n          } else {\n            // No record of this child\n            return indexedChildren;\n          }\n        }\n      }\n    );\n    return new IndexMap(newIndexes, this.indexSet_);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { Path, pathGetFront, pathGetLength, pathPopFront } from '../util/Path';\nimport { SortedMap, SortedMapIterator } from '../util/SortedMap';\nimport { MAX_NAME, MIN_NAME, sha1 } from '../util/util';\n\nimport { NAME_COMPARATOR } from './comparators';\nimport { Index } from './indexes/Index';\nimport { KEY_INDEX, KeyIndex } from './indexes/KeyIndex';\nimport {\n  PRIORITY_INDEX,\n  setMaxNode as setPriorityMaxNode\n} from './indexes/PriorityIndex';\nimport { IndexMap } from './IndexMap';\nimport { LeafNode } from './LeafNode';\nimport { NamedNode, Node } from './Node';\nimport { priorityHashText, setMaxNode, validatePriorityNode } from './snap';\n\nexport interface ChildrenNodeConstructor {\n  new (\n    children_: SortedMap<string, Node>,\n    priorityNode_: Node | null,\n    indexMap_: IndexMap\n  ): ChildrenNode;\n  EMPTY_NODE: ChildrenNode;\n}\n\n// TODO: For memory savings, don't store priorityNode_ if it's empty.\n\nlet EMPTY_NODE: ChildrenNode;\n\n/**\n * ChildrenNode is a class for storing internal nodes in a DataSnapshot\n * (i.e. nodes with children).  It implements Node and stores the\n * list of children in the children property, sorted by child name.\n */\nexport class ChildrenNode implements Node {\n  private lazyHash_: string | null = null;\n\n  static get EMPTY_NODE(): ChildrenNode {\n    return (\n      EMPTY_NODE ||\n      (EMPTY_NODE = new ChildrenNode(\n        new SortedMap<string, Node>(NAME_COMPARATOR),\n        null,\n        IndexMap.Default\n      ))\n    );\n  }\n\n  /**\n   * @param children_ - List of children of this node..\n   * @param priorityNode_ - The priority of this node (as a snapshot node).\n   */\n  constructor(\n    private readonly children_: SortedMap<string, Node>,\n    private readonly priorityNode_: Node | null,\n    private indexMap_: IndexMap\n  ) {\n    /**\n     * Note: The only reason we allow null priority is for EMPTY_NODE, since we can't use\n     * EMPTY_NODE as the priority of EMPTY_NODE.  We might want to consider making EMPTY_NODE its own\n     * class instead of an empty ChildrenNode.\n     */\n    if (this.priorityNode_) {\n      validatePriorityNode(this.priorityNode_);\n    }\n\n    if (this.children_.isEmpty()) {\n      assert(\n        !this.priorityNode_ || this.priorityNode_.isEmpty(),\n        'An empty node cannot have a priority'\n      );\n    }\n  }\n\n  /** @inheritDoc */\n  isLeafNode(): boolean {\n    return false;\n  }\n\n  /** @inheritDoc */\n  getPriority(): Node {\n    return this.priorityNode_ || EMPTY_NODE;\n  }\n\n  /** @inheritDoc */\n  updatePriority(newPriorityNode: Node): Node {\n    if (this.children_.isEmpty()) {\n      // Don't allow priorities on empty nodes\n      return this;\n    } else {\n      return new ChildrenNode(this.children_, newPriorityNode, this.indexMap_);\n    }\n  }\n\n  /** @inheritDoc */\n  getImmediateChild(childName: string): Node {\n    // Hack to treat priority as a regular child\n    if (childName === '.priority') {\n      return this.getPriority();\n    } else {\n      const child = this.children_.get(childName);\n      return child === null ? EMPTY_NODE : child;\n    }\n  }\n\n  /** @inheritDoc */\n  getChild(path: Path): Node {\n    const front = pathGetFront(path);\n    if (front === null) {\n      return this;\n    }\n\n    return this.getImmediateChild(front).getChild(pathPopFront(path));\n  }\n\n  /** @inheritDoc */\n  hasChild(childName: string): boolean {\n    return this.children_.get(childName) !== null;\n  }\n\n  /** @inheritDoc */\n  updateImmediateChild(childName: string, newChildNode: Node): Node {\n    assert(newChildNode, 'We should always be passing snapshot nodes');\n    if (childName === '.priority') {\n      return this.updatePriority(newChildNode);\n    } else {\n      const namedNode = new NamedNode(childName, newChildNode);\n      let newChildren, newIndexMap;\n      if (newChildNode.isEmpty()) {\n        newChildren = this.children_.remove(childName);\n        newIndexMap = this.indexMap_.removeFromIndexes(\n          namedNode,\n          this.children_\n        );\n      } else {\n        newChildren = this.children_.insert(childName, newChildNode);\n        newIndexMap = this.indexMap_.addToIndexes(namedNode, this.children_);\n      }\n\n      const newPriority = newChildren.isEmpty()\n        ? EMPTY_NODE\n        : this.priorityNode_;\n      return new ChildrenNode(newChildren, newPriority, newIndexMap);\n    }\n  }\n\n  /** @inheritDoc */\n  updateChild(path: Path, newChildNode: Node): Node {\n    const front = pathGetFront(path);\n    if (front === null) {\n      return newChildNode;\n    } else {\n      assert(\n        pathGetFront(path) !== '.priority' || pathGetLength(path) === 1,\n        '.priority must be the last token in a path'\n      );\n      const newImmediateChild = this.getImmediateChild(front).updateChild(\n        pathPopFront(path),\n        newChildNode\n      );\n      return this.updateImmediateChild(front, newImmediateChild);\n    }\n  }\n\n  /** @inheritDoc */\n  isEmpty(): boolean {\n    return this.children_.isEmpty();\n  }\n\n  /** @inheritDoc */\n  numChildren(): number {\n    return this.children_.count();\n  }\n\n  private static INTEGER_REGEXP_ = /^(0|[1-9]\\d*)$/;\n\n  /** @inheritDoc */\n  val(exportFormat?: boolean): object {\n    if (this.isEmpty()) {\n      return null;\n    }\n\n    const obj: { [k: string]: unknown } = {};\n    let numKeys = 0,\n      maxKey = 0,\n      allIntegerKeys = true;\n    this.forEachChild(PRIORITY_INDEX, (key: string, childNode: Node) => {\n      obj[key] = childNode.val(exportFormat);\n\n      numKeys++;\n      if (allIntegerKeys && ChildrenNode.INTEGER_REGEXP_.test(key)) {\n        maxKey = Math.max(maxKey, Number(key));\n      } else {\n        allIntegerKeys = false;\n      }\n    });\n\n    if (!exportFormat && allIntegerKeys && maxKey < 2 * numKeys) {\n      // convert to array.\n      const array: unknown[] = [];\n      // eslint-disable-next-line guard-for-in\n      for (const key in obj) {\n        array[key as unknown as number] = obj[key];\n      }\n\n      return array;\n    } else {\n      if (exportFormat && !this.getPriority().isEmpty()) {\n        obj['.priority'] = this.getPriority().val();\n      }\n      return obj;\n    }\n  }\n\n  /** @inheritDoc */\n  hash(): string {\n    if (this.lazyHash_ === null) {\n      let toHash = '';\n      if (!this.getPriority().isEmpty()) {\n        toHash +=\n          'priority:' +\n          priorityHashText(this.getPriority().val() as string | number) +\n          ':';\n      }\n\n      this.forEachChild(PRIORITY_INDEX, (key, childNode) => {\n        const childHash = childNode.hash();\n        if (childHash !== '') {\n          toHash += ':' + key + ':' + childHash;\n        }\n      });\n\n      this.lazyHash_ = toHash === '' ? '' : sha1(toHash);\n    }\n    return this.lazyHash_;\n  }\n\n  /** @inheritDoc */\n  getPredecessorChildName(\n    childName: string,\n    childNode: Node,\n    index: Index\n  ): string {\n    const idx = this.resolveIndex_(index);\n    if (idx) {\n      const predecessor = idx.getPredecessorKey(\n        new NamedNode(childName, childNode)\n      );\n      return predecessor ? predecessor.name : null;\n    } else {\n      return this.children_.getPredecessorKey(childName);\n    }\n  }\n\n  getFirstChildName(indexDefinition: Index): string | null {\n    const idx = this.resolveIndex_(indexDefinition);\n    if (idx) {\n      const minKey = idx.minKey();\n      return minKey && minKey.name;\n    } else {\n      return this.children_.minKey();\n    }\n  }\n\n  getFirstChild(indexDefinition: Index): NamedNode | null {\n    const minKey = this.getFirstChildName(indexDefinition);\n    if (minKey) {\n      return new NamedNode(minKey, this.children_.get(minKey));\n    } else {\n      return null;\n    }\n  }\n\n  /**\n   * Given an index, return the key name of the largest value we have, according to that index\n   */\n  getLastChildName(indexDefinition: Index): string | null {\n    const idx = this.resolveIndex_(indexDefinition);\n    if (idx) {\n      const maxKey = idx.maxKey();\n      return maxKey && maxKey.name;\n    } else {\n      return this.children_.maxKey();\n    }\n  }\n\n  getLastChild(indexDefinition: Index): NamedNode | null {\n    const maxKey = this.getLastChildName(indexDefinition);\n    if (maxKey) {\n      return new NamedNode(maxKey, this.children_.get(maxKey));\n    } else {\n      return null;\n    }\n  }\n  forEachChild(\n    index: Index,\n    action: (key: string, node: Node) => boolean | void\n  ): boolean {\n    const idx = this.resolveIndex_(index);\n    if (idx) {\n      return idx.inorderTraversal(wrappedNode => {\n        return action(wrappedNode.name, wrappedNode.node);\n      });\n    } else {\n      return this.children_.inorderTraversal(action);\n    }\n  }\n\n  getIterator(\n    indexDefinition: Index\n  ): SortedMapIterator<string | NamedNode, Node, NamedNode> {\n    return this.getIteratorFrom(indexDefinition.minPost(), indexDefinition);\n  }\n\n  getIteratorFrom(\n    startPost: NamedNode,\n    indexDefinition: Index\n  ): SortedMapIterator<string | NamedNode, Node, NamedNode> {\n    const idx = this.resolveIndex_(indexDefinition);\n    if (idx) {\n      return idx.getIteratorFrom(startPost, key => key);\n    } else {\n      const iterator = this.children_.getIteratorFrom(\n        startPost.name,\n        NamedNode.Wrap\n      );\n      let next = iterator.peek();\n      while (next != null && indexDefinition.compare(next, startPost) < 0) {\n        iterator.getNext();\n        next = iterator.peek();\n      }\n      return iterator;\n    }\n  }\n\n  getReverseIterator(\n    indexDefinition: Index\n  ): SortedMapIterator<string | NamedNode, Node, NamedNode> {\n    return this.getReverseIteratorFrom(\n      indexDefinition.maxPost(),\n      indexDefinition\n    );\n  }\n\n  getReverseIteratorFrom(\n    endPost: NamedNode,\n    indexDefinition: Index\n  ): SortedMapIterator<string | NamedNode, Node, NamedNode> {\n    const idx = this.resolveIndex_(indexDefinition);\n    if (idx) {\n      return idx.getReverseIteratorFrom(endPost, key => {\n        return key;\n      });\n    } else {\n      const iterator = this.children_.getReverseIteratorFrom(\n        endPost.name,\n        NamedNode.Wrap\n      );\n      let next = iterator.peek();\n      while (next != null && indexDefinition.compare(next, endPost) > 0) {\n        iterator.getNext();\n        next = iterator.peek();\n      }\n      return iterator;\n    }\n  }\n  compareTo(other: ChildrenNode): number {\n    if (this.isEmpty()) {\n      if (other.isEmpty()) {\n        return 0;\n      } else {\n        return -1;\n      }\n    } else if (other.isLeafNode() || other.isEmpty()) {\n      return 1;\n    } else if (other === MAX_NODE) {\n      return -1;\n    } else {\n      // Must be another node with children.\n      return 0;\n    }\n  }\n  withIndex(indexDefinition: Index): Node {\n    if (\n      indexDefinition === KEY_INDEX ||\n      this.indexMap_.hasIndex(indexDefinition)\n    ) {\n      return this;\n    } else {\n      const newIndexMap = this.indexMap_.addIndex(\n        indexDefinition,\n        this.children_\n      );\n      return new ChildrenNode(this.children_, this.priorityNode_, newIndexMap);\n    }\n  }\n  isIndexed(index: Index): boolean {\n    return index === KEY_INDEX || this.indexMap_.hasIndex(index);\n  }\n  equals(other: Node): boolean {\n    if (other === this) {\n      return true;\n    } else if (other.isLeafNode()) {\n      return false;\n    } else {\n      const otherChildrenNode = other as ChildrenNode;\n      if (!this.getPriority().equals(otherChildrenNode.getPriority())) {\n        return false;\n      } else if (\n        this.children_.count() === otherChildrenNode.children_.count()\n      ) {\n        const thisIter = this.getIterator(PRIORITY_INDEX);\n        const otherIter = otherChildrenNode.getIterator(PRIORITY_INDEX);\n        let thisCurrent = thisIter.getNext();\n        let otherCurrent = otherIter.getNext();\n        while (thisCurrent && otherCurrent) {\n          if (\n            thisCurrent.name !== otherCurrent.name ||\n            !thisCurrent.node.equals(otherCurrent.node)\n          ) {\n            return false;\n          }\n          thisCurrent = thisIter.getNext();\n          otherCurrent = otherIter.getNext();\n        }\n        return thisCurrent === null && otherCurrent === null;\n      } else {\n        return false;\n      }\n    }\n  }\n\n  /**\n   * Returns a SortedMap ordered by index, or null if the default (by-key) ordering can be used\n   * instead.\n   *\n   */\n  private resolveIndex_(\n    indexDefinition: Index\n  ): SortedMap<NamedNode, Node> | null {\n    if (indexDefinition === KEY_INDEX) {\n      return null;\n    } else {\n      return this.indexMap_.get(indexDefinition.toString());\n    }\n  }\n}\n\nexport class MaxNode extends ChildrenNode {\n  constructor() {\n    super(\n      new SortedMap<string, Node>(NAME_COMPARATOR),\n      ChildrenNode.EMPTY_NODE,\n      IndexMap.Default\n    );\n  }\n\n  compareTo(other: Node): number {\n    if (other === this) {\n      return 0;\n    } else {\n      return 1;\n    }\n  }\n\n  equals(other: Node): boolean {\n    // Not that we every compare it, but MAX_NODE is only ever equal to itself\n    return other === this;\n  }\n\n  getPriority(): MaxNode {\n    return this;\n  }\n\n  getImmediateChild(childName: string): ChildrenNode {\n    return ChildrenNode.EMPTY_NODE;\n  }\n\n  isEmpty(): boolean {\n    return false;\n  }\n}\n\n/**\n * Marker that will sort higher than any other snapshot.\n */\nexport const MAX_NODE = new MaxNode();\n\n/**\n * Document NamedNode extensions\n */\ndeclare module './Node' {\n  interface NamedNode {\n    MIN: NamedNode;\n    MAX: NamedNode;\n  }\n}\n\nObject.defineProperties(NamedNode, {\n  MIN: {\n    value: new NamedNode(MIN_NAME, ChildrenNode.EMPTY_NODE)\n  },\n  MAX: {\n    value: new NamedNode(MAX_NAME, MAX_NODE)\n  }\n});\n\n/**\n * Reference Extensions\n */\nKeyIndex.__EMPTY_NODE = ChildrenNode.EMPTY_NODE;\nLeafNode.__childrenNodeConstructor = ChildrenNode;\nsetMaxNode(MAX_NODE);\nsetPriorityMaxNode(MAX_NODE);\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { contains, assert } from '@firebase/util';\n\nimport { Indexable } from '../util/misc';\nimport { SortedMap } from '../util/SortedMap';\nimport { each } from '../util/util';\n\nimport { ChildrenNode } from './ChildrenNode';\nimport { buildChildSet } from './childSet';\nimport { NAME_COMPARATOR, NAME_ONLY_COMPARATOR } from './comparators';\nimport { PRIORITY_INDEX, setNodeFromJSON } from './indexes/PriorityIndex';\nimport { IndexMap } from './IndexMap';\nimport { LeafNode } from './LeafNode';\nimport { NamedNode, Node } from './Node';\n\nconst USE_HINZE = true;\n\n/**\n * Constructs a snapshot node representing the passed JSON and returns it.\n * @param json - JSON to create a node for.\n * @param priority - Optional priority to use.  This will be ignored if the\n * passed JSON contains a .priority property.\n */\nexport function nodeFromJSON(\n  json: unknown | null,\n  priority: unknown = null\n): Node {\n  if (json === null) {\n    return ChildrenNode.EMPTY_NODE;\n  }\n\n  if (typeof json === 'object' && '.priority' in json) {\n    priority = json['.priority'];\n  }\n\n  assert(\n    priority === null ||\n      typeof priority === 'string' ||\n      typeof priority === 'number' ||\n      (typeof priority === 'object' && '.sv' in (priority as object)),\n    'Invalid priority type found: ' + typeof priority\n  );\n\n  if (typeof json === 'object' && '.value' in json && json['.value'] !== null) {\n    json = json['.value'];\n  }\n\n  // Valid leaf nodes include non-objects or server-value wrapper objects\n  if (typeof json !== 'object' || '.sv' in json) {\n    const jsonLeaf = json as string | number | boolean | Indexable;\n    return new LeafNode(jsonLeaf, nodeFromJSON(priority));\n  }\n\n  if (!(json instanceof Array) && USE_HINZE) {\n    const children: NamedNode[] = [];\n    let childrenHavePriority = false;\n    const hinzeJsonObj = json;\n    each(hinzeJsonObj, (key, child) => {\n      if (key.substring(0, 1) !== '.') {\n        // Ignore metadata nodes\n        const childNode = nodeFromJSON(child);\n        if (!childNode.isEmpty()) {\n          childrenHavePriority =\n            childrenHavePriority || !childNode.getPriority().isEmpty();\n          children.push(new NamedNode(key, childNode));\n        }\n      }\n    });\n\n    if (children.length === 0) {\n      return ChildrenNode.EMPTY_NODE;\n    }\n\n    const childSet = buildChildSet(\n      children,\n      NAME_ONLY_COMPARATOR,\n      namedNode => namedNode.name,\n      NAME_COMPARATOR\n    ) as SortedMap<string, Node>;\n    if (childrenHavePriority) {\n      const sortedChildSet = buildChildSet(\n        children,\n        PRIORITY_INDEX.getCompare()\n      );\n      return new ChildrenNode(\n        childSet,\n        nodeFromJSON(priority),\n        new IndexMap(\n          { '.priority': sortedChildSet },\n          { '.priority': PRIORITY_INDEX }\n        )\n      );\n    } else {\n      return new ChildrenNode(\n        childSet,\n        nodeFromJSON(priority),\n        IndexMap.Default\n      );\n    }\n  } else {\n    let node: Node = ChildrenNode.EMPTY_NODE;\n    each(json, (key: string, childData: unknown) => {\n      if (contains(json as object, key)) {\n        if (key.substring(0, 1) !== '.') {\n          // ignore metadata nodes.\n          const childNode = nodeFromJSON(childData);\n          if (childNode.isLeafNode() || !childNode.isEmpty()) {\n            node = node.updateImmediateChild(key, childNode);\n          }\n        }\n      }\n    });\n\n    return node.updatePriority(nodeFromJSON(priority));\n  }\n}\n\nsetNodeFromJSON(nodeFromJSON);\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { Path, pathGetFront, pathIsEmpty, pathSlice } from '../../util/Path';\nimport { MAX_NAME, nameCompare } from '../../util/util';\nimport { ChildrenNode, MAX_NODE } from '../ChildrenNode';\nimport { NamedNode, Node } from '../Node';\nimport { nodeFromJSON } from '../nodeFromJSON';\n\nimport { Index } from './Index';\n\nexport class PathIndex extends Index {\n  constructor(private indexPath_: Path) {\n    super();\n\n    assert(\n      !pathIsEmpty(indexPath_) && pathGetFront(indexPath_) !== '.priority',\n      \"Can't create PathIndex with empty path or .priority key\"\n    );\n  }\n\n  protected extractChild(snap: Node): Node {\n    return snap.getChild(this.indexPath_);\n  }\n  isDefinedOn(node: Node): boolean {\n    return !node.getChild(this.indexPath_).isEmpty();\n  }\n  compare(a: NamedNode, b: NamedNode): number {\n    const aChild = this.extractChild(a.node);\n    const bChild = this.extractChild(b.node);\n    const indexCmp = aChild.compareTo(bChild);\n    if (indexCmp === 0) {\n      return nameCompare(a.name, b.name);\n    } else {\n      return indexCmp;\n    }\n  }\n  makePost(indexValue: object, name: string): NamedNode {\n    const valueNode = nodeFromJSON(indexValue);\n    const node = ChildrenNode.EMPTY_NODE.updateChild(\n      this.indexPath_,\n      valueNode\n    );\n    return new NamedNode(name, node);\n  }\n  maxPost(): NamedNode {\n    const node = ChildrenNode.EMPTY_NODE.updateChild(this.indexPath_, MAX_NODE);\n    return new NamedNode(MAX_NAME, node);\n  }\n  toString(): string {\n    return pathSlice(this.indexPath_, 0).join('/');\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { nameCompare } from '../../util/util';\nimport { NamedNode, Node } from '../Node';\nimport { nodeFromJSON } from '../nodeFromJSON';\n\nimport { Index } from './Index';\n\nexport class ValueIndex extends Index {\n  compare(a: NamedNode, b: NamedNode): number {\n    const indexCmp = a.node.compareTo(b.node);\n    if (indexCmp === 0) {\n      return nameCompare(a.name, b.name);\n    } else {\n      return indexCmp;\n    }\n  }\n  isDefinedOn(node: Node): boolean {\n    return true;\n  }\n  indexedValueChanged(oldNode: Node, newNode: Node): boolean {\n    return !oldNode.equals(newNode);\n  }\n  minPost(): NamedNode {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return (NamedNode as any).MIN;\n  }\n  maxPost(): NamedNode {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return (NamedNode as any).MAX;\n  }\n\n  makePost(indexValue: object, name: string): NamedNode {\n    const valueNode = nodeFromJSON(indexValue);\n    return new NamedNode(name, valueNode);\n  }\n\n  /**\n   * @returns String representation for inclusion in a query spec\n   */\n  toString(): string {\n    return '.value';\n  }\n}\n\nexport const VALUE_INDEX = new ValueIndex();\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Node } from '../snap/Node';\n\nexport const enum ChangeType {\n  /** Event type for a child added */\n  CHILD_ADDED = 'child_added',\n  /** Event type for a child removed */\n  CHILD_REMOVED = 'child_removed',\n  /** Event type for a child changed */\n  CHILD_CHANGED = 'child_changed',\n  /** Event type for a child moved */\n  CHILD_MOVED = 'child_moved',\n  /** Event type for a value change */\n  VALUE = 'value'\n}\n\nexport interface Change {\n  /** @param type - The event type */\n  type: ChangeType;\n  /** @param snapshotNode - The data */\n  snapshotNode: Node;\n  /** @param childName - The name for this child, if it's a child even */\n  childName?: string;\n  /** @param oldSnap - Used for intermediate processing of child changed events */\n  oldSnap?: Node;\n  /**  * @param prevName - The name for the previous child, if applicable */\n  prevName?: string | null;\n}\n\nexport function changeValue(snapshotNode: Node): Change {\n  return { type: ChangeType.VALUE, snapshotNode };\n}\n\nexport function changeChildAdded(\n  childName: string,\n  snapshotNode: Node\n): Change {\n  return { type: ChangeType.CHILD_ADDED, snapshotNode, childName };\n}\n\nexport function changeChildRemoved(\n  childName: string,\n  snapshotNode: Node\n): Change {\n  return { type: ChangeType.CHILD_REMOVED, snapshotNode, childName };\n}\n\nexport function changeChildChanged(\n  childName: string,\n  snapshotNode: Node,\n  oldSnap: Node\n): Change {\n  return {\n    type: ChangeType.CHILD_CHANGED,\n    snapshotNode,\n    childName,\n    oldSnap\n  };\n}\n\nexport function changeChildMoved(\n  childName: string,\n  snapshotNode: Node\n): Change {\n  return { type: ChangeType.CHILD_MOVED, snapshotNode, childName };\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { ChildrenNode } from '../../snap/ChildrenNode';\nimport { Index } from '../../snap/indexes/Index';\nimport { PRIORITY_INDEX } from '../../snap/indexes/PriorityIndex';\nimport { Node } from '../../snap/Node';\nimport { Path } from '../../util/Path';\nimport {\n  changeChildAdded,\n  changeChildChanged,\n  changeChildRemoved\n} from '../Change';\nimport { ChildChangeAccumulator } from '../ChildChangeAccumulator';\nimport { CompleteChildSource } from '../CompleteChildSource';\n\nimport { NodeFilter } from './NodeFilter';\n\n/**\n * Doesn't really filter nodes but applies an index to the node and keeps track of any changes\n */\nexport class IndexedFilter implements NodeFilter {\n  constructor(private readonly index_: Index) {}\n\n  updateChild(\n    snap: Node,\n    key: string,\n    newChild: Node,\n    affectedPath: Path,\n    source: CompleteChildSource,\n    optChangeAccumulator: ChildChangeAccumulator | null\n  ): Node {\n    assert(\n      snap.isIndexed(this.index_),\n      'A node must be indexed if only a child is updated'\n    );\n    const oldChild = snap.getImmediateChild(key);\n    // Check if anything actually changed.\n    if (\n      oldChild.getChild(affectedPath).equals(newChild.getChild(affectedPath))\n    ) {\n      // There's an edge case where a child can enter or leave the view because affectedPath was set to null.\n      // In this case, affectedPath will appear null in both the old and new snapshots.  So we need\n      // to avoid treating these cases as \"nothing changed.\"\n      if (oldChild.isEmpty() === newChild.isEmpty()) {\n        // Nothing changed.\n\n        // This assert should be valid, but it's expensive (can dominate perf testing) so don't actually do it.\n        //assert(oldChild.equals(newChild), 'Old and new snapshots should be equal.');\n        return snap;\n      }\n    }\n\n    if (optChangeAccumulator != null) {\n      if (newChild.isEmpty()) {\n        if (snap.hasChild(key)) {\n          optChangeAccumulator.trackChildChange(\n            changeChildRemoved(key, oldChild)\n          );\n        } else {\n          assert(\n            snap.isLeafNode(),\n            'A child remove without an old child only makes sense on a leaf node'\n          );\n        }\n      } else if (oldChild.isEmpty()) {\n        optChangeAccumulator.trackChildChange(changeChildAdded(key, newChild));\n      } else {\n        optChangeAccumulator.trackChildChange(\n          changeChildChanged(key, newChild, oldChild)\n        );\n      }\n    }\n    if (snap.isLeafNode() && newChild.isEmpty()) {\n      return snap;\n    } else {\n      // Make sure the node is indexed\n      return snap.updateImmediateChild(key, newChild).withIndex(this.index_);\n    }\n  }\n  updateFullNode(\n    oldSnap: Node,\n    newSnap: Node,\n    optChangeAccumulator: ChildChangeAccumulator | null\n  ): Node {\n    if (optChangeAccumulator != null) {\n      if (!oldSnap.isLeafNode()) {\n        oldSnap.forEachChild(PRIORITY_INDEX, (key, childNode) => {\n          if (!newSnap.hasChild(key)) {\n            optChangeAccumulator.trackChildChange(\n              changeChildRemoved(key, childNode)\n            );\n          }\n        });\n      }\n      if (!newSnap.isLeafNode()) {\n        newSnap.forEachChild(PRIORITY_INDEX, (key, childNode) => {\n          if (oldSnap.hasChild(key)) {\n            const oldChild = oldSnap.getImmediateChild(key);\n            if (!oldChild.equals(childNode)) {\n              optChangeAccumulator.trackChildChange(\n                changeChildChanged(key, childNode, oldChild)\n              );\n            }\n          } else {\n            optChangeAccumulator.trackChildChange(\n              changeChildAdded(key, childNode)\n            );\n          }\n        });\n      }\n    }\n    return newSnap.withIndex(this.index_);\n  }\n  updatePriority(oldSnap: Node, newPriority: Node): Node {\n    if (oldSnap.isEmpty()) {\n      return ChildrenNode.EMPTY_NODE;\n    } else {\n      return oldSnap.updatePriority(newPriority);\n    }\n  }\n  filtersNodes(): boolean {\n    return false;\n  }\n  getIndexedFilter(): IndexedFilter {\n    return this;\n  }\n  getIndex(): Index {\n    return this.index_;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NamedNode, Node } from '../../../core/snap/Node';\nimport { ChildrenNode } from '../../snap/ChildrenNode';\nimport { Index } from '../../snap/indexes/Index';\nimport { PRIORITY_INDEX } from '../../snap/indexes/PriorityIndex';\nimport { Path } from '../../util/Path';\nimport { ChildChangeAccumulator } from '../ChildChangeAccumulator';\nimport { CompleteChildSource } from '../CompleteChildSource';\nimport { QueryParams } from '../QueryParams';\n\nimport { IndexedFilter } from './IndexedFilter';\nimport { NodeFilter } from './NodeFilter';\n\n/**\n * Filters nodes by range and uses an IndexFilter to track any changes after filtering the node\n */\nexport class RangedFilter implements NodeFilter {\n  private indexedFilter_: IndexedFilter;\n\n  private index_: Index;\n\n  private startPost_: NamedNode;\n\n  private endPost_: NamedNode;\n\n  private startIsInclusive_: boolean;\n\n  private endIsInclusive_: boolean;\n\n  constructor(params: QueryParams) {\n    this.indexedFilter_ = new IndexedFilter(params.getIndex());\n    this.index_ = params.getIndex();\n    this.startPost_ = RangedFilter.getStartPost_(params);\n    this.endPost_ = RangedFilter.getEndPost_(params);\n    this.startIsInclusive_ = !params.startAfterSet_;\n    this.endIsInclusive_ = !params.endBeforeSet_;\n  }\n\n  getStartPost(): NamedNode {\n    return this.startPost_;\n  }\n\n  getEndPost(): NamedNode {\n    return this.endPost_;\n  }\n\n  matches(node: NamedNode): boolean {\n    const isWithinStart = this.startIsInclusive_\n      ? this.index_.compare(this.getStartPost(), node) <= 0\n      : this.index_.compare(this.getStartPost(), node) < 0;\n    const isWithinEnd = this.endIsInclusive_\n      ? this.index_.compare(node, this.getEndPost()) <= 0\n      : this.index_.compare(node, this.getEndPost()) < 0;\n    return isWithinStart && isWithinEnd;\n  }\n  updateChild(\n    snap: Node,\n    key: string,\n    newChild: Node,\n    affectedPath: Path,\n    source: CompleteChildSource,\n    optChangeAccumulator: ChildChangeAccumulator | null\n  ): Node {\n    if (!this.matches(new NamedNode(key, newChild))) {\n      newChild = ChildrenNode.EMPTY_NODE;\n    }\n    return this.indexedFilter_.updateChild(\n      snap,\n      key,\n      newChild,\n      affectedPath,\n      source,\n      optChangeAccumulator\n    );\n  }\n  updateFullNode(\n    oldSnap: Node,\n    newSnap: Node,\n    optChangeAccumulator: ChildChangeAccumulator | null\n  ): Node {\n    if (newSnap.isLeafNode()) {\n      // Make sure we have a children node with the correct index, not a leaf node;\n      newSnap = ChildrenNode.EMPTY_NODE;\n    }\n    let filtered = newSnap.withIndex(this.index_);\n    // Don't support priorities on queries\n    filtered = filtered.updatePriority(ChildrenNode.EMPTY_NODE);\n    const self = this;\n    newSnap.forEachChild(PRIORITY_INDEX, (key, childNode) => {\n      if (!self.matches(new NamedNode(key, childNode))) {\n        filtered = filtered.updateImmediateChild(key, ChildrenNode.EMPTY_NODE);\n      }\n    });\n    return this.indexedFilter_.updateFullNode(\n      oldSnap,\n      filtered,\n      optChangeAccumulator\n    );\n  }\n  updatePriority(oldSnap: Node, newPriority: Node): Node {\n    // Don't support priorities on queries\n    return oldSnap;\n  }\n  filtersNodes(): boolean {\n    return true;\n  }\n  getIndexedFilter(): IndexedFilter {\n    return this.indexedFilter_;\n  }\n  getIndex(): Index {\n    return this.index_;\n  }\n\n  private static getStartPost_(params: QueryParams): NamedNode {\n    if (params.hasStart()) {\n      const startName = params.getIndexStartName();\n      return params.getIndex().makePost(params.getIndexStartValue(), startName);\n    } else {\n      return params.getIndex().minPost();\n    }\n  }\n\n  private static getEndPost_(params: QueryParams): NamedNode {\n    if (params.hasEnd()) {\n      const endName = params.getIndexEndName();\n      return params.getIndex().makePost(params.getIndexEndValue(), endName);\n    } else {\n      return params.getIndex().maxPost();\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { ChildrenNode } from '../../snap/ChildrenNode';\nimport { Index } from '../../snap/indexes/Index';\nimport { NamedNode, Node } from '../../snap/Node';\nimport { Path } from '../../util/Path';\nimport {\n  changeChildAdded,\n  changeChildChanged,\n  changeChildRemoved\n} from '../Change';\nimport { ChildChangeAccumulator } from '../ChildChangeAccumulator';\nimport { CompleteChildSource } from '../CompleteChildSource';\nimport { QueryParams } from '../QueryParams';\n\nimport { IndexedFilter } from './IndexedFilter';\nimport { NodeFilter } from './NodeFilter';\nimport { RangedFilter } from './RangedFilter';\n\n/**\n * Applies a limit and a range to a node and uses RangedFilter to do the heavy lifting where possible\n */\nexport class LimitedFilter implements NodeFilter {\n  private readonly rangedFilter_: RangedFilter;\n\n  private readonly index_: Index;\n\n  private readonly limit_: number;\n\n  private readonly reverse_: boolean;\n\n  private readonly startIsInclusive_: boolean;\n\n  private readonly endIsInclusive_: boolean;\n\n  constructor(params: QueryParams) {\n    this.rangedFilter_ = new RangedFilter(params);\n    this.index_ = params.getIndex();\n    this.limit_ = params.getLimit();\n    this.reverse_ = !params.isViewFromLeft();\n    this.startIsInclusive_ = !params.startAfterSet_;\n    this.endIsInclusive_ = !params.endBeforeSet_;\n  }\n  updateChild(\n    snap: Node,\n    key: string,\n    newChild: Node,\n    affectedPath: Path,\n    source: CompleteChildSource,\n    optChangeAccumulator: ChildChangeAccumulator | null\n  ): Node {\n    if (!this.rangedFilter_.matches(new NamedNode(key, newChild))) {\n      newChild = ChildrenNode.EMPTY_NODE;\n    }\n    if (snap.getImmediateChild(key).equals(newChild)) {\n      // No change\n      return snap;\n    } else if (snap.numChildren() < this.limit_) {\n      return this.rangedFilter_\n        .getIndexedFilter()\n        .updateChild(\n          snap,\n          key,\n          newChild,\n          affectedPath,\n          source,\n          optChangeAccumulator\n        );\n    } else {\n      return this.fullLimitUpdateChild_(\n        snap,\n        key,\n        newChild,\n        source,\n        optChangeAccumulator\n      );\n    }\n  }\n  updateFullNode(\n    oldSnap: Node,\n    newSnap: Node,\n    optChangeAccumulator: ChildChangeAccumulator | null\n  ): Node {\n    let filtered;\n    if (newSnap.isLeafNode() || newSnap.isEmpty()) {\n      // Make sure we have a children node with the correct index, not a leaf node;\n      filtered = ChildrenNode.EMPTY_NODE.withIndex(this.index_);\n    } else {\n      if (\n        this.limit_ * 2 < newSnap.numChildren() &&\n        newSnap.isIndexed(this.index_)\n      ) {\n        // Easier to build up a snapshot, since what we're given has more than twice the elements we want\n        filtered = ChildrenNode.EMPTY_NODE.withIndex(this.index_);\n        // anchor to the startPost, endPost, or last element as appropriate\n        let iterator;\n        if (this.reverse_) {\n          iterator = (newSnap as ChildrenNode).getReverseIteratorFrom(\n            this.rangedFilter_.getEndPost(),\n            this.index_\n          );\n        } else {\n          iterator = (newSnap as ChildrenNode).getIteratorFrom(\n            this.rangedFilter_.getStartPost(),\n            this.index_\n          );\n        }\n        let count = 0;\n        while (iterator.hasNext() && count < this.limit_) {\n          const next = iterator.getNext();\n          if (!this.withinDirectionalStart(next)) {\n            // if we have not reached the start, skip to the next element\n            continue;\n          } else if (!this.withinDirectionalEnd(next)) {\n            // if we have reached the end, stop adding elements\n            break;\n          } else {\n            filtered = filtered.updateImmediateChild(next.name, next.node);\n            count++;\n          }\n        }\n      } else {\n        // The snap contains less than twice the limit. Faster to delete from the snap than build up a new one\n        filtered = newSnap.withIndex(this.index_);\n        // Don't support priorities on queries\n        filtered = filtered.updatePriority(\n          ChildrenNode.EMPTY_NODE\n        ) as ChildrenNode;\n\n        let iterator;\n        if (this.reverse_) {\n          iterator = filtered.getReverseIterator(this.index_);\n        } else {\n          iterator = filtered.getIterator(this.index_);\n        }\n\n        let count = 0;\n        while (iterator.hasNext()) {\n          const next = iterator.getNext();\n          const inRange =\n            count < this.limit_ &&\n            this.withinDirectionalStart(next) &&\n            this.withinDirectionalEnd(next);\n          if (inRange) {\n            count++;\n          } else {\n            filtered = filtered.updateImmediateChild(\n              next.name,\n              ChildrenNode.EMPTY_NODE\n            );\n          }\n        }\n      }\n    }\n    return this.rangedFilter_\n      .getIndexedFilter()\n      .updateFullNode(oldSnap, filtered, optChangeAccumulator);\n  }\n  updatePriority(oldSnap: Node, newPriority: Node): Node {\n    // Don't support priorities on queries\n    return oldSnap;\n  }\n  filtersNodes(): boolean {\n    return true;\n  }\n  getIndexedFilter(): IndexedFilter {\n    return this.rangedFilter_.getIndexedFilter();\n  }\n  getIndex(): Index {\n    return this.index_;\n  }\n\n  private fullLimitUpdateChild_(\n    snap: Node,\n    childKey: string,\n    childSnap: Node,\n    source: CompleteChildSource,\n    changeAccumulator: ChildChangeAccumulator | null\n  ): Node {\n    // TODO: rename all cache stuff etc to general snap terminology\n    let cmp;\n    if (this.reverse_) {\n      const indexCmp = this.index_.getCompare();\n      cmp = (a: NamedNode, b: NamedNode) => indexCmp(b, a);\n    } else {\n      cmp = this.index_.getCompare();\n    }\n    const oldEventCache = snap as ChildrenNode;\n    assert(oldEventCache.numChildren() === this.limit_, '');\n    const newChildNamedNode = new NamedNode(childKey, childSnap);\n    const windowBoundary = this.reverse_\n      ? oldEventCache.getFirstChild(this.index_)\n      : (oldEventCache.getLastChild(this.index_) as NamedNode);\n    const inRange = this.rangedFilter_.matches(newChildNamedNode);\n    if (oldEventCache.hasChild(childKey)) {\n      const oldChildSnap = oldEventCache.getImmediateChild(childKey);\n      let nextChild = source.getChildAfterChild(\n        this.index_,\n        windowBoundary,\n        this.reverse_\n      );\n      while (\n        nextChild != null &&\n        (nextChild.name === childKey || oldEventCache.hasChild(nextChild.name))\n      ) {\n        // There is a weird edge case where a node is updated as part of a merge in the write tree, but hasn't\n        // been applied to the limited filter yet. Ignore this next child which will be updated later in\n        // the limited filter...\n        nextChild = source.getChildAfterChild(\n          this.index_,\n          nextChild,\n          this.reverse_\n        );\n      }\n      const compareNext =\n        nextChild == null ? 1 : cmp(nextChild, newChildNamedNode);\n      const remainsInWindow =\n        inRange && !childSnap.isEmpty() && compareNext >= 0;\n      if (remainsInWindow) {\n        if (changeAccumulator != null) {\n          changeAccumulator.trackChildChange(\n            changeChildChanged(childKey, childSnap, oldChildSnap)\n          );\n        }\n        return oldEventCache.updateImmediateChild(childKey, childSnap);\n      } else {\n        if (changeAccumulator != null) {\n          changeAccumulator.trackChildChange(\n            changeChildRemoved(childKey, oldChildSnap)\n          );\n        }\n        const newEventCache = oldEventCache.updateImmediateChild(\n          childKey,\n          ChildrenNode.EMPTY_NODE\n        );\n        const nextChildInRange =\n          nextChild != null && this.rangedFilter_.matches(nextChild);\n        if (nextChildInRange) {\n          if (changeAccumulator != null) {\n            changeAccumulator.trackChildChange(\n              changeChildAdded(nextChild.name, nextChild.node)\n            );\n          }\n          return newEventCache.updateImmediateChild(\n            nextChild.name,\n            nextChild.node\n          );\n        } else {\n          return newEventCache;\n        }\n      }\n    } else if (childSnap.isEmpty()) {\n      // we're deleting a node, but it was not in the window, so ignore it\n      return snap;\n    } else if (inRange) {\n      if (cmp(windowBoundary, newChildNamedNode) >= 0) {\n        if (changeAccumulator != null) {\n          changeAccumulator.trackChildChange(\n            changeChildRemoved(windowBoundary.name, windowBoundary.node)\n          );\n          changeAccumulator.trackChildChange(\n            changeChildAdded(childKey, childSnap)\n          );\n        }\n        return oldEventCache\n          .updateImmediateChild(childKey, childSnap)\n          .updateImmediateChild(windowBoundary.name, ChildrenNode.EMPTY_NODE);\n      } else {\n        return snap;\n      }\n    } else {\n      return snap;\n    }\n  }\n\n  private withinDirectionalStart = (node: NamedNode) =>\n    this.reverse_ ? this.withinEndPost(node) : this.withinStartPost(node);\n\n  private withinDirectionalEnd = (node: NamedNode) =>\n    this.reverse_ ? this.withinStartPost(node) : this.withinEndPost(node);\n\n  private withinStartPost = (node: NamedNode) => {\n    const compareRes = this.index_.compare(\n      this.rangedFilter_.getStartPost(),\n      node\n    );\n    return this.startIsInclusive_ ? compareRes <= 0 : compareRes < 0;\n  };\n\n  private withinEndPost = (node: NamedNode) => {\n    const compareRes = this.index_.compare(\n      node,\n      this.rangedFilter_.getEndPost()\n    );\n    return this.endIsInclusive_ ? compareRes <= 0 : compareRes < 0;\n  };\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert, stringify } from '@firebase/util';\n\nimport { Index } from '../snap/indexes/Index';\nimport { KEY_INDEX } from '../snap/indexes/KeyIndex';\nimport { PathIndex } from '../snap/indexes/PathIndex';\nimport { PRIORITY_INDEX, PriorityIndex } from '../snap/indexes/PriorityIndex';\nimport { VALUE_INDEX } from '../snap/indexes/ValueIndex';\nimport { MAX_NAME, MIN_NAME } from '../util/util';\n\nimport { IndexedFilter } from './filter/IndexedFilter';\nimport { LimitedFilter } from './filter/LimitedFilter';\nimport { NodeFilter } from './filter/NodeFilter';\nimport { RangedFilter } from './filter/RangedFilter';\n\n/**\n * Wire Protocol Constants\n */\nconst enum WIRE_PROTOCOL_CONSTANTS {\n  INDEX_START_VALUE = 'sp',\n  INDEX_START_NAME = 'sn',\n  INDEX_START_IS_INCLUSIVE = 'sin',\n  INDEX_END_VALUE = 'ep',\n  INDEX_END_NAME = 'en',\n  INDEX_END_IS_INCLUSIVE = 'ein',\n  LIMIT = 'l',\n  VIEW_FROM = 'vf',\n  VIEW_FROM_LEFT = 'l',\n  VIEW_FROM_RIGHT = 'r',\n  INDEX = 'i'\n}\n\n/**\n * REST Query Constants\n */\nconst enum REST_QUERY_CONSTANTS {\n  ORDER_BY = 'orderBy',\n  PRIORITY_INDEX = '$priority',\n  VALUE_INDEX = '$value',\n  KEY_INDEX = '$key',\n  START_AFTER = 'startAfter',\n  START_AT = 'startAt',\n  END_AT = 'endAt',\n  END_BEFORE = 'endBefore',\n  LIMIT_TO_FIRST = 'limitToFirst',\n  LIMIT_TO_LAST = 'limitToLast'\n}\n\n/**\n * This class is an immutable-from-the-public-api struct containing a set of query parameters defining a\n * range to be returned for a particular location. It is assumed that validation of parameters is done at the\n * user-facing API level, so it is not done here.\n *\n * @internal\n */\nexport class QueryParams {\n  limitSet_ = false;\n  startSet_ = false;\n  startNameSet_ = false;\n  startAfterSet_ = false; // can only be true if startSet_ is true\n  endSet_ = false;\n  endNameSet_ = false;\n  endBeforeSet_ = false; // can only be true if endSet_ is true\n  limit_ = 0;\n  viewFrom_ = '';\n  indexStartValue_: unknown | null = null;\n  indexStartName_ = '';\n  indexEndValue_: unknown | null = null;\n  indexEndName_ = '';\n  index_: PriorityIndex = PRIORITY_INDEX;\n\n  hasStart(): boolean {\n    return this.startSet_;\n  }\n\n  /**\n   * @returns True if it would return from left.\n   */\n  isViewFromLeft(): boolean {\n    if (this.viewFrom_ === '') {\n      // limit(), rather than limitToFirst or limitToLast was called.\n      // This means that only one of startSet_ and endSet_ is true. Use them\n      // to calculate which side of the view to anchor to. If neither is set,\n      // anchor to the end.\n      return this.startSet_;\n    } else {\n      return this.viewFrom_ === WIRE_PROTOCOL_CONSTANTS.VIEW_FROM_LEFT;\n    }\n  }\n\n  /**\n   * Only valid to call if hasStart() returns true\n   */\n  getIndexStartValue(): unknown {\n    assert(this.startSet_, 'Only valid if start has been set');\n    return this.indexStartValue_;\n  }\n\n  /**\n   * Only valid to call if hasStart() returns true.\n   * Returns the starting key name for the range defined by these query parameters\n   */\n  getIndexStartName(): string {\n    assert(this.startSet_, 'Only valid if start has been set');\n    if (this.startNameSet_) {\n      return this.indexStartName_;\n    } else {\n      return MIN_NAME;\n    }\n  }\n\n  hasEnd(): boolean {\n    return this.endSet_;\n  }\n\n  /**\n   * Only valid to call if hasEnd() returns true.\n   */\n  getIndexEndValue(): unknown {\n    assert(this.endSet_, 'Only valid if end has been set');\n    return this.indexEndValue_;\n  }\n\n  /**\n   * Only valid to call if hasEnd() returns true.\n   * Returns the end key name for the range defined by these query parameters\n   */\n  getIndexEndName(): string {\n    assert(this.endSet_, 'Only valid if end has been set');\n    if (this.endNameSet_) {\n      return this.indexEndName_;\n    } else {\n      return MAX_NAME;\n    }\n  }\n\n  hasLimit(): boolean {\n    return this.limitSet_;\n  }\n\n  /**\n   * @returns True if a limit has been set and it has been explicitly anchored\n   */\n  hasAnchoredLimit(): boolean {\n    return this.limitSet_ && this.viewFrom_ !== '';\n  }\n\n  /**\n   * Only valid to call if hasLimit() returns true\n   */\n  getLimit(): number {\n    assert(this.limitSet_, 'Only valid if limit has been set');\n    return this.limit_;\n  }\n\n  getIndex(): Index {\n    return this.index_;\n  }\n\n  loadsAllData(): boolean {\n    return !(this.startSet_ || this.endSet_ || this.limitSet_);\n  }\n\n  isDefault(): boolean {\n    return this.loadsAllData() && this.index_ === PRIORITY_INDEX;\n  }\n\n  copy(): QueryParams {\n    const copy = new QueryParams();\n    copy.limitSet_ = this.limitSet_;\n    copy.limit_ = this.limit_;\n    copy.startSet_ = this.startSet_;\n    copy.startAfterSet_ = this.startAfterSet_;\n    copy.indexStartValue_ = this.indexStartValue_;\n    copy.startNameSet_ = this.startNameSet_;\n    copy.indexStartName_ = this.indexStartName_;\n    copy.endSet_ = this.endSet_;\n    copy.endBeforeSet_ = this.endBeforeSet_;\n    copy.indexEndValue_ = this.indexEndValue_;\n    copy.endNameSet_ = this.endNameSet_;\n    copy.indexEndName_ = this.indexEndName_;\n    copy.index_ = this.index_;\n    copy.viewFrom_ = this.viewFrom_;\n    return copy;\n  }\n}\n\nexport function queryParamsGetNodeFilter(queryParams: QueryParams): NodeFilter {\n  if (queryParams.loadsAllData()) {\n    return new IndexedFilter(queryParams.getIndex());\n  } else if (queryParams.hasLimit()) {\n    return new LimitedFilter(queryParams);\n  } else {\n    return new RangedFilter(queryParams);\n  }\n}\n\nexport function queryParamsLimit(\n  queryParams: QueryParams,\n  newLimit: number\n): QueryParams {\n  const newParams = queryParams.copy();\n  newParams.limitSet_ = true;\n  newParams.limit_ = newLimit;\n  newParams.viewFrom_ = '';\n  return newParams;\n}\n\nexport function queryParamsLimitToFirst(\n  queryParams: QueryParams,\n  newLimit: number\n): QueryParams {\n  const newParams = queryParams.copy();\n  newParams.limitSet_ = true;\n  newParams.limit_ = newLimit;\n  newParams.viewFrom_ = WIRE_PROTOCOL_CONSTANTS.VIEW_FROM_LEFT;\n  return newParams;\n}\n\nexport function queryParamsLimitToLast(\n  queryParams: QueryParams,\n  newLimit: number\n): QueryParams {\n  const newParams = queryParams.copy();\n  newParams.limitSet_ = true;\n  newParams.limit_ = newLimit;\n  newParams.viewFrom_ = WIRE_PROTOCOL_CONSTANTS.VIEW_FROM_RIGHT;\n  return newParams;\n}\n\nexport function queryParamsStartAt(\n  queryParams: QueryParams,\n  indexValue: unknown,\n  key?: string | null\n): QueryParams {\n  const newParams = queryParams.copy();\n  newParams.startSet_ = true;\n  if (indexValue === undefined) {\n    indexValue = null;\n  }\n  newParams.indexStartValue_ = indexValue;\n  if (key != null) {\n    newParams.startNameSet_ = true;\n    newParams.indexStartName_ = key;\n  } else {\n    newParams.startNameSet_ = false;\n    newParams.indexStartName_ = '';\n  }\n  return newParams;\n}\n\nexport function queryParamsStartAfter(\n  queryParams: QueryParams,\n  indexValue: unknown,\n  key?: string | null\n): QueryParams {\n  let params: QueryParams;\n  if (queryParams.index_ === KEY_INDEX || !!key) {\n    params = queryParamsStartAt(queryParams, indexValue, key);\n  } else {\n    params = queryParamsStartAt(queryParams, indexValue, MAX_NAME);\n  }\n  params.startAfterSet_ = true;\n  return params;\n}\n\nexport function queryParamsEndAt(\n  queryParams: QueryParams,\n  indexValue: unknown,\n  key?: string | null\n): QueryParams {\n  const newParams = queryParams.copy();\n  newParams.endSet_ = true;\n  if (indexValue === undefined) {\n    indexValue = null;\n  }\n  newParams.indexEndValue_ = indexValue;\n  if (key !== undefined) {\n    newParams.endNameSet_ = true;\n    newParams.indexEndName_ = key;\n  } else {\n    newParams.endNameSet_ = false;\n    newParams.indexEndName_ = '';\n  }\n  return newParams;\n}\n\nexport function queryParamsEndBefore(\n  queryParams: QueryParams,\n  indexValue: unknown,\n  key?: string | null\n): QueryParams {\n  let params: QueryParams;\n  if (queryParams.index_ === KEY_INDEX || !!key) {\n    params = queryParamsEndAt(queryParams, indexValue, key);\n  } else {\n    params = queryParamsEndAt(queryParams, indexValue, MIN_NAME);\n  }\n  params.endBeforeSet_ = true;\n  return params;\n}\n\nexport function queryParamsOrderBy(\n  queryParams: QueryParams,\n  index: Index\n): QueryParams {\n  const newParams = queryParams.copy();\n  newParams.index_ = index;\n  return newParams;\n}\n\n/**\n * Returns a set of REST query string parameters representing this query.\n *\n * @returns query string parameters\n */\nexport function queryParamsToRestQueryStringParameters(\n  queryParams: QueryParams\n): Record<string, string | number> {\n  const qs: Record<string, string | number> = {};\n\n  if (queryParams.isDefault()) {\n    return qs;\n  }\n\n  let orderBy;\n  if (queryParams.index_ === PRIORITY_INDEX) {\n    orderBy = REST_QUERY_CONSTANTS.PRIORITY_INDEX;\n  } else if (queryParams.index_ === VALUE_INDEX) {\n    orderBy = REST_QUERY_CONSTANTS.VALUE_INDEX;\n  } else if (queryParams.index_ === KEY_INDEX) {\n    orderBy = REST_QUERY_CONSTANTS.KEY_INDEX;\n  } else {\n    assert(queryParams.index_ instanceof PathIndex, 'Unrecognized index type!');\n    orderBy = queryParams.index_.toString();\n  }\n  qs[REST_QUERY_CONSTANTS.ORDER_BY] = stringify(orderBy);\n\n  if (queryParams.startSet_) {\n    const startParam = queryParams.startAfterSet_\n      ? REST_QUERY_CONSTANTS.START_AFTER\n      : REST_QUERY_CONSTANTS.START_AT;\n    qs[startParam] = stringify(queryParams.indexStartValue_);\n    if (queryParams.startNameSet_) {\n      qs[startParam] += ',' + stringify(queryParams.indexStartName_);\n    }\n  }\n\n  if (queryParams.endSet_) {\n    const endParam = queryParams.endBeforeSet_\n      ? REST_QUERY_CONSTANTS.END_BEFORE\n      : REST_QUERY_CONSTANTS.END_AT;\n    qs[endParam] = stringify(queryParams.indexEndValue_);\n    if (queryParams.endNameSet_) {\n      qs[endParam] += ',' + stringify(queryParams.indexEndName_);\n    }\n  }\n\n  if (queryParams.limitSet_) {\n    if (queryParams.isViewFromLeft()) {\n      qs[REST_QUERY_CONSTANTS.LIMIT_TO_FIRST] = queryParams.limit_;\n    } else {\n      qs[REST_QUERY_CONSTANTS.LIMIT_TO_LAST] = queryParams.limit_;\n    }\n  }\n\n  return qs;\n}\n\nexport function queryParamsGetQueryObject(\n  queryParams: QueryParams\n): Record<string, unknown> {\n  const obj: Record<string, unknown> = {};\n  if (queryParams.startSet_) {\n    obj[WIRE_PROTOCOL_CONSTANTS.INDEX_START_VALUE] =\n      queryParams.indexStartValue_;\n    if (queryParams.startNameSet_) {\n      obj[WIRE_PROTOCOL_CONSTANTS.INDEX_START_NAME] =\n        queryParams.indexStartName_;\n    }\n    obj[WIRE_PROTOCOL_CONSTANTS.INDEX_START_IS_INCLUSIVE] =\n      !queryParams.startAfterSet_;\n  }\n  if (queryParams.endSet_) {\n    obj[WIRE_PROTOCOL_CONSTANTS.INDEX_END_VALUE] = queryParams.indexEndValue_;\n    if (queryParams.endNameSet_) {\n      obj[WIRE_PROTOCOL_CONSTANTS.INDEX_END_NAME] = queryParams.indexEndName_;\n    }\n    obj[WIRE_PROTOCOL_CONSTANTS.INDEX_END_IS_INCLUSIVE] =\n      !queryParams.endBeforeSet_;\n  }\n  if (queryParams.limitSet_) {\n    obj[WIRE_PROTOCOL_CONSTANTS.LIMIT] = queryParams.limit_;\n    let viewFrom = queryParams.viewFrom_;\n    if (viewFrom === '') {\n      if (queryParams.isViewFromLeft()) {\n        viewFrom = WIRE_PROTOCOL_CONSTANTS.VIEW_FROM_LEFT;\n      } else {\n        viewFrom = WIRE_PROTOCOL_CONSTANTS.VIEW_FROM_RIGHT;\n      }\n    }\n    obj[WIRE_PROTOCOL_CONSTANTS.VIEW_FROM] = viewFrom;\n  }\n  // For now, priority index is the default, so we only specify if it's some other index\n  if (queryParams.index_ !== PRIORITY_INDEX) {\n    obj[WIRE_PROTOCOL_CONSTANTS.INDEX] = queryParams.index_.toString();\n  }\n  return obj;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  assert,\n  jsonEval,\n  safeGet,\n  querystring,\n  Deferred\n} from '@firebase/util';\n\nimport { AppCheckTokenProvider } from './AppCheckTokenProvider';\nimport { AuthTokenProvider } from './AuthTokenProvider';\nimport { RepoInfo } from './RepoInfo';\nimport { ServerActions } from './ServerActions';\nimport { logWrapper, warn } from './util/util';\nimport { QueryContext } from './view/EventRegistration';\nimport { queryParamsToRestQueryStringParameters } from './view/QueryParams';\n\n/**\n * An implementation of ServerActions that communicates with the server via REST requests.\n * This is mostly useful for compatibility with crawlers, where we don't want to spin up a full\n * persistent connection (using WebSockets or long-polling)\n */\nexport class ReadonlyRestClient extends ServerActions {\n  reportStats(stats: { [k: string]: unknown }): void {\n    throw new Error('Method not implemented.');\n  }\n\n  /** @private {function(...[*])} */\n  private log_: (...args: unknown[]) => void = logWrapper('p:rest:');\n\n  /**\n   * We don't actually need to track listens, except to prevent us calling an onComplete for a listen\n   * that's been removed. :-/\n   */\n  private listens_: { [k: string]: object } = {};\n\n  static getListenId_(query: QueryContext, tag?: number | null): string {\n    if (tag !== undefined) {\n      return 'tag$' + tag;\n    } else {\n      assert(\n        query._queryParams.isDefault(),\n        \"should have a tag if it's not a default query.\"\n      );\n      return query._path.toString();\n    }\n  }\n\n  /**\n   * @param repoInfo_ - Data about the namespace we are connecting to\n   * @param onDataUpdate_ - A callback for new data from the server\n   */\n  constructor(\n    private repoInfo_: RepoInfo,\n    private onDataUpdate_: (\n      a: string,\n      b: unknown,\n      c: boolean,\n      d: number | null\n    ) => void,\n    private authTokenProvider_: AuthTokenProvider,\n    private appCheckTokenProvider_: AppCheckTokenProvider\n  ) {\n    super();\n  }\n\n  /** @inheritDoc */\n  listen(\n    query: QueryContext,\n    currentHashFn: () => string,\n    tag: number | null,\n    onComplete: (a: string, b: unknown) => void\n  ) {\n    const pathString = query._path.toString();\n    this.log_('Listen called for ' + pathString + ' ' + query._queryIdentifier);\n\n    // Mark this listener so we can tell if it's removed.\n    const listenId = ReadonlyRestClient.getListenId_(query, tag);\n    const thisListen = {};\n    this.listens_[listenId] = thisListen;\n\n    const queryStringParameters = queryParamsToRestQueryStringParameters(\n      query._queryParams\n    );\n\n    this.restRequest_(\n      pathString + '.json',\n      queryStringParameters,\n      (error, result) => {\n        let data = result;\n\n        if (error === 404) {\n          data = null;\n          error = null;\n        }\n\n        if (error === null) {\n          this.onDataUpdate_(pathString, data, /*isMerge=*/ false, tag);\n        }\n\n        if (safeGet(this.listens_, listenId) === thisListen) {\n          let status;\n          if (!error) {\n            status = 'ok';\n          } else if (error === 401) {\n            status = 'permission_denied';\n          } else {\n            status = 'rest_error:' + error;\n          }\n\n          onComplete(status, null);\n        }\n      }\n    );\n  }\n\n  /** @inheritDoc */\n  unlisten(query: QueryContext, tag: number | null) {\n    const listenId = ReadonlyRestClient.getListenId_(query, tag);\n    delete this.listens_[listenId];\n  }\n\n  get(query: QueryContext): Promise<string> {\n    const queryStringParameters = queryParamsToRestQueryStringParameters(\n      query._queryParams\n    );\n\n    const pathString = query._path.toString();\n\n    const deferred = new Deferred<string>();\n\n    this.restRequest_(\n      pathString + '.json',\n      queryStringParameters,\n      (error, result) => {\n        let data = result;\n\n        if (error === 404) {\n          data = null;\n          error = null;\n        }\n\n        if (error === null) {\n          this.onDataUpdate_(\n            pathString,\n            data,\n            /*isMerge=*/ false,\n            /*tag=*/ null\n          );\n          deferred.resolve(data as string);\n        } else {\n          deferred.reject(new Error(data as string));\n        }\n      }\n    );\n    return deferred.promise;\n  }\n\n  /** @inheritDoc */\n  refreshAuthToken(token: string) {\n    // no-op since we just always call getToken.\n  }\n\n  /**\n   * Performs a REST request to the given path, with the provided query string parameters,\n   * and any auth credentials we have.\n   */\n  private restRequest_(\n    pathString: string,\n    queryStringParameters: { [k: string]: string | number } = {},\n    callback: ((a: number | null, b?: unknown) => void) | null\n  ) {\n    queryStringParameters['format'] = 'export';\n\n    return Promise.all([\n      this.authTokenProvider_.getToken(/*forceRefresh=*/ false),\n      this.appCheckTokenProvider_.getToken(/*forceRefresh=*/ false)\n    ]).then(([authToken, appCheckToken]) => {\n      if (authToken && authToken.accessToken) {\n        queryStringParameters['auth'] = authToken.accessToken;\n      }\n      if (appCheckToken && appCheckToken.token) {\n        queryStringParameters['ac'] = appCheckToken.token;\n      }\n\n      const url =\n        (this.repoInfo_.secure ? 'https://' : 'http://') +\n        this.repoInfo_.host +\n        pathString +\n        '?' +\n        'ns=' +\n        this.repoInfo_.namespace +\n        querystring(queryStringParameters);\n\n      this.log_('Sending REST request for ' + url);\n      const xhr = new XMLHttpRequest();\n      xhr.onreadystatechange = () => {\n        if (callback && xhr.readyState === 4) {\n          this.log_(\n            'REST Response for ' + url + ' received. status:',\n            xhr.status,\n            'response:',\n            xhr.responseText\n          );\n          let res = null;\n          if (xhr.status >= 200 && xhr.status < 300) {\n            try {\n              res = jsonEval(xhr.responseText);\n            } catch (e) {\n              warn(\n                'Failed to parse JSON response for ' +\n                  url +\n                  ': ' +\n                  xhr.responseText\n              );\n            }\n            callback(null, res);\n          } else {\n            // 401 and 404 are expected.\n            if (xhr.status !== 401 && xhr.status !== 404) {\n              warn(\n                'Got unsuccessful REST response for ' +\n                  url +\n                  ' Status: ' +\n                  xhr.status\n              );\n            }\n            callback(xhr.status);\n          }\n          callback = null;\n        }\n      };\n\n      xhr.open('GET', url, /*asynchronous=*/ true);\n      xhr.send();\n    });\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { PRIORITY_INDEX } from './snap/indexes/PriorityIndex';\nimport { Node } from './snap/Node';\nimport { Path, pathGetFront, pathIsEmpty, pathPopFront } from './util/Path';\n\n/**\n * Helper class to store a sparse set of snapshots.\n */\nexport interface SparseSnapshotTree {\n  value: Node | null;\n  readonly children: Map<string, SparseSnapshotTree>;\n}\n\nexport function newSparseSnapshotTree(): SparseSnapshotTree {\n  return {\n    value: null,\n    children: new Map()\n  };\n}\n\n/**\n * Gets the node stored at the given path if one exists.\n * Only seems to be used in tests.\n *\n * @param path - Path to look up snapshot for.\n * @returns The retrieved node, or null.\n */\nexport function sparseSnapshotTreeFind(\n  sparseSnapshotTree: SparseSnapshotTree,\n  path: Path\n): Node | null {\n  if (sparseSnapshotTree.value != null) {\n    return sparseSnapshotTree.value.getChild(path);\n  } else if (!pathIsEmpty(path) && sparseSnapshotTree.children.size > 0) {\n    const childKey = pathGetFront(path);\n    path = pathPopFront(path);\n    if (sparseSnapshotTree.children.has(childKey)) {\n      const childTree = sparseSnapshotTree.children.get(childKey);\n      return sparseSnapshotTreeFind(childTree, path);\n    } else {\n      return null;\n    }\n  } else {\n    return null;\n  }\n}\n\n/**\n * Stores the given node at the specified path. If there is already a node\n * at a shallower path, it merges the new data into that snapshot node.\n *\n * @param path - Path to look up snapshot for.\n * @param data - The new data, or null.\n */\nexport function sparseSnapshotTreeRemember(\n  sparseSnapshotTree: SparseSnapshotTree,\n  path: Path,\n  data: Node\n): void {\n  if (pathIsEmpty(path)) {\n    sparseSnapshotTree.value = data;\n    sparseSnapshotTree.children.clear();\n  } else if (sparseSnapshotTree.value !== null) {\n    sparseSnapshotTree.value = sparseSnapshotTree.value.updateChild(path, data);\n  } else {\n    const childKey = pathGetFront(path);\n    if (!sparseSnapshotTree.children.has(childKey)) {\n      sparseSnapshotTree.children.set(childKey, newSparseSnapshotTree());\n    }\n\n    const child = sparseSnapshotTree.children.get(childKey);\n    path = pathPopFront(path);\n    sparseSnapshotTreeRemember(child, path, data);\n  }\n}\n\n/**\n * Purge the data at path from the cache.\n *\n * @param path - Path to look up snapshot for.\n * @returns True if this node should now be removed.\n */\nexport function sparseSnapshotTreeForget(\n  sparseSnapshotTree: SparseSnapshotTree,\n  path: Path\n): boolean {\n  if (pathIsEmpty(path)) {\n    sparseSnapshotTree.value = null;\n    sparseSnapshotTree.children.clear();\n    return true;\n  } else {\n    if (sparseSnapshotTree.value !== null) {\n      if (sparseSnapshotTree.value.isLeafNode()) {\n        // We're trying to forget a node that doesn't exist\n        return false;\n      } else {\n        const value = sparseSnapshotTree.value;\n        sparseSnapshotTree.value = null;\n\n        value.forEachChild(PRIORITY_INDEX, (key, tree) => {\n          sparseSnapshotTreeRemember(sparseSnapshotTree, new Path(key), tree);\n        });\n\n        return sparseSnapshotTreeForget(sparseSnapshotTree, path);\n      }\n    } else if (sparseSnapshotTree.children.size > 0) {\n      const childKey = pathGetFront(path);\n      path = pathPopFront(path);\n      if (sparseSnapshotTree.children.has(childKey)) {\n        const safeToRemove = sparseSnapshotTreeForget(\n          sparseSnapshotTree.children.get(childKey),\n          path\n        );\n        if (safeToRemove) {\n          sparseSnapshotTree.children.delete(childKey);\n        }\n      }\n\n      return sparseSnapshotTree.children.size === 0;\n    } else {\n      return true;\n    }\n  }\n}\n\n/**\n * Recursively iterates through all of the stored tree and calls the\n * callback on each one.\n *\n * @param prefixPath - Path to look up node for.\n * @param func - The function to invoke for each tree.\n */\nexport function sparseSnapshotTreeForEachTree(\n  sparseSnapshotTree: SparseSnapshotTree,\n  prefixPath: Path,\n  func: (a: Path, b: Node) => unknown\n): void {\n  if (sparseSnapshotTree.value !== null) {\n    func(prefixPath, sparseSnapshotTree.value);\n  } else {\n    sparseSnapshotTreeForEachChild(sparseSnapshotTree, (key, tree) => {\n      const path = new Path(prefixPath.toString() + '/' + key);\n      sparseSnapshotTreeForEachTree(tree, path, func);\n    });\n  }\n}\n\n/**\n * Iterates through each immediate child and triggers the callback.\n * Only seems to be used in tests.\n *\n * @param func - The function to invoke for each child.\n */\nexport function sparseSnapshotTreeForEachChild(\n  sparseSnapshotTree: SparseSnapshotTree,\n  func: (a: string, b: SparseSnapshotTree) => void\n): void {\n  sparseSnapshotTree.children.forEach((tree, key) => {\n    func(key, tree);\n  });\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ChildrenNode } from './snap/ChildrenNode';\nimport { Node } from './snap/Node';\nimport { Path } from './util/Path';\n\n/**\n * Mutable object which basically just stores a reference to the \"latest\" immutable snapshot.\n */\nexport class SnapshotHolder {\n  private rootNode_: Node = ChildrenNode.EMPTY_NODE;\n\n  getNode(path: Path): Node {\n    return this.rootNode_.getChild(path);\n  }\n\n  updateSnapshot(path: Path, newSnapshotNode: Node) {\n    this.rootNode_ = this.rootNode_.updateChild(path, newSnapshotNode);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { each } from '../util/util';\n\nimport { StatsCollection } from './StatsCollection';\n\n/**\n * Returns the delta from the previous call to get stats.\n *\n * @param collection_ - The collection to \"listen\" to.\n */\nexport class StatsListener {\n  private last_: { [k: string]: number } | null = null;\n\n  constructor(private collection_: StatsCollection) {}\n\n  get(): { [k: string]: number } {\n    const newStats = this.collection_.get();\n\n    const delta = { ...newStats };\n    if (this.last_) {\n      each(this.last_, (stat: string, value: number) => {\n        delta[stat] = delta[stat] - value;\n      });\n    }\n    this.last_ = newStats;\n\n    return delta;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { contains } from '@firebase/util';\n\nimport { ServerActions } from '../ServerActions';\nimport { setTimeoutNonBlocking, each } from '../util/util';\n\nimport { StatsCollection } from './StatsCollection';\nimport { StatsListener } from './StatsListener';\n\n// Assuming some apps may have a short amount of time on page, and a bulk of firebase operations probably\n// happen on page load, we try to report our first set of stats pretty quickly, but we wait at least 10\n// seconds to try to ensure the Firebase connection is established / settled.\nconst FIRST_STATS_MIN_TIME = 10 * 1000;\nconst FIRST_STATS_MAX_TIME = 30 * 1000;\n\n// We'll continue to report stats on average every 5 minutes.\nconst REPORT_STATS_INTERVAL = 5 * 60 * 1000;\n\nexport class StatsReporter {\n  private statsListener_: StatsListener;\n  statsToReport_: { [k: string]: boolean } = {};\n\n  constructor(collection: StatsCollection, private server_: ServerActions) {\n    this.statsListener_ = new StatsListener(collection);\n\n    const timeout =\n      FIRST_STATS_MIN_TIME +\n      (FIRST_STATS_MAX_TIME - FIRST_STATS_MIN_TIME) * Math.random();\n    setTimeoutNonBlocking(this.reportStats_.bind(this), Math.floor(timeout));\n  }\n\n  private reportStats_() {\n    const stats = this.statsListener_.get();\n    const reportedStats: typeof stats = {};\n    let haveStatsToReport = false;\n\n    each(stats, (stat: string, value: number) => {\n      if (value > 0 && contains(this.statsToReport_, stat)) {\n        reportedStats[stat] = value;\n        haveStatsToReport = true;\n      }\n    });\n\n    if (haveStatsToReport) {\n      this.server_.reportStats(reportedStats);\n    }\n\n    // queue our next run.\n    setTimeoutNonBlocking(\n      this.reportStats_.bind(this),\n      Math.floor(Math.random() * 2 * REPORT_STATS_INTERVAL)\n    );\n  }\n}\n\nexport function statsReporterIncludeStat(\n  reporter: StatsReporter,\n  stat: string\n) {\n  reporter.statsToReport_[stat] = true;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Path } from '../util/Path';\n\n/**\n *\n * @enum\n */\nexport enum OperationType {\n  OVERWRITE,\n  MERGE,\n  ACK_USER_WRITE,\n  LISTEN_COMPLETE\n}\n\n/**\n * @interface\n */\nexport interface Operation {\n  source: OperationSource;\n\n  type: OperationType;\n\n  path: Path;\n\n  operationForChild(childName: string): Operation | null;\n}\n\nexport interface OperationSource {\n  fromUser: boolean;\n  fromServer: boolean;\n  queryId: string | null;\n  tagged: boolean;\n}\n\nexport function newOperationSourceUser(): OperationSource {\n  return {\n    fromUser: true,\n    fromServer: false,\n    queryId: null,\n    tagged: false\n  };\n}\n\nexport function newOperationSourceServer(): OperationSource {\n  return {\n    fromUser: false,\n    fromServer: true,\n    queryId: null,\n    tagged: false\n  };\n}\n\nexport function newOperationSourceServerTaggedQuery(\n  queryId: string\n): OperationSource {\n  return {\n    fromUser: false,\n    fromServer: true,\n    queryId,\n    tagged: true\n  };\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { newEmptyPath, Path, pathIsEmpty, pathPopFront } from '../util/Path';\n\nimport { Operation, OperationSource, OperationType } from './Operation';\n\nexport class ListenComplete implements Operation {\n  /** @inheritDoc */\n  type = OperationType.LISTEN_COMPLETE;\n\n  constructor(public source: OperationSource, public path: Path) {}\n\n  operationForChild(childName: string): ListenComplete {\n    if (pathIsEmpty(this.path)) {\n      return new ListenComplete(this.source, newEmptyPath());\n    } else {\n      return new ListenComplete(this.source, pathPopFront(this.path));\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Node } from '../snap/Node';\nimport { newEmptyPath, Path, pathIsEmpty, pathPopFront } from '../util/Path';\n\nimport { Operation, OperationSource, OperationType } from './Operation';\n\nexport class Overwrite implements Operation {\n  /** @inheritDoc */\n  type = OperationType.OVERWRITE;\n\n  constructor(\n    public source: OperationSource,\n    public path: Path,\n    public snap: Node\n  ) {}\n\n  operationForChild(childName: string): Overwrite {\n    if (pathIsEmpty(this.path)) {\n      return new Overwrite(\n        this.source,\n        newEmptyPath(),\n        this.snap.getImmediateChild(childName)\n      );\n    } else {\n      return new Overwrite(this.source, pathPopFront(this.path), this.snap);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { Node } from '../snap/Node';\nimport { ImmutableTree } from '../util/ImmutableTree';\nimport {\n  newEmptyPath,\n  Path,\n  pathGetFront,\n  pathIsEmpty,\n  pathPopFront\n} from '../util/Path';\n\nimport { Operation, OperationSource, OperationType } from './Operation';\nimport { Overwrite } from './Overwrite';\n\nexport class Merge implements Operation {\n  /** @inheritDoc */\n  type = OperationType.MERGE;\n\n  constructor(\n    /** @inheritDoc */ public source: OperationSource,\n    /** @inheritDoc */ public path: Path,\n    /** @inheritDoc */ public children: ImmutableTree<Node>\n  ) {}\n  operationForChild(childName: string): Operation {\n    if (pathIsEmpty(this.path)) {\n      const childTree = this.children.subtree(new Path(childName));\n      if (childTree.isEmpty()) {\n        // This child is unaffected\n        return null;\n      } else if (childTree.value) {\n        // We have a snapshot for the child in question.  This becomes an overwrite of the child.\n        return new Overwrite(this.source, newEmptyPath(), childTree.value);\n      } else {\n        // This is a merge at a deeper level\n        return new Merge(this.source, newEmptyPath(), childTree);\n      }\n    } else {\n      assert(\n        pathGetFront(this.path) === childName,\n        \"Can't get a merge for a child not on the path of the operation\"\n      );\n      return new Merge(this.source, pathPopFront(this.path), this.children);\n    }\n  }\n  toString(): string {\n    return (\n      'Operation(' +\n      this.path +\n      ': ' +\n      this.source.toString() +\n      ' merge: ' +\n      this.children.toString() +\n      ')'\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Node } from '../snap/Node';\nimport { Path, pathGetFront, pathIsEmpty } from '../util/Path';\n\n/**\n * A cache node only stores complete children. Additionally it holds a flag whether the node can be considered fully\n * initialized in the sense that we know at one point in time this represented a valid state of the world, e.g.\n * initialized with data from the server, or a complete overwrite by the client. The filtered flag also tracks\n * whether a node potentially had children removed due to a filter.\n */\nexport class CacheNode {\n  constructor(\n    private node_: Node,\n    private fullyInitialized_: boolean,\n    private filtered_: boolean\n  ) {}\n\n  /**\n   * Returns whether this node was fully initialized with either server data or a complete overwrite by the client\n   */\n  isFullyInitialized(): boolean {\n    return this.fullyInitialized_;\n  }\n\n  /**\n   * Returns whether this node is potentially missing children due to a filter applied to the node\n   */\n  isFiltered(): boolean {\n    return this.filtered_;\n  }\n\n  isCompleteForPath(path: Path): boolean {\n    if (pathIsEmpty(path)) {\n      return this.isFullyInitialized() && !this.filtered_;\n    }\n\n    const childKey = pathGetFront(path);\n    return this.isCompleteForChild(childKey);\n  }\n\n  isCompleteForChild(key: string): boolean {\n    return (\n      (this.isFullyInitialized() && !this.filtered_) || this.node_.hasChild(key)\n    );\n  }\n\n  getNode(): Node {\n    return this.node_;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assertionError } from '@firebase/util';\n\nimport { Index } from '../snap/indexes/Index';\nimport { NamedNode, Node } from '../snap/Node';\n\nimport { Change, ChangeType, changeChildMoved } from './Change';\nimport { Event } from './Event';\nimport { EventRegistration, QueryContext } from './EventRegistration';\n\n/**\n * An EventGenerator is used to convert \"raw\" changes (Change) as computed by the\n * CacheDiffer into actual events (Event) that can be raised.  See generateEventsForChanges()\n * for details.\n *\n */\nexport class EventGenerator {\n  index_: Index;\n\n  constructor(public query_: QueryContext) {\n    this.index_ = this.query_._queryParams.getIndex();\n  }\n}\n\n/**\n * Given a set of raw changes (no moved events and prevName not specified yet), and a set of\n * EventRegistrations that should be notified of these changes, generate the actual events to be raised.\n *\n * Notes:\n *  - child_moved events will be synthesized at this time for any child_changed events that affect\n *    our index.\n *  - prevName will be calculated based on the index ordering.\n */\nexport function eventGeneratorGenerateEventsForChanges(\n  eventGenerator: EventGenerator,\n  changes: Change[],\n  eventCache: Node,\n  eventRegistrations: EventRegistration[]\n): Event[] {\n  const events: Event[] = [];\n  const moves: Change[] = [];\n\n  changes.forEach(change => {\n    if (\n      change.type === ChangeType.CHILD_CHANGED &&\n      eventGenerator.index_.indexedValueChanged(\n        change.oldSnap as Node,\n        change.snapshotNode\n      )\n    ) {\n      moves.push(changeChildMoved(change.childName, change.snapshotNode));\n    }\n  });\n\n  eventGeneratorGenerateEventsForType(\n    eventGenerator,\n    events,\n    ChangeType.CHILD_REMOVED,\n    changes,\n    eventRegistrations,\n    eventCache\n  );\n  eventGeneratorGenerateEventsForType(\n    eventGenerator,\n    events,\n    ChangeType.CHILD_ADDED,\n    changes,\n    eventRegistrations,\n    eventCache\n  );\n  eventGeneratorGenerateEventsForType(\n    eventGenerator,\n    events,\n    ChangeType.CHILD_MOVED,\n    moves,\n    eventRegistrations,\n    eventCache\n  );\n  eventGeneratorGenerateEventsForType(\n    eventGenerator,\n    events,\n    ChangeType.CHILD_CHANGED,\n    changes,\n    eventRegistrations,\n    eventCache\n  );\n  eventGeneratorGenerateEventsForType(\n    eventGenerator,\n    events,\n    ChangeType.VALUE,\n    changes,\n    eventRegistrations,\n    eventCache\n  );\n\n  return events;\n}\n\n/**\n * Given changes of a single change type, generate the corresponding events.\n */\nfunction eventGeneratorGenerateEventsForType(\n  eventGenerator: EventGenerator,\n  events: Event[],\n  eventType: string,\n  changes: Change[],\n  registrations: EventRegistration[],\n  eventCache: Node\n) {\n  const filteredChanges = changes.filter(change => change.type === eventType);\n\n  filteredChanges.sort((a, b) =>\n    eventGeneratorCompareChanges(eventGenerator, a, b)\n  );\n  filteredChanges.forEach(change => {\n    const materializedChange = eventGeneratorMaterializeSingleChange(\n      eventGenerator,\n      change,\n      eventCache\n    );\n    registrations.forEach(registration => {\n      if (registration.respondsTo(change.type)) {\n        events.push(\n          registration.createEvent(materializedChange, eventGenerator.query_)\n        );\n      }\n    });\n  });\n}\n\nfunction eventGeneratorMaterializeSingleChange(\n  eventGenerator: EventGenerator,\n  change: Change,\n  eventCache: Node\n): Change {\n  if (change.type === 'value' || change.type === 'child_removed') {\n    return change;\n  } else {\n    change.prevName = eventCache.getPredecessorChildName(\n      change.childName,\n      change.snapshotNode,\n      eventGenerator.index_\n    );\n    return change;\n  }\n}\n\nfunction eventGeneratorCompareChanges(\n  eventGenerator: EventGenerator,\n  a: Change,\n  b: Change\n) {\n  if (a.childName == null || b.childName == null) {\n    throw assertionError('Should only compare child_ events.');\n  }\n  const aWrapped = new NamedNode(a.childName, a.snapshotNode);\n  const bWrapped = new NamedNode(b.childName, b.snapshotNode);\n  return eventGenerator.index_.compare(aWrapped, bWrapped);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Node } from '../snap/Node';\n\nimport { CacheNode } from './CacheNode';\n\n/**\n * Stores the data we have cached for a view.\n *\n * serverSnap is the cached server data, eventSnap is the cached event data (server data plus any local writes).\n */\nexport interface ViewCache {\n  readonly eventCache: CacheNode;\n  readonly serverCache: CacheNode;\n}\n\nexport function newViewCache(\n  eventCache: CacheNode,\n  serverCache: CacheNode\n): ViewCache {\n  return { eventCache, serverCache };\n}\n\nexport function viewCacheUpdateEventSnap(\n  viewCache: ViewCache,\n  eventSnap: Node,\n  complete: boolean,\n  filtered: boolean\n): ViewCache {\n  return newViewCache(\n    new CacheNode(eventSnap, complete, filtered),\n    viewCache.serverCache\n  );\n}\n\nexport function viewCacheUpdateServerSnap(\n  viewCache: ViewCache,\n  serverSnap: Node,\n  complete: boolean,\n  filtered: boolean\n): ViewCache {\n  return newViewCache(\n    viewCache.eventCache,\n    new CacheNode(serverSnap, complete, filtered)\n  );\n}\n\nexport function viewCacheGetCompleteEventSnap(\n  viewCache: ViewCache\n): Node | null {\n  return viewCache.eventCache.isFullyInitialized()\n    ? viewCache.eventCache.getNode()\n    : null;\n}\n\nexport function viewCacheGetCompleteServerSnap(\n  viewCache: ViewCache\n): Node | null {\n  return viewCache.serverCache.isFullyInitialized()\n    ? viewCache.serverCache.getNode()\n    : null;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  newEmptyPath,\n  Path,\n  pathChild,\n  pathGetFront,\n  pathIsEmpty,\n  pathPopFront\n} from './Path';\nimport { SortedMap } from './SortedMap';\nimport { each, stringCompare } from './util';\n\nlet emptyChildrenSingleton: SortedMap<string, ImmutableTree<null>>;\n\n/**\n * Singleton empty children collection.\n *\n */\nconst EmptyChildren = (): SortedMap<string, ImmutableTree<null>> => {\n  if (!emptyChildrenSingleton) {\n    emptyChildrenSingleton = new SortedMap<string, ImmutableTree<null>>(\n      stringCompare\n    );\n  }\n  return emptyChildrenSingleton;\n};\n\n/**\n * A tree with immutable elements.\n */\nexport class ImmutableTree<T> {\n  static fromObject<T>(obj: { [k: string]: T }): ImmutableTree<T> {\n    let tree: ImmutableTree<T> = new ImmutableTree<T>(null);\n    each(obj, (childPath: string, childSnap: T) => {\n      tree = tree.set(new Path(childPath), childSnap);\n    });\n    return tree;\n  }\n\n  constructor(\n    public readonly value: T | null,\n    public readonly children: SortedMap<\n      string,\n      ImmutableTree<T>\n    > = EmptyChildren()\n  ) {}\n\n  /**\n   * True if the value is empty and there are no children\n   */\n  isEmpty(): boolean {\n    return this.value === null && this.children.isEmpty();\n  }\n\n  /**\n   * Given a path and predicate, return the first node and the path to that node\n   * where the predicate returns true.\n   *\n   * TODO Do a perf test -- If we're creating a bunch of `{path: value:}`\n   * objects on the way back out, it may be better to pass down a pathSoFar obj.\n   *\n   * @param relativePath - The remainder of the path\n   * @param predicate - The predicate to satisfy to return a node\n   */\n  findRootMostMatchingPathAndValue(\n    relativePath: Path,\n    predicate: (a: T) => boolean\n  ): { path: Path; value: T } | null {\n    if (this.value != null && predicate(this.value)) {\n      return { path: newEmptyPath(), value: this.value };\n    } else {\n      if (pathIsEmpty(relativePath)) {\n        return null;\n      } else {\n        const front = pathGetFront(relativePath);\n        const child = this.children.get(front);\n        if (child !== null) {\n          const childExistingPathAndValue =\n            child.findRootMostMatchingPathAndValue(\n              pathPopFront(relativePath),\n              predicate\n            );\n          if (childExistingPathAndValue != null) {\n            const fullPath = pathChild(\n              new Path(front),\n              childExistingPathAndValue.path\n            );\n            return { path: fullPath, value: childExistingPathAndValue.value };\n          } else {\n            return null;\n          }\n        } else {\n          return null;\n        }\n      }\n    }\n  }\n\n  /**\n   * Find, if it exists, the shortest subpath of the given path that points a defined\n   * value in the tree\n   */\n  findRootMostValueAndPath(\n    relativePath: Path\n  ): { path: Path; value: T } | null {\n    return this.findRootMostMatchingPathAndValue(relativePath, () => true);\n  }\n\n  /**\n   * @returns The subtree at the given path\n   */\n  subtree(relativePath: Path): ImmutableTree<T> {\n    if (pathIsEmpty(relativePath)) {\n      return this;\n    } else {\n      const front = pathGetFront(relativePath);\n      const childTree = this.children.get(front);\n      if (childTree !== null) {\n        return childTree.subtree(pathPopFront(relativePath));\n      } else {\n        return new ImmutableTree<T>(null);\n      }\n    }\n  }\n\n  /**\n   * Sets a value at the specified path.\n   *\n   * @param relativePath - Path to set value at.\n   * @param toSet - Value to set.\n   * @returns Resulting tree.\n   */\n  set(relativePath: Path, toSet: T | null): ImmutableTree<T> {\n    if (pathIsEmpty(relativePath)) {\n      return new ImmutableTree(toSet, this.children);\n    } else {\n      const front = pathGetFront(relativePath);\n      const child = this.children.get(front) || new ImmutableTree<T>(null);\n      const newChild = child.set(pathPopFront(relativePath), toSet);\n      const newChildren = this.children.insert(front, newChild);\n      return new ImmutableTree(this.value, newChildren);\n    }\n  }\n\n  /**\n   * Removes the value at the specified path.\n   *\n   * @param relativePath - Path to value to remove.\n   * @returns Resulting tree.\n   */\n  remove(relativePath: Path): ImmutableTree<T> {\n    if (pathIsEmpty(relativePath)) {\n      if (this.children.isEmpty()) {\n        return new ImmutableTree<T>(null);\n      } else {\n        return new ImmutableTree(null, this.children);\n      }\n    } else {\n      const front = pathGetFront(relativePath);\n      const child = this.children.get(front);\n      if (child) {\n        const newChild = child.remove(pathPopFront(relativePath));\n        let newChildren;\n        if (newChild.isEmpty()) {\n          newChildren = this.children.remove(front);\n        } else {\n          newChildren = this.children.insert(front, newChild);\n        }\n        if (this.value === null && newChildren.isEmpty()) {\n          return new ImmutableTree<T>(null);\n        } else {\n          return new ImmutableTree(this.value, newChildren);\n        }\n      } else {\n        return this;\n      }\n    }\n  }\n\n  /**\n   * Gets a value from the tree.\n   *\n   * @param relativePath - Path to get value for.\n   * @returns Value at path, or null.\n   */\n  get(relativePath: Path): T | null {\n    if (pathIsEmpty(relativePath)) {\n      return this.value;\n    } else {\n      const front = pathGetFront(relativePath);\n      const child = this.children.get(front);\n      if (child) {\n        return child.get(pathPopFront(relativePath));\n      } else {\n        return null;\n      }\n    }\n  }\n\n  /**\n   * Replace the subtree at the specified path with the given new tree.\n   *\n   * @param relativePath - Path to replace subtree for.\n   * @param newTree - New tree.\n   * @returns Resulting tree.\n   */\n  setTree(relativePath: Path, newTree: ImmutableTree<T>): ImmutableTree<T> {\n    if (pathIsEmpty(relativePath)) {\n      return newTree;\n    } else {\n      const front = pathGetFront(relativePath);\n      const child = this.children.get(front) || new ImmutableTree<T>(null);\n      const newChild = child.setTree(pathPopFront(relativePath), newTree);\n      let newChildren;\n      if (newChild.isEmpty()) {\n        newChildren = this.children.remove(front);\n      } else {\n        newChildren = this.children.insert(front, newChild);\n      }\n      return new ImmutableTree(this.value, newChildren);\n    }\n  }\n\n  /**\n   * Performs a depth first fold on this tree. Transforms a tree into a single\n   * value, given a function that operates on the path to a node, an optional\n   * current value, and a map of child names to folded subtrees\n   */\n  fold<V>(fn: (path: Path, value: T, children: { [k: string]: V }) => V): V {\n    return this.fold_(newEmptyPath(), fn);\n  }\n\n  /**\n   * Recursive helper for public-facing fold() method\n   */\n  private fold_<V>(\n    pathSoFar: Path,\n    fn: (path: Path, value: T | null, children: { [k: string]: V }) => V\n  ): V {\n    const accum: { [k: string]: V } = {};\n    this.children.inorderTraversal(\n      (childKey: string, childTree: ImmutableTree<T>) => {\n        accum[childKey] = childTree.fold_(pathChild(pathSoFar, childKey), fn);\n      }\n    );\n    return fn(pathSoFar, this.value, accum);\n  }\n\n  /**\n   * Find the first matching value on the given path. Return the result of applying f to it.\n   */\n  findOnPath<V>(path: Path, f: (path: Path, value: T) => V | null): V | null {\n    return this.findOnPath_(path, newEmptyPath(), f);\n  }\n\n  private findOnPath_<V>(\n    pathToFollow: Path,\n    pathSoFar: Path,\n    f: (path: Path, value: T) => V | null\n  ): V | null {\n    const result = this.value ? f(pathSoFar, this.value) : false;\n    if (result) {\n      return result;\n    } else {\n      if (pathIsEmpty(pathToFollow)) {\n        return null;\n      } else {\n        const front = pathGetFront(pathToFollow)!;\n        const nextChild = this.children.get(front);\n        if (nextChild) {\n          return nextChild.findOnPath_(\n            pathPopFront(pathToFollow),\n            pathChild(pathSoFar, front),\n            f\n          );\n        } else {\n          return null;\n        }\n      }\n    }\n  }\n\n  foreachOnPath(\n    path: Path,\n    f: (path: Path, value: T) => void\n  ): ImmutableTree<T> {\n    return this.foreachOnPath_(path, newEmptyPath(), f);\n  }\n\n  private foreachOnPath_(\n    pathToFollow: Path,\n    currentRelativePath: Path,\n    f: (path: Path, value: T) => void\n  ): ImmutableTree<T> {\n    if (pathIsEmpty(pathToFollow)) {\n      return this;\n    } else {\n      if (this.value) {\n        f(currentRelativePath, this.value);\n      }\n      const front = pathGetFront(pathToFollow);\n      const nextChild = this.children.get(front);\n      if (nextChild) {\n        return nextChild.foreachOnPath_(\n          pathPopFront(pathToFollow),\n          pathChild(currentRelativePath, front),\n          f\n        );\n      } else {\n        return new ImmutableTree<T>(null);\n      }\n    }\n  }\n\n  /**\n   * Calls the given function for each node in the tree that has a value.\n   *\n   * @param f - A function to be called with the path from the root of the tree to\n   * a node, and the value at that node. Called in depth-first order.\n   */\n  foreach(f: (path: Path, value: T) => void) {\n    this.foreach_(newEmptyPath(), f);\n  }\n\n  private foreach_(\n    currentRelativePath: Path,\n    f: (path: Path, value: T) => void\n  ) {\n    this.children.inorderTraversal((childName, childTree) => {\n      childTree.foreach_(pathChild(currentRelativePath, childName), f);\n    });\n    if (this.value) {\n      f(currentRelativePath, this.value);\n    }\n  }\n\n  foreachChild(f: (name: string, value: T) => void) {\n    this.children.inorderTraversal(\n      (childName: string, childTree: ImmutableTree<T>) => {\n        if (childTree.value) {\n          f(childName, childTree.value);\n        }\n      }\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { ChildrenNode } from './snap/ChildrenNode';\nimport { PRIORITY_INDEX } from './snap/indexes/PriorityIndex';\nimport { NamedNode, Node } from './snap/Node';\nimport { ImmutableTree } from './util/ImmutableTree';\nimport {\n  newEmptyPath,\n  newRelativePath,\n  Path,\n  pathChild,\n  pathIsEmpty\n} from './util/Path';\nimport { each } from './util/util';\n\n/**\n * This class holds a collection of writes that can be applied to nodes in unison. It abstracts away the logic with\n * dealing with priority writes and multiple nested writes. At any given path there is only allowed to be one write\n * modifying that path. Any write to an existing path or shadowing an existing path will modify that existing write\n * to reflect the write added.\n */\nexport class CompoundWrite {\n  constructor(public writeTree_: ImmutableTree<Node>) {}\n\n  static empty(): CompoundWrite {\n    return new CompoundWrite(new ImmutableTree(null));\n  }\n}\n\nexport function compoundWriteAddWrite(\n  compoundWrite: CompoundWrite,\n  path: Path,\n  node: Node\n): CompoundWrite {\n  if (pathIsEmpty(path)) {\n    return new CompoundWrite(new ImmutableTree(node));\n  } else {\n    const rootmost = compoundWrite.writeTree_.findRootMostValueAndPath(path);\n    if (rootmost != null) {\n      const rootMostPath = rootmost.path;\n      let value = rootmost.value;\n      const relativePath = newRelativePath(rootMostPath, path);\n      value = value.updateChild(relativePath, node);\n      return new CompoundWrite(\n        compoundWrite.writeTree_.set(rootMostPath, value)\n      );\n    } else {\n      const subtree = new ImmutableTree(node);\n      const newWriteTree = compoundWrite.writeTree_.setTree(path, subtree);\n      return new CompoundWrite(newWriteTree);\n    }\n  }\n}\n\nexport function compoundWriteAddWrites(\n  compoundWrite: CompoundWrite,\n  path: Path,\n  updates: { [name: string]: Node }\n): CompoundWrite {\n  let newWrite = compoundWrite;\n  each(updates, (childKey: string, node: Node) => {\n    newWrite = compoundWriteAddWrite(newWrite, pathChild(path, childKey), node);\n  });\n  return newWrite;\n}\n\n/**\n * Will remove a write at the given path and deeper paths. This will <em>not</em> modify a write at a higher\n * location, which must be removed by calling this method with that path.\n *\n * @param compoundWrite - The CompoundWrite to remove.\n * @param path - The path at which a write and all deeper writes should be removed\n * @returns The new CompoundWrite with the removed path\n */\nexport function compoundWriteRemoveWrite(\n  compoundWrite: CompoundWrite,\n  path: Path\n): CompoundWrite {\n  if (pathIsEmpty(path)) {\n    return CompoundWrite.empty();\n  } else {\n    const newWriteTree = compoundWrite.writeTree_.setTree(\n      path,\n      new ImmutableTree<Node>(null)\n    );\n    return new CompoundWrite(newWriteTree);\n  }\n}\n\n/**\n * Returns whether this CompoundWrite will fully overwrite a node at a given location and can therefore be\n * considered \"complete\".\n *\n * @param compoundWrite - The CompoundWrite to check.\n * @param path - The path to check for\n * @returns Whether there is a complete write at that path\n */\nexport function compoundWriteHasCompleteWrite(\n  compoundWrite: CompoundWrite,\n  path: Path\n): boolean {\n  return compoundWriteGetCompleteNode(compoundWrite, path) != null;\n}\n\n/**\n * Returns a node for a path if and only if the node is a \"complete\" overwrite at that path. This will not aggregate\n * writes from deeper paths, but will return child nodes from a more shallow path.\n *\n * @param compoundWrite - The CompoundWrite to get the node from.\n * @param path - The path to get a complete write\n * @returns The node if complete at that path, or null otherwise.\n */\nexport function compoundWriteGetCompleteNode(\n  compoundWrite: CompoundWrite,\n  path: Path\n): Node | null {\n  const rootmost = compoundWrite.writeTree_.findRootMostValueAndPath(path);\n  if (rootmost != null) {\n    return compoundWrite.writeTree_\n      .get(rootmost.path)\n      .getChild(newRelativePath(rootmost.path, path));\n  } else {\n    return null;\n  }\n}\n\n/**\n * Returns all children that are guaranteed to be a complete overwrite.\n *\n * @param compoundWrite - The CompoundWrite to get children from.\n * @returns A list of all complete children.\n */\nexport function compoundWriteGetCompleteChildren(\n  compoundWrite: CompoundWrite\n): NamedNode[] {\n  const children: NamedNode[] = [];\n  const node = compoundWrite.writeTree_.value;\n  if (node != null) {\n    // If it's a leaf node, it has no children; so nothing to do.\n    if (!node.isLeafNode()) {\n      (node as ChildrenNode).forEachChild(\n        PRIORITY_INDEX,\n        (childName, childNode) => {\n          children.push(new NamedNode(childName, childNode));\n        }\n      );\n    }\n  } else {\n    compoundWrite.writeTree_.children.inorderTraversal(\n      (childName, childTree) => {\n        if (childTree.value != null) {\n          children.push(new NamedNode(childName, childTree.value));\n        }\n      }\n    );\n  }\n  return children;\n}\n\nexport function compoundWriteChildCompoundWrite(\n  compoundWrite: CompoundWrite,\n  path: Path\n): CompoundWrite {\n  if (pathIsEmpty(path)) {\n    return compoundWrite;\n  } else {\n    const shadowingNode = compoundWriteGetCompleteNode(compoundWrite, path);\n    if (shadowingNode != null) {\n      return new CompoundWrite(new ImmutableTree(shadowingNode));\n    } else {\n      return new CompoundWrite(compoundWrite.writeTree_.subtree(path));\n    }\n  }\n}\n\n/**\n * Returns true if this CompoundWrite is empty and therefore does not modify any nodes.\n * @returns Whether this CompoundWrite is empty\n */\nexport function compoundWriteIsEmpty(compoundWrite: CompoundWrite): boolean {\n  return compoundWrite.writeTree_.isEmpty();\n}\n\n/**\n * Applies this CompoundWrite to a node. The node is returned with all writes from this CompoundWrite applied to the\n * node\n * @param node - The node to apply this CompoundWrite to\n * @returns The node with all writes applied\n */\nexport function compoundWriteApply(\n  compoundWrite: CompoundWrite,\n  node: Node\n): Node {\n  return applySubtreeWrite(newEmptyPath(), compoundWrite.writeTree_, node);\n}\n\nfunction applySubtreeWrite(\n  relativePath: Path,\n  writeTree: ImmutableTree<Node>,\n  node: Node\n): Node {\n  if (writeTree.value != null) {\n    // Since there a write is always a leaf, we're done here\n    return node.updateChild(relativePath, writeTree.value);\n  } else {\n    let priorityWrite = null;\n    writeTree.children.inorderTraversal((childKey, childTree) => {\n      if (childKey === '.priority') {\n        // Apply priorities at the end so we don't update priorities for either empty nodes or forget\n        // to apply priorities to empty nodes that are later filled\n        assert(\n          childTree.value !== null,\n          'Priority writes must always be leaf nodes'\n        );\n        priorityWrite = childTree.value;\n      } else {\n        node = applySubtreeWrite(\n          pathChild(relativePath, childKey),\n          childTree,\n          node\n        );\n      }\n    });\n    // If there was a priority write, we only apply it if the node is not empty\n    if (!node.getChild(relativePath).isEmpty() && priorityWrite !== null) {\n      node = node.updateChild(\n        pathChild(relativePath, '.priority'),\n        priorityWrite\n      );\n    }\n    return node;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert, assertionError, safeGet } from '@firebase/util';\n\nimport {\n  CompoundWrite,\n  compoundWriteAddWrite,\n  compoundWriteAddWrites,\n  compoundWriteApply,\n  compoundWriteChildCompoundWrite,\n  compoundWriteGetCompleteChildren,\n  compoundWriteGetCompleteNode,\n  compoundWriteHasCompleteWrite,\n  compoundWriteIsEmpty,\n  compoundWriteRemoveWrite\n} from './CompoundWrite';\nimport { ChildrenNode } from './snap/ChildrenNode';\nimport { Index } from './snap/indexes/Index';\nimport { PRIORITY_INDEX } from './snap/indexes/PriorityIndex';\nimport { NamedNode, Node } from './snap/Node';\nimport {\n  newEmptyPath,\n  newRelativePath,\n  Path,\n  pathChild,\n  pathContains,\n  pathGetFront,\n  pathIsEmpty,\n  pathPopFront\n} from './util/Path';\nimport { each } from './util/util';\nimport { CacheNode } from './view/CacheNode';\n\n/**\n * Defines a single user-initiated write operation. May be the result of a set(), transaction(), or update() call. In\n * the case of a set() or transaction, snap wil be non-null.  In the case of an update(), children will be non-null.\n */\nexport interface WriteRecord {\n  writeId: number;\n  path: Path;\n  snap?: Node | null;\n  children?: { [k: string]: Node } | null;\n  visible: boolean;\n}\n\n/**\n * Create a new WriteTreeRef for the given path. For use with a new sync point at the given path.\n *\n */\nexport function writeTreeChildWrites(\n  writeTree: WriteTree,\n  path: Path\n): WriteTreeRef {\n  return newWriteTreeRef(path, writeTree);\n}\n\n/**\n * Record a new overwrite from user code.\n *\n * @param visible - This is set to false by some transactions. It should be excluded from event caches\n */\nexport function writeTreeAddOverwrite(\n  writeTree: WriteTree,\n  path: Path,\n  snap: Node,\n  writeId: number,\n  visible?: boolean\n) {\n  assert(\n    writeId > writeTree.lastWriteId,\n    'Stacking an older write on top of newer ones'\n  );\n  if (visible === undefined) {\n    visible = true;\n  }\n  writeTree.allWrites.push({\n    path,\n    snap,\n    writeId,\n    visible\n  });\n\n  if (visible) {\n    writeTree.visibleWrites = compoundWriteAddWrite(\n      writeTree.visibleWrites,\n      path,\n      snap\n    );\n  }\n  writeTree.lastWriteId = writeId;\n}\n\n/**\n * Record a new merge from user code.\n */\nexport function writeTreeAddMerge(\n  writeTree: WriteTree,\n  path: Path,\n  changedChildren: { [k: string]: Node },\n  writeId: number\n) {\n  assert(\n    writeId > writeTree.lastWriteId,\n    'Stacking an older merge on top of newer ones'\n  );\n  writeTree.allWrites.push({\n    path,\n    children: changedChildren,\n    writeId,\n    visible: true\n  });\n\n  writeTree.visibleWrites = compoundWriteAddWrites(\n    writeTree.visibleWrites,\n    path,\n    changedChildren\n  );\n  writeTree.lastWriteId = writeId;\n}\n\nexport function writeTreeGetWrite(\n  writeTree: WriteTree,\n  writeId: number\n): WriteRecord | null {\n  for (let i = 0; i < writeTree.allWrites.length; i++) {\n    const record = writeTree.allWrites[i];\n    if (record.writeId === writeId) {\n      return record;\n    }\n  }\n  return null;\n}\n\n/**\n * Remove a write (either an overwrite or merge) that has been successfully acknowledge by the server. Recalculates\n * the tree if necessary.  We return true if it may have been visible, meaning views need to reevaluate.\n *\n * @returns true if the write may have been visible (meaning we'll need to reevaluate / raise\n * events as a result).\n */\nexport function writeTreeRemoveWrite(\n  writeTree: WriteTree,\n  writeId: number\n): boolean {\n  // Note: disabling this check. It could be a transaction that preempted another transaction, and thus was applied\n  // out of order.\n  //const validClear = revert || this.allWrites_.length === 0 || writeId <= this.allWrites_[0].writeId;\n  //assert(validClear, \"Either we don't have this write, or it's the first one in the queue\");\n\n  const idx = writeTree.allWrites.findIndex(s => {\n    return s.writeId === writeId;\n  });\n  assert(idx >= 0, 'removeWrite called with nonexistent writeId.');\n  const writeToRemove = writeTree.allWrites[idx];\n  writeTree.allWrites.splice(idx, 1);\n\n  let removedWriteWasVisible = writeToRemove.visible;\n  let removedWriteOverlapsWithOtherWrites = false;\n\n  let i = writeTree.allWrites.length - 1;\n\n  while (removedWriteWasVisible && i >= 0) {\n    const currentWrite = writeTree.allWrites[i];\n    if (currentWrite.visible) {\n      if (\n        i >= idx &&\n        writeTreeRecordContainsPath_(currentWrite, writeToRemove.path)\n      ) {\n        // The removed write was completely shadowed by a subsequent write.\n        removedWriteWasVisible = false;\n      } else if (pathContains(writeToRemove.path, currentWrite.path)) {\n        // Either we're covering some writes or they're covering part of us (depending on which came first).\n        removedWriteOverlapsWithOtherWrites = true;\n      }\n    }\n    i--;\n  }\n\n  if (!removedWriteWasVisible) {\n    return false;\n  } else if (removedWriteOverlapsWithOtherWrites) {\n    // There's some shadowing going on. Just rebuild the visible writes from scratch.\n    writeTreeResetTree_(writeTree);\n    return true;\n  } else {\n    // There's no shadowing.  We can safely just remove the write(s) from visibleWrites.\n    if (writeToRemove.snap) {\n      writeTree.visibleWrites = compoundWriteRemoveWrite(\n        writeTree.visibleWrites,\n        writeToRemove.path\n      );\n    } else {\n      const children = writeToRemove.children;\n      each(children, (childName: string) => {\n        writeTree.visibleWrites = compoundWriteRemoveWrite(\n          writeTree.visibleWrites,\n          pathChild(writeToRemove.path, childName)\n        );\n      });\n    }\n    return true;\n  }\n}\n\nfunction writeTreeRecordContainsPath_(\n  writeRecord: WriteRecord,\n  path: Path\n): boolean {\n  if (writeRecord.snap) {\n    return pathContains(writeRecord.path, path);\n  } else {\n    for (const childName in writeRecord.children) {\n      if (\n        writeRecord.children.hasOwnProperty(childName) &&\n        pathContains(pathChild(writeRecord.path, childName), path)\n      ) {\n        return true;\n      }\n    }\n    return false;\n  }\n}\n\n/**\n * Re-layer the writes and merges into a tree so we can efficiently calculate event snapshots\n */\nfunction writeTreeResetTree_(writeTree: WriteTree) {\n  writeTree.visibleWrites = writeTreeLayerTree_(\n    writeTree.allWrites,\n    writeTreeDefaultFilter_,\n    newEmptyPath()\n  );\n  if (writeTree.allWrites.length > 0) {\n    writeTree.lastWriteId =\n      writeTree.allWrites[writeTree.allWrites.length - 1].writeId;\n  } else {\n    writeTree.lastWriteId = -1;\n  }\n}\n\n/**\n * The default filter used when constructing the tree. Keep everything that's visible.\n */\nfunction writeTreeDefaultFilter_(write: WriteRecord) {\n  return write.visible;\n}\n\n/**\n * Static method. Given an array of WriteRecords, a filter for which ones to include, and a path, construct the tree of\n * event data at that path.\n */\nfunction writeTreeLayerTree_(\n  writes: WriteRecord[],\n  filter: (w: WriteRecord) => boolean,\n  treeRoot: Path\n): CompoundWrite {\n  let compoundWrite = CompoundWrite.empty();\n  for (let i = 0; i < writes.length; ++i) {\n    const write = writes[i];\n    // Theory, a later set will either:\n    // a) abort a relevant transaction, so no need to worry about excluding it from calculating that transaction\n    // b) not be relevant to a transaction (separate branch), so again will not affect the data for that transaction\n    if (filter(write)) {\n      const writePath = write.path;\n      let relativePath: Path;\n      if (write.snap) {\n        if (pathContains(treeRoot, writePath)) {\n          relativePath = newRelativePath(treeRoot, writePath);\n          compoundWrite = compoundWriteAddWrite(\n            compoundWrite,\n            relativePath,\n            write.snap\n          );\n        } else if (pathContains(writePath, treeRoot)) {\n          relativePath = newRelativePath(writePath, treeRoot);\n          compoundWrite = compoundWriteAddWrite(\n            compoundWrite,\n            newEmptyPath(),\n            write.snap.getChild(relativePath)\n          );\n        } else {\n          // There is no overlap between root path and write path, ignore write\n        }\n      } else if (write.children) {\n        if (pathContains(treeRoot, writePath)) {\n          relativePath = newRelativePath(treeRoot, writePath);\n          compoundWrite = compoundWriteAddWrites(\n            compoundWrite,\n            relativePath,\n            write.children\n          );\n        } else if (pathContains(writePath, treeRoot)) {\n          relativePath = newRelativePath(writePath, treeRoot);\n          if (pathIsEmpty(relativePath)) {\n            compoundWrite = compoundWriteAddWrites(\n              compoundWrite,\n              newEmptyPath(),\n              write.children\n            );\n          } else {\n            const child = safeGet(write.children, pathGetFront(relativePath));\n            if (child) {\n              // There exists a child in this node that matches the root path\n              const deepNode = child.getChild(pathPopFront(relativePath));\n              compoundWrite = compoundWriteAddWrite(\n                compoundWrite,\n                newEmptyPath(),\n                deepNode\n              );\n            }\n          }\n        } else {\n          // There is no overlap between root path and write path, ignore write\n        }\n      } else {\n        throw assertionError('WriteRecord should have .snap or .children');\n      }\n    }\n  }\n  return compoundWrite;\n}\n\n/**\n * Return a complete snapshot for the given path if there's visible write data at that path, else null.\n * No server data is considered.\n *\n */\nexport function writeTreeGetCompleteWriteData(\n  writeTree: WriteTree,\n  path: Path\n): Node | null {\n  return compoundWriteGetCompleteNode(writeTree.visibleWrites, path);\n}\n\n/**\n * Given optional, underlying server data, and an optional set of constraints (exclude some sets, include hidden\n * writes), attempt to calculate a complete snapshot for the given path\n *\n * @param writeIdsToExclude - An optional set to be excluded\n * @param includeHiddenWrites - Defaults to false, whether or not to layer on writes with visible set to false\n */\nexport function writeTreeCalcCompleteEventCache(\n  writeTree: WriteTree,\n  treePath: Path,\n  completeServerCache: Node | null,\n  writeIdsToExclude?: number[],\n  includeHiddenWrites?: boolean\n): Node | null {\n  if (!writeIdsToExclude && !includeHiddenWrites) {\n    const shadowingNode = compoundWriteGetCompleteNode(\n      writeTree.visibleWrites,\n      treePath\n    );\n    if (shadowingNode != null) {\n      return shadowingNode;\n    } else {\n      const subMerge = compoundWriteChildCompoundWrite(\n        writeTree.visibleWrites,\n        treePath\n      );\n      if (compoundWriteIsEmpty(subMerge)) {\n        return completeServerCache;\n      } else if (\n        completeServerCache == null &&\n        !compoundWriteHasCompleteWrite(subMerge, newEmptyPath())\n      ) {\n        // We wouldn't have a complete snapshot, since there's no underlying data and no complete shadow\n        return null;\n      } else {\n        const layeredCache = completeServerCache || ChildrenNode.EMPTY_NODE;\n        return compoundWriteApply(subMerge, layeredCache);\n      }\n    }\n  } else {\n    const merge = compoundWriteChildCompoundWrite(\n      writeTree.visibleWrites,\n      treePath\n    );\n    if (!includeHiddenWrites && compoundWriteIsEmpty(merge)) {\n      return completeServerCache;\n    } else {\n      // If the server cache is null, and we don't have a complete cache, we need to return null\n      if (\n        !includeHiddenWrites &&\n        completeServerCache == null &&\n        !compoundWriteHasCompleteWrite(merge, newEmptyPath())\n      ) {\n        return null;\n      } else {\n        const filter = function (write: WriteRecord) {\n          return (\n            (write.visible || includeHiddenWrites) &&\n            (!writeIdsToExclude ||\n              !~writeIdsToExclude.indexOf(write.writeId)) &&\n            (pathContains(write.path, treePath) ||\n              pathContains(treePath, write.path))\n          );\n        };\n        const mergeAtPath = writeTreeLayerTree_(\n          writeTree.allWrites,\n          filter,\n          treePath\n        );\n        const layeredCache = completeServerCache || ChildrenNode.EMPTY_NODE;\n        return compoundWriteApply(mergeAtPath, layeredCache);\n      }\n    }\n  }\n}\n\n/**\n * With optional, underlying server data, attempt to return a children node of children that we have complete data for.\n * Used when creating new views, to pre-fill their complete event children snapshot.\n */\nexport function writeTreeCalcCompleteEventChildren(\n  writeTree: WriteTree,\n  treePath: Path,\n  completeServerChildren: ChildrenNode | null\n) {\n  let completeChildren = ChildrenNode.EMPTY_NODE as Node;\n  const topLevelSet = compoundWriteGetCompleteNode(\n    writeTree.visibleWrites,\n    treePath\n  );\n  if (topLevelSet) {\n    if (!topLevelSet.isLeafNode()) {\n      // we're shadowing everything. Return the children.\n      topLevelSet.forEachChild(PRIORITY_INDEX, (childName, childSnap) => {\n        completeChildren = completeChildren.updateImmediateChild(\n          childName,\n          childSnap\n        );\n      });\n    }\n    return completeChildren;\n  } else if (completeServerChildren) {\n    // Layer any children we have on top of this\n    // We know we don't have a top-level set, so just enumerate existing children\n    const merge = compoundWriteChildCompoundWrite(\n      writeTree.visibleWrites,\n      treePath\n    );\n    completeServerChildren.forEachChild(\n      PRIORITY_INDEX,\n      (childName, childNode) => {\n        const node = compoundWriteApply(\n          compoundWriteChildCompoundWrite(merge, new Path(childName)),\n          childNode\n        );\n        completeChildren = completeChildren.updateImmediateChild(\n          childName,\n          node\n        );\n      }\n    );\n    // Add any complete children we have from the set\n    compoundWriteGetCompleteChildren(merge).forEach(namedNode => {\n      completeChildren = completeChildren.updateImmediateChild(\n        namedNode.name,\n        namedNode.node\n      );\n    });\n    return completeChildren;\n  } else {\n    // We don't have anything to layer on top of. Layer on any children we have\n    // Note that we can return an empty snap if we have a defined delete\n    const merge = compoundWriteChildCompoundWrite(\n      writeTree.visibleWrites,\n      treePath\n    );\n    compoundWriteGetCompleteChildren(merge).forEach(namedNode => {\n      completeChildren = completeChildren.updateImmediateChild(\n        namedNode.name,\n        namedNode.node\n      );\n    });\n    return completeChildren;\n  }\n}\n\n/**\n * Given that the underlying server data has updated, determine what, if anything, needs to be\n * applied to the event cache.\n *\n * Possibilities:\n *\n * 1. No writes are shadowing. Events should be raised, the snap to be applied comes from the server data\n *\n * 2. Some write is completely shadowing. No events to be raised\n *\n * 3. Is partially shadowed. Events\n *\n * Either existingEventSnap or existingServerSnap must exist\n */\nexport function writeTreeCalcEventCacheAfterServerOverwrite(\n  writeTree: WriteTree,\n  treePath: Path,\n  childPath: Path,\n  existingEventSnap: Node | null,\n  existingServerSnap: Node | null\n): Node | null {\n  assert(\n    existingEventSnap || existingServerSnap,\n    'Either existingEventSnap or existingServerSnap must exist'\n  );\n  const path = pathChild(treePath, childPath);\n  if (compoundWriteHasCompleteWrite(writeTree.visibleWrites, path)) {\n    // At this point we can probably guarantee that we're in case 2, meaning no events\n    // May need to check visibility while doing the findRootMostValueAndPath call\n    return null;\n  } else {\n    // No complete shadowing. We're either partially shadowing or not shadowing at all.\n    const childMerge = compoundWriteChildCompoundWrite(\n      writeTree.visibleWrites,\n      path\n    );\n    if (compoundWriteIsEmpty(childMerge)) {\n      // We're not shadowing at all. Case 1\n      return existingServerSnap.getChild(childPath);\n    } else {\n      // This could be more efficient if the serverNode + updates doesn't change the eventSnap\n      // However this is tricky to find out, since user updates don't necessary change the server\n      // snap, e.g. priority updates on empty nodes, or deep deletes. Another special case is if the server\n      // adds nodes, but doesn't change any existing writes. It is therefore not enough to\n      // only check if the updates change the serverNode.\n      // Maybe check if the merge tree contains these special cases and only do a full overwrite in that case?\n      return compoundWriteApply(\n        childMerge,\n        existingServerSnap.getChild(childPath)\n      );\n    }\n  }\n}\n\n/**\n * Returns a complete child for a given server snap after applying all user writes or null if there is no\n * complete child for this ChildKey.\n */\nexport function writeTreeCalcCompleteChild(\n  writeTree: WriteTree,\n  treePath: Path,\n  childKey: string,\n  existingServerSnap: CacheNode\n): Node | null {\n  const path = pathChild(treePath, childKey);\n  const shadowingNode = compoundWriteGetCompleteNode(\n    writeTree.visibleWrites,\n    path\n  );\n  if (shadowingNode != null) {\n    return shadowingNode;\n  } else {\n    if (existingServerSnap.isCompleteForChild(childKey)) {\n      const childMerge = compoundWriteChildCompoundWrite(\n        writeTree.visibleWrites,\n        path\n      );\n      return compoundWriteApply(\n        childMerge,\n        existingServerSnap.getNode().getImmediateChild(childKey)\n      );\n    } else {\n      return null;\n    }\n  }\n}\n\n/**\n * Returns a node if there is a complete overwrite for this path. More specifically, if there is a write at\n * a higher path, this will return the child of that write relative to the write and this path.\n * Returns null if there is no write at this path.\n */\nexport function writeTreeShadowingWrite(\n  writeTree: WriteTree,\n  path: Path\n): Node | null {\n  return compoundWriteGetCompleteNode(writeTree.visibleWrites, path);\n}\n\n/**\n * This method is used when processing child remove events on a query. If we can, we pull in children that were outside\n * the window, but may now be in the window.\n */\nexport function writeTreeCalcIndexedSlice(\n  writeTree: WriteTree,\n  treePath: Path,\n  completeServerData: Node | null,\n  startPost: NamedNode,\n  count: number,\n  reverse: boolean,\n  index: Index\n): NamedNode[] {\n  let toIterate: Node;\n  const merge = compoundWriteChildCompoundWrite(\n    writeTree.visibleWrites,\n    treePath\n  );\n  const shadowingNode = compoundWriteGetCompleteNode(merge, newEmptyPath());\n  if (shadowingNode != null) {\n    toIterate = shadowingNode;\n  } else if (completeServerData != null) {\n    toIterate = compoundWriteApply(merge, completeServerData);\n  } else {\n    // no children to iterate on\n    return [];\n  }\n  toIterate = toIterate.withIndex(index);\n  if (!toIterate.isEmpty() && !toIterate.isLeafNode()) {\n    const nodes = [];\n    const cmp = index.getCompare();\n    const iter = reverse\n      ? (toIterate as ChildrenNode).getReverseIteratorFrom(startPost, index)\n      : (toIterate as ChildrenNode).getIteratorFrom(startPost, index);\n    let next = iter.getNext();\n    while (next && nodes.length < count) {\n      if (cmp(next, startPost) !== 0) {\n        nodes.push(next);\n      }\n      next = iter.getNext();\n    }\n    return nodes;\n  } else {\n    return [];\n  }\n}\n\nexport function newWriteTree(): WriteTree {\n  return {\n    visibleWrites: CompoundWrite.empty(),\n    allWrites: [],\n    lastWriteId: -1\n  };\n}\n\n/**\n * WriteTree tracks all pending user-initiated writes and has methods to calculate the result of merging them\n * with underlying server data (to create \"event cache\" data).  Pending writes are added with addOverwrite()\n * and addMerge(), and removed with removeWrite().\n */\nexport interface WriteTree {\n  /**\n   * A tree tracking the result of applying all visible writes.  This does not include transactions with\n   * applyLocally=false or writes that are completely shadowed by other writes.\n   */\n  visibleWrites: CompoundWrite;\n\n  /**\n   * A list of all pending writes, regardless of visibility and shadowed-ness.  Used to calculate arbitrary\n   * sets of the changed data, such as hidden writes (from transactions) or changes with certain writes excluded (also\n   * used by transactions).\n   */\n  allWrites: WriteRecord[];\n\n  lastWriteId: number;\n}\n\n/**\n * If possible, returns a complete event cache, using the underlying server data if possible. In addition, can be used\n * to get a cache that includes hidden writes, and excludes arbitrary writes. Note that customizing the returned node\n * can lead to a more expensive calculation.\n *\n * @param writeIdsToExclude - Optional writes to exclude.\n * @param includeHiddenWrites - Defaults to false, whether or not to layer on writes with visible set to false\n */\nexport function writeTreeRefCalcCompleteEventCache(\n  writeTreeRef: WriteTreeRef,\n  completeServerCache: Node | null,\n  writeIdsToExclude?: number[],\n  includeHiddenWrites?: boolean\n): Node | null {\n  return writeTreeCalcCompleteEventCache(\n    writeTreeRef.writeTree,\n    writeTreeRef.treePath,\n    completeServerCache,\n    writeIdsToExclude,\n    includeHiddenWrites\n  );\n}\n\n/**\n * If possible, returns a children node containing all of the complete children we have data for. The returned data is a\n * mix of the given server data and write data.\n *\n */\nexport function writeTreeRefCalcCompleteEventChildren(\n  writeTreeRef: WriteTreeRef,\n  completeServerChildren: ChildrenNode | null\n): ChildrenNode {\n  return writeTreeCalcCompleteEventChildren(\n    writeTreeRef.writeTree,\n    writeTreeRef.treePath,\n    completeServerChildren\n  ) as ChildrenNode;\n}\n\n/**\n * Given that either the underlying server data has updated or the outstanding writes have updated, determine what,\n * if anything, needs to be applied to the event cache.\n *\n * Possibilities:\n *\n * 1. No writes are shadowing. Events should be raised, the snap to be applied comes from the server data\n *\n * 2. Some write is completely shadowing. No events to be raised\n *\n * 3. Is partially shadowed. Events should be raised\n *\n * Either existingEventSnap or existingServerSnap must exist, this is validated via an assert\n *\n *\n */\nexport function writeTreeRefCalcEventCacheAfterServerOverwrite(\n  writeTreeRef: WriteTreeRef,\n  path: Path,\n  existingEventSnap: Node | null,\n  existingServerSnap: Node | null\n): Node | null {\n  return writeTreeCalcEventCacheAfterServerOverwrite(\n    writeTreeRef.writeTree,\n    writeTreeRef.treePath,\n    path,\n    existingEventSnap,\n    existingServerSnap\n  );\n}\n\n/**\n * Returns a node if there is a complete overwrite for this path. More specifically, if there is a write at\n * a higher path, this will return the child of that write relative to the write and this path.\n * Returns null if there is no write at this path.\n *\n */\nexport function writeTreeRefShadowingWrite(\n  writeTreeRef: WriteTreeRef,\n  path: Path\n): Node | null {\n  return writeTreeShadowingWrite(\n    writeTreeRef.writeTree,\n    pathChild(writeTreeRef.treePath, path)\n  );\n}\n\n/**\n * This method is used when processing child remove events on a query. If we can, we pull in children that were outside\n * the window, but may now be in the window\n */\nexport function writeTreeRefCalcIndexedSlice(\n  writeTreeRef: WriteTreeRef,\n  completeServerData: Node | null,\n  startPost: NamedNode,\n  count: number,\n  reverse: boolean,\n  index: Index\n): NamedNode[] {\n  return writeTreeCalcIndexedSlice(\n    writeTreeRef.writeTree,\n    writeTreeRef.treePath,\n    completeServerData,\n    startPost,\n    count,\n    reverse,\n    index\n  );\n}\n\n/**\n * Returns a complete child for a given server snap after applying all user writes or null if there is no\n * complete child for this ChildKey.\n */\nexport function writeTreeRefCalcCompleteChild(\n  writeTreeRef: WriteTreeRef,\n  childKey: string,\n  existingServerCache: CacheNode\n): Node | null {\n  return writeTreeCalcCompleteChild(\n    writeTreeRef.writeTree,\n    writeTreeRef.treePath,\n    childKey,\n    existingServerCache\n  );\n}\n\n/**\n * Return a WriteTreeRef for a child.\n */\nexport function writeTreeRefChild(\n  writeTreeRef: WriteTreeRef,\n  childName: string\n): WriteTreeRef {\n  return newWriteTreeRef(\n    pathChild(writeTreeRef.treePath, childName),\n    writeTreeRef.writeTree\n  );\n}\n\nexport function newWriteTreeRef(\n  path: Path,\n  writeTree: WriteTree\n): WriteTreeRef {\n  return {\n    treePath: path,\n    writeTree\n  };\n}\n\n/**\n * A WriteTreeRef wraps a WriteTree and a path, for convenient access to a particular subtree.  All of the methods\n * just proxy to the underlying WriteTree.\n *\n */\nexport interface WriteTreeRef {\n  /**\n   * The path to this particular write tree ref. Used for calling methods on writeTree_ while exposing a simpler\n   * interface to callers.\n   */\n  readonly treePath: Path;\n\n  /**\n   * * A reference to the actual tree of write data. All methods are pass-through to the tree, but with the appropriate\n   * path prefixed.\n   *\n   * This lets us make cheap references to points in the tree for sync points without having to copy and maintain all of\n   * the data.\n   */\n  readonly writeTree: WriteTree;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert, assertionError } from '@firebase/util';\n\nimport { AckUserWrite } from '../operation/AckUserWrite';\nimport { Merge } from '../operation/Merge';\nimport { Operation, OperationType } from '../operation/Operation';\nimport { Overwrite } from '../operation/Overwrite';\nimport { ChildrenNode } from '../snap/ChildrenNode';\nimport { KEY_INDEX } from '../snap/indexes/KeyIndex';\nimport { Node } from '../snap/Node';\nimport { ImmutableTree } from '../util/ImmutableTree';\nimport {\n  newEmptyPath,\n  Path,\n  pathChild,\n  pathGetBack,\n  pathGetFront,\n  pathGetLength,\n  pathIsEmpty,\n  pathParent,\n  pathPopFront\n} from '../util/Path';\nimport {\n  WriteTreeRef,\n  writeTreeRefCalcCompleteChild,\n  writeTreeRefCalcCompleteEventCache,\n  writeTreeRefCalcCompleteEventChildren,\n  writeTreeRefCalcEventCacheAfterServerOverwrite,\n  writeTreeRefShadowingWrite\n} from '../WriteTree';\n\nimport { Change, changeValue } from './Change';\nimport { ChildChangeAccumulator } from './ChildChangeAccumulator';\nimport {\n  CompleteChildSource,\n  NO_COMPLETE_CHILD_SOURCE,\n  WriteTreeCompleteChildSource\n} from './CompleteChildSource';\nimport { NodeFilter } from './filter/NodeFilter';\nimport {\n  ViewCache,\n  viewCacheGetCompleteEventSnap,\n  viewCacheGetCompleteServerSnap,\n  viewCacheUpdateEventSnap,\n  viewCacheUpdateServerSnap\n} from './ViewCache';\n\nexport interface ProcessorResult {\n  readonly viewCache: ViewCache;\n  readonly changes: Change[];\n}\n\nexport interface ViewProcessor {\n  readonly filter: NodeFilter;\n}\n\nexport function newViewProcessor(filter: NodeFilter): ViewProcessor {\n  return { filter };\n}\n\nexport function viewProcessorAssertIndexed(\n  viewProcessor: ViewProcessor,\n  viewCache: ViewCache\n): void {\n  assert(\n    viewCache.eventCache.getNode().isIndexed(viewProcessor.filter.getIndex()),\n    'Event snap not indexed'\n  );\n  assert(\n    viewCache.serverCache.getNode().isIndexed(viewProcessor.filter.getIndex()),\n    'Server snap not indexed'\n  );\n}\n\nexport function viewProcessorApplyOperation(\n  viewProcessor: ViewProcessor,\n  oldViewCache: ViewCache,\n  operation: Operation,\n  writesCache: WriteTreeRef,\n  completeCache: Node | null\n): ProcessorResult {\n  const accumulator = new ChildChangeAccumulator();\n  let newViewCache, filterServerNode;\n  if (operation.type === OperationType.OVERWRITE) {\n    const overwrite = operation as Overwrite;\n    if (overwrite.source.fromUser) {\n      newViewCache = viewProcessorApplyUserOverwrite(\n        viewProcessor,\n        oldViewCache,\n        overwrite.path,\n        overwrite.snap,\n        writesCache,\n        completeCache,\n        accumulator\n      );\n    } else {\n      assert(overwrite.source.fromServer, 'Unknown source.');\n      // We filter the node if it's a tagged update or the node has been previously filtered  and the\n      // update is not at the root in which case it is ok (and necessary) to mark the node unfiltered\n      // again\n      filterServerNode =\n        overwrite.source.tagged ||\n        (oldViewCache.serverCache.isFiltered() && !pathIsEmpty(overwrite.path));\n      newViewCache = viewProcessorApplyServerOverwrite(\n        viewProcessor,\n        oldViewCache,\n        overwrite.path,\n        overwrite.snap,\n        writesCache,\n        completeCache,\n        filterServerNode,\n        accumulator\n      );\n    }\n  } else if (operation.type === OperationType.MERGE) {\n    const merge = operation as Merge;\n    if (merge.source.fromUser) {\n      newViewCache = viewProcessorApplyUserMerge(\n        viewProcessor,\n        oldViewCache,\n        merge.path,\n        merge.children,\n        writesCache,\n        completeCache,\n        accumulator\n      );\n    } else {\n      assert(merge.source.fromServer, 'Unknown source.');\n      // We filter the node if it's a tagged update or the node has been previously filtered\n      filterServerNode =\n        merge.source.tagged || oldViewCache.serverCache.isFiltered();\n      newViewCache = viewProcessorApplyServerMerge(\n        viewProcessor,\n        oldViewCache,\n        merge.path,\n        merge.children,\n        writesCache,\n        completeCache,\n        filterServerNode,\n        accumulator\n      );\n    }\n  } else if (operation.type === OperationType.ACK_USER_WRITE) {\n    const ackUserWrite = operation as AckUserWrite;\n    if (!ackUserWrite.revert) {\n      newViewCache = viewProcessorAckUserWrite(\n        viewProcessor,\n        oldViewCache,\n        ackUserWrite.path,\n        ackUserWrite.affectedTree,\n        writesCache,\n        completeCache,\n        accumulator\n      );\n    } else {\n      newViewCache = viewProcessorRevertUserWrite(\n        viewProcessor,\n        oldViewCache,\n        ackUserWrite.path,\n        writesCache,\n        completeCache,\n        accumulator\n      );\n    }\n  } else if (operation.type === OperationType.LISTEN_COMPLETE) {\n    newViewCache = viewProcessorListenComplete(\n      viewProcessor,\n      oldViewCache,\n      operation.path,\n      writesCache,\n      accumulator\n    );\n  } else {\n    throw assertionError('Unknown operation type: ' + operation.type);\n  }\n  const changes = accumulator.getChanges();\n  viewProcessorMaybeAddValueEvent(oldViewCache, newViewCache, changes);\n  return { viewCache: newViewCache, changes };\n}\n\nfunction viewProcessorMaybeAddValueEvent(\n  oldViewCache: ViewCache,\n  newViewCache: ViewCache,\n  accumulator: Change[]\n): void {\n  const eventSnap = newViewCache.eventCache;\n  if (eventSnap.isFullyInitialized()) {\n    const isLeafOrEmpty =\n      eventSnap.getNode().isLeafNode() || eventSnap.getNode().isEmpty();\n    const oldCompleteSnap = viewCacheGetCompleteEventSnap(oldViewCache);\n    if (\n      accumulator.length > 0 ||\n      !oldViewCache.eventCache.isFullyInitialized() ||\n      (isLeafOrEmpty && !eventSnap.getNode().equals(oldCompleteSnap)) ||\n      !eventSnap.getNode().getPriority().equals(oldCompleteSnap.getPriority())\n    ) {\n      accumulator.push(\n        changeValue(viewCacheGetCompleteEventSnap(newViewCache))\n      );\n    }\n  }\n}\n\nfunction viewProcessorGenerateEventCacheAfterServerEvent(\n  viewProcessor: ViewProcessor,\n  viewCache: ViewCache,\n  changePath: Path,\n  writesCache: WriteTreeRef,\n  source: CompleteChildSource,\n  accumulator: ChildChangeAccumulator\n): ViewCache {\n  const oldEventSnap = viewCache.eventCache;\n  if (writeTreeRefShadowingWrite(writesCache, changePath) != null) {\n    // we have a shadowing write, ignore changes\n    return viewCache;\n  } else {\n    let newEventCache, serverNode;\n    if (pathIsEmpty(changePath)) {\n      // TODO: figure out how this plays with \"sliding ack windows\"\n      assert(\n        viewCache.serverCache.isFullyInitialized(),\n        'If change path is empty, we must have complete server data'\n      );\n      if (viewCache.serverCache.isFiltered()) {\n        // We need to special case this, because we need to only apply writes to complete children, or\n        // we might end up raising events for incomplete children. If the server data is filtered deep\n        // writes cannot be guaranteed to be complete\n        const serverCache = viewCacheGetCompleteServerSnap(viewCache);\n        const completeChildren =\n          serverCache instanceof ChildrenNode\n            ? serverCache\n            : ChildrenNode.EMPTY_NODE;\n        const completeEventChildren = writeTreeRefCalcCompleteEventChildren(\n          writesCache,\n          completeChildren\n        );\n        newEventCache = viewProcessor.filter.updateFullNode(\n          viewCache.eventCache.getNode(),\n          completeEventChildren,\n          accumulator\n        );\n      } else {\n        const completeNode = writeTreeRefCalcCompleteEventCache(\n          writesCache,\n          viewCacheGetCompleteServerSnap(viewCache)\n        );\n        newEventCache = viewProcessor.filter.updateFullNode(\n          viewCache.eventCache.getNode(),\n          completeNode,\n          accumulator\n        );\n      }\n    } else {\n      const childKey = pathGetFront(changePath);\n      if (childKey === '.priority') {\n        assert(\n          pathGetLength(changePath) === 1,\n          \"Can't have a priority with additional path components\"\n        );\n        const oldEventNode = oldEventSnap.getNode();\n        serverNode = viewCache.serverCache.getNode();\n        // we might have overwrites for this priority\n        const updatedPriority = writeTreeRefCalcEventCacheAfterServerOverwrite(\n          writesCache,\n          changePath,\n          oldEventNode,\n          serverNode\n        );\n        if (updatedPriority != null) {\n          newEventCache = viewProcessor.filter.updatePriority(\n            oldEventNode,\n            updatedPriority\n          );\n        } else {\n          // priority didn't change, keep old node\n          newEventCache = oldEventSnap.getNode();\n        }\n      } else {\n        const childChangePath = pathPopFront(changePath);\n        // update child\n        let newEventChild;\n        if (oldEventSnap.isCompleteForChild(childKey)) {\n          serverNode = viewCache.serverCache.getNode();\n          const eventChildUpdate =\n            writeTreeRefCalcEventCacheAfterServerOverwrite(\n              writesCache,\n              changePath,\n              oldEventSnap.getNode(),\n              serverNode\n            );\n          if (eventChildUpdate != null) {\n            newEventChild = oldEventSnap\n              .getNode()\n              .getImmediateChild(childKey)\n              .updateChild(childChangePath, eventChildUpdate);\n          } else {\n            // Nothing changed, just keep the old child\n            newEventChild = oldEventSnap.getNode().getImmediateChild(childKey);\n          }\n        } else {\n          newEventChild = writeTreeRefCalcCompleteChild(\n            writesCache,\n            childKey,\n            viewCache.serverCache\n          );\n        }\n        if (newEventChild != null) {\n          newEventCache = viewProcessor.filter.updateChild(\n            oldEventSnap.getNode(),\n            childKey,\n            newEventChild,\n            childChangePath,\n            source,\n            accumulator\n          );\n        } else {\n          // no complete child available or no change\n          newEventCache = oldEventSnap.getNode();\n        }\n      }\n    }\n    return viewCacheUpdateEventSnap(\n      viewCache,\n      newEventCache,\n      oldEventSnap.isFullyInitialized() || pathIsEmpty(changePath),\n      viewProcessor.filter.filtersNodes()\n    );\n  }\n}\n\nfunction viewProcessorApplyServerOverwrite(\n  viewProcessor: ViewProcessor,\n  oldViewCache: ViewCache,\n  changePath: Path,\n  changedSnap: Node,\n  writesCache: WriteTreeRef,\n  completeCache: Node | null,\n  filterServerNode: boolean,\n  accumulator: ChildChangeAccumulator\n): ViewCache {\n  const oldServerSnap = oldViewCache.serverCache;\n  let newServerCache;\n  const serverFilter = filterServerNode\n    ? viewProcessor.filter\n    : viewProcessor.filter.getIndexedFilter();\n  if (pathIsEmpty(changePath)) {\n    newServerCache = serverFilter.updateFullNode(\n      oldServerSnap.getNode(),\n      changedSnap,\n      null\n    );\n  } else if (serverFilter.filtersNodes() && !oldServerSnap.isFiltered()) {\n    // we want to filter the server node, but we didn't filter the server node yet, so simulate a full update\n    const newServerNode = oldServerSnap\n      .getNode()\n      .updateChild(changePath, changedSnap);\n    newServerCache = serverFilter.updateFullNode(\n      oldServerSnap.getNode(),\n      newServerNode,\n      null\n    );\n  } else {\n    const childKey = pathGetFront(changePath);\n    if (\n      !oldServerSnap.isCompleteForPath(changePath) &&\n      pathGetLength(changePath) > 1\n    ) {\n      // We don't update incomplete nodes with updates intended for other listeners\n      return oldViewCache;\n    }\n    const childChangePath = pathPopFront(changePath);\n    const childNode = oldServerSnap.getNode().getImmediateChild(childKey);\n    const newChildNode = childNode.updateChild(childChangePath, changedSnap);\n    if (childKey === '.priority') {\n      newServerCache = serverFilter.updatePriority(\n        oldServerSnap.getNode(),\n        newChildNode\n      );\n    } else {\n      newServerCache = serverFilter.updateChild(\n        oldServerSnap.getNode(),\n        childKey,\n        newChildNode,\n        childChangePath,\n        NO_COMPLETE_CHILD_SOURCE,\n        null\n      );\n    }\n  }\n  const newViewCache = viewCacheUpdateServerSnap(\n    oldViewCache,\n    newServerCache,\n    oldServerSnap.isFullyInitialized() || pathIsEmpty(changePath),\n    serverFilter.filtersNodes()\n  );\n  const source = new WriteTreeCompleteChildSource(\n    writesCache,\n    newViewCache,\n    completeCache\n  );\n  return viewProcessorGenerateEventCacheAfterServerEvent(\n    viewProcessor,\n    newViewCache,\n    changePath,\n    writesCache,\n    source,\n    accumulator\n  );\n}\n\nfunction viewProcessorApplyUserOverwrite(\n  viewProcessor: ViewProcessor,\n  oldViewCache: ViewCache,\n  changePath: Path,\n  changedSnap: Node,\n  writesCache: WriteTreeRef,\n  completeCache: Node | null,\n  accumulator: ChildChangeAccumulator\n): ViewCache {\n  const oldEventSnap = oldViewCache.eventCache;\n  let newViewCache, newEventCache;\n  const source = new WriteTreeCompleteChildSource(\n    writesCache,\n    oldViewCache,\n    completeCache\n  );\n  if (pathIsEmpty(changePath)) {\n    newEventCache = viewProcessor.filter.updateFullNode(\n      oldViewCache.eventCache.getNode(),\n      changedSnap,\n      accumulator\n    );\n    newViewCache = viewCacheUpdateEventSnap(\n      oldViewCache,\n      newEventCache,\n      true,\n      viewProcessor.filter.filtersNodes()\n    );\n  } else {\n    const childKey = pathGetFront(changePath);\n    if (childKey === '.priority') {\n      newEventCache = viewProcessor.filter.updatePriority(\n        oldViewCache.eventCache.getNode(),\n        changedSnap\n      );\n      newViewCache = viewCacheUpdateEventSnap(\n        oldViewCache,\n        newEventCache,\n        oldEventSnap.isFullyInitialized(),\n        oldEventSnap.isFiltered()\n      );\n    } else {\n      const childChangePath = pathPopFront(changePath);\n      const oldChild = oldEventSnap.getNode().getImmediateChild(childKey);\n      let newChild;\n      if (pathIsEmpty(childChangePath)) {\n        // Child overwrite, we can replace the child\n        newChild = changedSnap;\n      } else {\n        const childNode = source.getCompleteChild(childKey);\n        if (childNode != null) {\n          if (\n            pathGetBack(childChangePath) === '.priority' &&\n            childNode.getChild(pathParent(childChangePath)).isEmpty()\n          ) {\n            // This is a priority update on an empty node. If this node exists on the server, the\n            // server will send down the priority in the update, so ignore for now\n            newChild = childNode;\n          } else {\n            newChild = childNode.updateChild(childChangePath, changedSnap);\n          }\n        } else {\n          // There is no complete child node available\n          newChild = ChildrenNode.EMPTY_NODE;\n        }\n      }\n      if (!oldChild.equals(newChild)) {\n        const newEventSnap = viewProcessor.filter.updateChild(\n          oldEventSnap.getNode(),\n          childKey,\n          newChild,\n          childChangePath,\n          source,\n          accumulator\n        );\n        newViewCache = viewCacheUpdateEventSnap(\n          oldViewCache,\n          newEventSnap,\n          oldEventSnap.isFullyInitialized(),\n          viewProcessor.filter.filtersNodes()\n        );\n      } else {\n        newViewCache = oldViewCache;\n      }\n    }\n  }\n  return newViewCache;\n}\n\nfunction viewProcessorCacheHasChild(\n  viewCache: ViewCache,\n  childKey: string\n): boolean {\n  return viewCache.eventCache.isCompleteForChild(childKey);\n}\n\nfunction viewProcessorApplyUserMerge(\n  viewProcessor: ViewProcessor,\n  viewCache: ViewCache,\n  path: Path,\n  changedChildren: ImmutableTree<Node>,\n  writesCache: WriteTreeRef,\n  serverCache: Node | null,\n  accumulator: ChildChangeAccumulator\n): ViewCache {\n  // HACK: In the case of a limit query, there may be some changes that bump things out of the\n  // window leaving room for new items.  It's important we process these changes first, so we\n  // iterate the changes twice, first processing any that affect items currently in view.\n  // TODO: I consider an item \"in view\" if cacheHasChild is true, which checks both the server\n  // and event snap.  I'm not sure if this will result in edge cases when a child is in one but\n  // not the other.\n  let curViewCache = viewCache;\n  changedChildren.foreach((relativePath, childNode) => {\n    const writePath = pathChild(path, relativePath);\n    if (viewProcessorCacheHasChild(viewCache, pathGetFront(writePath))) {\n      curViewCache = viewProcessorApplyUserOverwrite(\n        viewProcessor,\n        curViewCache,\n        writePath,\n        childNode,\n        writesCache,\n        serverCache,\n        accumulator\n      );\n    }\n  });\n\n  changedChildren.foreach((relativePath, childNode) => {\n    const writePath = pathChild(path, relativePath);\n    if (!viewProcessorCacheHasChild(viewCache, pathGetFront(writePath))) {\n      curViewCache = viewProcessorApplyUserOverwrite(\n        viewProcessor,\n        curViewCache,\n        writePath,\n        childNode,\n        writesCache,\n        serverCache,\n        accumulator\n      );\n    }\n  });\n\n  return curViewCache;\n}\n\nfunction viewProcessorApplyMerge(\n  viewProcessor: ViewProcessor,\n  node: Node,\n  merge: ImmutableTree<Node>\n): Node {\n  merge.foreach((relativePath, childNode) => {\n    node = node.updateChild(relativePath, childNode);\n  });\n  return node;\n}\n\nfunction viewProcessorApplyServerMerge(\n  viewProcessor: ViewProcessor,\n  viewCache: ViewCache,\n  path: Path,\n  changedChildren: ImmutableTree<Node>,\n  writesCache: WriteTreeRef,\n  serverCache: Node | null,\n  filterServerNode: boolean,\n  accumulator: ChildChangeAccumulator\n): ViewCache {\n  // If we don't have a cache yet, this merge was intended for a previously listen in the same location. Ignore it and\n  // wait for the complete data update coming soon.\n  if (\n    viewCache.serverCache.getNode().isEmpty() &&\n    !viewCache.serverCache.isFullyInitialized()\n  ) {\n    return viewCache;\n  }\n\n  // HACK: In the case of a limit query, there may be some changes that bump things out of the\n  // window leaving room for new items.  It's important we process these changes first, so we\n  // iterate the changes twice, first processing any that affect items currently in view.\n  // TODO: I consider an item \"in view\" if cacheHasChild is true, which checks both the server\n  // and event snap.  I'm not sure if this will result in edge cases when a child is in one but\n  // not the other.\n  let curViewCache = viewCache;\n  let viewMergeTree: ImmutableTree<Node>;\n  if (pathIsEmpty(path)) {\n    viewMergeTree = changedChildren;\n  } else {\n    viewMergeTree = new ImmutableTree<Node>(null).setTree(\n      path,\n      changedChildren\n    );\n  }\n  const serverNode = viewCache.serverCache.getNode();\n  viewMergeTree.children.inorderTraversal((childKey, childTree) => {\n    if (serverNode.hasChild(childKey)) {\n      const serverChild = viewCache.serverCache\n        .getNode()\n        .getImmediateChild(childKey);\n      const newChild = viewProcessorApplyMerge(\n        viewProcessor,\n        serverChild,\n        childTree\n      );\n      curViewCache = viewProcessorApplyServerOverwrite(\n        viewProcessor,\n        curViewCache,\n        new Path(childKey),\n        newChild,\n        writesCache,\n        serverCache,\n        filterServerNode,\n        accumulator\n      );\n    }\n  });\n  viewMergeTree.children.inorderTraversal((childKey, childMergeTree) => {\n    const isUnknownDeepMerge =\n      !viewCache.serverCache.isCompleteForChild(childKey) &&\n      childMergeTree.value === null;\n    if (!serverNode.hasChild(childKey) && !isUnknownDeepMerge) {\n      const serverChild = viewCache.serverCache\n        .getNode()\n        .getImmediateChild(childKey);\n      const newChild = viewProcessorApplyMerge(\n        viewProcessor,\n        serverChild,\n        childMergeTree\n      );\n      curViewCache = viewProcessorApplyServerOverwrite(\n        viewProcessor,\n        curViewCache,\n        new Path(childKey),\n        newChild,\n        writesCache,\n        serverCache,\n        filterServerNode,\n        accumulator\n      );\n    }\n  });\n\n  return curViewCache;\n}\n\nfunction viewProcessorAckUserWrite(\n  viewProcessor: ViewProcessor,\n  viewCache: ViewCache,\n  ackPath: Path,\n  affectedTree: ImmutableTree<boolean>,\n  writesCache: WriteTreeRef,\n  completeCache: Node | null,\n  accumulator: ChildChangeAccumulator\n): ViewCache {\n  if (writeTreeRefShadowingWrite(writesCache, ackPath) != null) {\n    return viewCache;\n  }\n\n  // Only filter server node if it is currently filtered\n  const filterServerNode = viewCache.serverCache.isFiltered();\n\n  // Essentially we'll just get our existing server cache for the affected paths and re-apply it as a server update\n  // now that it won't be shadowed.\n  const serverCache = viewCache.serverCache;\n  if (affectedTree.value != null) {\n    // This is an overwrite.\n    if (\n      (pathIsEmpty(ackPath) && serverCache.isFullyInitialized()) ||\n      serverCache.isCompleteForPath(ackPath)\n    ) {\n      return viewProcessorApplyServerOverwrite(\n        viewProcessor,\n        viewCache,\n        ackPath,\n        serverCache.getNode().getChild(ackPath),\n        writesCache,\n        completeCache,\n        filterServerNode,\n        accumulator\n      );\n    } else if (pathIsEmpty(ackPath)) {\n      // This is a goofy edge case where we are acking data at this location but don't have full data.  We\n      // should just re-apply whatever we have in our cache as a merge.\n      let changedChildren = new ImmutableTree<Node>(null);\n      serverCache.getNode().forEachChild(KEY_INDEX, (name, node) => {\n        changedChildren = changedChildren.set(new Path(name), node);\n      });\n      return viewProcessorApplyServerMerge(\n        viewProcessor,\n        viewCache,\n        ackPath,\n        changedChildren,\n        writesCache,\n        completeCache,\n        filterServerNode,\n        accumulator\n      );\n    } else {\n      return viewCache;\n    }\n  } else {\n    // This is a merge.\n    let changedChildren = new ImmutableTree<Node>(null);\n    affectedTree.foreach((mergePath, value) => {\n      const serverCachePath = pathChild(ackPath, mergePath);\n      if (serverCache.isCompleteForPath(serverCachePath)) {\n        changedChildren = changedChildren.set(\n          mergePath,\n          serverCache.getNode().getChild(serverCachePath)\n        );\n      }\n    });\n    return viewProcessorApplyServerMerge(\n      viewProcessor,\n      viewCache,\n      ackPath,\n      changedChildren,\n      writesCache,\n      completeCache,\n      filterServerNode,\n      accumulator\n    );\n  }\n}\n\nfunction viewProcessorListenComplete(\n  viewProcessor: ViewProcessor,\n  viewCache: ViewCache,\n  path: Path,\n  writesCache: WriteTreeRef,\n  accumulator: ChildChangeAccumulator\n): ViewCache {\n  const oldServerNode = viewCache.serverCache;\n  const newViewCache = viewCacheUpdateServerSnap(\n    viewCache,\n    oldServerNode.getNode(),\n    oldServerNode.isFullyInitialized() || pathIsEmpty(path),\n    oldServerNode.isFiltered()\n  );\n  return viewProcessorGenerateEventCacheAfterServerEvent(\n    viewProcessor,\n    newViewCache,\n    path,\n    writesCache,\n    NO_COMPLETE_CHILD_SOURCE,\n    accumulator\n  );\n}\n\nfunction viewProcessorRevertUserWrite(\n  viewProcessor: ViewProcessor,\n  viewCache: ViewCache,\n  path: Path,\n  writesCache: WriteTreeRef,\n  completeServerCache: Node | null,\n  accumulator: ChildChangeAccumulator\n): ViewCache {\n  let complete;\n  if (writeTreeRefShadowingWrite(writesCache, path) != null) {\n    return viewCache;\n  } else {\n    const source = new WriteTreeCompleteChildSource(\n      writesCache,\n      viewCache,\n      completeServerCache\n    );\n    const oldEventCache = viewCache.eventCache.getNode();\n    let newEventCache;\n    if (pathIsEmpty(path) || pathGetFront(path) === '.priority') {\n      let newNode;\n      if (viewCache.serverCache.isFullyInitialized()) {\n        newNode = writeTreeRefCalcCompleteEventCache(\n          writesCache,\n          viewCacheGetCompleteServerSnap(viewCache)\n        );\n      } else {\n        const serverChildren = viewCache.serverCache.getNode();\n        assert(\n          serverChildren instanceof ChildrenNode,\n          'serverChildren would be complete if leaf node'\n        );\n        newNode = writeTreeRefCalcCompleteEventChildren(\n          writesCache,\n          serverChildren as ChildrenNode\n        );\n      }\n      newNode = newNode as Node;\n      newEventCache = viewProcessor.filter.updateFullNode(\n        oldEventCache,\n        newNode,\n        accumulator\n      );\n    } else {\n      const childKey = pathGetFront(path);\n      let newChild = writeTreeRefCalcCompleteChild(\n        writesCache,\n        childKey,\n        viewCache.serverCache\n      );\n      if (\n        newChild == null &&\n        viewCache.serverCache.isCompleteForChild(childKey)\n      ) {\n        newChild = oldEventCache.getImmediateChild(childKey);\n      }\n      if (newChild != null) {\n        newEventCache = viewProcessor.filter.updateChild(\n          oldEventCache,\n          childKey,\n          newChild,\n          pathPopFront(path),\n          source,\n          accumulator\n        );\n      } else if (viewCache.eventCache.getNode().hasChild(childKey)) {\n        // No complete child available, delete the existing one, if any\n        newEventCache = viewProcessor.filter.updateChild(\n          oldEventCache,\n          childKey,\n          ChildrenNode.EMPTY_NODE,\n          pathPopFront(path),\n          source,\n          accumulator\n        );\n      } else {\n        newEventCache = oldEventCache;\n      }\n      if (\n        newEventCache.isEmpty() &&\n        viewCache.serverCache.isFullyInitialized()\n      ) {\n        // We might have reverted all child writes. Maybe the old event was a leaf node\n        complete = writeTreeRefCalcCompleteEventCache(\n          writesCache,\n          viewCacheGetCompleteServerSnap(viewCache)\n        );\n        if (complete.isLeafNode()) {\n          newEventCache = viewProcessor.filter.updateFullNode(\n            newEventCache,\n            complete,\n            accumulator\n          );\n        }\n      }\n    }\n    complete =\n      viewCache.serverCache.isFullyInitialized() ||\n      writeTreeRefShadowingWrite(writesCache, newEmptyPath()) != null;\n    return viewCacheUpdateEventSnap(\n      viewCache,\n      newEventCache,\n      complete,\n      viewProcessor.filter.filtersNodes()\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { Operation, OperationType } from '../operation/Operation';\nimport { ChildrenNode } from '../snap/ChildrenNode';\nimport { PRIORITY_INDEX } from '../snap/indexes/PriorityIndex';\nimport { Node } from '../snap/Node';\nimport { Path, pathGetFront, pathIsEmpty } from '../util/Path';\nimport { WriteTreeRef } from '../WriteTree';\n\nimport { CacheNode } from './CacheNode';\nimport { Change, changeChildAdded, changeValue } from './Change';\nimport { CancelEvent, Event } from './Event';\nimport {\n  EventGenerator,\n  eventGeneratorGenerateEventsForChanges\n} from './EventGenerator';\nimport { EventRegistration, QueryContext } from './EventRegistration';\nimport { IndexedFilter } from './filter/IndexedFilter';\nimport { queryParamsGetNodeFilter } from './QueryParams';\nimport {\n  newViewCache,\n  ViewCache,\n  viewCacheGetCompleteEventSnap,\n  viewCacheGetCompleteServerSnap\n} from './ViewCache';\nimport {\n  newViewProcessor,\n  ViewProcessor,\n  viewProcessorApplyOperation,\n  viewProcessorAssertIndexed\n} from './ViewProcessor';\n\n/**\n * A view represents a specific location and query that has 1 or more event registrations.\n *\n * It does several things:\n *  - Maintains the list of event registrations for this location/query.\n *  - Maintains a cache of the data visible for this location/query.\n *  - Applies new operations (via applyOperation), updates the cache, and based on the event\n *    registrations returns the set of events to be raised.\n */\nexport class View {\n  processor_: ViewProcessor;\n  viewCache_: ViewCache;\n  eventRegistrations_: EventRegistration[] = [];\n  eventGenerator_: EventGenerator;\n\n  constructor(private query_: QueryContext, initialViewCache: ViewCache) {\n    const params = this.query_._queryParams;\n\n    const indexFilter = new IndexedFilter(params.getIndex());\n    const filter = queryParamsGetNodeFilter(params);\n\n    this.processor_ = newViewProcessor(filter);\n\n    const initialServerCache = initialViewCache.serverCache;\n    const initialEventCache = initialViewCache.eventCache;\n\n    // Don't filter server node with other filter than index, wait for tagged listen\n    const serverSnap = indexFilter.updateFullNode(\n      ChildrenNode.EMPTY_NODE,\n      initialServerCache.getNode(),\n      null\n    );\n    const eventSnap = filter.updateFullNode(\n      ChildrenNode.EMPTY_NODE,\n      initialEventCache.getNode(),\n      null\n    );\n    const newServerCache = new CacheNode(\n      serverSnap,\n      initialServerCache.isFullyInitialized(),\n      indexFilter.filtersNodes()\n    );\n    const newEventCache = new CacheNode(\n      eventSnap,\n      initialEventCache.isFullyInitialized(),\n      filter.filtersNodes()\n    );\n\n    this.viewCache_ = newViewCache(newEventCache, newServerCache);\n    this.eventGenerator_ = new EventGenerator(this.query_);\n  }\n\n  get query(): QueryContext {\n    return this.query_;\n  }\n}\n\nexport function viewGetServerCache(view: View): Node | null {\n  return view.viewCache_.serverCache.getNode();\n}\n\nexport function viewGetCompleteNode(view: View): Node | null {\n  return viewCacheGetCompleteEventSnap(view.viewCache_);\n}\n\nexport function viewGetCompleteServerCache(\n  view: View,\n  path: Path\n): Node | null {\n  const cache = viewCacheGetCompleteServerSnap(view.viewCache_);\n  if (cache) {\n    // If this isn't a \"loadsAllData\" view, then cache isn't actually a complete cache and\n    // we need to see if it contains the child we're interested in.\n    if (\n      view.query._queryParams.loadsAllData() ||\n      (!pathIsEmpty(path) &&\n        !cache.getImmediateChild(pathGetFront(path)).isEmpty())\n    ) {\n      return cache.getChild(path);\n    }\n  }\n  return null;\n}\n\nexport function viewIsEmpty(view: View): boolean {\n  return view.eventRegistrations_.length === 0;\n}\n\nexport function viewAddEventRegistration(\n  view: View,\n  eventRegistration: EventRegistration\n) {\n  view.eventRegistrations_.push(eventRegistration);\n}\n\n/**\n * @param eventRegistration - If null, remove all callbacks.\n * @param cancelError - If a cancelError is provided, appropriate cancel events will be returned.\n * @returns Cancel events, if cancelError was provided.\n */\nexport function viewRemoveEventRegistration(\n  view: View,\n  eventRegistration: EventRegistration | null,\n  cancelError?: Error\n): Event[] {\n  const cancelEvents: CancelEvent[] = [];\n  if (cancelError) {\n    assert(\n      eventRegistration == null,\n      'A cancel should cancel all event registrations.'\n    );\n    const path = view.query._path;\n    view.eventRegistrations_.forEach(registration => {\n      const maybeEvent = registration.createCancelEvent(cancelError, path);\n      if (maybeEvent) {\n        cancelEvents.push(maybeEvent);\n      }\n    });\n  }\n\n  if (eventRegistration) {\n    let remaining = [];\n    for (let i = 0; i < view.eventRegistrations_.length; ++i) {\n      const existing = view.eventRegistrations_[i];\n      if (!existing.matches(eventRegistration)) {\n        remaining.push(existing);\n      } else if (eventRegistration.hasAnyCallback()) {\n        // We're removing just this one\n        remaining = remaining.concat(view.eventRegistrations_.slice(i + 1));\n        break;\n      }\n    }\n    view.eventRegistrations_ = remaining;\n  } else {\n    view.eventRegistrations_ = [];\n  }\n  return cancelEvents;\n}\n\n/**\n * Applies the given Operation, updates our cache, and returns the appropriate events.\n */\nexport function viewApplyOperation(\n  view: View,\n  operation: Operation,\n  writesCache: WriteTreeRef,\n  completeServerCache: Node | null\n): Event[] {\n  if (\n    operation.type === OperationType.MERGE &&\n    operation.source.queryId !== null\n  ) {\n    assert(\n      viewCacheGetCompleteServerSnap(view.viewCache_),\n      'We should always have a full cache before handling merges'\n    );\n    assert(\n      viewCacheGetCompleteEventSnap(view.viewCache_),\n      'Missing event cache, even though we have a server cache'\n    );\n  }\n\n  const oldViewCache = view.viewCache_;\n  const result = viewProcessorApplyOperation(\n    view.processor_,\n    oldViewCache,\n    operation,\n    writesCache,\n    completeServerCache\n  );\n  viewProcessorAssertIndexed(view.processor_, result.viewCache);\n\n  assert(\n    result.viewCache.serverCache.isFullyInitialized() ||\n      !oldViewCache.serverCache.isFullyInitialized(),\n    'Once a server snap is complete, it should never go back'\n  );\n\n  view.viewCache_ = result.viewCache;\n\n  return viewGenerateEventsForChanges_(\n    view,\n    result.changes,\n    result.viewCache.eventCache.getNode(),\n    null\n  );\n}\n\nexport function viewGetInitialEvents(\n  view: View,\n  registration: EventRegistration\n): Event[] {\n  const eventSnap = view.viewCache_.eventCache;\n  const initialChanges: Change[] = [];\n  if (!eventSnap.getNode().isLeafNode()) {\n    const eventNode = eventSnap.getNode() as ChildrenNode;\n    eventNode.forEachChild(PRIORITY_INDEX, (key, childNode) => {\n      initialChanges.push(changeChildAdded(key, childNode));\n    });\n  }\n  if (eventSnap.isFullyInitialized()) {\n    initialChanges.push(changeValue(eventSnap.getNode()));\n  }\n  return viewGenerateEventsForChanges_(\n    view,\n    initialChanges,\n    eventSnap.getNode(),\n    registration\n  );\n}\n\nfunction viewGenerateEventsForChanges_(\n  view: View,\n  changes: Change[],\n  eventCache: Node,\n  eventRegistration?: EventRegistration\n): Event[] {\n  const registrations = eventRegistration\n    ? [eventRegistration]\n    : view.eventRegistrations_;\n  return eventGeneratorGenerateEventsForChanges(\n    view.eventGenerator_,\n    changes,\n    eventCache,\n    registrations\n  );\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { ReferenceConstructor } from '../api/Reference';\n\nimport { Operation } from './operation/Operation';\nimport { ChildrenNode } from './snap/ChildrenNode';\nimport { Node } from './snap/Node';\nimport { Path } from './util/Path';\nimport { CacheNode } from './view/CacheNode';\nimport { Event } from './view/Event';\nimport { EventRegistration, QueryContext } from './view/EventRegistration';\nimport {\n  View,\n  viewAddEventRegistration,\n  viewApplyOperation,\n  viewGetCompleteServerCache,\n  viewGetInitialEvents,\n  viewIsEmpty,\n  viewRemoveEventRegistration\n} from './view/View';\nimport { newViewCache } from './view/ViewCache';\nimport {\n  WriteTreeRef,\n  writeTreeRefCalcCompleteEventCache,\n  writeTreeRefCalcCompleteEventChildren\n} from './WriteTree';\n\nlet referenceConstructor: ReferenceConstructor;\n\n/**\n * SyncPoint represents a single location in a SyncTree with 1 or more event registrations, meaning we need to\n * maintain 1 or more Views at this location to cache server data and raise appropriate events for server changes\n * and user writes (set, transaction, update).\n *\n * It's responsible for:\n *  - Maintaining the set of 1 or more views necessary at this location (a SyncPoint with 0 views should be removed).\n *  - Proxying user / server operations to the views as appropriate (i.e. applyServerOverwrite,\n *    applyUserOverwrite, etc.)\n */\nexport class SyncPoint {\n  /**\n   * The Views being tracked at this location in the tree, stored as a map where the key is a\n   * queryId and the value is the View for that query.\n   *\n   * NOTE: This list will be quite small (usually 1, but perhaps 2 or 3; any more is an odd use case).\n   */\n  readonly views: Map<string, View> = new Map();\n}\n\nexport function syncPointSetReferenceConstructor(\n  val: ReferenceConstructor\n): void {\n  assert(\n    !referenceConstructor,\n    '__referenceConstructor has already been defined'\n  );\n  referenceConstructor = val;\n}\n\nfunction syncPointGetReferenceConstructor(): ReferenceConstructor {\n  assert(referenceConstructor, 'Reference.ts has not been loaded');\n  return referenceConstructor;\n}\n\nexport function syncPointIsEmpty(syncPoint: SyncPoint): boolean {\n  return syncPoint.views.size === 0;\n}\n\nexport function syncPointApplyOperation(\n  syncPoint: SyncPoint,\n  operation: Operation,\n  writesCache: WriteTreeRef,\n  optCompleteServerCache: Node | null\n): Event[] {\n  const queryId = operation.source.queryId;\n  if (queryId !== null) {\n    const view = syncPoint.views.get(queryId);\n    assert(view != null, 'SyncTree gave us an op for an invalid query.');\n    return viewApplyOperation(\n      view,\n      operation,\n      writesCache,\n      optCompleteServerCache\n    );\n  } else {\n    let events: Event[] = [];\n\n    for (const view of syncPoint.views.values()) {\n      events = events.concat(\n        viewApplyOperation(view, operation, writesCache, optCompleteServerCache)\n      );\n    }\n\n    return events;\n  }\n}\n\n/**\n * Get a view for the specified query.\n *\n * @param query - The query to return a view for\n * @param writesCache\n * @param serverCache\n * @param serverCacheComplete\n * @returns Events to raise.\n */\nexport function syncPointGetView(\n  syncPoint: SyncPoint,\n  query: QueryContext,\n  writesCache: WriteTreeRef,\n  serverCache: Node | null,\n  serverCacheComplete: boolean\n): View {\n  const queryId = query._queryIdentifier;\n  const view = syncPoint.views.get(queryId);\n  if (!view) {\n    // TODO: make writesCache take flag for complete server node\n    let eventCache = writeTreeRefCalcCompleteEventCache(\n      writesCache,\n      serverCacheComplete ? serverCache : null\n    );\n    let eventCacheComplete = false;\n    if (eventCache) {\n      eventCacheComplete = true;\n    } else if (serverCache instanceof ChildrenNode) {\n      eventCache = writeTreeRefCalcCompleteEventChildren(\n        writesCache,\n        serverCache\n      );\n      eventCacheComplete = false;\n    } else {\n      eventCache = ChildrenNode.EMPTY_NODE;\n      eventCacheComplete = false;\n    }\n    const viewCache = newViewCache(\n      new CacheNode(eventCache, eventCacheComplete, false),\n      new CacheNode(serverCache, serverCacheComplete, false)\n    );\n    return new View(query, viewCache);\n  }\n  return view;\n}\n\n/**\n * Add an event callback for the specified query.\n *\n * @param query\n * @param eventRegistration\n * @param writesCache\n * @param serverCache - Complete server cache, if we have it.\n * @param serverCacheComplete\n * @returns Events to raise.\n */\nexport function syncPointAddEventRegistration(\n  syncPoint: SyncPoint,\n  query: QueryContext,\n  eventRegistration: EventRegistration,\n  writesCache: WriteTreeRef,\n  serverCache: Node | null,\n  serverCacheComplete: boolean\n): Event[] {\n  const view = syncPointGetView(\n    syncPoint,\n    query,\n    writesCache,\n    serverCache,\n    serverCacheComplete\n  );\n  if (!syncPoint.views.has(query._queryIdentifier)) {\n    syncPoint.views.set(query._queryIdentifier, view);\n  }\n  // This is guaranteed to exist now, we just created anything that was missing\n  viewAddEventRegistration(view, eventRegistration);\n  return viewGetInitialEvents(view, eventRegistration);\n}\n\n/**\n * Remove event callback(s).  Return cancelEvents if a cancelError is specified.\n *\n * If query is the default query, we'll check all views for the specified eventRegistration.\n * If eventRegistration is null, we'll remove all callbacks for the specified view(s).\n *\n * @param eventRegistration - If null, remove all callbacks.\n * @param cancelError - If a cancelError is provided, appropriate cancel events will be returned.\n * @returns removed queries and any cancel events\n */\nexport function syncPointRemoveEventRegistration(\n  syncPoint: SyncPoint,\n  query: QueryContext,\n  eventRegistration: EventRegistration | null,\n  cancelError?: Error\n): { removed: QueryContext[]; events: Event[] } {\n  const queryId = query._queryIdentifier;\n  const removed: QueryContext[] = [];\n  let cancelEvents: Event[] = [];\n  const hadCompleteView = syncPointHasCompleteView(syncPoint);\n  if (queryId === 'default') {\n    // When you do ref.off(...), we search all views for the registration to remove.\n    for (const [viewQueryId, view] of syncPoint.views.entries()) {\n      cancelEvents = cancelEvents.concat(\n        viewRemoveEventRegistration(view, eventRegistration, cancelError)\n      );\n      if (viewIsEmpty(view)) {\n        syncPoint.views.delete(viewQueryId);\n\n        // We'll deal with complete views later.\n        if (!view.query._queryParams.loadsAllData()) {\n          removed.push(view.query);\n        }\n      }\n    }\n  } else {\n    // remove the callback from the specific view.\n    const view = syncPoint.views.get(queryId);\n    if (view) {\n      cancelEvents = cancelEvents.concat(\n        viewRemoveEventRegistration(view, eventRegistration, cancelError)\n      );\n      if (viewIsEmpty(view)) {\n        syncPoint.views.delete(queryId);\n\n        // We'll deal with complete views later.\n        if (!view.query._queryParams.loadsAllData()) {\n          removed.push(view.query);\n        }\n      }\n    }\n  }\n\n  if (hadCompleteView && !syncPointHasCompleteView(syncPoint)) {\n    // We removed our last complete view.\n    removed.push(\n      new (syncPointGetReferenceConstructor())(query._repo, query._path)\n    );\n  }\n\n  return { removed, events: cancelEvents };\n}\n\nexport function syncPointGetQueryViews(syncPoint: SyncPoint): View[] {\n  const result = [];\n  for (const view of syncPoint.views.values()) {\n    if (!view.query._queryParams.loadsAllData()) {\n      result.push(view);\n    }\n  }\n  return result;\n}\n\n/**\n * @param path - The path to the desired complete snapshot\n * @returns A complete cache, if it exists\n */\nexport function syncPointGetCompleteServerCache(\n  syncPoint: SyncPoint,\n  path: Path\n): Node | null {\n  let serverCache: Node | null = null;\n  for (const view of syncPoint.views.values()) {\n    serverCache = serverCache || viewGetCompleteServerCache(view, path);\n  }\n  return serverCache;\n}\n\nexport function syncPointViewForQuery(\n  syncPoint: SyncPoint,\n  query: QueryContext\n): View | null {\n  const params = query._queryParams;\n  if (params.loadsAllData()) {\n    return syncPointGetCompleteView(syncPoint);\n  } else {\n    const queryId = query._queryIdentifier;\n    return syncPoint.views.get(queryId);\n  }\n}\n\nexport function syncPointViewExistsForQuery(\n  syncPoint: SyncPoint,\n  query: QueryContext\n): boolean {\n  return syncPointViewForQuery(syncPoint, query) != null;\n}\n\nexport function syncPointHasCompleteView(syncPoint: SyncPoint): boolean {\n  return syncPointGetCompleteView(syncPoint) != null;\n}\n\nexport function syncPointGetCompleteView(syncPoint: SyncPoint): View | null {\n  for (const view of syncPoint.views.values()) {\n    if (view.query._queryParams.loadsAllData()) {\n      return view;\n    }\n  }\n  return null;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { ReferenceConstructor } from '../api/Reference';\n\nimport { AckUserWrite } from './operation/AckUserWrite';\nimport { ListenComplete } from './operation/ListenComplete';\nimport { Merge } from './operation/Merge';\nimport {\n  newOperationSourceServer,\n  newOperationSourceServerTaggedQuery,\n  newOperationSourceUser,\n  Operation\n} from './operation/Operation';\nimport { Overwrite } from './operation/Overwrite';\nimport { ChildrenNode } from './snap/ChildrenNode';\nimport { Node } from './snap/Node';\nimport {\n  SyncPoint,\n  syncPointAddEventRegistration,\n  syncPointApplyOperation,\n  syncPointGetCompleteServerCache,\n  syncPointGetCompleteView,\n  syncPointGetQueryViews,\n  syncPointGetView,\n  syncPointHasCompleteView,\n  syncPointIsEmpty,\n  syncPointRemoveEventRegistration,\n  syncPointViewExistsForQuery,\n  syncPointViewForQuery\n} from './SyncPoint';\nimport { ImmutableTree } from './util/ImmutableTree';\nimport {\n  newEmptyPath,\n  newRelativePath,\n  Path,\n  pathGetFront,\n  pathIsEmpty\n} from './util/Path';\nimport { each, errorForServerCode } from './util/util';\nimport { CacheNode } from './view/CacheNode';\nimport { Event } from './view/Event';\nimport { EventRegistration, QueryContext } from './view/EventRegistration';\nimport { View, viewGetCompleteNode, viewGetServerCache } from './view/View';\nimport {\n  newWriteTree,\n  WriteTree,\n  writeTreeAddMerge,\n  writeTreeAddOverwrite,\n  writeTreeCalcCompleteEventCache,\n  writeTreeChildWrites,\n  writeTreeGetWrite,\n  WriteTreeRef,\n  writeTreeRefChild,\n  writeTreeRemoveWrite\n} from './WriteTree';\n\nlet referenceConstructor: ReferenceConstructor;\n\nexport function syncTreeSetReferenceConstructor(\n  val: ReferenceConstructor\n): void {\n  assert(\n    !referenceConstructor,\n    '__referenceConstructor has already been defined'\n  );\n  referenceConstructor = val;\n}\n\nfunction syncTreeGetReferenceConstructor(): ReferenceConstructor {\n  assert(referenceConstructor, 'Reference.ts has not been loaded');\n  return referenceConstructor;\n}\n\nexport interface ListenProvider {\n  startListening(\n    query: QueryContext,\n    tag: number | null,\n    hashFn: () => string,\n    onComplete: (a: string, b?: unknown) => Event[]\n  ): Event[];\n\n  stopListening(a: QueryContext, b: number | null): void;\n}\n\n/**\n * Static tracker for next query tag.\n */\nlet syncTreeNextQueryTag_ = 1;\n\nexport function resetSyncTreeTag() {\n  syncTreeNextQueryTag_ = 1;\n}\n\n/**\n * SyncTree is the central class for managing event callback registration, data caching, views\n * (query processing), and event generation.  There are typically two SyncTree instances for\n * each Repo, one for the normal Firebase data, and one for the .info data.\n *\n * It has a number of responsibilities, including:\n *  - Tracking all user event callbacks (registered via addEventRegistration() and removeEventRegistration()).\n *  - Applying and caching data changes for user set(), transaction(), and update() calls\n *    (applyUserOverwrite(), applyUserMerge()).\n *  - Applying and caching data changes for server data changes (applyServerOverwrite(),\n *    applyServerMerge()).\n *  - Generating user-facing events for server and user changes (all of the apply* methods\n *    return the set of events that need to be raised as a result).\n *  - Maintaining the appropriate set of server listens to ensure we are always subscribed\n *    to the correct set of paths and queries to satisfy the current set of user event\n *    callbacks (listens are started/stopped using the provided listenProvider).\n *\n * NOTE: Although SyncTree tracks event callbacks and calculates events to raise, the actual\n * events are returned to the caller rather than raised synchronously.\n *\n */\nexport class SyncTree {\n  /**\n   * Tree of SyncPoints.  There's a SyncPoint at any location that has 1 or more views.\n   */\n  syncPointTree_: ImmutableTree<SyncPoint> = new ImmutableTree<SyncPoint>(null);\n\n  /**\n   * A tree of all pending user writes (user-initiated set()'s, transaction()'s, update()'s, etc.).\n   */\n  pendingWriteTree_: WriteTree = newWriteTree();\n\n  readonly tagToQueryMap: Map<number, string> = new Map();\n  readonly queryToTagMap: Map<string, number> = new Map();\n\n  /**\n   * @param listenProvider_ - Used by SyncTree to start / stop listening\n   *   to server data.\n   */\n  constructor(public listenProvider_: ListenProvider) {}\n}\n\n/**\n * Apply the data changes for a user-generated set() or transaction() call.\n *\n * @returns Events to raise.\n */\nexport function syncTreeApplyUserOverwrite(\n  syncTree: SyncTree,\n  path: Path,\n  newData: Node,\n  writeId: number,\n  visible?: boolean\n): Event[] {\n  // Record pending write.\n  writeTreeAddOverwrite(\n    syncTree.pendingWriteTree_,\n    path,\n    newData,\n    writeId,\n    visible\n  );\n\n  if (!visible) {\n    return [];\n  } else {\n    return syncTreeApplyOperationToSyncPoints_(\n      syncTree,\n      new Overwrite(newOperationSourceUser(), path, newData)\n    );\n  }\n}\n\n/**\n * Apply the data from a user-generated update() call\n *\n * @returns Events to raise.\n */\nexport function syncTreeApplyUserMerge(\n  syncTree: SyncTree,\n  path: Path,\n  changedChildren: { [k: string]: Node },\n  writeId: number\n): Event[] {\n  // Record pending merge.\n  writeTreeAddMerge(syncTree.pendingWriteTree_, path, changedChildren, writeId);\n\n  const changeTree = ImmutableTree.fromObject(changedChildren);\n\n  return syncTreeApplyOperationToSyncPoints_(\n    syncTree,\n    new Merge(newOperationSourceUser(), path, changeTree)\n  );\n}\n\n/**\n * Acknowledge a pending user write that was previously registered with applyUserOverwrite() or applyUserMerge().\n *\n * @param revert - True if the given write failed and needs to be reverted\n * @returns Events to raise.\n */\nexport function syncTreeAckUserWrite(\n  syncTree: SyncTree,\n  writeId: number,\n  revert: boolean = false\n) {\n  const write = writeTreeGetWrite(syncTree.pendingWriteTree_, writeId);\n  const needToReevaluate = writeTreeRemoveWrite(\n    syncTree.pendingWriteTree_,\n    writeId\n  );\n  if (!needToReevaluate) {\n    return [];\n  } else {\n    let affectedTree = new ImmutableTree<boolean>(null);\n    if (write.snap != null) {\n      // overwrite\n      affectedTree = affectedTree.set(newEmptyPath(), true);\n    } else {\n      each(write.children, (pathString: string) => {\n        affectedTree = affectedTree.set(new Path(pathString), true);\n      });\n    }\n    return syncTreeApplyOperationToSyncPoints_(\n      syncTree,\n      new AckUserWrite(write.path, affectedTree, revert)\n    );\n  }\n}\n\n/**\n * Apply new server data for the specified path..\n *\n * @returns Events to raise.\n */\nexport function syncTreeApplyServerOverwrite(\n  syncTree: SyncTree,\n  path: Path,\n  newData: Node\n): Event[] {\n  return syncTreeApplyOperationToSyncPoints_(\n    syncTree,\n    new Overwrite(newOperationSourceServer(), path, newData)\n  );\n}\n\n/**\n * Apply new server data to be merged in at the specified path.\n *\n * @returns Events to raise.\n */\nexport function syncTreeApplyServerMerge(\n  syncTree: SyncTree,\n  path: Path,\n  changedChildren: { [k: string]: Node }\n): Event[] {\n  const changeTree = ImmutableTree.fromObject(changedChildren);\n\n  return syncTreeApplyOperationToSyncPoints_(\n    syncTree,\n    new Merge(newOperationSourceServer(), path, changeTree)\n  );\n}\n\n/**\n * Apply a listen complete for a query\n *\n * @returns Events to raise.\n */\nexport function syncTreeApplyListenComplete(\n  syncTree: SyncTree,\n  path: Path\n): Event[] {\n  return syncTreeApplyOperationToSyncPoints_(\n    syncTree,\n    new ListenComplete(newOperationSourceServer(), path)\n  );\n}\n\n/**\n * Apply a listen complete for a tagged query\n *\n * @returns Events to raise.\n */\nexport function syncTreeApplyTaggedListenComplete(\n  syncTree: SyncTree,\n  path: Path,\n  tag: number\n): Event[] {\n  const queryKey = syncTreeQueryKeyForTag_(syncTree, tag);\n  if (queryKey) {\n    const r = syncTreeParseQueryKey_(queryKey);\n    const queryPath = r.path,\n      queryId = r.queryId;\n    const relativePath = newRelativePath(queryPath, path);\n    const op = new ListenComplete(\n      newOperationSourceServerTaggedQuery(queryId),\n      relativePath\n    );\n    return syncTreeApplyTaggedOperation_(syncTree, queryPath, op);\n  } else {\n    // We've already removed the query. No big deal, ignore the update\n    return [];\n  }\n}\n\n/**\n * Remove event callback(s).\n *\n * If query is the default query, we'll check all queries for the specified eventRegistration.\n * If eventRegistration is null, we'll remove all callbacks for the specified query/queries.\n *\n * @param eventRegistration - If null, all callbacks are removed.\n * @param cancelError - If a cancelError is provided, appropriate cancel events will be returned.\n * @param skipListenerDedup - When performing a `get()`, we don't add any new listeners, so no\n *  deduping needs to take place. This flag allows toggling of that behavior\n * @returns Cancel events, if cancelError was provided.\n */\nexport function syncTreeRemoveEventRegistration(\n  syncTree: SyncTree,\n  query: QueryContext,\n  eventRegistration: EventRegistration | null,\n  cancelError?: Error,\n  skipListenerDedup = false\n): Event[] {\n  // Find the syncPoint first. Then deal with whether or not it has matching listeners\n  const path = query._path;\n  const maybeSyncPoint = syncTree.syncPointTree_.get(path);\n  let cancelEvents: Event[] = [];\n  // A removal on a default query affects all queries at that location. A removal on an indexed query, even one without\n  // other query constraints, does *not* affect all queries at that location. So this check must be for 'default', and\n  // not loadsAllData().\n  if (\n    maybeSyncPoint &&\n    (query._queryIdentifier === 'default' ||\n      syncPointViewExistsForQuery(maybeSyncPoint, query))\n  ) {\n    const removedAndEvents = syncPointRemoveEventRegistration(\n      maybeSyncPoint,\n      query,\n      eventRegistration,\n      cancelError\n    );\n    if (syncPointIsEmpty(maybeSyncPoint)) {\n      syncTree.syncPointTree_ = syncTree.syncPointTree_.remove(path);\n    }\n\n    const removed = removedAndEvents.removed;\n    cancelEvents = removedAndEvents.events;\n\n    if (!skipListenerDedup) {\n      /**\n       * We may have just removed one of many listeners and can short-circuit this whole process\n       * We may also not have removed a default listener, in which case all of the descendant listeners should already be\n       * properly set up.\n       */\n\n      // Since indexed queries can shadow if they don't have other query constraints, check for loadsAllData(), instead of\n      // queryId === 'default'\n      const removingDefault =\n        -1 !==\n        removed.findIndex(query => {\n          return query._queryParams.loadsAllData();\n        });\n      const covered = syncTree.syncPointTree_.findOnPath(\n        path,\n        (relativePath, parentSyncPoint) =>\n          syncPointHasCompleteView(parentSyncPoint)\n      );\n\n      if (removingDefault && !covered) {\n        const subtree = syncTree.syncPointTree_.subtree(path);\n        // There are potentially child listeners. Determine what if any listens we need to send before executing the\n        // removal\n        if (!subtree.isEmpty()) {\n          // We need to fold over our subtree and collect the listeners to send\n          const newViews = syncTreeCollectDistinctViewsForSubTree_(subtree);\n\n          // Ok, we've collected all the listens we need. Set them up.\n          for (let i = 0; i < newViews.length; ++i) {\n            const view = newViews[i],\n              newQuery = view.query;\n            const listener = syncTreeCreateListenerForView_(syncTree, view);\n            syncTree.listenProvider_.startListening(\n              syncTreeQueryForListening_(newQuery),\n              syncTreeTagForQuery(syncTree, newQuery),\n              listener.hashFn,\n              listener.onComplete\n            );\n          }\n        }\n        // Otherwise there's nothing below us, so nothing we need to start listening on\n      }\n      // If we removed anything and we're not covered by a higher up listen, we need to stop listening on this query\n      // The above block has us covered in terms of making sure we're set up on listens lower in the tree.\n      // Also, note that if we have a cancelError, it's already been removed at the provider level.\n      if (!covered && removed.length > 0 && !cancelError) {\n        // If we removed a default, then we weren't listening on any of the other queries here. Just cancel the one\n        // default. Otherwise, we need to iterate through and cancel each individual query\n        if (removingDefault) {\n          // We don't tag default listeners\n          const defaultTag: number | null = null;\n          syncTree.listenProvider_.stopListening(\n            syncTreeQueryForListening_(query),\n            defaultTag\n          );\n        } else {\n          removed.forEach((queryToRemove: QueryContext) => {\n            const tagToRemove = syncTree.queryToTagMap.get(\n              syncTreeMakeQueryKey_(queryToRemove)\n            );\n            syncTree.listenProvider_.stopListening(\n              syncTreeQueryForListening_(queryToRemove),\n              tagToRemove\n            );\n          });\n        }\n      }\n    }\n    // Now, clear all of the tags we're tracking for the removed listens\n    syncTreeRemoveTags_(syncTree, removed);\n  } else {\n    // No-op, this listener must've been already removed\n  }\n  return cancelEvents;\n}\n\n/**\n * Apply new server data for the specified tagged query.\n *\n * @returns Events to raise.\n */\nexport function syncTreeApplyTaggedQueryOverwrite(\n  syncTree: SyncTree,\n  path: Path,\n  snap: Node,\n  tag: number\n): Event[] {\n  const queryKey = syncTreeQueryKeyForTag_(syncTree, tag);\n  if (queryKey != null) {\n    const r = syncTreeParseQueryKey_(queryKey);\n    const queryPath = r.path,\n      queryId = r.queryId;\n    const relativePath = newRelativePath(queryPath, path);\n    const op = new Overwrite(\n      newOperationSourceServerTaggedQuery(queryId),\n      relativePath,\n      snap\n    );\n    return syncTreeApplyTaggedOperation_(syncTree, queryPath, op);\n  } else {\n    // Query must have been removed already\n    return [];\n  }\n}\n\n/**\n * Apply server data to be merged in for the specified tagged query.\n *\n * @returns Events to raise.\n */\nexport function syncTreeApplyTaggedQueryMerge(\n  syncTree: SyncTree,\n  path: Path,\n  changedChildren: { [k: string]: Node },\n  tag: number\n): Event[] {\n  const queryKey = syncTreeQueryKeyForTag_(syncTree, tag);\n  if (queryKey) {\n    const r = syncTreeParseQueryKey_(queryKey);\n    const queryPath = r.path,\n      queryId = r.queryId;\n    const relativePath = newRelativePath(queryPath, path);\n    const changeTree = ImmutableTree.fromObject(changedChildren);\n    const op = new Merge(\n      newOperationSourceServerTaggedQuery(queryId),\n      relativePath,\n      changeTree\n    );\n    return syncTreeApplyTaggedOperation_(syncTree, queryPath, op);\n  } else {\n    // We've already removed the query. No big deal, ignore the update\n    return [];\n  }\n}\n\n/**\n * Add an event callback for the specified query.\n *\n * @returns Events to raise.\n */\nexport function syncTreeAddEventRegistration(\n  syncTree: SyncTree,\n  query: QueryContext,\n  eventRegistration: EventRegistration,\n  skipSetupListener = false\n): Event[] {\n  const path = query._path;\n\n  let serverCache: Node | null = null;\n  let foundAncestorDefaultView = false;\n  // Any covering writes will necessarily be at the root, so really all we need to find is the server cache.\n  // Consider optimizing this once there's a better understanding of what actual behavior will be.\n  syncTree.syncPointTree_.foreachOnPath(path, (pathToSyncPoint, sp) => {\n    const relativePath = newRelativePath(pathToSyncPoint, path);\n    serverCache =\n      serverCache || syncPointGetCompleteServerCache(sp, relativePath);\n    foundAncestorDefaultView =\n      foundAncestorDefaultView || syncPointHasCompleteView(sp);\n  });\n  let syncPoint = syncTree.syncPointTree_.get(path);\n  if (!syncPoint) {\n    syncPoint = new SyncPoint();\n    syncTree.syncPointTree_ = syncTree.syncPointTree_.set(path, syncPoint);\n  } else {\n    foundAncestorDefaultView =\n      foundAncestorDefaultView || syncPointHasCompleteView(syncPoint);\n    serverCache =\n      serverCache || syncPointGetCompleteServerCache(syncPoint, newEmptyPath());\n  }\n\n  let serverCacheComplete;\n  if (serverCache != null) {\n    serverCacheComplete = true;\n  } else {\n    serverCacheComplete = false;\n    serverCache = ChildrenNode.EMPTY_NODE;\n    const subtree = syncTree.syncPointTree_.subtree(path);\n    subtree.foreachChild((childName, childSyncPoint) => {\n      const completeCache = syncPointGetCompleteServerCache(\n        childSyncPoint,\n        newEmptyPath()\n      );\n      if (completeCache) {\n        serverCache = serverCache.updateImmediateChild(\n          childName,\n          completeCache\n        );\n      }\n    });\n  }\n\n  const viewAlreadyExists = syncPointViewExistsForQuery(syncPoint, query);\n  if (!viewAlreadyExists && !query._queryParams.loadsAllData()) {\n    // We need to track a tag for this query\n    const queryKey = syncTreeMakeQueryKey_(query);\n    assert(\n      !syncTree.queryToTagMap.has(queryKey),\n      'View does not exist, but we have a tag'\n    );\n    const tag = syncTreeGetNextQueryTag_();\n    syncTree.queryToTagMap.set(queryKey, tag);\n    syncTree.tagToQueryMap.set(tag, queryKey);\n  }\n  const writesCache = writeTreeChildWrites(syncTree.pendingWriteTree_, path);\n  let events = syncPointAddEventRegistration(\n    syncPoint,\n    query,\n    eventRegistration,\n    writesCache,\n    serverCache,\n    serverCacheComplete\n  );\n  if (!viewAlreadyExists && !foundAncestorDefaultView && !skipSetupListener) {\n    const view = syncPointViewForQuery(syncPoint, query);\n    events = events.concat(syncTreeSetupListener_(syncTree, query, view));\n  }\n  return events;\n}\n\n/**\n * Returns a complete cache, if we have one, of the data at a particular path. If the location does not have a\n * listener above it, we will get a false \"null\". This shouldn't be a problem because transactions will always\n * have a listener above, and atomic operations would correctly show a jitter of <increment value> ->\n *     <incremented total> as the write is applied locally and then acknowledged at the server.\n *\n * Note: this method will *include* hidden writes from transaction with applyLocally set to false.\n *\n * @param path - The path to the data we want\n * @param writeIdsToExclude - A specific set to be excluded\n */\nexport function syncTreeCalcCompleteEventCache(\n  syncTree: SyncTree,\n  path: Path,\n  writeIdsToExclude?: number[]\n): Node {\n  const includeHiddenSets = true;\n  const writeTree = syncTree.pendingWriteTree_;\n  const serverCache = syncTree.syncPointTree_.findOnPath(\n    path,\n    (pathSoFar, syncPoint) => {\n      const relativePath = newRelativePath(pathSoFar, path);\n      const serverCache = syncPointGetCompleteServerCache(\n        syncPoint,\n        relativePath\n      );\n      if (serverCache) {\n        return serverCache;\n      }\n    }\n  );\n  return writeTreeCalcCompleteEventCache(\n    writeTree,\n    path,\n    serverCache,\n    writeIdsToExclude,\n    includeHiddenSets\n  );\n}\n\nexport function syncTreeGetServerValue(\n  syncTree: SyncTree,\n  query: QueryContext\n): Node | null {\n  const path = query._path;\n  let serverCache: Node | null = null;\n  // Any covering writes will necessarily be at the root, so really all we need to find is the server cache.\n  // Consider optimizing this once there's a better understanding of what actual behavior will be.\n  syncTree.syncPointTree_.foreachOnPath(path, (pathToSyncPoint, sp) => {\n    const relativePath = newRelativePath(pathToSyncPoint, path);\n    serverCache =\n      serverCache || syncPointGetCompleteServerCache(sp, relativePath);\n  });\n  let syncPoint = syncTree.syncPointTree_.get(path);\n  if (!syncPoint) {\n    syncPoint = new SyncPoint();\n    syncTree.syncPointTree_ = syncTree.syncPointTree_.set(path, syncPoint);\n  } else {\n    serverCache =\n      serverCache || syncPointGetCompleteServerCache(syncPoint, newEmptyPath());\n  }\n  const serverCacheComplete = serverCache != null;\n  const serverCacheNode: CacheNode | null = serverCacheComplete\n    ? new CacheNode(serverCache, true, false)\n    : null;\n  const writesCache: WriteTreeRef | null = writeTreeChildWrites(\n    syncTree.pendingWriteTree_,\n    query._path\n  );\n  const view: View = syncPointGetView(\n    syncPoint,\n    query,\n    writesCache,\n    serverCacheComplete ? serverCacheNode.getNode() : ChildrenNode.EMPTY_NODE,\n    serverCacheComplete\n  );\n  return viewGetCompleteNode(view);\n}\n\n/**\n * A helper method that visits all descendant and ancestor SyncPoints, applying the operation.\n *\n * NOTES:\n * - Descendant SyncPoints will be visited first (since we raise events depth-first).\n *\n * - We call applyOperation() on each SyncPoint passing three things:\n *   1. A version of the Operation that has been made relative to the SyncPoint location.\n *   2. A WriteTreeRef of any writes we have cached at the SyncPoint location.\n *   3. A snapshot Node with cached server data, if we have it.\n *\n * - We concatenate all of the events returned by each SyncPoint and return the result.\n */\nfunction syncTreeApplyOperationToSyncPoints_(\n  syncTree: SyncTree,\n  operation: Operation\n): Event[] {\n  return syncTreeApplyOperationHelper_(\n    operation,\n    syncTree.syncPointTree_,\n    /*serverCache=*/ null,\n    writeTreeChildWrites(syncTree.pendingWriteTree_, newEmptyPath())\n  );\n}\n\n/**\n * Recursive helper for applyOperationToSyncPoints_\n */\nfunction syncTreeApplyOperationHelper_(\n  operation: Operation,\n  syncPointTree: ImmutableTree<SyncPoint>,\n  serverCache: Node | null,\n  writesCache: WriteTreeRef\n): Event[] {\n  if (pathIsEmpty(operation.path)) {\n    return syncTreeApplyOperationDescendantsHelper_(\n      operation,\n      syncPointTree,\n      serverCache,\n      writesCache\n    );\n  } else {\n    const syncPoint = syncPointTree.get(newEmptyPath());\n\n    // If we don't have cached server data, see if we can get it from this SyncPoint.\n    if (serverCache == null && syncPoint != null) {\n      serverCache = syncPointGetCompleteServerCache(syncPoint, newEmptyPath());\n    }\n\n    let events: Event[] = [];\n    const childName = pathGetFront(operation.path);\n    const childOperation = operation.operationForChild(childName);\n    const childTree = syncPointTree.children.get(childName);\n    if (childTree && childOperation) {\n      const childServerCache = serverCache\n        ? serverCache.getImmediateChild(childName)\n        : null;\n      const childWritesCache = writeTreeRefChild(writesCache, childName);\n      events = events.concat(\n        syncTreeApplyOperationHelper_(\n          childOperation,\n          childTree,\n          childServerCache,\n          childWritesCache\n        )\n      );\n    }\n\n    if (syncPoint) {\n      events = events.concat(\n        syncPointApplyOperation(syncPoint, operation, writesCache, serverCache)\n      );\n    }\n\n    return events;\n  }\n}\n\n/**\n * Recursive helper for applyOperationToSyncPoints_\n */\nfunction syncTreeApplyOperationDescendantsHelper_(\n  operation: Operation,\n  syncPointTree: ImmutableTree<SyncPoint>,\n  serverCache: Node | null,\n  writesCache: WriteTreeRef\n): Event[] {\n  const syncPoint = syncPointTree.get(newEmptyPath());\n\n  // If we don't have cached server data, see if we can get it from this SyncPoint.\n  if (serverCache == null && syncPoint != null) {\n    serverCache = syncPointGetCompleteServerCache(syncPoint, newEmptyPath());\n  }\n\n  let events: Event[] = [];\n  syncPointTree.children.inorderTraversal((childName, childTree) => {\n    const childServerCache = serverCache\n      ? serverCache.getImmediateChild(childName)\n      : null;\n    const childWritesCache = writeTreeRefChild(writesCache, childName);\n    const childOperation = operation.operationForChild(childName);\n    if (childOperation) {\n      events = events.concat(\n        syncTreeApplyOperationDescendantsHelper_(\n          childOperation,\n          childTree,\n          childServerCache,\n          childWritesCache\n        )\n      );\n    }\n  });\n\n  if (syncPoint) {\n    events = events.concat(\n      syncPointApplyOperation(syncPoint, operation, writesCache, serverCache)\n    );\n  }\n\n  return events;\n}\n\nfunction syncTreeCreateListenerForView_(\n  syncTree: SyncTree,\n  view: View\n): { hashFn(): string; onComplete(a: string, b?: unknown): Event[] } {\n  const query = view.query;\n  const tag = syncTreeTagForQuery(syncTree, query);\n\n  return {\n    hashFn: () => {\n      const cache = viewGetServerCache(view) || ChildrenNode.EMPTY_NODE;\n      return cache.hash();\n    },\n    onComplete: (status: string): Event[] => {\n      if (status === 'ok') {\n        if (tag) {\n          return syncTreeApplyTaggedListenComplete(syncTree, query._path, tag);\n        } else {\n          return syncTreeApplyListenComplete(syncTree, query._path);\n        }\n      } else {\n        // If a listen failed, kill all of the listeners here, not just the one that triggered the error.\n        // Note that this may need to be scoped to just this listener if we change permissions on filtered children\n        const error = errorForServerCode(status, query);\n        return syncTreeRemoveEventRegistration(\n          syncTree,\n          query,\n          /*eventRegistration*/ null,\n          error\n        );\n      }\n    }\n  };\n}\n\n/**\n * Return the tag associated with the given query.\n */\nexport function syncTreeTagForQuery(\n  syncTree: SyncTree,\n  query: QueryContext\n): number | null {\n  const queryKey = syncTreeMakeQueryKey_(query);\n  return syncTree.queryToTagMap.get(queryKey);\n}\n\n/**\n * Given a query, computes a \"queryKey\" suitable for use in our queryToTagMap_.\n */\nfunction syncTreeMakeQueryKey_(query: QueryContext): string {\n  return query._path.toString() + '$' + query._queryIdentifier;\n}\n\n/**\n * Return the query associated with the given tag, if we have one\n */\nfunction syncTreeQueryKeyForTag_(\n  syncTree: SyncTree,\n  tag: number\n): string | null {\n  return syncTree.tagToQueryMap.get(tag);\n}\n\n/**\n * Given a queryKey (created by makeQueryKey), parse it back into a path and queryId.\n */\nfunction syncTreeParseQueryKey_(queryKey: string): {\n  queryId: string;\n  path: Path;\n} {\n  const splitIndex = queryKey.indexOf('$');\n  assert(\n    splitIndex !== -1 && splitIndex < queryKey.length - 1,\n    'Bad queryKey.'\n  );\n  return {\n    queryId: queryKey.substr(splitIndex + 1),\n    path: new Path(queryKey.substr(0, splitIndex))\n  };\n}\n\n/**\n * A helper method to apply tagged operations\n */\nfunction syncTreeApplyTaggedOperation_(\n  syncTree: SyncTree,\n  queryPath: Path,\n  operation: Operation\n): Event[] {\n  const syncPoint = syncTree.syncPointTree_.get(queryPath);\n  assert(syncPoint, \"Missing sync point for query tag that we're tracking\");\n  const writesCache = writeTreeChildWrites(\n    syncTree.pendingWriteTree_,\n    queryPath\n  );\n  return syncPointApplyOperation(syncPoint, operation, writesCache, null);\n}\n\n/**\n * This collapses multiple unfiltered views into a single view, since we only need a single\n * listener for them.\n */\nfunction syncTreeCollectDistinctViewsForSubTree_(\n  subtree: ImmutableTree<SyncPoint>\n): View[] {\n  return subtree.fold<View[]>((relativePath, maybeChildSyncPoint, childMap) => {\n    if (maybeChildSyncPoint && syncPointHasCompleteView(maybeChildSyncPoint)) {\n      const completeView = syncPointGetCompleteView(maybeChildSyncPoint);\n      return [completeView];\n    } else {\n      // No complete view here, flatten any deeper listens into an array\n      let views: View[] = [];\n      if (maybeChildSyncPoint) {\n        views = syncPointGetQueryViews(maybeChildSyncPoint);\n      }\n      each(childMap, (_key: string, childViews: View[]) => {\n        views = views.concat(childViews);\n      });\n      return views;\n    }\n  });\n}\n\n/**\n * Normalizes a query to a query we send the server for listening\n *\n * @returns The normalized query\n */\nfunction syncTreeQueryForListening_(query: QueryContext): QueryContext {\n  if (query._queryParams.loadsAllData() && !query._queryParams.isDefault()) {\n    // We treat queries that load all data as default queries\n    // Cast is necessary because ref() technically returns Firebase which is actually fb.api.Firebase which inherits\n    // from Query\n    return new (syncTreeGetReferenceConstructor())(query._repo, query._path);\n  } else {\n    return query;\n  }\n}\n\nfunction syncTreeRemoveTags_(syncTree: SyncTree, queries: QueryContext[]) {\n  for (let j = 0; j < queries.length; ++j) {\n    const removedQuery = queries[j];\n    if (!removedQuery._queryParams.loadsAllData()) {\n      // We should have a tag for this\n      const removedQueryKey = syncTreeMakeQueryKey_(removedQuery);\n      const removedQueryTag = syncTree.queryToTagMap.get(removedQueryKey);\n      syncTree.queryToTagMap.delete(removedQueryKey);\n      syncTree.tagToQueryMap.delete(removedQueryTag);\n    }\n  }\n}\n\n/**\n * Static accessor for query tags.\n */\nfunction syncTreeGetNextQueryTag_(): number {\n  return syncTreeNextQueryTag_++;\n}\n\n/**\n * For a given new listen, manage the de-duplication of outstanding subscriptions.\n *\n * @returns This method can return events to support synchronous data sources\n */\nfunction syncTreeSetupListener_(\n  syncTree: SyncTree,\n  query: QueryContext,\n  view: View\n): Event[] {\n  const path = query._path;\n  const tag = syncTreeTagForQuery(syncTree, query);\n  const listener = syncTreeCreateListenerForView_(syncTree, view);\n\n  const events = syncTree.listenProvider_.startListening(\n    syncTreeQueryForListening_(query),\n    tag,\n    listener.hashFn,\n    listener.onComplete\n  );\n\n  const subtree = syncTree.syncPointTree_.subtree(path);\n  // The root of this subtree has our query. We're here because we definitely need to send a listen for that, but we\n  // may need to shadow other listens as well.\n  if (tag) {\n    assert(\n      !syncPointHasCompleteView(subtree.value),\n      \"If we're adding a query, it shouldn't be shadowed\"\n    );\n  } else {\n    // Shadow everything at or below this location, this is a default listener.\n    const queriesToStop = subtree.fold<QueryContext[]>(\n      (relativePath, maybeChildSyncPoint, childMap) => {\n        if (\n          !pathIsEmpty(relativePath) &&\n          maybeChildSyncPoint &&\n          syncPointHasCompleteView(maybeChildSyncPoint)\n        ) {\n          return [syncPointGetCompleteView(maybeChildSyncPoint).query];\n        } else {\n          // No default listener here, flatten any deeper queries into an array\n          let queries: QueryContext[] = [];\n          if (maybeChildSyncPoint) {\n            queries = queries.concat(\n              syncPointGetQueryViews(maybeChildSyncPoint).map(\n                view => view.query\n              )\n            );\n          }\n          each(childMap, (_key: string, childQueries: QueryContext[]) => {\n            queries = queries.concat(childQueries);\n          });\n          return queries;\n        }\n      }\n    );\n    for (let i = 0; i < queriesToStop.length; ++i) {\n      const queryToStop = queriesToStop[i];\n      syncTree.listenProvider_.stopListening(\n        syncTreeQueryForListening_(queryToStop),\n        syncTreeTagForQuery(syncTree, queryToStop)\n      );\n    }\n  }\n  return events;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { ChildrenNode } from '../snap/ChildrenNode';\nimport { PRIORITY_INDEX } from '../snap/indexes/PriorityIndex';\nimport { LeafNode } from '../snap/LeafNode';\nimport { Node } from '../snap/Node';\nimport { nodeFromJSON } from '../snap/nodeFromJSON';\nimport { SyncTree, syncTreeCalcCompleteEventCache } from '../SyncTree';\n\nimport { Indexable } from './misc';\nimport { Path, pathChild } from './Path';\n\n/* It's critical for performance that we do not calculate actual values from a SyncTree\n * unless and until the value is needed. Because we expose both a SyncTree and Node\n * version of deferred value resolution, we ned a wrapper class that will let us share\n * code.\n *\n * @see https://github.com/firebase/firebase-js-sdk/issues/2487\n */\ninterface ValueProvider {\n  getImmediateChild(childName: string): ValueProvider;\n  node(): Node;\n}\n\nclass ExistingValueProvider implements ValueProvider {\n  constructor(readonly node_: Node) {}\n\n  getImmediateChild(childName: string): ValueProvider {\n    const child = this.node_.getImmediateChild(childName);\n    return new ExistingValueProvider(child);\n  }\n\n  node(): Node {\n    return this.node_;\n  }\n}\n\nclass DeferredValueProvider implements ValueProvider {\n  private syncTree_: SyncTree;\n  private path_: Path;\n\n  constructor(syncTree: SyncTree, path: Path) {\n    this.syncTree_ = syncTree;\n    this.path_ = path;\n  }\n\n  getImmediateChild(childName: string): ValueProvider {\n    const childPath = pathChild(this.path_, childName);\n    return new DeferredValueProvider(this.syncTree_, childPath);\n  }\n\n  node(): Node {\n    return syncTreeCalcCompleteEventCache(this.syncTree_, this.path_);\n  }\n}\n\n/**\n * Generate placeholders for deferred values.\n */\nexport const generateWithValues = function (\n  values: {\n    [k: string]: unknown;\n  } | null\n): { [k: string]: unknown } {\n  values = values || {};\n  values['timestamp'] = values['timestamp'] || new Date().getTime();\n  return values;\n};\n\n/**\n * Value to use when firing local events. When writing server values, fire\n * local events with an approximate value, otherwise return value as-is.\n */\nexport const resolveDeferredLeafValue = function (\n  value: { [k: string]: unknown } | string | number | boolean,\n  existingVal: ValueProvider,\n  serverValues: { [k: string]: unknown }\n): string | number | boolean {\n  if (!value || typeof value !== 'object') {\n    return value as string | number | boolean;\n  }\n  assert('.sv' in value, 'Unexpected leaf node or priority contents');\n\n  if (typeof value['.sv'] === 'string') {\n    return resolveScalarDeferredValue(value['.sv'], existingVal, serverValues);\n  } else if (typeof value['.sv'] === 'object') {\n    return resolveComplexDeferredValue(value['.sv'], existingVal, serverValues);\n  } else {\n    assert(false, 'Unexpected server value: ' + JSON.stringify(value, null, 2));\n  }\n};\n\nconst resolveScalarDeferredValue = function (\n  op: string,\n  existing: ValueProvider,\n  serverValues: { [k: string]: unknown }\n): string | number | boolean {\n  switch (op) {\n    case 'timestamp':\n      return serverValues['timestamp'] as string | number | boolean;\n    default:\n      assert(false, 'Unexpected server value: ' + op);\n  }\n};\n\nconst resolveComplexDeferredValue = function (\n  op: object,\n  existing: ValueProvider,\n  unused: { [k: string]: unknown }\n): string | number | boolean {\n  if (!op.hasOwnProperty('increment')) {\n    assert(false, 'Unexpected server value: ' + JSON.stringify(op, null, 2));\n  }\n  const delta = op['increment'];\n  if (typeof delta !== 'number') {\n    assert(false, 'Unexpected increment value: ' + delta);\n  }\n\n  const existingNode = existing.node();\n  assert(\n    existingNode !== null && typeof existingNode !== 'undefined',\n    'Expected ChildrenNode.EMPTY_NODE for nulls'\n  );\n\n  // Incrementing a non-number sets the value to the incremented amount\n  if (!existingNode.isLeafNode()) {\n    return delta;\n  }\n\n  const leaf = existingNode as LeafNode;\n  const existingVal = leaf.getValue();\n  if (typeof existingVal !== 'number') {\n    return delta;\n  }\n\n  // No need to do over/underflow arithmetic here because JS only handles floats under the covers\n  return existingVal + delta;\n};\n\n/**\n * Recursively replace all deferred values and priorities in the tree with the\n * specified generated replacement values.\n * @param path - path to which write is relative\n * @param node - new data written at path\n * @param syncTree - current data\n */\nexport const resolveDeferredValueTree = function (\n  path: Path,\n  node: Node,\n  syncTree: SyncTree,\n  serverValues: Indexable\n): Node {\n  return resolveDeferredValue(\n    node,\n    new DeferredValueProvider(syncTree, path),\n    serverValues\n  );\n};\n\n/**\n * Recursively replace all deferred values and priorities in the node with the\n * specified generated replacement values.  If there are no server values in the node,\n * it'll be returned as-is.\n */\nexport const resolveDeferredValueSnapshot = function (\n  node: Node,\n  existing: Node,\n  serverValues: Indexable\n): Node {\n  return resolveDeferredValue(\n    node,\n    new ExistingValueProvider(existing),\n    serverValues\n  );\n};\n\nfunction resolveDeferredValue(\n  node: Node,\n  existingVal: ValueProvider,\n  serverValues: Indexable\n): Node {\n  const rawPri = node.getPriority().val() as\n    | Indexable\n    | boolean\n    | null\n    | number\n    | string;\n  const priority = resolveDeferredLeafValue(\n    rawPri,\n    existingVal.getImmediateChild('.priority'),\n    serverValues\n  );\n  let newNode: Node;\n\n  if (node.isLeafNode()) {\n    const leafNode = node as LeafNode;\n    const value = resolveDeferredLeafValue(\n      leafNode.getValue(),\n      existingVal,\n      serverValues\n    );\n    if (\n      value !== leafNode.getValue() ||\n      priority !== leafNode.getPriority().val()\n    ) {\n      return new LeafNode(value, nodeFromJSON(priority));\n    } else {\n      return node;\n    }\n  } else {\n    const childrenNode = node as ChildrenNode;\n    newNode = childrenNode;\n    if (priority !== childrenNode.getPriority().val()) {\n      newNode = newNode.updatePriority(new LeafNode(priority));\n    }\n    childrenNode.forEachChild(PRIORITY_INDEX, (childName, childNode) => {\n      const newChildNode = resolveDeferredValue(\n        childNode,\n        existingVal.getImmediateChild(childName),\n        serverValues\n      );\n      if (newChildNode !== childNode) {\n        newNode = newNode.updateImmediateChild(childName, newChildNode);\n      }\n    });\n    return newNode;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { contains, safeGet } from '@firebase/util';\n\nimport { Path, pathGetFront, pathPopFront } from './Path';\nimport { each } from './util';\n\n/**\n * Node in a Tree.\n */\nexport interface TreeNode<T> {\n  // TODO: Consider making accessors that create children and value lazily or\n  // separate Internal / Leaf 'types'.\n  children: Record<string, TreeNode<T>>;\n  childCount: number;\n  value?: T;\n}\n\n/**\n * A light-weight tree, traversable by path.  Nodes can have both values and children.\n * Nodes are not enumerated (by forEachChild) unless they have a value or non-empty\n * children.\n */\nexport class Tree<T> {\n  /**\n   * @param name - Optional name of the node.\n   * @param parent - Optional parent node.\n   * @param node - Optional node to wrap.\n   */\n  constructor(\n    readonly name: string = '',\n    readonly parent: Tree<T> | null = null,\n    public node: TreeNode<T> = { children: {}, childCount: 0 }\n  ) {}\n}\n\n/**\n * Returns a sub-Tree for the given path.\n *\n * @param pathObj - Path to look up.\n * @returns Tree for path.\n */\nexport function treeSubTree<T>(tree: Tree<T>, pathObj: string | Path): Tree<T> {\n  // TODO: Require pathObj to be Path?\n  let path = pathObj instanceof Path ? pathObj : new Path(pathObj);\n  let child = tree,\n    next = pathGetFront(path);\n  while (next !== null) {\n    const childNode = safeGet(child.node.children, next) || {\n      children: {},\n      childCount: 0\n    };\n    child = new Tree<T>(next, child, childNode);\n    path = pathPopFront(path);\n    next = pathGetFront(path);\n  }\n\n  return child;\n}\n\n/**\n * Returns the data associated with this tree node.\n *\n * @returns The data or null if no data exists.\n */\nexport function treeGetValue<T>(tree: Tree<T>): T | undefined {\n  return tree.node.value;\n}\n\n/**\n * Sets data to this tree node.\n *\n * @param value - Value to set.\n */\nexport function treeSetValue<T>(tree: Tree<T>, value: T | undefined): void {\n  tree.node.value = value;\n  treeUpdateParents(tree);\n}\n\n/**\n * @returns Whether the tree has any children.\n */\nexport function treeHasChildren<T>(tree: Tree<T>): boolean {\n  return tree.node.childCount > 0;\n}\n\n/**\n * @returns Whethe rthe tree is empty (no value or children).\n */\nexport function treeIsEmpty<T>(tree: Tree<T>): boolean {\n  return treeGetValue(tree) === undefined && !treeHasChildren(tree);\n}\n\n/**\n * Calls action for each child of this tree node.\n *\n * @param action - Action to be called for each child.\n */\nexport function treeForEachChild<T>(\n  tree: Tree<T>,\n  action: (tree: Tree<T>) => void\n): void {\n  each(tree.node.children, (child: string, childTree: TreeNode<T>) => {\n    action(new Tree<T>(child, tree, childTree));\n  });\n}\n\n/**\n * Does a depth-first traversal of this node's descendants, calling action for each one.\n *\n * @param action - Action to be called for each child.\n * @param includeSelf - Whether to call action on this node as well. Defaults to\n *   false.\n * @param childrenFirst - Whether to call action on children before calling it on\n *   parent.\n */\nexport function treeForEachDescendant<T>(\n  tree: Tree<T>,\n  action: (tree: Tree<T>) => void,\n  includeSelf?: boolean,\n  childrenFirst?: boolean\n): void {\n  if (includeSelf && !childrenFirst) {\n    action(tree);\n  }\n\n  treeForEachChild(tree, child => {\n    treeForEachDescendant(child, action, true, childrenFirst);\n  });\n\n  if (includeSelf && childrenFirst) {\n    action(tree);\n  }\n}\n\n/**\n * Calls action on each ancestor node.\n *\n * @param action - Action to be called on each parent; return\n *   true to abort.\n * @param includeSelf - Whether to call action on this node as well.\n * @returns true if the action callback returned true.\n */\nexport function treeForEachAncestor<T>(\n  tree: Tree<T>,\n  action: (tree: Tree<T>) => unknown,\n  includeSelf?: boolean\n): boolean {\n  let node = includeSelf ? tree : tree.parent;\n  while (node !== null) {\n    if (action(node)) {\n      return true;\n    }\n    node = node.parent;\n  }\n  return false;\n}\n\n/**\n * Does a depth-first traversal of this node's descendants.  When a descendant with a value\n * is found, action is called on it and traversal does not continue inside the node.\n * Action is *not* called on this node.\n *\n * @param action - Action to be called for each child.\n */\nexport function treeForEachImmediateDescendantWithValue<T>(\n  tree: Tree<T>,\n  action: (tree: Tree<T>) => void\n): void {\n  treeForEachChild(tree, child => {\n    if (treeGetValue(child) !== undefined) {\n      action(child);\n    } else {\n      treeForEachImmediateDescendantWithValue(child, action);\n    }\n  });\n}\n\n/**\n * @returns The path of this tree node, as a Path.\n */\nexport function treeGetPath<T>(tree: Tree<T>) {\n  return new Path(\n    tree.parent === null\n      ? tree.name\n      : treeGetPath(tree.parent) + '/' + tree.name\n  );\n}\n\n/**\n * Adds or removes this child from its parent based on whether it's empty or not.\n */\nfunction treeUpdateParents<T>(tree: Tree<T>) {\n  if (tree.parent !== null) {\n    treeUpdateChild(tree.parent, tree.name, tree);\n  }\n}\n\n/**\n * Adds or removes the passed child to this tree node, depending on whether it's empty.\n *\n * @param childName - The name of the child to update.\n * @param child - The child to update.\n */\nfunction treeUpdateChild<T>(tree: Tree<T>, childName: string, child: Tree<T>) {\n  const childEmpty = treeIsEmpty(child);\n  const childExists = contains(tree.node.children, childName);\n  if (childEmpty && childExists) {\n    delete tree.node.children[childName];\n    tree.node.childCount--;\n    treeUpdateParents(tree);\n  } else if (!childEmpty && !childExists) {\n    tree.node.children[childName] = child.node;\n    tree.node.childCount++;\n    treeUpdateParents(tree);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  contains,\n  errorPrefix as errorPrefixFxn,\n  safeGet,\n  stringLength\n} from '@firebase/util';\n\nimport { RepoInfo } from '../RepoInfo';\n\nimport {\n  Path,\n  pathChild,\n  pathCompare,\n  pathContains,\n  pathGetBack,\n  pathGetFront,\n  pathSlice,\n  ValidationPath,\n  validationPathPop,\n  validationPathPush,\n  validationPathToErrorString\n} from './Path';\nimport { each, isInvalidJSONNumber } from './util';\n\n/**\n * True for invalid Firebase keys\n */\nexport const INVALID_KEY_REGEX_ = /[\\[\\].#$\\/\\u0000-\\u001F\\u007F]/;\n\n/**\n * True for invalid Firebase paths.\n * Allows '/' in paths.\n */\nexport const INVALID_PATH_REGEX_ = /[\\[\\].#$\\u0000-\\u001F\\u007F]/;\n\n/**\n * Maximum number of characters to allow in leaf value\n */\nexport const MAX_LEAF_SIZE_ = 10 * 1024 * 1024;\n\nexport const isValidKey = function (key: unknown): boolean {\n  return (\n    typeof key === 'string' && key.length !== 0 && !INVALID_KEY_REGEX_.test(key)\n  );\n};\n\nexport const isValidPathString = function (pathString: string): boolean {\n  return (\n    typeof pathString === 'string' &&\n    pathString.length !== 0 &&\n    !INVALID_PATH_REGEX_.test(pathString)\n  );\n};\n\nexport const isValidRootPathString = function (pathString: string): boolean {\n  if (pathString) {\n    // Allow '/.info/' at the beginning.\n    pathString = pathString.replace(/^\\/*\\.info(\\/|$)/, '/');\n  }\n\n  return isValidPathString(pathString);\n};\n\nexport const isValidPriority = function (priority: unknown): boolean {\n  return (\n    priority === null ||\n    typeof priority === 'string' ||\n    (typeof priority === 'number' && !isInvalidJSONNumber(priority)) ||\n    (priority &&\n      typeof priority === 'object' &&\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      contains(priority as any, '.sv'))\n  );\n};\n\n/**\n * Pre-validate a datum passed as an argument to Firebase function.\n */\nexport const validateFirebaseDataArg = function (\n  fnName: string,\n  value: unknown,\n  path: Path,\n  optional: boolean\n) {\n  if (optional && value === undefined) {\n    return;\n  }\n\n  validateFirebaseData(errorPrefixFxn(fnName, 'value'), value, path);\n};\n\n/**\n * Validate a data object client-side before sending to server.\n */\nexport const validateFirebaseData = function (\n  errorPrefix: string,\n  data: unknown,\n  path_: Path | ValidationPath\n) {\n  const path =\n    path_ instanceof Path ? new ValidationPath(path_, errorPrefix) : path_;\n\n  if (data === undefined) {\n    throw new Error(\n      errorPrefix + 'contains undefined ' + validationPathToErrorString(path)\n    );\n  }\n  if (typeof data === 'function') {\n    throw new Error(\n      errorPrefix +\n        'contains a function ' +\n        validationPathToErrorString(path) +\n        ' with contents = ' +\n        data.toString()\n    );\n  }\n  if (isInvalidJSONNumber(data)) {\n    throw new Error(\n      errorPrefix +\n        'contains ' +\n        data.toString() +\n        ' ' +\n        validationPathToErrorString(path)\n    );\n  }\n\n  // Check max leaf size, but try to avoid the utf8 conversion if we can.\n  if (\n    typeof data === 'string' &&\n    data.length > MAX_LEAF_SIZE_ / 3 &&\n    stringLength(data) > MAX_LEAF_SIZE_\n  ) {\n    throw new Error(\n      errorPrefix +\n        'contains a string greater than ' +\n        MAX_LEAF_SIZE_ +\n        ' utf8 bytes ' +\n        validationPathToErrorString(path) +\n        \" ('\" +\n        data.substring(0, 50) +\n        \"...')\"\n    );\n  }\n\n  // TODO = Perf = Consider combining the recursive validation of keys into NodeFromJSON\n  // to save extra walking of large objects.\n  if (data && typeof data === 'object') {\n    let hasDotValue = false;\n    let hasActualChild = false;\n    each(data, (key: string, value: unknown) => {\n      if (key === '.value') {\n        hasDotValue = true;\n      } else if (key !== '.priority' && key !== '.sv') {\n        hasActualChild = true;\n        if (!isValidKey(key)) {\n          throw new Error(\n            errorPrefix +\n              ' contains an invalid key (' +\n              key +\n              ') ' +\n              validationPathToErrorString(path) +\n              '.  Keys must be non-empty strings ' +\n              'and can\\'t contain \".\", \"#\", \"$\", \"/\", \"[\", or \"]\"'\n          );\n        }\n      }\n\n      validationPathPush(path, key);\n      validateFirebaseData(errorPrefix, value, path);\n      validationPathPop(path);\n    });\n\n    if (hasDotValue && hasActualChild) {\n      throw new Error(\n        errorPrefix +\n          ' contains \".value\" child ' +\n          validationPathToErrorString(path) +\n          ' in addition to actual children.'\n      );\n    }\n  }\n};\n\n/**\n * Pre-validate paths passed in the firebase function.\n */\nexport const validateFirebaseMergePaths = function (\n  errorPrefix: string,\n  mergePaths: Path[]\n) {\n  let i, curPath: Path;\n  for (i = 0; i < mergePaths.length; i++) {\n    curPath = mergePaths[i];\n    const keys = pathSlice(curPath);\n    for (let j = 0; j < keys.length; j++) {\n      if (keys[j] === '.priority' && j === keys.length - 1) {\n        // .priority is OK\n      } else if (!isValidKey(keys[j])) {\n        throw new Error(\n          errorPrefix +\n            'contains an invalid key (' +\n            keys[j] +\n            ') in path ' +\n            curPath.toString() +\n            '. Keys must be non-empty strings ' +\n            'and can\\'t contain \".\", \"#\", \"$\", \"/\", \"[\", or \"]\"'\n        );\n      }\n    }\n  }\n\n  // Check that update keys are not descendants of each other.\n  // We rely on the property that sorting guarantees that ancestors come\n  // right before descendants.\n  mergePaths.sort(pathCompare);\n  let prevPath: Path | null = null;\n  for (i = 0; i < mergePaths.length; i++) {\n    curPath = mergePaths[i];\n    if (prevPath !== null && pathContains(prevPath, curPath)) {\n      throw new Error(\n        errorPrefix +\n          'contains a path ' +\n          prevPath.toString() +\n          ' that is ancestor of another path ' +\n          curPath.toString()\n      );\n    }\n    prevPath = curPath;\n  }\n};\n\n/**\n * pre-validate an object passed as an argument to firebase function (\n * must be an object - e.g. for firebase.update()).\n */\nexport const validateFirebaseMergeDataArg = function (\n  fnName: string,\n  data: unknown,\n  path: Path,\n  optional: boolean\n) {\n  if (optional && data === undefined) {\n    return;\n  }\n\n  const errorPrefix = errorPrefixFxn(fnName, 'values');\n\n  if (!(data && typeof data === 'object') || Array.isArray(data)) {\n    throw new Error(\n      errorPrefix + ' must be an object containing the children to replace.'\n    );\n  }\n\n  const mergePaths: Path[] = [];\n  each(data, (key: string, value: unknown) => {\n    const curPath = new Path(key);\n    validateFirebaseData(errorPrefix, value, pathChild(path, curPath));\n    if (pathGetBack(curPath) === '.priority') {\n      if (!isValidPriority(value)) {\n        throw new Error(\n          errorPrefix +\n            \"contains an invalid value for '\" +\n            curPath.toString() +\n            \"', which must be a valid \" +\n            'Firebase priority (a string, finite number, server value, or null).'\n        );\n      }\n    }\n    mergePaths.push(curPath);\n  });\n  validateFirebaseMergePaths(errorPrefix, mergePaths);\n};\n\nexport const validatePriority = function (\n  fnName: string,\n  priority: unknown,\n  optional: boolean\n) {\n  if (optional && priority === undefined) {\n    return;\n  }\n  if (isInvalidJSONNumber(priority)) {\n    throw new Error(\n      errorPrefixFxn(fnName, 'priority') +\n        'is ' +\n        priority.toString() +\n        ', but must be a valid Firebase priority (a string, finite number, ' +\n        'server value, or null).'\n    );\n  }\n  // Special case to allow importing data with a .sv.\n  if (!isValidPriority(priority)) {\n    throw new Error(\n      errorPrefixFxn(fnName, 'priority') +\n        'must be a valid Firebase priority ' +\n        '(a string, finite number, server value, or null).'\n    );\n  }\n};\n\nexport const validateKey = function (\n  fnName: string,\n  argumentName: string,\n  key: string,\n  optional: boolean\n) {\n  if (optional && key === undefined) {\n    return;\n  }\n  if (!isValidKey(key)) {\n    throw new Error(\n      errorPrefixFxn(fnName, argumentName) +\n        'was an invalid key = \"' +\n        key +\n        '\".  Firebase keys must be non-empty strings and ' +\n        'can\\'t contain \".\", \"#\", \"$\", \"/\", \"[\", or \"]\").'\n    );\n  }\n};\n\n/**\n * @internal\n */\nexport const validatePathString = function (\n  fnName: string,\n  argumentName: string,\n  pathString: string,\n  optional: boolean\n) {\n  if (optional && pathString === undefined) {\n    return;\n  }\n\n  if (!isValidPathString(pathString)) {\n    throw new Error(\n      errorPrefixFxn(fnName, argumentName) +\n        'was an invalid path = \"' +\n        pathString +\n        '\". Paths must be non-empty strings and ' +\n        'can\\'t contain \".\", \"#\", \"$\", \"[\", or \"]\"'\n    );\n  }\n};\n\nexport const validateRootPathString = function (\n  fnName: string,\n  argumentName: string,\n  pathString: string,\n  optional: boolean\n) {\n  if (pathString) {\n    // Allow '/.info/' at the beginning.\n    pathString = pathString.replace(/^\\/*\\.info(\\/|$)/, '/');\n  }\n\n  validatePathString(fnName, argumentName, pathString, optional);\n};\n\n/**\n * @internal\n */\nexport const validateWritablePath = function (fnName: string, path: Path) {\n  if (pathGetFront(path) === '.info') {\n    throw new Error(fnName + \" failed = Can't modify data under /.info/\");\n  }\n};\n\nexport const validateUrl = function (\n  fnName: string,\n  parsedUrl: { repoInfo: RepoInfo; path: Path }\n) {\n  // TODO = Validate server better.\n  const pathString = parsedUrl.path.toString();\n  if (\n    !(typeof parsedUrl.repoInfo.host === 'string') ||\n    parsedUrl.repoInfo.host.length === 0 ||\n    (!isValidKey(parsedUrl.repoInfo.namespace) &&\n      parsedUrl.repoInfo.host.split(':')[0] !== 'localhost') ||\n    (pathString.length !== 0 && !isValidRootPathString(pathString))\n  ) {\n    throw new Error(\n      errorPrefixFxn(fnName, 'url') +\n        'must be a valid firebase URL and ' +\n        'the path can\\'t contain \".\", \"#\", \"$\", \"[\", or \"]\".'\n    );\n  }\n};\n\nexport const validateString = function (\n  fnName: string,\n  argumentName: string,\n  string: unknown,\n  optional: boolean\n) {\n  if (optional && string === undefined) {\n    return;\n  }\n  if (!(typeof string === 'string')) {\n    throw new Error(\n      errorPrefixFxn(fnName, argumentName) + 'must be a valid string.'\n    );\n  }\n};\n\nexport const validateObject = function (\n  fnName: string,\n  argumentName: string,\n  obj: unknown,\n  optional: boolean\n) {\n  if (optional && obj === undefined) {\n    return;\n  }\n  if (!(obj && typeof obj === 'object') || obj === null) {\n    throw new Error(\n      errorPrefixFxn(fnName, argumentName) + 'must be a valid object.'\n    );\n  }\n};\n\nexport const validateObjectContainsKey = function (\n  fnName: string,\n  argumentName: string,\n  obj: unknown,\n  key: string,\n  optional: boolean,\n  optType?: string\n) {\n  const objectContainsKey =\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    obj && typeof obj === 'object' && contains(obj as any, key);\n\n  if (!objectContainsKey) {\n    if (optional) {\n      return;\n    } else {\n      throw new Error(\n        errorPrefixFxn(fnName, argumentName) +\n          'must contain the key \"' +\n          key +\n          '\"'\n      );\n    }\n  }\n\n  if (optType) {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const val = safeGet(obj as any, key);\n    if (\n      (optType === 'number' && !(typeof val === 'number')) ||\n      (optType === 'string' && !(typeof val === 'string')) ||\n      (optType === 'boolean' && !(typeof val === 'boolean')) ||\n      (optType === 'function' && !(typeof val === 'function')) ||\n      (optType === 'object' && !(typeof val === 'object') && val)\n    ) {\n      if (optional) {\n        throw new Error(\n          errorPrefixFxn(fnName, argumentName) +\n            'contains invalid value for key \"' +\n            key +\n            '\" (must be of type \"' +\n            optType +\n            '\")'\n        );\n      } else {\n        throw new Error(\n          errorPrefixFxn(fnName, argumentName) +\n            'must contain the key \"' +\n            key +\n            '\" with type \"' +\n            optType +\n            '\"'\n        );\n      }\n    }\n  }\n};\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Path, pathContains, pathEquals } from '../util/Path';\nimport { exceptionGuard, log, logger } from '../util/util';\n\nimport { Event } from './Event';\n\n/**\n * The event queue serves a few purposes:\n * 1. It ensures we maintain event order in the face of event callbacks doing operations that result in more\n *    events being queued.\n * 2. raiseQueuedEvents() handles being called reentrantly nicely.  That is, if in the course of raising events,\n *    raiseQueuedEvents() is called again, the \"inner\" call will pick up raising events where the \"outer\" call\n *    left off, ensuring that the events are still raised synchronously and in order.\n * 3. You can use raiseEventsAtPath and raiseEventsForChangedPath to ensure only relevant previously-queued\n *    events are raised synchronously.\n *\n * NOTE: This can all go away if/when we move to async events.\n *\n */\nexport class EventQueue {\n  eventLists_: EventList[] = [];\n\n  /**\n   * Tracks recursion depth of raiseQueuedEvents_, for debugging purposes.\n   */\n  recursionDepth_ = 0;\n}\n\n/**\n * @param eventDataList - The new events to queue.\n */\nexport function eventQueueQueueEvents(\n  eventQueue: EventQueue,\n  eventDataList: Event[]\n) {\n  // We group events by path, storing them in a single EventList, to make it easier to skip over them quickly.\n  let currList: EventList | null = null;\n  for (let i = 0; i < eventDataList.length; i++) {\n    const data = eventDataList[i];\n    const path = data.getPath();\n    if (currList !== null && !pathEquals(path, currList.path)) {\n      eventQueue.eventLists_.push(currList);\n      currList = null;\n    }\n\n    if (currList === null) {\n      currList = { events: [], path };\n    }\n\n    currList.events.push(data);\n  }\n  if (currList) {\n    eventQueue.eventLists_.push(currList);\n  }\n}\n\n/**\n * Queues the specified events and synchronously raises all events (including previously queued ones)\n * for the specified path.\n *\n * It is assumed that the new events are all for the specified path.\n *\n * @param path - The path to raise events for.\n * @param eventDataList - The new events to raise.\n */\nexport function eventQueueRaiseEventsAtPath(\n  eventQueue: EventQueue,\n  path: Path,\n  eventDataList: Event[]\n) {\n  eventQueueQueueEvents(eventQueue, eventDataList);\n  eventQueueRaiseQueuedEventsMatchingPredicate(eventQueue, eventPath =>\n    pathEquals(eventPath, path)\n  );\n}\n\n/**\n * Queues the specified events and synchronously raises all events (including previously queued ones) for\n * locations related to the specified change path (i.e. all ancestors and descendants).\n *\n * It is assumed that the new events are all related (ancestor or descendant) to the specified path.\n *\n * @param changedPath - The path to raise events for.\n * @param eventDataList - The events to raise\n */\nexport function eventQueueRaiseEventsForChangedPath(\n  eventQueue: EventQueue,\n  changedPath: Path,\n  eventDataList: Event[]\n) {\n  eventQueueQueueEvents(eventQueue, eventDataList);\n  eventQueueRaiseQueuedEventsMatchingPredicate(\n    eventQueue,\n    eventPath =>\n      pathContains(eventPath, changedPath) ||\n      pathContains(changedPath, eventPath)\n  );\n}\n\nfunction eventQueueRaiseQueuedEventsMatchingPredicate(\n  eventQueue: EventQueue,\n  predicate: (path: Path) => boolean\n) {\n  eventQueue.recursionDepth_++;\n\n  let sentAll = true;\n  for (let i = 0; i < eventQueue.eventLists_.length; i++) {\n    const eventList = eventQueue.eventLists_[i];\n    if (eventList) {\n      const eventPath = eventList.path;\n      if (predicate(eventPath)) {\n        eventListRaise(eventQueue.eventLists_[i]);\n        eventQueue.eventLists_[i] = null;\n      } else {\n        sentAll = false;\n      }\n    }\n  }\n\n  if (sentAll) {\n    eventQueue.eventLists_ = [];\n  }\n\n  eventQueue.recursionDepth_--;\n}\n\ninterface EventList {\n  events: Event[];\n  path: Path;\n}\n\n/**\n * Iterates through the list and raises each event\n */\nfunction eventListRaise(eventList: EventList) {\n  for (let i = 0; i < eventList.events.length; i++) {\n    const eventData = eventList.events[i];\n    if (eventData !== null) {\n      eventList.events[i] = null;\n      const eventFn = eventData.getEventRunner();\n      if (logger) {\n        log('event: ' + eventData.toString());\n      }\n      exceptionGuard(eventFn);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  assert,\n  contains,\n  isEmpty,\n  map,\n  safeGet,\n  stringify\n} from '@firebase/util';\n\nimport { ValueEventRegistration } from '../api/Reference_impl';\n\nimport { AppCheckTokenProvider } from './AppCheckTokenProvider';\nimport { AuthTokenProvider } from './AuthTokenProvider';\nimport { PersistentConnection } from './PersistentConnection';\nimport { ReadonlyRestClient } from './ReadonlyRestClient';\nimport { RepoInfo } from './RepoInfo';\nimport { ServerActions } from './ServerActions';\nimport { ChildrenNode } from './snap/ChildrenNode';\nimport { Node } from './snap/Node';\nimport { nodeFromJSON } from './snap/nodeFromJSON';\nimport { SnapshotHolder } from './SnapshotHolder';\nimport {\n  newSparseSnapshotTree,\n  SparseSnapshotTree,\n  sparseSnapshotTreeForEachTree,\n  sparseSnapshotTreeForget,\n  sparseSnapshotTreeRemember\n} from './SparseSnapshotTree';\nimport { StatsCollection } from './stats/StatsCollection';\nimport { StatsListener } from './stats/StatsListener';\nimport {\n  statsManagerGetCollection,\n  statsManagerGetOrCreateReporter\n} from './stats/StatsManager';\nimport { StatsReporter, statsReporterIncludeStat } from './stats/StatsReporter';\nimport {\n  SyncTree,\n  syncTreeAckUserWrite,\n  syncTreeAddEventRegistration,\n  syncTreeApplyServerMerge,\n  syncTreeApplyServerOverwrite,\n  syncTreeApplyTaggedQueryMerge,\n  syncTreeApplyTaggedQueryOverwrite,\n  syncTreeApplyUserMerge,\n  syncTreeApplyUserOverwrite,\n  syncTreeCalcCompleteEventCache,\n  syncTreeGetServerValue,\n  syncTreeRemoveEventRegistration,\n  syncTreeTagForQuery\n} from './SyncTree';\nimport { Indexable } from './util/misc';\nimport {\n  newEmptyPath,\n  newRelativePath,\n  Path,\n  pathChild,\n  pathGetFront,\n  pathPopFront\n} from './util/Path';\nimport {\n  generateWithValues,\n  resolveDeferredValueSnapshot,\n  resolveDeferredValueTree\n} from './util/ServerValues';\nimport {\n  Tree,\n  treeForEachAncestor,\n  treeForEachChild,\n  treeForEachDescendant,\n  treeGetPath,\n  treeGetValue,\n  treeHasChildren,\n  treeSetValue,\n  treeSubTree\n} from './util/Tree';\nimport {\n  beingCrawled,\n  each,\n  exceptionGuard,\n  log,\n  LUIDGenerator,\n  warn\n} from './util/util';\nimport { isValidPriority, validateFirebaseData } from './util/validation';\nimport { Event } from './view/Event';\nimport {\n  EventQueue,\n  eventQueueQueueEvents,\n  eventQueueRaiseEventsAtPath,\n  eventQueueRaiseEventsForChangedPath\n} from './view/EventQueue';\nimport { EventRegistration, QueryContext } from './view/EventRegistration';\n\nconst INTERRUPT_REASON = 'repo_interrupt';\n\n/**\n * If a transaction does not succeed after 25 retries, we abort it. Among other\n * things this ensure that if there's ever a bug causing a mismatch between\n * client / server hashes for some data, we won't retry indefinitely.\n */\nconst MAX_TRANSACTION_RETRIES = 25;\n\nconst enum TransactionStatus {\n  // We've run the transaction and updated transactionResultData_ with the result, but it isn't currently sent to the\n  // server. A transaction will go from RUN -> SENT -> RUN if it comes back from the server as rejected due to\n  // mismatched hash.\n  RUN,\n\n  // We've run the transaction and sent it to the server and it's currently outstanding (hasn't come back as accepted\n  // or rejected yet).\n  SENT,\n\n  // Temporary state used to mark completed transactions (whether successful or aborted).  The transaction will be\n  // removed when we get a chance to prune completed ones.\n  COMPLETED,\n\n  // Used when an already-sent transaction needs to be aborted (e.g. due to a conflicting set() call that was made).\n  // If it comes back as unsuccessful, we'll abort it.\n  SENT_NEEDS_ABORT,\n\n  // Temporary state used to mark transactions that need to be aborted.\n  NEEDS_ABORT\n}\n\ninterface Transaction {\n  path: Path;\n  update: (a: unknown) => unknown;\n  onComplete: (\n    error: Error | null,\n    committed: boolean,\n    node: Node | null\n  ) => void;\n  status: TransactionStatus;\n  order: number;\n  applyLocally: boolean;\n  retryCount: number;\n  unwatcher: () => void;\n  abortReason: string | null;\n  currentWriteId: number;\n  currentInputSnapshot: Node | null;\n  currentOutputSnapshotRaw: Node | null;\n  currentOutputSnapshotResolved: Node | null;\n}\n\n/**\n * A connection to a single data repository.\n */\nexport class Repo {\n  /** Key for uniquely identifying this repo, used in RepoManager */\n  readonly key: string;\n\n  dataUpdateCount = 0;\n  infoSyncTree_: SyncTree;\n  serverSyncTree_: SyncTree;\n\n  stats_: StatsCollection;\n  statsListener_: StatsListener | null = null;\n  eventQueue_ = new EventQueue();\n  nextWriteId_ = 1;\n  server_: ServerActions;\n  statsReporter_: StatsReporter;\n  infoData_: SnapshotHolder;\n  interceptServerDataCallback_: ((a: string, b: unknown) => void) | null = null;\n\n  /** A list of data pieces and paths to be set when this client disconnects. */\n  onDisconnect_: SparseSnapshotTree = newSparseSnapshotTree();\n\n  /** Stores queues of outstanding transactions for Firebase locations. */\n  transactionQueueTree_ = new Tree<Transaction[]>();\n\n  // TODO: This should be @private but it's used by test_access.js and internal.js\n  persistentConnection_: PersistentConnection | null = null;\n\n  constructor(\n    public repoInfo_: RepoInfo,\n    public forceRestClient_: boolean,\n    public authTokenProvider_: AuthTokenProvider,\n    public appCheckProvider_: AppCheckTokenProvider\n  ) {\n    // This key is intentionally not updated if RepoInfo is later changed or replaced\n    this.key = this.repoInfo_.toURLString();\n  }\n\n  /**\n   * @returns The URL corresponding to the root of this Firebase.\n   */\n  toString(): string {\n    return (\n      (this.repoInfo_.secure ? 'https://' : 'http://') + this.repoInfo_.host\n    );\n  }\n}\n\nexport function repoStart(\n  repo: Repo,\n  appId: string,\n  authOverride?: object\n): void {\n  repo.stats_ = statsManagerGetCollection(repo.repoInfo_);\n\n  if (repo.forceRestClient_ || beingCrawled()) {\n    repo.server_ = new ReadonlyRestClient(\n      repo.repoInfo_,\n      (\n        pathString: string,\n        data: unknown,\n        isMerge: boolean,\n        tag: number | null\n      ) => {\n        repoOnDataUpdate(repo, pathString, data, isMerge, tag);\n      },\n      repo.authTokenProvider_,\n      repo.appCheckProvider_\n    );\n\n    // Minor hack: Fire onConnect immediately, since there's no actual connection.\n    setTimeout(() => repoOnConnectStatus(repo, /* connectStatus= */ true), 0);\n  } else {\n    // Validate authOverride\n    if (typeof authOverride !== 'undefined' && authOverride !== null) {\n      if (typeof authOverride !== 'object') {\n        throw new Error(\n          'Only objects are supported for option databaseAuthVariableOverride'\n        );\n      }\n      try {\n        stringify(authOverride);\n      } catch (e) {\n        throw new Error('Invalid authOverride provided: ' + e);\n      }\n    }\n\n    repo.persistentConnection_ = new PersistentConnection(\n      repo.repoInfo_,\n      appId,\n      (\n        pathString: string,\n        data: unknown,\n        isMerge: boolean,\n        tag: number | null\n      ) => {\n        repoOnDataUpdate(repo, pathString, data, isMerge, tag);\n      },\n      (connectStatus: boolean) => {\n        repoOnConnectStatus(repo, connectStatus);\n      },\n      (updates: object) => {\n        repoOnServerInfoUpdate(repo, updates);\n      },\n      repo.authTokenProvider_,\n      repo.appCheckProvider_,\n      authOverride\n    );\n\n    repo.server_ = repo.persistentConnection_;\n  }\n\n  repo.authTokenProvider_.addTokenChangeListener(token => {\n    repo.server_.refreshAuthToken(token);\n  });\n\n  repo.appCheckProvider_.addTokenChangeListener(result => {\n    repo.server_.refreshAppCheckToken(result.token);\n  });\n\n  // In the case of multiple Repos for the same repoInfo (i.e. there are multiple Firebase.Contexts being used),\n  // we only want to create one StatsReporter.  As such, we'll report stats over the first Repo created.\n  repo.statsReporter_ = statsManagerGetOrCreateReporter(\n    repo.repoInfo_,\n    () => new StatsReporter(repo.stats_, repo.server_)\n  );\n\n  // Used for .info.\n  repo.infoData_ = new SnapshotHolder();\n  repo.infoSyncTree_ = new SyncTree({\n    startListening: (query, tag, currentHashFn, onComplete) => {\n      let infoEvents: Event[] = [];\n      const node = repo.infoData_.getNode(query._path);\n      // This is possibly a hack, but we have different semantics for .info endpoints. We don't raise null events\n      // on initial data...\n      if (!node.isEmpty()) {\n        infoEvents = syncTreeApplyServerOverwrite(\n          repo.infoSyncTree_,\n          query._path,\n          node\n        );\n        setTimeout(() => {\n          onComplete('ok');\n        }, 0);\n      }\n      return infoEvents;\n    },\n    stopListening: () => {}\n  });\n  repoUpdateInfo(repo, 'connected', false);\n\n  repo.serverSyncTree_ = new SyncTree({\n    startListening: (query, tag, currentHashFn, onComplete) => {\n      repo.server_.listen(query, currentHashFn, tag, (status, data) => {\n        const events = onComplete(status, data);\n        eventQueueRaiseEventsForChangedPath(\n          repo.eventQueue_,\n          query._path,\n          events\n        );\n      });\n      // No synchronous events for network-backed sync trees\n      return [];\n    },\n    stopListening: (query, tag) => {\n      repo.server_.unlisten(query, tag);\n    }\n  });\n}\n\n/**\n * @returns The time in milliseconds, taking the server offset into account if we have one.\n */\nexport function repoServerTime(repo: Repo): number {\n  const offsetNode = repo.infoData_.getNode(new Path('.info/serverTimeOffset'));\n  const offset = (offsetNode.val() as number) || 0;\n  return new Date().getTime() + offset;\n}\n\n/**\n * Generate ServerValues using some variables from the repo object.\n */\nexport function repoGenerateServerValues(repo: Repo): Indexable {\n  return generateWithValues({\n    timestamp: repoServerTime(repo)\n  });\n}\n\n/**\n * Called by realtime when we get new messages from the server.\n */\nfunction repoOnDataUpdate(\n  repo: Repo,\n  pathString: string,\n  data: unknown,\n  isMerge: boolean,\n  tag: number | null\n): void {\n  // For testing.\n  repo.dataUpdateCount++;\n  const path = new Path(pathString);\n  data = repo.interceptServerDataCallback_\n    ? repo.interceptServerDataCallback_(pathString, data)\n    : data;\n  let events = [];\n  if (tag) {\n    if (isMerge) {\n      const taggedChildren = map(\n        data as { [k: string]: unknown },\n        (raw: unknown) => nodeFromJSON(raw)\n      );\n      events = syncTreeApplyTaggedQueryMerge(\n        repo.serverSyncTree_,\n        path,\n        taggedChildren,\n        tag\n      );\n    } else {\n      const taggedSnap = nodeFromJSON(data);\n      events = syncTreeApplyTaggedQueryOverwrite(\n        repo.serverSyncTree_,\n        path,\n        taggedSnap,\n        tag\n      );\n    }\n  } else if (isMerge) {\n    const changedChildren = map(\n      data as { [k: string]: unknown },\n      (raw: unknown) => nodeFromJSON(raw)\n    );\n    events = syncTreeApplyServerMerge(\n      repo.serverSyncTree_,\n      path,\n      changedChildren\n    );\n  } else {\n    const snap = nodeFromJSON(data);\n    events = syncTreeApplyServerOverwrite(repo.serverSyncTree_, path, snap);\n  }\n  let affectedPath = path;\n  if (events.length > 0) {\n    // Since we have a listener outstanding for each transaction, receiving any events\n    // is a proxy for some change having occurred.\n    affectedPath = repoRerunTransactions(repo, path);\n  }\n  eventQueueRaiseEventsForChangedPath(repo.eventQueue_, affectedPath, events);\n}\n\n// TODO: This should be @private but it's used by test_access.js and internal.js\nexport function repoInterceptServerData(\n  repo: Repo,\n  callback: ((a: string, b: unknown) => unknown) | null\n): void {\n  repo.interceptServerDataCallback_ = callback;\n}\n\nfunction repoOnConnectStatus(repo: Repo, connectStatus: boolean): void {\n  repoUpdateInfo(repo, 'connected', connectStatus);\n  if (connectStatus === false) {\n    repoRunOnDisconnectEvents(repo);\n  }\n}\n\nfunction repoOnServerInfoUpdate(repo: Repo, updates: object): void {\n  each(updates, (key: string, value: unknown) => {\n    repoUpdateInfo(repo, key, value);\n  });\n}\n\nfunction repoUpdateInfo(repo: Repo, pathString: string, value: unknown): void {\n  const path = new Path('/.info/' + pathString);\n  const newNode = nodeFromJSON(value);\n  repo.infoData_.updateSnapshot(path, newNode);\n  const events = syncTreeApplyServerOverwrite(\n    repo.infoSyncTree_,\n    path,\n    newNode\n  );\n  eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, events);\n}\n\nfunction repoGetNextWriteId(repo: Repo): number {\n  return repo.nextWriteId_++;\n}\n\n/**\n * The purpose of `getValue` is to return the latest known value\n * satisfying `query`.\n *\n * This method will first check for in-memory cached values\n * belonging to active listeners. If they are found, such values\n * are considered to be the most up-to-date.\n *\n * If the client is not connected, this method will wait until the\n *  repo has established a connection and then request the value for `query`.\n * If the client is not able to retrieve the query result for another reason,\n * it reports an error.\n *\n * @param query - The query to surface a value for.\n */\nexport function repoGetValue(\n  repo: Repo,\n  query: QueryContext,\n  eventRegistration: ValueEventRegistration\n): Promise<Node> {\n  // Only active queries are cached. There is no persisted cache.\n  const cached = syncTreeGetServerValue(repo.serverSyncTree_, query);\n  if (cached != null) {\n    return Promise.resolve(cached);\n  }\n  return repo.server_.get(query).then(\n    payload => {\n      const node = nodeFromJSON(payload).withIndex(\n        query._queryParams.getIndex()\n      );\n      /**\n       * Below we simulate the actions of an `onlyOnce` `onValue()` event where:\n       * Add an event registration,\n       * Update data at the path,\n       * Raise any events,\n       * Cleanup the SyncTree\n       */\n      syncTreeAddEventRegistration(\n        repo.serverSyncTree_,\n        query,\n        eventRegistration,\n        true\n      );\n      let events: Event[];\n      if (query._queryParams.loadsAllData()) {\n        events = syncTreeApplyServerOverwrite(\n          repo.serverSyncTree_,\n          query._path,\n          node\n        );\n      } else {\n        const tag = syncTreeTagForQuery(repo.serverSyncTree_, query);\n        events = syncTreeApplyTaggedQueryOverwrite(\n          repo.serverSyncTree_,\n          query._path,\n          node,\n          tag\n        );\n      }\n      /*\n       * We need to raise events in the scenario where `get()` is called at a parent path, and\n       * while the `get()` is pending, `onValue` is called at a child location. While get() is waiting\n       * for the data, `onValue` will register a new event. Then, get() will come back, and update the syncTree\n       * and its corresponding serverCache, including the child location where `onValue` is called. Then,\n       * `onValue` will receive the event from the server, but look at the syncTree and see that the data received\n       * from the server is already at the SyncPoint, and so the `onValue` callback will never get fired.\n       * Calling `eventQueueRaiseEventsForChangedPath()` is the correct way to propagate the events and\n       * ensure the corresponding child events will get fired.\n       */\n      eventQueueRaiseEventsForChangedPath(\n        repo.eventQueue_,\n        query._path,\n        events\n      );\n      syncTreeRemoveEventRegistration(\n        repo.serverSyncTree_,\n        query,\n        eventRegistration,\n        null,\n        true\n      );\n      return node;\n    },\n    err => {\n      repoLog(repo, 'get for query ' + stringify(query) + ' failed: ' + err);\n      return Promise.reject(new Error(err as string));\n    }\n  );\n}\n\nexport function repoSetWithPriority(\n  repo: Repo,\n  path: Path,\n  newVal: unknown,\n  newPriority: number | string | null,\n  onComplete: ((status: Error | null, errorReason?: string) => void) | null\n): void {\n  repoLog(repo, 'set', {\n    path: path.toString(),\n    value: newVal,\n    priority: newPriority\n  });\n\n  // TODO: Optimize this behavior to either (a) store flag to skip resolving where possible and / or\n  // (b) store unresolved paths on JSON parse\n  const serverValues = repoGenerateServerValues(repo);\n  const newNodeUnresolved = nodeFromJSON(newVal, newPriority);\n  const existing = syncTreeCalcCompleteEventCache(repo.serverSyncTree_, path);\n  const newNode = resolveDeferredValueSnapshot(\n    newNodeUnresolved,\n    existing,\n    serverValues\n  );\n\n  const writeId = repoGetNextWriteId(repo);\n  const events = syncTreeApplyUserOverwrite(\n    repo.serverSyncTree_,\n    path,\n    newNode,\n    writeId,\n    true\n  );\n  eventQueueQueueEvents(repo.eventQueue_, events);\n  repo.server_.put(\n    path.toString(),\n    newNodeUnresolved.val(/*export=*/ true),\n    (status, errorReason) => {\n      const success = status === 'ok';\n      if (!success) {\n        warn('set at ' + path + ' failed: ' + status);\n      }\n\n      const clearEvents = syncTreeAckUserWrite(\n        repo.serverSyncTree_,\n        writeId,\n        !success\n      );\n      eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, clearEvents);\n      repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n    }\n  );\n  const affectedPath = repoAbortTransactions(repo, path);\n  repoRerunTransactions(repo, affectedPath);\n  // We queued the events above, so just flush the queue here\n  eventQueueRaiseEventsForChangedPath(repo.eventQueue_, affectedPath, []);\n}\n\nexport function repoUpdate(\n  repo: Repo,\n  path: Path,\n  childrenToMerge: { [k: string]: unknown },\n  onComplete: ((status: Error | null, errorReason?: string) => void) | null\n): void {\n  repoLog(repo, 'update', { path: path.toString(), value: childrenToMerge });\n\n  // Start with our existing data and merge each child into it.\n  let empty = true;\n  const serverValues = repoGenerateServerValues(repo);\n  const changedChildren: { [k: string]: Node } = {};\n  each(childrenToMerge, (changedKey: string, changedValue: unknown) => {\n    empty = false;\n    changedChildren[changedKey] = resolveDeferredValueTree(\n      pathChild(path, changedKey),\n      nodeFromJSON(changedValue),\n      repo.serverSyncTree_,\n      serverValues\n    );\n  });\n\n  if (!empty) {\n    const writeId = repoGetNextWriteId(repo);\n    const events = syncTreeApplyUserMerge(\n      repo.serverSyncTree_,\n      path,\n      changedChildren,\n      writeId\n    );\n    eventQueueQueueEvents(repo.eventQueue_, events);\n    repo.server_.merge(\n      path.toString(),\n      childrenToMerge,\n      (status, errorReason) => {\n        const success = status === 'ok';\n        if (!success) {\n          warn('update at ' + path + ' failed: ' + status);\n        }\n\n        const clearEvents = syncTreeAckUserWrite(\n          repo.serverSyncTree_,\n          writeId,\n          !success\n        );\n        const affectedPath =\n          clearEvents.length > 0 ? repoRerunTransactions(repo, path) : path;\n        eventQueueRaiseEventsForChangedPath(\n          repo.eventQueue_,\n          affectedPath,\n          clearEvents\n        );\n        repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n      }\n    );\n\n    each(childrenToMerge, (changedPath: string) => {\n      const affectedPath = repoAbortTransactions(\n        repo,\n        pathChild(path, changedPath)\n      );\n      repoRerunTransactions(repo, affectedPath);\n    });\n\n    // We queued the events above, so just flush the queue here\n    eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, []);\n  } else {\n    log(\"update() called with empty data.  Don't do anything.\");\n    repoCallOnCompleteCallback(repo, onComplete, 'ok', undefined);\n  }\n}\n\n/**\n * Applies all of the changes stored up in the onDisconnect_ tree.\n */\nfunction repoRunOnDisconnectEvents(repo: Repo): void {\n  repoLog(repo, 'onDisconnectEvents');\n\n  const serverValues = repoGenerateServerValues(repo);\n  const resolvedOnDisconnectTree = newSparseSnapshotTree();\n  sparseSnapshotTreeForEachTree(\n    repo.onDisconnect_,\n    newEmptyPath(),\n    (path, node) => {\n      const resolved = resolveDeferredValueTree(\n        path,\n        node,\n        repo.serverSyncTree_,\n        serverValues\n      );\n      sparseSnapshotTreeRemember(resolvedOnDisconnectTree, path, resolved);\n    }\n  );\n  let events: Event[] = [];\n\n  sparseSnapshotTreeForEachTree(\n    resolvedOnDisconnectTree,\n    newEmptyPath(),\n    (path, snap) => {\n      events = events.concat(\n        syncTreeApplyServerOverwrite(repo.serverSyncTree_, path, snap)\n      );\n      const affectedPath = repoAbortTransactions(repo, path);\n      repoRerunTransactions(repo, affectedPath);\n    }\n  );\n\n  repo.onDisconnect_ = newSparseSnapshotTree();\n  eventQueueRaiseEventsForChangedPath(repo.eventQueue_, newEmptyPath(), events);\n}\n\nexport function repoOnDisconnectCancel(\n  repo: Repo,\n  path: Path,\n  onComplete: ((status: Error | null, errorReason?: string) => void) | null\n): void {\n  repo.server_.onDisconnectCancel(path.toString(), (status, errorReason) => {\n    if (status === 'ok') {\n      sparseSnapshotTreeForget(repo.onDisconnect_, path);\n    }\n    repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n  });\n}\n\nexport function repoOnDisconnectSet(\n  repo: Repo,\n  path: Path,\n  value: unknown,\n  onComplete: ((status: Error | null, errorReason?: string) => void) | null\n): void {\n  const newNode = nodeFromJSON(value);\n  repo.server_.onDisconnectPut(\n    path.toString(),\n    newNode.val(/*export=*/ true),\n    (status, errorReason) => {\n      if (status === 'ok') {\n        sparseSnapshotTreeRemember(repo.onDisconnect_, path, newNode);\n      }\n      repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n    }\n  );\n}\n\nexport function repoOnDisconnectSetWithPriority(\n  repo: Repo,\n  path: Path,\n  value: unknown,\n  priority: unknown,\n  onComplete: ((status: Error | null, errorReason?: string) => void) | null\n): void {\n  const newNode = nodeFromJSON(value, priority);\n  repo.server_.onDisconnectPut(\n    path.toString(),\n    newNode.val(/*export=*/ true),\n    (status, errorReason) => {\n      if (status === 'ok') {\n        sparseSnapshotTreeRemember(repo.onDisconnect_, path, newNode);\n      }\n      repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n    }\n  );\n}\n\nexport function repoOnDisconnectUpdate(\n  repo: Repo,\n  path: Path,\n  childrenToMerge: { [k: string]: unknown },\n  onComplete: ((status: Error | null, errorReason?: string) => void) | null\n): void {\n  if (isEmpty(childrenToMerge)) {\n    log(\"onDisconnect().update() called with empty data.  Don't do anything.\");\n    repoCallOnCompleteCallback(repo, onComplete, 'ok', undefined);\n    return;\n  }\n\n  repo.server_.onDisconnectMerge(\n    path.toString(),\n    childrenToMerge,\n    (status, errorReason) => {\n      if (status === 'ok') {\n        each(childrenToMerge, (childName: string, childNode: unknown) => {\n          const newChildNode = nodeFromJSON(childNode);\n          sparseSnapshotTreeRemember(\n            repo.onDisconnect_,\n            pathChild(path, childName),\n            newChildNode\n          );\n        });\n      }\n      repoCallOnCompleteCallback(repo, onComplete, status, errorReason);\n    }\n  );\n}\n\nexport function repoAddEventCallbackForQuery(\n  repo: Repo,\n  query: QueryContext,\n  eventRegistration: EventRegistration\n): void {\n  let events;\n  if (pathGetFront(query._path) === '.info') {\n    events = syncTreeAddEventRegistration(\n      repo.infoSyncTree_,\n      query,\n      eventRegistration\n    );\n  } else {\n    events = syncTreeAddEventRegistration(\n      repo.serverSyncTree_,\n      query,\n      eventRegistration\n    );\n  }\n  eventQueueRaiseEventsAtPath(repo.eventQueue_, query._path, events);\n}\n\nexport function repoRemoveEventCallbackForQuery(\n  repo: Repo,\n  query: QueryContext,\n  eventRegistration: EventRegistration\n): void {\n  // These are guaranteed not to raise events, since we're not passing in a cancelError. However, we can future-proof\n  // a little bit by handling the return values anyways.\n  let events;\n  if (pathGetFront(query._path) === '.info') {\n    events = syncTreeRemoveEventRegistration(\n      repo.infoSyncTree_,\n      query,\n      eventRegistration\n    );\n  } else {\n    events = syncTreeRemoveEventRegistration(\n      repo.serverSyncTree_,\n      query,\n      eventRegistration\n    );\n  }\n  eventQueueRaiseEventsAtPath(repo.eventQueue_, query._path, events);\n}\n\nexport function repoInterrupt(repo: Repo): void {\n  if (repo.persistentConnection_) {\n    repo.persistentConnection_.interrupt(INTERRUPT_REASON);\n  }\n}\n\nexport function repoResume(repo: Repo): void {\n  if (repo.persistentConnection_) {\n    repo.persistentConnection_.resume(INTERRUPT_REASON);\n  }\n}\n\nexport function repoStats(repo: Repo, showDelta: boolean = false): void {\n  if (typeof console === 'undefined') {\n    return;\n  }\n\n  let stats: { [k: string]: unknown };\n  if (showDelta) {\n    if (!repo.statsListener_) {\n      repo.statsListener_ = new StatsListener(repo.stats_);\n    }\n    stats = repo.statsListener_.get();\n  } else {\n    stats = repo.stats_.get();\n  }\n\n  const longestName = Object.keys(stats).reduce(\n    (previousValue, currentValue) =>\n      Math.max(currentValue.length, previousValue),\n    0\n  );\n\n  each(stats, (stat: string, value: unknown) => {\n    let paddedStat = stat;\n    // pad stat names to be the same length (plus 2 extra spaces).\n    for (let i = stat.length; i < longestName + 2; i++) {\n      paddedStat += ' ';\n    }\n    console.log(paddedStat + value);\n  });\n}\n\nexport function repoStatsIncrementCounter(repo: Repo, metric: string): void {\n  repo.stats_.incrementCounter(metric);\n  statsReporterIncludeStat(repo.statsReporter_, metric);\n}\n\nfunction repoLog(repo: Repo, ...varArgs: unknown[]): void {\n  let prefix = '';\n  if (repo.persistentConnection_) {\n    prefix = repo.persistentConnection_.id + ':';\n  }\n  log(prefix, ...varArgs);\n}\n\nexport function repoCallOnCompleteCallback(\n  repo: Repo,\n  callback: ((status: Error | null, errorReason?: string) => void) | null,\n  status: string,\n  errorReason?: string | null\n): void {\n  if (callback) {\n    exceptionGuard(() => {\n      if (status === 'ok') {\n        callback(null);\n      } else {\n        const code = (status || 'error').toUpperCase();\n        let message = code;\n        if (errorReason) {\n          message += ': ' + errorReason;\n        }\n\n        const error = new Error(message);\n\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        (error as any).code = code;\n        callback(error);\n      }\n    });\n  }\n}\n\n/**\n * Creates a new transaction, adds it to the transactions we're tracking, and\n * sends it to the server if possible.\n *\n * @param path - Path at which to do transaction.\n * @param transactionUpdate - Update callback.\n * @param onComplete - Completion callback.\n * @param unwatcher - Function that will be called when the transaction no longer\n * need data updates for `path`.\n * @param applyLocally - Whether or not to make intermediate results visible\n */\nexport function repoStartTransaction(\n  repo: Repo,\n  path: Path,\n  transactionUpdate: (a: unknown) => unknown,\n  onComplete: ((error: Error, committed: boolean, node: Node) => void) | null,\n  unwatcher: () => void,\n  applyLocally: boolean\n): void {\n  repoLog(repo, 'transaction on ' + path);\n\n  // Initialize transaction.\n  const transaction: Transaction = {\n    path,\n    update: transactionUpdate,\n    onComplete,\n    // One of TransactionStatus enums.\n    status: null,\n    // Used when combining transactions at different locations to figure out\n    // which one goes first.\n    order: LUIDGenerator(),\n    // Whether to raise local events for this transaction.\n    applyLocally,\n    // Count of how many times we've retried the transaction.\n    retryCount: 0,\n    // Function to call to clean up our .on() listener.\n    unwatcher,\n    // Stores why a transaction was aborted.\n    abortReason: null,\n    currentWriteId: null,\n    currentInputSnapshot: null,\n    currentOutputSnapshotRaw: null,\n    currentOutputSnapshotResolved: null\n  };\n\n  // Run transaction initially.\n  const currentState = repoGetLatestState(repo, path, undefined);\n  transaction.currentInputSnapshot = currentState;\n  const newVal = transaction.update(currentState.val());\n  if (newVal === undefined) {\n    // Abort transaction.\n    transaction.unwatcher();\n    transaction.currentOutputSnapshotRaw = null;\n    transaction.currentOutputSnapshotResolved = null;\n    if (transaction.onComplete) {\n      transaction.onComplete(null, false, transaction.currentInputSnapshot);\n    }\n  } else {\n    validateFirebaseData(\n      'transaction failed: Data returned ',\n      newVal,\n      transaction.path\n    );\n\n    // Mark as run and add to our queue.\n    transaction.status = TransactionStatus.RUN;\n    const queueNode = treeSubTree(repo.transactionQueueTree_, path);\n    const nodeQueue = treeGetValue(queueNode) || [];\n    nodeQueue.push(transaction);\n\n    treeSetValue(queueNode, nodeQueue);\n\n    // Update visibleData and raise events\n    // Note: We intentionally raise events after updating all of our\n    // transaction state, since the user could start new transactions from the\n    // event callbacks.\n    let priorityForNode;\n    if (\n      typeof newVal === 'object' &&\n      newVal !== null &&\n      contains(newVal, '.priority')\n    ) {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      priorityForNode = safeGet(newVal as any, '.priority');\n      assert(\n        isValidPriority(priorityForNode),\n        'Invalid priority returned by transaction. ' +\n          'Priority must be a valid string, finite number, server value, or null.'\n      );\n    } else {\n      const currentNode =\n        syncTreeCalcCompleteEventCache(repo.serverSyncTree_, path) ||\n        ChildrenNode.EMPTY_NODE;\n      priorityForNode = currentNode.getPriority().val();\n    }\n\n    const serverValues = repoGenerateServerValues(repo);\n    const newNodeUnresolved = nodeFromJSON(newVal, priorityForNode);\n    const newNode = resolveDeferredValueSnapshot(\n      newNodeUnresolved,\n      currentState,\n      serverValues\n    );\n    transaction.currentOutputSnapshotRaw = newNodeUnresolved;\n    transaction.currentOutputSnapshotResolved = newNode;\n    transaction.currentWriteId = repoGetNextWriteId(repo);\n\n    const events = syncTreeApplyUserOverwrite(\n      repo.serverSyncTree_,\n      path,\n      newNode,\n      transaction.currentWriteId,\n      transaction.applyLocally\n    );\n    eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, events);\n\n    repoSendReadyTransactions(repo, repo.transactionQueueTree_);\n  }\n}\n\n/**\n * @param excludeSets - A specific set to exclude\n */\nfunction repoGetLatestState(\n  repo: Repo,\n  path: Path,\n  excludeSets?: number[]\n): Node {\n  return (\n    syncTreeCalcCompleteEventCache(repo.serverSyncTree_, path, excludeSets) ||\n    ChildrenNode.EMPTY_NODE\n  );\n}\n\n/**\n * Sends any already-run transactions that aren't waiting for outstanding\n * transactions to complete.\n *\n * Externally it's called with no arguments, but it calls itself recursively\n * with a particular transactionQueueTree node to recurse through the tree.\n *\n * @param node - transactionQueueTree node to start at.\n */\nfunction repoSendReadyTransactions(\n  repo: Repo,\n  node: Tree<Transaction[]> = repo.transactionQueueTree_\n): void {\n  // Before recursing, make sure any completed transactions are removed.\n  if (!node) {\n    repoPruneCompletedTransactionsBelowNode(repo, node);\n  }\n\n  if (treeGetValue(node)) {\n    const queue = repoBuildTransactionQueue(repo, node);\n    assert(queue.length > 0, 'Sending zero length transaction queue');\n\n    const allRun = queue.every(\n      (transaction: Transaction) => transaction.status === TransactionStatus.RUN\n    );\n\n    // If they're all run (and not sent), we can send them.  Else, we must wait.\n    if (allRun) {\n      repoSendTransactionQueue(repo, treeGetPath(node), queue);\n    }\n  } else if (treeHasChildren(node)) {\n    treeForEachChild(node, childNode => {\n      repoSendReadyTransactions(repo, childNode);\n    });\n  }\n}\n\n/**\n * Given a list of run transactions, send them to the server and then handle\n * the result (success or failure).\n *\n * @param path - The location of the queue.\n * @param queue - Queue of transactions under the specified location.\n */\nfunction repoSendTransactionQueue(\n  repo: Repo,\n  path: Path,\n  queue: Transaction[]\n): void {\n  // Mark transactions as sent and increment retry count!\n  const setsToIgnore = queue.map(txn => {\n    return txn.currentWriteId;\n  });\n  const latestState = repoGetLatestState(repo, path, setsToIgnore);\n  let snapToSend = latestState;\n  const latestHash = latestState.hash();\n  for (let i = 0; i < queue.length; i++) {\n    const txn = queue[i];\n    assert(\n      txn.status === TransactionStatus.RUN,\n      'tryToSendTransactionQueue_: items in queue should all be run.'\n    );\n    txn.status = TransactionStatus.SENT;\n    txn.retryCount++;\n    const relativePath = newRelativePath(path, txn.path);\n    // If we've gotten to this point, the output snapshot must be defined.\n    snapToSend = snapToSend.updateChild(\n      relativePath /** @type {!Node} */,\n      txn.currentOutputSnapshotRaw\n    );\n  }\n\n  const dataToSend = snapToSend.val(true);\n  const pathToSend = path;\n\n  // Send the put.\n  repo.server_.put(\n    pathToSend.toString(),\n    dataToSend,\n    (status: string) => {\n      repoLog(repo, 'transaction put response', {\n        path: pathToSend.toString(),\n        status\n      });\n\n      let events: Event[] = [];\n      if (status === 'ok') {\n        // Queue up the callbacks and fire them after cleaning up all of our\n        // transaction state, since the callback could trigger more\n        // transactions or sets.\n        const callbacks = [];\n        for (let i = 0; i < queue.length; i++) {\n          queue[i].status = TransactionStatus.COMPLETED;\n          events = events.concat(\n            syncTreeAckUserWrite(repo.serverSyncTree_, queue[i].currentWriteId)\n          );\n          if (queue[i].onComplete) {\n            // We never unset the output snapshot, and given that this\n            // transaction is complete, it should be set\n            callbacks.push(() =>\n              queue[i].onComplete(\n                null,\n                true,\n                queue[i].currentOutputSnapshotResolved\n              )\n            );\n          }\n          queue[i].unwatcher();\n        }\n\n        // Now remove the completed transactions.\n        repoPruneCompletedTransactionsBelowNode(\n          repo,\n          treeSubTree(repo.transactionQueueTree_, path)\n        );\n        // There may be pending transactions that we can now send.\n        repoSendReadyTransactions(repo, repo.transactionQueueTree_);\n\n        eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, events);\n\n        // Finally, trigger onComplete callbacks.\n        for (let i = 0; i < callbacks.length; i++) {\n          exceptionGuard(callbacks[i]);\n        }\n      } else {\n        // transactions are no longer sent.  Update their status appropriately.\n        if (status === 'datastale') {\n          for (let i = 0; i < queue.length; i++) {\n            if (queue[i].status === TransactionStatus.SENT_NEEDS_ABORT) {\n              queue[i].status = TransactionStatus.NEEDS_ABORT;\n            } else {\n              queue[i].status = TransactionStatus.RUN;\n            }\n          }\n        } else {\n          warn(\n            'transaction at ' + pathToSend.toString() + ' failed: ' + status\n          );\n          for (let i = 0; i < queue.length; i++) {\n            queue[i].status = TransactionStatus.NEEDS_ABORT;\n            queue[i].abortReason = status;\n          }\n        }\n\n        repoRerunTransactions(repo, path);\n      }\n    },\n    latestHash\n  );\n}\n\n/**\n * Finds all transactions dependent on the data at changedPath and reruns them.\n *\n * Should be called any time cached data changes.\n *\n * Return the highest path that was affected by rerunning transactions. This\n * is the path at which events need to be raised for.\n *\n * @param changedPath - The path in mergedData that changed.\n * @returns The rootmost path that was affected by rerunning transactions.\n */\nfunction repoRerunTransactions(repo: Repo, changedPath: Path): Path {\n  const rootMostTransactionNode = repoGetAncestorTransactionNode(\n    repo,\n    changedPath\n  );\n  const path = treeGetPath(rootMostTransactionNode);\n\n  const queue = repoBuildTransactionQueue(repo, rootMostTransactionNode);\n  repoRerunTransactionQueue(repo, queue, path);\n\n  return path;\n}\n\n/**\n * Does all the work of rerunning transactions (as well as cleans up aborted\n * transactions and whatnot).\n *\n * @param queue - The queue of transactions to run.\n * @param path - The path the queue is for.\n */\nfunction repoRerunTransactionQueue(\n  repo: Repo,\n  queue: Transaction[],\n  path: Path\n): void {\n  if (queue.length === 0) {\n    return; // Nothing to do!\n  }\n\n  // Queue up the callbacks and fire them after cleaning up all of our\n  // transaction state, since the callback could trigger more transactions or\n  // sets.\n  const callbacks = [];\n  let events: Event[] = [];\n  // Ignore all of the sets we're going to re-run.\n  const txnsToRerun = queue.filter(q => {\n    return q.status === TransactionStatus.RUN;\n  });\n  const setsToIgnore = txnsToRerun.map(q => {\n    return q.currentWriteId;\n  });\n  for (let i = 0; i < queue.length; i++) {\n    const transaction = queue[i];\n    const relativePath = newRelativePath(path, transaction.path);\n    let abortTransaction = false,\n      abortReason;\n    assert(\n      relativePath !== null,\n      'rerunTransactionsUnderNode_: relativePath should not be null.'\n    );\n\n    if (transaction.status === TransactionStatus.NEEDS_ABORT) {\n      abortTransaction = true;\n      abortReason = transaction.abortReason;\n      events = events.concat(\n        syncTreeAckUserWrite(\n          repo.serverSyncTree_,\n          transaction.currentWriteId,\n          true\n        )\n      );\n    } else if (transaction.status === TransactionStatus.RUN) {\n      if (transaction.retryCount >= MAX_TRANSACTION_RETRIES) {\n        abortTransaction = true;\n        abortReason = 'maxretry';\n        events = events.concat(\n          syncTreeAckUserWrite(\n            repo.serverSyncTree_,\n            transaction.currentWriteId,\n            true\n          )\n        );\n      } else {\n        // This code reruns a transaction\n        const currentNode = repoGetLatestState(\n          repo,\n          transaction.path,\n          setsToIgnore\n        );\n        transaction.currentInputSnapshot = currentNode;\n        const newData = queue[i].update(currentNode.val());\n        if (newData !== undefined) {\n          validateFirebaseData(\n            'transaction failed: Data returned ',\n            newData,\n            transaction.path\n          );\n          let newDataNode = nodeFromJSON(newData);\n          const hasExplicitPriority =\n            typeof newData === 'object' &&\n            newData != null &&\n            contains(newData, '.priority');\n          if (!hasExplicitPriority) {\n            // Keep the old priority if there wasn't a priority explicitly specified.\n            newDataNode = newDataNode.updatePriority(currentNode.getPriority());\n          }\n\n          const oldWriteId = transaction.currentWriteId;\n          const serverValues = repoGenerateServerValues(repo);\n          const newNodeResolved = resolveDeferredValueSnapshot(\n            newDataNode,\n            currentNode,\n            serverValues\n          );\n\n          transaction.currentOutputSnapshotRaw = newDataNode;\n          transaction.currentOutputSnapshotResolved = newNodeResolved;\n          transaction.currentWriteId = repoGetNextWriteId(repo);\n          // Mutates setsToIgnore in place\n          setsToIgnore.splice(setsToIgnore.indexOf(oldWriteId), 1);\n          events = events.concat(\n            syncTreeApplyUserOverwrite(\n              repo.serverSyncTree_,\n              transaction.path,\n              newNodeResolved,\n              transaction.currentWriteId,\n              transaction.applyLocally\n            )\n          );\n          events = events.concat(\n            syncTreeAckUserWrite(repo.serverSyncTree_, oldWriteId, true)\n          );\n        } else {\n          abortTransaction = true;\n          abortReason = 'nodata';\n          events = events.concat(\n            syncTreeAckUserWrite(\n              repo.serverSyncTree_,\n              transaction.currentWriteId,\n              true\n            )\n          );\n        }\n      }\n    }\n    eventQueueRaiseEventsForChangedPath(repo.eventQueue_, path, events);\n    events = [];\n    if (abortTransaction) {\n      // Abort.\n      queue[i].status = TransactionStatus.COMPLETED;\n\n      // Removing a listener can trigger pruning which can muck with\n      // mergedData/visibleData (as it prunes data). So defer the unwatcher\n      // until we're done.\n      (function (unwatcher) {\n        setTimeout(unwatcher, Math.floor(0));\n      })(queue[i].unwatcher);\n\n      if (queue[i].onComplete) {\n        if (abortReason === 'nodata') {\n          callbacks.push(() =>\n            queue[i].onComplete(null, false, queue[i].currentInputSnapshot)\n          );\n        } else {\n          callbacks.push(() =>\n            queue[i].onComplete(new Error(abortReason), false, null)\n          );\n        }\n      }\n    }\n  }\n\n  // Clean up completed transactions.\n  repoPruneCompletedTransactionsBelowNode(repo, repo.transactionQueueTree_);\n\n  // Now fire callbacks, now that we're in a good, known state.\n  for (let i = 0; i < callbacks.length; i++) {\n    exceptionGuard(callbacks[i]);\n  }\n\n  // Try to send the transaction result to the server.\n  repoSendReadyTransactions(repo, repo.transactionQueueTree_);\n}\n\n/**\n * Returns the rootmost ancestor node of the specified path that has a pending\n * transaction on it, or just returns the node for the given path if there are\n * no pending transactions on any ancestor.\n *\n * @param path - The location to start at.\n * @returns The rootmost node with a transaction.\n */\nfunction repoGetAncestorTransactionNode(\n  repo: Repo,\n  path: Path\n): Tree<Transaction[]> {\n  let front;\n\n  // Start at the root and walk deeper into the tree towards path until we\n  // find a node with pending transactions.\n  let transactionNode = repo.transactionQueueTree_;\n  front = pathGetFront(path);\n  while (front !== null && treeGetValue(transactionNode) === undefined) {\n    transactionNode = treeSubTree(transactionNode, front);\n    path = pathPopFront(path);\n    front = pathGetFront(path);\n  }\n\n  return transactionNode;\n}\n\n/**\n * Builds the queue of all transactions at or below the specified\n * transactionNode.\n *\n * @param transactionNode\n * @returns The generated queue.\n */\nfunction repoBuildTransactionQueue(\n  repo: Repo,\n  transactionNode: Tree<Transaction[]>\n): Transaction[] {\n  // Walk any child transaction queues and aggregate them into a single queue.\n  const transactionQueue: Transaction[] = [];\n  repoAggregateTransactionQueuesForNode(\n    repo,\n    transactionNode,\n    transactionQueue\n  );\n\n  // Sort them by the order the transactions were created.\n  transactionQueue.sort((a, b) => a.order - b.order);\n\n  return transactionQueue;\n}\n\nfunction repoAggregateTransactionQueuesForNode(\n  repo: Repo,\n  node: Tree<Transaction[]>,\n  queue: Transaction[]\n): void {\n  const nodeQueue = treeGetValue(node);\n  if (nodeQueue) {\n    for (let i = 0; i < nodeQueue.length; i++) {\n      queue.push(nodeQueue[i]);\n    }\n  }\n\n  treeForEachChild(node, child => {\n    repoAggregateTransactionQueuesForNode(repo, child, queue);\n  });\n}\n\n/**\n * Remove COMPLETED transactions at or below this node in the transactionQueueTree_.\n */\nfunction repoPruneCompletedTransactionsBelowNode(\n  repo: Repo,\n  node: Tree<Transaction[]>\n): void {\n  const queue = treeGetValue(node);\n  if (queue) {\n    let to = 0;\n    for (let from = 0; from < queue.length; from++) {\n      if (queue[from].status !== TransactionStatus.COMPLETED) {\n        queue[to] = queue[from];\n        to++;\n      }\n    }\n    queue.length = to;\n    treeSetValue(node, queue.length > 0 ? queue : undefined);\n  }\n\n  treeForEachChild(node, childNode => {\n    repoPruneCompletedTransactionsBelowNode(repo, childNode);\n  });\n}\n\n/**\n * Aborts all transactions on ancestors or descendants of the specified path.\n * Called when doing a set() or update() since we consider them incompatible\n * with transactions.\n *\n * @param path - Path for which we want to abort related transactions.\n */\nfunction repoAbortTransactions(repo: Repo, path: Path): Path {\n  const affectedPath = treeGetPath(repoGetAncestorTransactionNode(repo, path));\n\n  const transactionNode = treeSubTree(repo.transactionQueueTree_, path);\n\n  treeForEachAncestor(transactionNode, (node: Tree<Transaction[]>) => {\n    repoAbortTransactionsOnNode(repo, node);\n  });\n\n  repoAbortTransactionsOnNode(repo, transactionNode);\n\n  treeForEachDescendant(transactionNode, (node: Tree<Transaction[]>) => {\n    repoAbortTransactionsOnNode(repo, node);\n  });\n\n  return affectedPath;\n}\n\n/**\n * Abort transactions stored in this transaction queue node.\n *\n * @param node - Node to abort transactions for.\n */\nfunction repoAbortTransactionsOnNode(\n  repo: Repo,\n  node: Tree<Transaction[]>\n): void {\n  const queue = treeGetValue(node);\n  if (queue) {\n    // Queue up the callbacks and fire them after cleaning up all of our\n    // transaction state, since the callback could trigger more transactions\n    // or sets.\n    const callbacks = [];\n\n    // Go through queue.  Any already-sent transactions must be marked for\n    // abort, while the unsent ones can be immediately aborted and removed.\n    let events: Event[] = [];\n    let lastSent = -1;\n    for (let i = 0; i < queue.length; i++) {\n      if (queue[i].status === TransactionStatus.SENT_NEEDS_ABORT) {\n        // Already marked.  No action needed.\n      } else if (queue[i].status === TransactionStatus.SENT) {\n        assert(\n          lastSent === i - 1,\n          'All SENT items should be at beginning of queue.'\n        );\n        lastSent = i;\n        // Mark transaction for abort when it comes back.\n        queue[i].status = TransactionStatus.SENT_NEEDS_ABORT;\n        queue[i].abortReason = 'set';\n      } else {\n        assert(\n          queue[i].status === TransactionStatus.RUN,\n          'Unexpected transaction status in abort'\n        );\n        // We can abort it immediately.\n        queue[i].unwatcher();\n        events = events.concat(\n          syncTreeAckUserWrite(\n            repo.serverSyncTree_,\n            queue[i].currentWriteId,\n            true\n          )\n        );\n        if (queue[i].onComplete) {\n          callbacks.push(\n            queue[i].onComplete.bind(null, new Error('set'), false, null)\n          );\n        }\n      }\n    }\n    if (lastSent === -1) {\n      // We're not waiting for any sent transactions.  We can clear the queue.\n      treeSetValue(node, undefined);\n    } else {\n      // Remove the transactions we aborted.\n      queue.length = lastSent + 1;\n    }\n\n    // Now fire the callbacks.\n    eventQueueRaiseEventsForChangedPath(\n      repo.eventQueue_,\n      treeGetPath(node),\n      events\n    );\n    for (let i = 0; i < callbacks.length; i++) {\n      exceptionGuard(callbacks[i]);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { RepoInfo } from '../../RepoInfo';\nimport { Path } from '../Path';\nimport { warnIfPageIsSecure, warn, fatal } from '../util';\n\nfunction decodePath(pathString: string): string {\n  let pathStringDecoded = '';\n  const pieces = pathString.split('/');\n  for (let i = 0; i < pieces.length; i++) {\n    if (pieces[i].length > 0) {\n      let piece = pieces[i];\n      try {\n        piece = decodeURIComponent(piece.replace(/\\+/g, ' '));\n      } catch (e) {}\n      pathStringDecoded += '/' + piece;\n    }\n  }\n  return pathStringDecoded;\n}\n\n/**\n * @returns key value hash\n */\nfunction decodeQuery(queryString: string): { [key: string]: string } {\n  const results = {};\n  if (queryString.charAt(0) === '?') {\n    queryString = queryString.substring(1);\n  }\n  for (const segment of queryString.split('&')) {\n    if (segment.length === 0) {\n      continue;\n    }\n    const kv = segment.split('=');\n    if (kv.length === 2) {\n      results[decodeURIComponent(kv[0])] = decodeURIComponent(kv[1]);\n    } else {\n      warn(`Invalid query segment '${segment}' in query '${queryString}'`);\n    }\n  }\n  return results;\n}\n\nexport const parseRepoInfo = function (\n  dataURL: string,\n  nodeAdmin: boolean\n): { repoInfo: RepoInfo; path: Path } {\n  const parsedUrl = parseDatabaseURL(dataURL),\n    namespace = parsedUrl.namespace;\n\n  if (parsedUrl.domain === 'firebase.com') {\n    fatal(\n      parsedUrl.host +\n        ' is no longer supported. ' +\n        'Please use <YOUR FIREBASE>.firebaseio.com instead'\n    );\n  }\n\n  // Catch common error of uninitialized namespace value.\n  if (\n    (!namespace || namespace === 'undefined') &&\n    parsedUrl.domain !== 'localhost'\n  ) {\n    fatal(\n      'Cannot parse Firebase url. Please use https://<YOUR FIREBASE>.firebaseio.com'\n    );\n  }\n\n  if (!parsedUrl.secure) {\n    warnIfPageIsSecure();\n  }\n\n  const webSocketOnly = parsedUrl.scheme === 'ws' || parsedUrl.scheme === 'wss';\n\n  return {\n    repoInfo: new RepoInfo(\n      parsedUrl.host,\n      parsedUrl.secure,\n      namespace,\n      webSocketOnly,\n      nodeAdmin,\n      /*persistenceKey=*/ '',\n      /*includeNamespaceInQueryParams=*/ namespace !== parsedUrl.subdomain\n    ),\n    path: new Path(parsedUrl.pathString)\n  };\n};\n\nexport const parseDatabaseURL = function (dataURL: string): {\n  host: string;\n  port: number;\n  domain: string;\n  subdomain: string;\n  secure: boolean;\n  scheme: string;\n  pathString: string;\n  namespace: string;\n} {\n  // Default to empty strings in the event of a malformed string.\n  let host = '',\n    domain = '',\n    subdomain = '',\n    pathString = '',\n    namespace = '';\n\n  // Always default to SSL, unless otherwise specified.\n  let secure = true,\n    scheme = 'https',\n    port = 443;\n\n  // Don't do any validation here. The caller is responsible for validating the result of parsing.\n  if (typeof dataURL === 'string') {\n    // Parse scheme.\n    let colonInd = dataURL.indexOf('//');\n    if (colonInd >= 0) {\n      scheme = dataURL.substring(0, colonInd - 1);\n      dataURL = dataURL.substring(colonInd + 2);\n    }\n\n    // Parse host, path, and query string.\n    let slashInd = dataURL.indexOf('/');\n    if (slashInd === -1) {\n      slashInd = dataURL.length;\n    }\n    let questionMarkInd = dataURL.indexOf('?');\n    if (questionMarkInd === -1) {\n      questionMarkInd = dataURL.length;\n    }\n    host = dataURL.substring(0, Math.min(slashInd, questionMarkInd));\n    if (slashInd < questionMarkInd) {\n      // For pathString, questionMarkInd will always come after slashInd\n      pathString = decodePath(dataURL.substring(slashInd, questionMarkInd));\n    }\n    const queryParams = decodeQuery(\n      dataURL.substring(Math.min(dataURL.length, questionMarkInd))\n    );\n\n    // If we have a port, use scheme for determining if it's secure.\n    colonInd = host.indexOf(':');\n    if (colonInd >= 0) {\n      secure = scheme === 'https' || scheme === 'wss';\n      port = parseInt(host.substring(colonInd + 1), 10);\n    } else {\n      colonInd = host.length;\n    }\n\n    const hostWithoutPort = host.slice(0, colonInd);\n    if (hostWithoutPort.toLowerCase() === 'localhost') {\n      domain = 'localhost';\n    } else if (hostWithoutPort.split('.').length <= 2) {\n      domain = hostWithoutPort;\n    } else {\n      // Interpret the subdomain of a 3 or more component URL as the namespace name.\n      const dotInd = host.indexOf('.');\n      subdomain = host.substring(0, dotInd).toLowerCase();\n      domain = host.substring(dotInd + 1);\n      // Normalize namespaces to lowercase to share storage / connection.\n      namespace = subdomain;\n    }\n    // Always treat the value of the `ns` as the namespace name if it is present.\n    if ('ns' in queryParams) {\n      namespace = queryParams['ns'];\n    }\n  }\n\n  return {\n    host,\n    port,\n    domain,\n    subdomain,\n    secure,\n    scheme,\n    pathString,\n    namespace\n  };\n};\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { stringify } from '@firebase/util';\n\nimport { DataSnapshot as ExpDataSnapshot } from '../../api/Reference_impl';\nimport { Path } from '../util/Path';\n\nimport { EventRegistration } from './EventRegistration';\n\n/**\n * Encapsulates the data needed to raise an event\n * @interface\n */\nexport interface Event {\n  getPath(): Path;\n\n  getEventType(): string;\n\n  getEventRunner(): () => void;\n\n  toString(): string;\n}\n\n/**\n * One of the following strings: \"value\", \"child_added\", \"child_changed\",\n * \"child_removed\", or \"child_moved.\"\n */\nexport type EventType =\n  | 'value'\n  | 'child_added'\n  | 'child_changed'\n  | 'child_moved'\n  | 'child_removed';\n\n/**\n * Encapsulates the data needed to raise an event\n */\nexport class DataEvent implements Event {\n  /**\n   * @param eventType - One of: value, child_added, child_changed, child_moved, child_removed\n   * @param eventRegistration - The function to call to with the event data. User provided\n   * @param snapshot - The data backing the event\n   * @param prevName - Optional, the name of the previous child for child_* events.\n   */\n  constructor(\n    public eventType: EventType,\n    public eventRegistration: EventRegistration,\n    public snapshot: ExpDataSnapshot,\n    public prevName?: string | null\n  ) {}\n  getPath(): Path {\n    const ref = this.snapshot.ref;\n    if (this.eventType === 'value') {\n      return ref._path;\n    } else {\n      return ref.parent._path;\n    }\n  }\n  getEventType(): string {\n    return this.eventType;\n  }\n  getEventRunner(): () => void {\n    return this.eventRegistration.getEventRunner(this);\n  }\n  toString(): string {\n    return (\n      this.getPath().toString() +\n      ':' +\n      this.eventType +\n      ':' +\n      stringify(this.snapshot.exportVal())\n    );\n  }\n}\n\nexport class CancelEvent implements Event {\n  constructor(\n    public eventRegistration: EventRegistration,\n    public error: Error,\n    public path: Path\n  ) {}\n  getPath(): Path {\n    return this.path;\n  }\n  getEventType(): string {\n    return 'cancel';\n  }\n  getEventRunner(): () => void {\n    return this.eventRegistration.getEventRunner(this);\n  }\n  toString(): string {\n    return this.path.toString() + ':cancel';\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport { DataSnapshot } from '../../api/Reference_impl';\nimport { Repo } from '../Repo';\nimport { Path } from '../util/Path';\n\nimport { Change } from './Change';\nimport { CancelEvent, Event } from './Event';\nimport { QueryParams } from './QueryParams';\n\n/**\n * A user callback. Callbacks issues from the Legacy SDK maintain references\n * to the original user-issued callbacks, which allows equality\n * comparison by reference even though this callbacks are wrapped before\n * they can be passed to the firebase@exp SDK.\n *\n * @internal\n */\nexport interface UserCallback {\n  (dataSnapshot: DataSnapshot, previousChildName?: string | null): unknown;\n  userCallback?: unknown;\n  context?: object | null;\n}\n\n/**\n * A wrapper class that converts events from the database@exp SDK to the legacy\n * Database SDK. Events are not converted directly as event registration relies\n * on reference comparison of the original user callback (see `matches()`) and\n * relies on equality of the legacy SDK's `context` object.\n */\nexport class CallbackContext {\n  constructor(\n    private readonly snapshotCallback: UserCallback,\n    private readonly cancelCallback?: (error: Error) => unknown\n  ) {}\n\n  onValue(\n    expDataSnapshot: DataSnapshot,\n    previousChildName?: string | null\n  ): void {\n    this.snapshotCallback.call(null, expDataSnapshot, previousChildName);\n  }\n\n  onCancel(error: Error): void {\n    assert(\n      this.hasCancelCallback,\n      'Raising a cancel event on a listener with no cancel callback'\n    );\n    return this.cancelCallback.call(null, error);\n  }\n\n  get hasCancelCallback(): boolean {\n    return !!this.cancelCallback;\n  }\n\n  matches(other: CallbackContext): boolean {\n    return (\n      this.snapshotCallback === other.snapshotCallback ||\n      (this.snapshotCallback.userCallback !== undefined &&\n        this.snapshotCallback.userCallback ===\n          other.snapshotCallback.userCallback &&\n        this.snapshotCallback.context === other.snapshotCallback.context)\n    );\n  }\n}\n\nexport interface QueryContext {\n  readonly _queryIdentifier: string;\n  readonly _queryObject: object;\n  readonly _repo: Repo;\n  readonly _path: Path;\n  readonly _queryParams: QueryParams;\n}\n\n/**\n * An EventRegistration is basically an event type ('value', 'child_added', etc.) and a callback\n * to be notified of that type of event.\n *\n * That said, it can also contain a cancel callback to be notified if the event is canceled.  And\n * currently, this code is organized around the idea that you would register multiple child_ callbacks\n * together, as a single EventRegistration.  Though currently we don't do that.\n */\nexport interface EventRegistration {\n  /**\n   * True if this container has a callback to trigger for this event type\n   */\n  respondsTo(eventType: string): boolean;\n\n  createEvent(change: Change, query: QueryContext): Event;\n\n  /**\n   * Given event data, return a function to trigger the user's callback\n   */\n  getEventRunner(eventData: Event): () => void;\n\n  createCancelEvent(error: Error, path: Path): CancelEvent | null;\n\n  matches(other: EventRegistration): boolean;\n\n  /**\n   * False basically means this is a \"dummy\" callback container being used as a sentinel\n   * to remove all callback containers of a particular type.  (e.g. if the user does\n   * ref.off('value') without specifying a specific callback).\n   *\n   * (TODO: Rework this, since it's hacky)\n   *\n   */\n  hasAnyCallback(): boolean;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert, getModularInstance, Deferred } from '@firebase/util';\n\nimport {\n  Repo,\n  repoAddEventCallbackForQuery,\n  repoGetValue,\n  repoRemoveEventCallbackForQuery,\n  repoServerTime,\n  repoSetWithPriority,\n  repoUpdate\n} from '../core/Repo';\nimport { ChildrenNode } from '../core/snap/ChildrenNode';\nimport { Index } from '../core/snap/indexes/Index';\nimport { KEY_INDEX } from '../core/snap/indexes/KeyIndex';\nimport { PathIndex } from '../core/snap/indexes/PathIndex';\nimport { PRIORITY_INDEX } from '../core/snap/indexes/PriorityIndex';\nimport { VALUE_INDEX } from '../core/snap/indexes/ValueIndex';\nimport { Node } from '../core/snap/Node';\nimport { syncPointSetReferenceConstructor } from '../core/SyncPoint';\nimport { syncTreeSetReferenceConstructor } from '../core/SyncTree';\nimport { parseRepoInfo } from '../core/util/libs/parser';\nimport { nextPushId } from '../core/util/NextPushId';\nimport {\n  Path,\n  pathEquals,\n  pathGetBack,\n  pathGetFront,\n  pathChild,\n  pathParent,\n  pathToUrlEncodedString,\n  pathIsEmpty\n} from '../core/util/Path';\nimport {\n  fatal,\n  MAX_NAME,\n  MIN_NAME,\n  ObjectToUniqueKey\n} from '../core/util/util';\nimport {\n  isValidPriority,\n  validateFirebaseDataArg,\n  validateFirebaseMergeDataArg,\n  validateKey,\n  validatePathString,\n  validatePriority,\n  validateRootPathString,\n  validateUrl,\n  validateWritablePath\n} from '../core/util/validation';\nimport { Change } from '../core/view/Change';\nimport { CancelEvent, DataEvent, EventType } from '../core/view/Event';\nimport {\n  CallbackContext,\n  EventRegistration,\n  QueryContext,\n  UserCallback\n} from '../core/view/EventRegistration';\nimport {\n  QueryParams,\n  queryParamsEndAt,\n  queryParamsEndBefore,\n  queryParamsGetQueryObject,\n  queryParamsLimitToFirst,\n  queryParamsLimitToLast,\n  queryParamsOrderBy,\n  queryParamsStartAfter,\n  queryParamsStartAt\n} from '../core/view/QueryParams';\n\nimport { Database } from './Database';\nimport { OnDisconnect } from './OnDisconnect';\nimport {\n  ListenOptions,\n  Query as Query,\n  DatabaseReference,\n  Unsubscribe,\n  ThenableReference\n} from './Reference';\n\n/**\n * @internal\n */\nexport class QueryImpl implements Query, QueryContext {\n  /**\n   * @hideconstructor\n   */\n  constructor(\n    readonly _repo: Repo,\n    readonly _path: Path,\n    readonly _queryParams: QueryParams,\n    readonly _orderByCalled: boolean\n  ) {}\n\n  get key(): string | null {\n    if (pathIsEmpty(this._path)) {\n      return null;\n    } else {\n      return pathGetBack(this._path);\n    }\n  }\n\n  get ref(): DatabaseReference {\n    return new ReferenceImpl(this._repo, this._path);\n  }\n\n  get _queryIdentifier(): string {\n    const obj = queryParamsGetQueryObject(this._queryParams);\n    const id = ObjectToUniqueKey(obj);\n    return id === '{}' ? 'default' : id;\n  }\n\n  /**\n   * An object representation of the query parameters used by this Query.\n   */\n  get _queryObject(): object {\n    return queryParamsGetQueryObject(this._queryParams);\n  }\n\n  isEqual(other: QueryImpl | null): boolean {\n    other = getModularInstance(other);\n    if (!(other instanceof QueryImpl)) {\n      return false;\n    }\n\n    const sameRepo = this._repo === other._repo;\n    const samePath = pathEquals(this._path, other._path);\n    const sameQueryIdentifier =\n      this._queryIdentifier === other._queryIdentifier;\n\n    return sameRepo && samePath && sameQueryIdentifier;\n  }\n\n  toJSON(): string {\n    return this.toString();\n  }\n\n  toString(): string {\n    return this._repo.toString() + pathToUrlEncodedString(this._path);\n  }\n}\n\n/**\n * Validates that no other order by call has been made\n */\nfunction validateNoPreviousOrderByCall(query: QueryImpl, fnName: string) {\n  if (query._orderByCalled === true) {\n    throw new Error(fnName + \": You can't combine multiple orderBy calls.\");\n  }\n}\n\n/**\n * Validates start/end values for queries.\n */\nfunction validateQueryEndpoints(params: QueryParams) {\n  let startNode = null;\n  let endNode = null;\n  if (params.hasStart()) {\n    startNode = params.getIndexStartValue();\n  }\n  if (params.hasEnd()) {\n    endNode = params.getIndexEndValue();\n  }\n\n  if (params.getIndex() === KEY_INDEX) {\n    const tooManyArgsError =\n      'Query: When ordering by key, you may only pass one argument to ' +\n      'startAt(), endAt(), or equalTo().';\n    const wrongArgTypeError =\n      'Query: When ordering by key, the argument passed to startAt(), startAfter(), ' +\n      'endAt(), endBefore(), or equalTo() must be a string.';\n    if (params.hasStart()) {\n      const startName = params.getIndexStartName();\n      if (startName !== MIN_NAME) {\n        throw new Error(tooManyArgsError);\n      } else if (typeof startNode !== 'string') {\n        throw new Error(wrongArgTypeError);\n      }\n    }\n    if (params.hasEnd()) {\n      const endName = params.getIndexEndName();\n      if (endName !== MAX_NAME) {\n        throw new Error(tooManyArgsError);\n      } else if (typeof endNode !== 'string') {\n        throw new Error(wrongArgTypeError);\n      }\n    }\n  } else if (params.getIndex() === PRIORITY_INDEX) {\n    if (\n      (startNode != null && !isValidPriority(startNode)) ||\n      (endNode != null && !isValidPriority(endNode))\n    ) {\n      throw new Error(\n        'Query: When ordering by priority, the first argument passed to startAt(), ' +\n          'startAfter() endAt(), endBefore(), or equalTo() must be a valid priority value ' +\n          '(null, a number, or a string).'\n      );\n    }\n  } else {\n    assert(\n      params.getIndex() instanceof PathIndex ||\n        params.getIndex() === VALUE_INDEX,\n      'unknown index type.'\n    );\n    if (\n      (startNode != null && typeof startNode === 'object') ||\n      (endNode != null && typeof endNode === 'object')\n    ) {\n      throw new Error(\n        'Query: First argument passed to startAt(), startAfter(), endAt(), endBefore(), or ' +\n          'equalTo() cannot be an object.'\n      );\n    }\n  }\n}\n\n/**\n * Validates that limit* has been called with the correct combination of parameters\n */\nfunction validateLimit(params: QueryParams) {\n  if (\n    params.hasStart() &&\n    params.hasEnd() &&\n    params.hasLimit() &&\n    !params.hasAnchoredLimit()\n  ) {\n    throw new Error(\n      \"Query: Can't combine startAt(), startAfter(), endAt(), endBefore(), and limit(). Use \" +\n        'limitToFirst() or limitToLast() instead.'\n    );\n  }\n}\n/**\n * @internal\n */\nexport class ReferenceImpl extends QueryImpl implements DatabaseReference {\n  /** @hideconstructor */\n  constructor(repo: Repo, path: Path) {\n    super(repo, path, new QueryParams(), false);\n  }\n\n  get parent(): ReferenceImpl | null {\n    const parentPath = pathParent(this._path);\n    return parentPath === null\n      ? null\n      : new ReferenceImpl(this._repo, parentPath);\n  }\n\n  get root(): ReferenceImpl {\n    let ref: ReferenceImpl = this;\n    while (ref.parent !== null) {\n      ref = ref.parent;\n    }\n    return ref;\n  }\n}\n\n/**\n * A `DataSnapshot` contains data from a Database location.\n *\n * Any time you read data from the Database, you receive the data as a\n * `DataSnapshot`. A `DataSnapshot` is passed to the event callbacks you attach\n * with `on()` or `once()`. You can extract the contents of the snapshot as a\n * JavaScript object by calling the `val()` method. Alternatively, you can\n * traverse into the snapshot by calling `child()` to return child snapshots\n * (which you could then call `val()` on).\n *\n * A `DataSnapshot` is an efficiently generated, immutable copy of the data at\n * a Database location. It cannot be modified and will never change (to modify\n * data, you always call the `set()` method on a `Reference` directly).\n */\nexport class DataSnapshot {\n  /**\n   * @param _node - A SnapshotNode to wrap.\n   * @param ref - The location this snapshot came from.\n   * @param _index - The iteration order for this snapshot\n   * @hideconstructor\n   */\n  constructor(\n    readonly _node: Node,\n    /**\n     * The location of this DataSnapshot.\n     */\n    readonly ref: DatabaseReference,\n    readonly _index: Index\n  ) {}\n\n  /**\n   * Gets the priority value of the data in this `DataSnapshot`.\n   *\n   * Applications need not use priority but can order collections by\n   * ordinary properties (see\n   * {@link https://firebase.google.com/docs/database/web/lists-of-data#sorting_and_filtering_data |Sorting and filtering data}\n   * ).\n   */\n  get priority(): string | number | null {\n    // typecast here because we never return deferred values or internal priorities (MAX_PRIORITY)\n    return this._node.getPriority().val() as string | number | null;\n  }\n\n  /**\n   * The key (last part of the path) of the location of this `DataSnapshot`.\n   *\n   * The last token in a Database location is considered its key. For example,\n   * \"ada\" is the key for the /users/ada/ node. Accessing the key on any\n   * `DataSnapshot` will return the key for the location that generated it.\n   * However, accessing the key on the root URL of a Database will return\n   * `null`.\n   */\n  get key(): string | null {\n    return this.ref.key;\n  }\n\n  /** Returns the number of child properties of this `DataSnapshot`. */\n  get size(): number {\n    return this._node.numChildren();\n  }\n\n  /**\n   * Gets another `DataSnapshot` for the location at the specified relative path.\n   *\n   * Passing a relative path to the `child()` method of a DataSnapshot returns\n   * another `DataSnapshot` for the location at the specified relative path. The\n   * relative path can either be a simple child name (for example, \"ada\") or a\n   * deeper, slash-separated path (for example, \"ada/name/first\"). If the child\n   * location has no data, an empty `DataSnapshot` (that is, a `DataSnapshot`\n   * whose value is `null`) is returned.\n   *\n   * @param path - A relative path to the location of child data.\n   */\n  child(path: string): DataSnapshot {\n    const childPath = new Path(path);\n    const childRef = child(this.ref, path);\n    return new DataSnapshot(\n      this._node.getChild(childPath),\n      childRef,\n      PRIORITY_INDEX\n    );\n  }\n  /**\n   * Returns true if this `DataSnapshot` contains any data. It is slightly more\n   * efficient than using `snapshot.val() !== null`.\n   */\n  exists(): boolean {\n    return !this._node.isEmpty();\n  }\n\n  /**\n   * Exports the entire contents of the DataSnapshot as a JavaScript object.\n   *\n   * The `exportVal()` method is similar to `val()`, except priority information\n   * is included (if available), making it suitable for backing up your data.\n   *\n   * @returns The DataSnapshot's contents as a JavaScript value (Object,\n   *   Array, string, number, boolean, or `null`).\n   */\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  exportVal(): any {\n    return this._node.val(true);\n  }\n\n  /**\n   * Enumerates the top-level children in the `DataSnapshot`.\n   *\n   * Because of the way JavaScript objects work, the ordering of data in the\n   * JavaScript object returned by `val()` is not guaranteed to match the\n   * ordering on the server nor the ordering of `onChildAdded()` events. That is\n   * where `forEach()` comes in handy. It guarantees the children of a\n   * `DataSnapshot` will be iterated in their query order.\n   *\n   * If no explicit `orderBy*()` method is used, results are returned\n   * ordered by key (unless priorities are used, in which case, results are\n   * returned by priority).\n   *\n   * @param action - A function that will be called for each child DataSnapshot.\n   * The callback can return true to cancel further enumeration.\n   * @returns true if enumeration was canceled due to your callback returning\n   * true.\n   */\n  forEach(action: (child: DataSnapshot) => boolean | void): boolean {\n    if (this._node.isLeafNode()) {\n      return false;\n    }\n\n    const childrenNode = this._node as ChildrenNode;\n    // Sanitize the return value to a boolean. ChildrenNode.forEachChild has a weird return type...\n    return !!childrenNode.forEachChild(this._index, (key, node) => {\n      return action(\n        new DataSnapshot(node, child(this.ref, key), PRIORITY_INDEX)\n      );\n    });\n  }\n\n  /**\n   * Returns true if the specified child path has (non-null) data.\n   *\n   * @param path - A relative path to the location of a potential child.\n   * @returns `true` if data exists at the specified child path; else\n   *  `false`.\n   */\n  hasChild(path: string): boolean {\n    const childPath = new Path(path);\n    return !this._node.getChild(childPath).isEmpty();\n  }\n\n  /**\n   * Returns whether or not the `DataSnapshot` has any non-`null` child\n   * properties.\n   *\n   * You can use `hasChildren()` to determine if a `DataSnapshot` has any\n   * children. If it does, you can enumerate them using `forEach()`. If it\n   * doesn't, then either this snapshot contains a primitive value (which can be\n   * retrieved with `val()`) or it is empty (in which case, `val()` will return\n   * `null`).\n   *\n   * @returns true if this snapshot has any children; else false.\n   */\n  hasChildren(): boolean {\n    if (this._node.isLeafNode()) {\n      return false;\n    } else {\n      return !this._node.isEmpty();\n    }\n  }\n\n  /**\n   * Returns a JSON-serializable representation of this object.\n   */\n  toJSON(): object | null {\n    return this.exportVal();\n  }\n\n  /**\n   * Extracts a JavaScript value from a `DataSnapshot`.\n   *\n   * Depending on the data in a `DataSnapshot`, the `val()` method may return a\n   * scalar type (string, number, or boolean), an array, or an object. It may\n   * also return null, indicating that the `DataSnapshot` is empty (contains no\n   * data).\n   *\n   * @returns The DataSnapshot's contents as a JavaScript value (Object,\n   *   Array, string, number, boolean, or `null`).\n   */\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  val(): any {\n    return this._node.val();\n  }\n}\n\n/**\n *\n * Returns a `Reference` representing the location in the Database\n * corresponding to the provided path. If no path is provided, the `Reference`\n * will point to the root of the Database.\n *\n * @param db - The database instance to obtain a reference for.\n * @param path - Optional path representing the location the returned\n *   `Reference` will point. If not provided, the returned `Reference` will\n *   point to the root of the Database.\n * @returns If a path is provided, a `Reference`\n *   pointing to the provided path. Otherwise, a `Reference` pointing to the\n *   root of the Database.\n */\nexport function ref(db: Database, path?: string): DatabaseReference {\n  db = getModularInstance(db);\n  db._checkNotDeleted('ref');\n  return path !== undefined ? child(db._root, path) : db._root;\n}\n\n/**\n * Returns a `Reference` representing the location in the Database\n * corresponding to the provided Firebase URL.\n *\n * An exception is thrown if the URL is not a valid Firebase Database URL or it\n * has a different domain than the current `Database` instance.\n *\n * Note that all query parameters (`orderBy`, `limitToLast`, etc.) are ignored\n * and are not applied to the returned `Reference`.\n *\n * @param db - The database instance to obtain a reference for.\n * @param url - The Firebase URL at which the returned `Reference` will\n *   point.\n * @returns A `Reference` pointing to the provided\n *   Firebase URL.\n */\nexport function refFromURL(db: Database, url: string): DatabaseReference {\n  db = getModularInstance(db);\n  db._checkNotDeleted('refFromURL');\n  const parsedURL = parseRepoInfo(url, db._repo.repoInfo_.nodeAdmin);\n  validateUrl('refFromURL', parsedURL);\n\n  const repoInfo = parsedURL.repoInfo;\n  if (\n    !db._repo.repoInfo_.isCustomHost() &&\n    repoInfo.host !== db._repo.repoInfo_.host\n  ) {\n    fatal(\n      'refFromURL' +\n        ': Host name does not match the current database: ' +\n        '(found ' +\n        repoInfo.host +\n        ' but expected ' +\n        db._repo.repoInfo_.host +\n        ')'\n    );\n  }\n\n  return ref(db, parsedURL.path.toString());\n}\n/**\n * Gets a `Reference` for the location at the specified relative path.\n *\n * The relative path can either be a simple child name (for example, \"ada\") or\n * a deeper slash-separated path (for example, \"ada/name/first\").\n *\n * @param parent - The parent location.\n * @param path - A relative path from this location to the desired child\n *   location.\n * @returns The specified child location.\n */\nexport function child(\n  parent: DatabaseReference,\n  path: string\n): DatabaseReference {\n  parent = getModularInstance(parent);\n  if (pathGetFront(parent._path) === null) {\n    validateRootPathString('child', 'path', path, false);\n  } else {\n    validatePathString('child', 'path', path, false);\n  }\n  return new ReferenceImpl(parent._repo, pathChild(parent._path, path));\n}\n\n/**\n * Returns an `OnDisconnect` object - see\n * {@link https://firebase.google.com/docs/database/web/offline-capabilities | Enabling Offline Capabilities in JavaScript}\n * for more information on how to use it.\n *\n * @param ref - The reference to add OnDisconnect triggers for.\n */\nexport function onDisconnect(ref: DatabaseReference): OnDisconnect {\n  ref = getModularInstance(ref) as ReferenceImpl;\n  return new OnDisconnect(ref._repo, ref._path);\n}\n\nexport interface ThenableReferenceImpl\n  extends ReferenceImpl,\n    Pick<Promise<ReferenceImpl>, 'then' | 'catch'> {}\n\n/**\n * Generates a new child location using a unique key and returns its\n * `Reference`.\n *\n * This is the most common pattern for adding data to a collection of items.\n *\n * If you provide a value to `push()`, the value is written to the\n * generated location. If you don't pass a value, nothing is written to the\n * database and the child remains empty (but you can use the `Reference`\n * elsewhere).\n *\n * The unique keys generated by `push()` are ordered by the current time, so the\n * resulting list of items is chronologically sorted. The keys are also\n * designed to be unguessable (they contain 72 random bits of entropy).\n *\n * See {@link https://firebase.google.com/docs/database/web/lists-of-data#append_to_a_list_of_data | Append to a list of data}.\n * See {@link https://firebase.googleblog.com/2015/02/the-2120-ways-to-ensure-unique_68.html | The 2^120 Ways to Ensure Unique Identifiers}.\n *\n * @param parent - The parent location.\n * @param value - Optional value to be written at the generated location.\n * @returns Combined `Promise` and `Reference`; resolves when write is complete,\n * but can be used immediately as the `Reference` to the child location.\n */\nexport function push(\n  parent: DatabaseReference,\n  value?: unknown\n): ThenableReference {\n  parent = getModularInstance(parent);\n  validateWritablePath('push', parent._path);\n  validateFirebaseDataArg('push', value, parent._path, true);\n  const now = repoServerTime(parent._repo);\n  const name = nextPushId(now);\n\n  // push() returns a ThennableReference whose promise is fulfilled with a\n  // regular Reference. We use child() to create handles to two different\n  // references. The first is turned into a ThennableReference below by adding\n  // then() and catch() methods and is used as the return value of push(). The\n  // second remains a regular Reference and is used as the fulfilled value of\n  // the first ThennableReference.\n  const thennablePushRef: Partial<ThenableReferenceImpl> = child(\n    parent,\n    name\n  ) as ReferenceImpl;\n  const pushRef = child(parent, name) as ReferenceImpl;\n\n  let promise: Promise<ReferenceImpl>;\n  if (value != null) {\n    promise = set(pushRef, value).then(() => pushRef);\n  } else {\n    promise = Promise.resolve(pushRef);\n  }\n\n  thennablePushRef.then = promise.then.bind(promise);\n  thennablePushRef.catch = promise.then.bind(promise, undefined);\n  return thennablePushRef as ThenableReferenceImpl;\n}\n\n/**\n * Removes the data at this Database location.\n *\n * Any data at child locations will also be deleted.\n *\n * The effect of the remove will be visible immediately and the corresponding\n * event 'value' will be triggered. Synchronization of the remove to the\n * Firebase servers will also be started, and the returned Promise will resolve\n * when complete. If provided, the onComplete callback will be called\n * asynchronously after synchronization has finished.\n *\n * @param ref - The location to remove.\n * @returns Resolves when remove on server is complete.\n */\nexport function remove(ref: DatabaseReference): Promise<void> {\n  validateWritablePath('remove', ref._path);\n  return set(ref, null);\n}\n\n/**\n * Writes data to this Database location.\n *\n * This will overwrite any data at this location and all child locations.\n *\n * The effect of the write will be visible immediately, and the corresponding\n * events (\"value\", \"child_added\", etc.) will be triggered. Synchronization of\n * the data to the Firebase servers will also be started, and the returned\n * Promise will resolve when complete. If provided, the `onComplete` callback\n * will be called asynchronously after synchronization has finished.\n *\n * Passing `null` for the new value is equivalent to calling `remove()`; namely,\n * all data at this location and all child locations will be deleted.\n *\n * `set()` will remove any priority stored at this location, so if priority is\n * meant to be preserved, you need to use `setWithPriority()` instead.\n *\n * Note that modifying data with `set()` will cancel any pending transactions\n * at that location, so extreme care should be taken if mixing `set()` and\n * `transaction()` to modify the same data.\n *\n * A single `set()` will generate a single \"value\" event at the location where\n * the `set()` was performed.\n *\n * @param ref - The location to write to.\n * @param value - The value to be written (string, number, boolean, object,\n *   array, or null).\n * @returns Resolves when write to server is complete.\n */\nexport function set(ref: DatabaseReference, value: unknown): Promise<void> {\n  ref = getModularInstance(ref);\n  validateWritablePath('set', ref._path);\n  validateFirebaseDataArg('set', value, ref._path, false);\n  const deferred = new Deferred<void>();\n  repoSetWithPriority(\n    ref._repo,\n    ref._path,\n    value,\n    /*priority=*/ null,\n    deferred.wrapCallback(() => {})\n  );\n  return deferred.promise;\n}\n\n/**\n * Sets a priority for the data at this Database location.\n *\n * Applications need not use priority but can order collections by\n * ordinary properties (see\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sorting_and_filtering_data | Sorting and filtering data}\n * ).\n *\n * @param ref - The location to write to.\n * @param priority - The priority to be written (string, number, or null).\n * @returns Resolves when write to server is complete.\n */\nexport function setPriority(\n  ref: DatabaseReference,\n  priority: string | number | null\n): Promise<void> {\n  ref = getModularInstance(ref);\n  validateWritablePath('setPriority', ref._path);\n  validatePriority('setPriority', priority, false);\n  const deferred = new Deferred<void>();\n  repoSetWithPriority(\n    ref._repo,\n    pathChild(ref._path, '.priority'),\n    priority,\n    null,\n    deferred.wrapCallback(() => {})\n  );\n  return deferred.promise;\n}\n\n/**\n * Writes data the Database location. Like `set()` but also specifies the\n * priority for that data.\n *\n * Applications need not use priority but can order collections by\n * ordinary properties (see\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sorting_and_filtering_data | Sorting and filtering data}\n * ).\n *\n * @param ref - The location to write to.\n * @param value - The value to be written (string, number, boolean, object,\n *   array, or null).\n * @param priority - The priority to be written (string, number, or null).\n * @returns Resolves when write to server is complete.\n */\nexport function setWithPriority(\n  ref: DatabaseReference,\n  value: unknown,\n  priority: string | number | null\n): Promise<void> {\n  validateWritablePath('setWithPriority', ref._path);\n  validateFirebaseDataArg('setWithPriority', value, ref._path, false);\n  validatePriority('setWithPriority', priority, false);\n  if (ref.key === '.length' || ref.key === '.keys') {\n    throw 'setWithPriority failed: ' + ref.key + ' is a read-only object.';\n  }\n\n  const deferred = new Deferred<void>();\n  repoSetWithPriority(\n    ref._repo,\n    ref._path,\n    value,\n    priority,\n    deferred.wrapCallback(() => {})\n  );\n  return deferred.promise;\n}\n\n/**\n * Writes multiple values to the Database at once.\n *\n * The `values` argument contains multiple property-value pairs that will be\n * written to the Database together. Each child property can either be a simple\n * property (for example, \"name\") or a relative path (for example,\n * \"name/first\") from the current location to the data to update.\n *\n * As opposed to the `set()` method, `update()` can be use to selectively update\n * only the referenced properties at the current location (instead of replacing\n * all the child properties at the current location).\n *\n * The effect of the write will be visible immediately, and the corresponding\n * events ('value', 'child_added', etc.) will be triggered. Synchronization of\n * the data to the Firebase servers will also be started, and the returned\n * Promise will resolve when complete. If provided, the `onComplete` callback\n * will be called asynchronously after synchronization has finished.\n *\n * A single `update()` will generate a single \"value\" event at the location\n * where the `update()` was performed, regardless of how many children were\n * modified.\n *\n * Note that modifying data with `update()` will cancel any pending\n * transactions at that location, so extreme care should be taken if mixing\n * `update()` and `transaction()` to modify the same data.\n *\n * Passing `null` to `update()` will remove the data at this location.\n *\n * See\n * {@link https://firebase.googleblog.com/2015/09/introducing-multi-location-updates-and_86.html | Introducing multi-location updates and more}.\n *\n * @param ref - The location to write to.\n * @param values - Object containing multiple values.\n * @returns Resolves when update on server is complete.\n */\nexport function update(ref: DatabaseReference, values: object): Promise<void> {\n  validateFirebaseMergeDataArg('update', values, ref._path, false);\n  const deferred = new Deferred<void>();\n  repoUpdate(\n    ref._repo,\n    ref._path,\n    values as Record<string, unknown>,\n    deferred.wrapCallback(() => {})\n  );\n  return deferred.promise;\n}\n\n/**\n * Gets the most up-to-date result for this query.\n *\n * @param query - The query to run.\n * @returns A `Promise` which resolves to the resulting DataSnapshot if a value is\n * available, or rejects if the client is unable to return a value (e.g., if the\n * server is unreachable and there is nothing cached).\n */\nexport function get(query: Query): Promise<DataSnapshot> {\n  query = getModularInstance(query) as QueryImpl;\n  const callbackContext = new CallbackContext(() => {});\n  const container = new ValueEventRegistration(callbackContext);\n  return repoGetValue(query._repo, query, container).then(node => {\n    return new DataSnapshot(\n      node,\n      new ReferenceImpl(query._repo, query._path),\n      query._queryParams.getIndex()\n    );\n  });\n}\n/**\n * Represents registration for 'value' events.\n */\nexport class ValueEventRegistration implements EventRegistration {\n  constructor(private callbackContext: CallbackContext) {}\n\n  respondsTo(eventType: string): boolean {\n    return eventType === 'value';\n  }\n\n  createEvent(change: Change, query: QueryContext): DataEvent {\n    const index = query._queryParams.getIndex();\n    return new DataEvent(\n      'value',\n      this,\n      new DataSnapshot(\n        change.snapshotNode,\n        new ReferenceImpl(query._repo, query._path),\n        index\n      )\n    );\n  }\n\n  getEventRunner(eventData: CancelEvent | DataEvent): () => void {\n    if (eventData.getEventType() === 'cancel') {\n      return () =>\n        this.callbackContext.onCancel((eventData as CancelEvent).error);\n    } else {\n      return () =>\n        this.callbackContext.onValue((eventData as DataEvent).snapshot, null);\n    }\n  }\n\n  createCancelEvent(error: Error, path: Path): CancelEvent | null {\n    if (this.callbackContext.hasCancelCallback) {\n      return new CancelEvent(this, error, path);\n    } else {\n      return null;\n    }\n  }\n\n  matches(other: EventRegistration): boolean {\n    if (!(other instanceof ValueEventRegistration)) {\n      return false;\n    } else if (!other.callbackContext || !this.callbackContext) {\n      // If no callback specified, we consider it to match any callback.\n      return true;\n    } else {\n      return other.callbackContext.matches(this.callbackContext);\n    }\n  }\n\n  hasAnyCallback(): boolean {\n    return this.callbackContext !== null;\n  }\n}\n\n/**\n * Represents the registration of a child_x event.\n */\nexport class ChildEventRegistration implements EventRegistration {\n  constructor(\n    private eventType: string,\n    private callbackContext: CallbackContext | null\n  ) {}\n\n  respondsTo(eventType: string): boolean {\n    let eventToCheck =\n      eventType === 'children_added' ? 'child_added' : eventType;\n    eventToCheck =\n      eventToCheck === 'children_removed' ? 'child_removed' : eventToCheck;\n    return this.eventType === eventToCheck;\n  }\n\n  createCancelEvent(error: Error, path: Path): CancelEvent | null {\n    if (this.callbackContext.hasCancelCallback) {\n      return new CancelEvent(this, error, path);\n    } else {\n      return null;\n    }\n  }\n\n  createEvent(change: Change, query: QueryContext): DataEvent {\n    assert(change.childName != null, 'Child events should have a childName.');\n    const childRef = child(\n      new ReferenceImpl(query._repo, query._path),\n      change.childName\n    );\n    const index = query._queryParams.getIndex();\n    return new DataEvent(\n      change.type as EventType,\n      this,\n      new DataSnapshot(change.snapshotNode, childRef, index),\n      change.prevName\n    );\n  }\n\n  getEventRunner(eventData: CancelEvent | DataEvent): () => void {\n    if (eventData.getEventType() === 'cancel') {\n      return () =>\n        this.callbackContext.onCancel((eventData as CancelEvent).error);\n    } else {\n      return () =>\n        this.callbackContext.onValue(\n          (eventData as DataEvent).snapshot,\n          (eventData as DataEvent).prevName\n        );\n    }\n  }\n\n  matches(other: EventRegistration): boolean {\n    if (other instanceof ChildEventRegistration) {\n      return (\n        this.eventType === other.eventType &&\n        (!this.callbackContext ||\n          !other.callbackContext ||\n          this.callbackContext.matches(other.callbackContext))\n      );\n    }\n\n    return false;\n  }\n\n  hasAnyCallback(): boolean {\n    return !!this.callbackContext;\n  }\n}\n\nfunction addEventListener(\n  query: Query,\n  eventType: EventType,\n  callback: UserCallback,\n  cancelCallbackOrListenOptions?: ((error: Error) => unknown) | ListenOptions,\n  options?: ListenOptions\n) {\n  let cancelCallback: ((error: Error) => unknown) | undefined;\n  if (typeof cancelCallbackOrListenOptions === 'object') {\n    cancelCallback = undefined;\n    options = cancelCallbackOrListenOptions;\n  }\n  if (typeof cancelCallbackOrListenOptions === 'function') {\n    cancelCallback = cancelCallbackOrListenOptions;\n  }\n\n  if (options && options.onlyOnce) {\n    const userCallback = callback;\n    const onceCallback: UserCallback = (dataSnapshot, previousChildName) => {\n      repoRemoveEventCallbackForQuery(query._repo, query, container);\n      userCallback(dataSnapshot, previousChildName);\n    };\n    onceCallback.userCallback = callback.userCallback;\n    onceCallback.context = callback.context;\n    callback = onceCallback;\n  }\n\n  const callbackContext = new CallbackContext(\n    callback,\n    cancelCallback || undefined\n  );\n  const container =\n    eventType === 'value'\n      ? new ValueEventRegistration(callbackContext)\n      : new ChildEventRegistration(eventType, callbackContext);\n  repoAddEventCallbackForQuery(query._repo, query, container);\n  return () => repoRemoveEventCallbackForQuery(query._repo, query, container);\n}\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onValue` event will trigger once with the initial data stored at this\n * location, and then trigger again each time the data changes. The\n * `DataSnapshot` passed to the callback will be for the location at which\n * `on()` was called. It won't trigger until the entire contents has been\n * synchronized. If the location has no data, it will be triggered with an empty\n * `DataSnapshot` (`val()` will return `null`).\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs. The\n * callback will be passed a DataSnapshot.\n * @param cancelCallback - An optional callback that will be notified if your\n * event subscription is ever canceled because your client does not have\n * permission to read this data (or it had permission but has now lost it).\n * This callback will be passed an `Error` object indicating why the failure\n * occurred.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onValue(\n  query: Query,\n  callback: (snapshot: DataSnapshot) => unknown,\n  cancelCallback?: (error: Error) => unknown\n): Unsubscribe;\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onValue` event will trigger once with the initial data stored at this\n * location, and then trigger again each time the data changes. The\n * `DataSnapshot` passed to the callback will be for the location at which\n * `on()` was called. It won't trigger until the entire contents has been\n * synchronized. If the location has no data, it will be triggered with an empty\n * `DataSnapshot` (`val()` will return `null`).\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs. The\n * callback will be passed a DataSnapshot.\n * @param options - An object that can be used to configure `onlyOnce`, which\n * then removes the listener after its first invocation.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onValue(\n  query: Query,\n  callback: (snapshot: DataSnapshot) => unknown,\n  options: ListenOptions\n): Unsubscribe;\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onValue` event will trigger once with the initial data stored at this\n * location, and then trigger again each time the data changes. The\n * `DataSnapshot` passed to the callback will be for the location at which\n * `on()` was called. It won't trigger until the entire contents has been\n * synchronized. If the location has no data, it will be triggered with an empty\n * `DataSnapshot` (`val()` will return `null`).\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs. The\n * callback will be passed a DataSnapshot.\n * @param cancelCallback - An optional callback that will be notified if your\n * event subscription is ever canceled because your client does not have\n * permission to read this data (or it had permission but has now lost it).\n * This callback will be passed an `Error` object indicating why the failure\n * occurred.\n * @param options - An object that can be used to configure `onlyOnce`, which\n * then removes the listener after its first invocation.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onValue(\n  query: Query,\n  callback: (snapshot: DataSnapshot) => unknown,\n  cancelCallback: (error: Error) => unknown,\n  options: ListenOptions\n): Unsubscribe;\n\nexport function onValue(\n  query: Query,\n  callback: (snapshot: DataSnapshot) => unknown,\n  cancelCallbackOrListenOptions?: ((error: Error) => unknown) | ListenOptions,\n  options?: ListenOptions\n): Unsubscribe {\n  return addEventListener(\n    query,\n    'value',\n    callback,\n    cancelCallbackOrListenOptions,\n    options\n  );\n}\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildAdded` event will be triggered once for each initial child at this\n * location, and it will be triggered again every time a new child is added. The\n * `DataSnapshot` passed into the callback will reflect the data for the\n * relevant child. For ordering purposes, it is passed a second argument which\n * is a string containing the key of the previous sibling child by sort order,\n * or `null` if it is the first child.\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param cancelCallback - An optional callback that will be notified if your\n * event subscription is ever canceled because your client does not have\n * permission to read this data (or it had permission but has now lost it).\n * This callback will be passed an `Error` object indicating why the failure\n * occurred.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildAdded(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName?: string | null\n  ) => unknown,\n  cancelCallback?: (error: Error) => unknown\n): Unsubscribe;\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildAdded` event will be triggered once for each initial child at this\n * location, and it will be triggered again every time a new child is added. The\n * `DataSnapshot` passed into the callback will reflect the data for the\n * relevant child. For ordering purposes, it is passed a second argument which\n * is a string containing the key of the previous sibling child by sort order,\n * or `null` if it is the first child.\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param options - An object that can be used to configure `onlyOnce`, which\n * then removes the listener after its first invocation.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildAdded(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName: string | null\n  ) => unknown,\n  options: ListenOptions\n): Unsubscribe;\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildAdded` event will be triggered once for each initial child at this\n * location, and it will be triggered again every time a new child is added. The\n * `DataSnapshot` passed into the callback will reflect the data for the\n * relevant child. For ordering purposes, it is passed a second argument which\n * is a string containing the key of the previous sibling child by sort order,\n * or `null` if it is the first child.\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param cancelCallback - An optional callback that will be notified if your\n * event subscription is ever canceled because your client does not have\n * permission to read this data (or it had permission but has now lost it).\n * This callback will be passed an `Error` object indicating why the failure\n * occurred.\n * @param options - An object that can be used to configure `onlyOnce`, which\n * then removes the listener after its first invocation.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildAdded(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName: string | null\n  ) => unknown,\n  cancelCallback: (error: Error) => unknown,\n  options: ListenOptions\n): Unsubscribe;\n\nexport function onChildAdded(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName: string | null\n  ) => unknown,\n  cancelCallbackOrListenOptions?: ((error: Error) => unknown) | ListenOptions,\n  options?: ListenOptions\n): Unsubscribe {\n  return addEventListener(\n    query,\n    'child_added',\n    callback,\n    cancelCallbackOrListenOptions,\n    options\n  );\n}\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildChanged` event will be triggered when the data stored in a child\n * (or any of its descendants) changes. Note that a single `child_changed` event\n * may represent multiple changes to the child. The `DataSnapshot` passed to the\n * callback will contain the new child contents. For ordering purposes, the\n * callback is also passed a second argument which is a string containing the\n * key of the previous sibling child by sort order, or `null` if it is the first\n * child.\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param cancelCallback - An optional callback that will be notified if your\n * event subscription is ever canceled because your client does not have\n * permission to read this data (or it had permission but has now lost it).\n * This callback will be passed an `Error` object indicating why the failure\n * occurred.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildChanged(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName: string | null\n  ) => unknown,\n  cancelCallback?: (error: Error) => unknown\n): Unsubscribe;\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildChanged` event will be triggered when the data stored in a child\n * (or any of its descendants) changes. Note that a single `child_changed` event\n * may represent multiple changes to the child. The `DataSnapshot` passed to the\n * callback will contain the new child contents. For ordering purposes, the\n * callback is also passed a second argument which is a string containing the\n * key of the previous sibling child by sort order, or `null` if it is the first\n * child.\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param options - An object that can be used to configure `onlyOnce`, which\n * then removes the listener after its first invocation.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildChanged(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName: string | null\n  ) => unknown,\n  options: ListenOptions\n): Unsubscribe;\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildChanged` event will be triggered when the data stored in a child\n * (or any of its descendants) changes. Note that a single `child_changed` event\n * may represent multiple changes to the child. The `DataSnapshot` passed to the\n * callback will contain the new child contents. For ordering purposes, the\n * callback is also passed a second argument which is a string containing the\n * key of the previous sibling child by sort order, or `null` if it is the first\n * child.\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param cancelCallback - An optional callback that will be notified if your\n * event subscription is ever canceled because your client does not have\n * permission to read this data (or it had permission but has now lost it).\n * This callback will be passed an `Error` object indicating why the failure\n * occurred.\n * @param options - An object that can be used to configure `onlyOnce`, which\n * then removes the listener after its first invocation.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildChanged(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName: string | null\n  ) => unknown,\n  cancelCallback: (error: Error) => unknown,\n  options: ListenOptions\n): Unsubscribe;\n\nexport function onChildChanged(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName: string | null\n  ) => unknown,\n  cancelCallbackOrListenOptions?: ((error: Error) => unknown) | ListenOptions,\n  options?: ListenOptions\n): Unsubscribe {\n  return addEventListener(\n    query,\n    'child_changed',\n    callback,\n    cancelCallbackOrListenOptions,\n    options\n  );\n}\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildMoved` event will be triggered when a child's sort order changes\n * such that its position relative to its siblings changes. The `DataSnapshot`\n * passed to the callback will be for the data of the child that has moved. It\n * is also passed a second argument which is a string containing the key of the\n * previous sibling child by sort order, or `null` if it is the first child.\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param cancelCallback - An optional callback that will be notified if your\n * event subscription is ever canceled because your client does not have\n * permission to read this data (or it had permission but has now lost it).\n * This callback will be passed an `Error` object indicating why the failure\n * occurred.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildMoved(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName: string | null\n  ) => unknown,\n  cancelCallback?: (error: Error) => unknown\n): Unsubscribe;\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildMoved` event will be triggered when a child's sort order changes\n * such that its position relative to its siblings changes. The `DataSnapshot`\n * passed to the callback will be for the data of the child that has moved. It\n * is also passed a second argument which is a string containing the key of the\n * previous sibling child by sort order, or `null` if it is the first child.\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param options - An object that can be used to configure `onlyOnce`, which\n * then removes the listener after its first invocation.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildMoved(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName: string | null\n  ) => unknown,\n  options: ListenOptions\n): Unsubscribe;\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildMoved` event will be triggered when a child's sort order changes\n * such that its position relative to its siblings changes. The `DataSnapshot`\n * passed to the callback will be for the data of the child that has moved. It\n * is also passed a second argument which is a string containing the key of the\n * previous sibling child by sort order, or `null` if it is the first child.\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param cancelCallback - An optional callback that will be notified if your\n * event subscription is ever canceled because your client does not have\n * permission to read this data (or it had permission but has now lost it).\n * This callback will be passed an `Error` object indicating why the failure\n * occurred.\n * @param options - An object that can be used to configure `onlyOnce`, which\n * then removes the listener after its first invocation.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildMoved(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName: string | null\n  ) => unknown,\n  cancelCallback: (error: Error) => unknown,\n  options: ListenOptions\n): Unsubscribe;\n\nexport function onChildMoved(\n  query: Query,\n  callback: (\n    snapshot: DataSnapshot,\n    previousChildName: string | null\n  ) => unknown,\n  cancelCallbackOrListenOptions?: ((error: Error) => unknown) | ListenOptions,\n  options?: ListenOptions\n): Unsubscribe {\n  return addEventListener(\n    query,\n    'child_moved',\n    callback,\n    cancelCallbackOrListenOptions,\n    options\n  );\n}\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildRemoved` event will be triggered once every time a child is\n * removed. The `DataSnapshot` passed into the callback will be the old data for\n * the child that was removed. A child will get removed when either:\n *\n * - a client explicitly calls `remove()` on that child or one of its ancestors\n * - a client calls `set(null)` on that child or one of its ancestors\n * - that child has all of its children removed\n * - there is a query in effect which now filters out the child (because it's\n *   sort order changed or the max limit was hit)\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param cancelCallback - An optional callback that will be notified if your\n * event subscription is ever canceled because your client does not have\n * permission to read this data (or it had permission but has now lost it).\n * This callback will be passed an `Error` object indicating why the failure\n * occurred.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildRemoved(\n  query: Query,\n  callback: (snapshot: DataSnapshot) => unknown,\n  cancelCallback?: (error: Error) => unknown\n): Unsubscribe;\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildRemoved` event will be triggered once every time a child is\n * removed. The `DataSnapshot` passed into the callback will be the old data for\n * the child that was removed. A child will get removed when either:\n *\n * - a client explicitly calls `remove()` on that child or one of its ancestors\n * - a client calls `set(null)` on that child or one of its ancestors\n * - that child has all of its children removed\n * - there is a query in effect which now filters out the child (because it's\n *   sort order changed or the max limit was hit)\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param options - An object that can be used to configure `onlyOnce`, which\n * then removes the listener after its first invocation.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildRemoved(\n  query: Query,\n  callback: (snapshot: DataSnapshot) => unknown,\n  options: ListenOptions\n): Unsubscribe;\n\n/**\n * Listens for data changes at a particular location.\n *\n * This is the primary way to read data from a Database. Your callback\n * will be triggered for the initial data and again whenever the data changes.\n * Invoke the returned unsubscribe callback to stop receiving updates. See\n * {@link https://firebase.google.com/docs/database/web/retrieve-data | Retrieve Data on the Web}\n * for more details.\n *\n * An `onChildRemoved` event will be triggered once every time a child is\n * removed. The `DataSnapshot` passed into the callback will be the old data for\n * the child that was removed. A child will get removed when either:\n *\n * - a client explicitly calls `remove()` on that child or one of its ancestors\n * - a client calls `set(null)` on that child or one of its ancestors\n * - that child has all of its children removed\n * - there is a query in effect which now filters out the child (because it's\n *   sort order changed or the max limit was hit)\n *\n * @param query - The query to run.\n * @param callback - A callback that fires when the specified event occurs.\n * The callback will be passed a DataSnapshot and a string containing the key of\n * the previous child, by sort order, or `null` if it is the first child.\n * @param cancelCallback - An optional callback that will be notified if your\n * event subscription is ever canceled because your client does not have\n * permission to read this data (or it had permission but has now lost it).\n * This callback will be passed an `Error` object indicating why the failure\n * occurred.\n * @param options - An object that can be used to configure `onlyOnce`, which\n * then removes the listener after its first invocation.\n * @returns A function that can be invoked to remove the listener.\n */\nexport function onChildRemoved(\n  query: Query,\n  callback: (snapshot: DataSnapshot) => unknown,\n  cancelCallback: (error: Error) => unknown,\n  options: ListenOptions\n): Unsubscribe;\n\nexport function onChildRemoved(\n  query: Query,\n  callback: (snapshot: DataSnapshot) => unknown,\n  cancelCallbackOrListenOptions?: ((error: Error) => unknown) | ListenOptions,\n  options?: ListenOptions\n): Unsubscribe {\n  return addEventListener(\n    query,\n    'child_removed',\n    callback,\n    cancelCallbackOrListenOptions,\n    options\n  );\n}\n\nexport { EventType };\n\n/**\n * Detaches a callback previously attached with the corresponding `on*()` (`onValue`, `onChildAdded`) listener.\n * Note: This is not the recommended way to remove a listener. Instead, please use the returned callback function from\n * the respective `on*` callbacks.\n *\n * Detach a callback previously attached with `on*()`. Calling `off()` on a parent listener\n * will not automatically remove listeners registered on child nodes, `off()`\n * must also be called on any child listeners to remove the callback.\n *\n * If a callback is not specified, all callbacks for the specified eventType\n * will be removed. Similarly, if no eventType is specified, all callbacks\n * for the `Reference` will be removed.\n *\n * Individual listeners can also be removed by invoking their unsubscribe\n * callbacks.\n *\n * @param query - The query that the listener was registered with.\n * @param eventType - One of the following strings: \"value\", \"child_added\",\n * \"child_changed\", \"child_removed\", or \"child_moved.\" If omitted, all callbacks\n * for the `Reference` will be removed.\n * @param callback - The callback function that was passed to `on()` or\n * `undefined` to remove all callbacks.\n */\nexport function off(\n  query: Query,\n  eventType?: EventType,\n  callback?: (\n    snapshot: DataSnapshot,\n    previousChildName?: string | null\n  ) => unknown\n): void {\n  let container: EventRegistration | null = null;\n  const expCallback = callback ? new CallbackContext(callback) : null;\n  if (eventType === 'value') {\n    container = new ValueEventRegistration(expCallback);\n  } else if (eventType) {\n    container = new ChildEventRegistration(eventType, expCallback);\n  }\n  repoRemoveEventCallbackForQuery(query._repo, query, container);\n}\n\n/** Describes the different query constraints available in this SDK. */\nexport type QueryConstraintType =\n  | 'endAt'\n  | 'endBefore'\n  | 'startAt'\n  | 'startAfter'\n  | 'limitToFirst'\n  | 'limitToLast'\n  | 'orderByChild'\n  | 'orderByKey'\n  | 'orderByPriority'\n  | 'orderByValue'\n  | 'equalTo';\n\n/**\n * A `QueryConstraint` is used to narrow the set of documents returned by a\n * Database query. `QueryConstraint`s are created by invoking {@link endAt},\n * {@link endBefore}, {@link startAt}, {@link startAfter}, {@link\n * limitToFirst}, {@link limitToLast}, {@link orderByChild},\n * {@link orderByChild}, {@link orderByKey} , {@link orderByPriority} ,\n * {@link orderByValue}  or {@link equalTo} and\n * can then be passed to {@link query} to create a new query instance that\n * also contains this `QueryConstraint`.\n */\nexport abstract class QueryConstraint {\n  /** The type of this query constraints */\n  abstract readonly type: QueryConstraintType;\n\n  /**\n   * Takes the provided `Query` and returns a copy of the `Query` with this\n   * `QueryConstraint` applied.\n   */\n  abstract _apply<T>(query: QueryImpl): QueryImpl;\n}\n\nclass QueryEndAtConstraint extends QueryConstraint {\n  readonly type: 'endAt';\n\n  constructor(\n    private readonly _value: number | string | boolean | null,\n    private readonly _key?: string\n  ) {\n    super();\n  }\n\n  _apply<T>(query: QueryImpl): QueryImpl {\n    validateFirebaseDataArg('endAt', this._value, query._path, true);\n    const newParams = queryParamsEndAt(\n      query._queryParams,\n      this._value,\n      this._key\n    );\n    validateLimit(newParams);\n    validateQueryEndpoints(newParams);\n    if (query._queryParams.hasEnd()) {\n      throw new Error(\n        'endAt: Starting point was already set (by another call to endAt, ' +\n          'endBefore or equalTo).'\n      );\n    }\n    return new QueryImpl(\n      query._repo,\n      query._path,\n      newParams,\n      query._orderByCalled\n    );\n  }\n}\n\n/**\n * Creates a `QueryConstraint` with the specified ending point.\n *\n * Using `startAt()`, `startAfter()`, `endBefore()`, `endAt()` and `equalTo()`\n * allows you to choose arbitrary starting and ending points for your queries.\n *\n * The ending point is inclusive, so children with exactly the specified value\n * will be included in the query. The optional key argument can be used to\n * further limit the range of the query. If it is specified, then children that\n * have exactly the specified value must also have a key name less than or equal\n * to the specified key.\n *\n * You can read more about `endAt()` in\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#filtering_data | Filtering data}.\n *\n * @param value - The value to end at. The argument type depends on which\n * `orderBy*()` function was used in this query. Specify a value that matches\n * the `orderBy*()` type. When used in combination with `orderByKey()`, the\n * value must be a string.\n * @param key - The child key to end at, among the children with the previously\n * specified priority. This argument is only allowed if ordering by child,\n * value, or priority.\n */\nexport function endAt(\n  value: number | string | boolean | null,\n  key?: string\n): QueryConstraint {\n  validateKey('endAt', 'key', key, true);\n  return new QueryEndAtConstraint(value, key);\n}\n\nclass QueryEndBeforeConstraint extends QueryConstraint {\n  readonly type: 'endBefore';\n\n  constructor(\n    private readonly _value: number | string | boolean | null,\n    private readonly _key?: string\n  ) {\n    super();\n  }\n\n  _apply<T>(query: QueryImpl): QueryImpl {\n    validateFirebaseDataArg('endBefore', this._value, query._path, false);\n    const newParams = queryParamsEndBefore(\n      query._queryParams,\n      this._value,\n      this._key\n    );\n    validateLimit(newParams);\n    validateQueryEndpoints(newParams);\n    if (query._queryParams.hasEnd()) {\n      throw new Error(\n        'endBefore: Starting point was already set (by another call to endAt, ' +\n          'endBefore or equalTo).'\n      );\n    }\n    return new QueryImpl(\n      query._repo,\n      query._path,\n      newParams,\n      query._orderByCalled\n    );\n  }\n}\n\n/**\n * Creates a `QueryConstraint` with the specified ending point (exclusive).\n *\n * Using `startAt()`, `startAfter()`, `endBefore()`, `endAt()` and `equalTo()`\n * allows you to choose arbitrary starting and ending points for your queries.\n *\n * The ending point is exclusive. If only a value is provided, children\n * with a value less than the specified value will be included in the query.\n * If a key is specified, then children must have a value less than or equal\n * to the specified value and a key name less than the specified key.\n *\n * @param value - The value to end before. The argument type depends on which\n * `orderBy*()` function was used in this query. Specify a value that matches\n * the `orderBy*()` type. When used in combination with `orderByKey()`, the\n * value must be a string.\n * @param key - The child key to end before, among the children with the\n * previously specified priority. This argument is only allowed if ordering by\n * child, value, or priority.\n */\nexport function endBefore(\n  value: number | string | boolean | null,\n  key?: string\n): QueryConstraint {\n  validateKey('endBefore', 'key', key, true);\n  return new QueryEndBeforeConstraint(value, key);\n}\n\nclass QueryStartAtConstraint extends QueryConstraint {\n  readonly type: 'startAt';\n\n  constructor(\n    private readonly _value: number | string | boolean | null,\n    private readonly _key?: string\n  ) {\n    super();\n  }\n\n  _apply<T>(query: QueryImpl): QueryImpl {\n    validateFirebaseDataArg('startAt', this._value, query._path, true);\n    const newParams = queryParamsStartAt(\n      query._queryParams,\n      this._value,\n      this._key\n    );\n    validateLimit(newParams);\n    validateQueryEndpoints(newParams);\n    if (query._queryParams.hasStart()) {\n      throw new Error(\n        'startAt: Starting point was already set (by another call to startAt, ' +\n          'startBefore or equalTo).'\n      );\n    }\n    return new QueryImpl(\n      query._repo,\n      query._path,\n      newParams,\n      query._orderByCalled\n    );\n  }\n}\n\n/**\n * Creates a `QueryConstraint` with the specified starting point.\n *\n * Using `startAt()`, `startAfter()`, `endBefore()`, `endAt()` and `equalTo()`\n * allows you to choose arbitrary starting and ending points for your queries.\n *\n * The starting point is inclusive, so children with exactly the specified value\n * will be included in the query. The optional key argument can be used to\n * further limit the range of the query. If it is specified, then children that\n * have exactly the specified value must also have a key name greater than or\n * equal to the specified key.\n *\n * You can read more about `startAt()` in\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#filtering_data | Filtering data}.\n *\n * @param value - The value to start at. The argument type depends on which\n * `orderBy*()` function was used in this query. Specify a value that matches\n * the `orderBy*()` type. When used in combination with `orderByKey()`, the\n * value must be a string.\n * @param key - The child key to start at. This argument is only allowed if\n * ordering by child, value, or priority.\n */\nexport function startAt(\n  value: number | string | boolean | null = null,\n  key?: string\n): QueryConstraint {\n  validateKey('startAt', 'key', key, true);\n  return new QueryStartAtConstraint(value, key);\n}\n\nclass QueryStartAfterConstraint extends QueryConstraint {\n  readonly type: 'startAfter';\n\n  constructor(\n    private readonly _value: number | string | boolean | null,\n    private readonly _key?: string\n  ) {\n    super();\n  }\n\n  _apply<T>(query: QueryImpl): QueryImpl {\n    validateFirebaseDataArg('startAfter', this._value, query._path, false);\n    const newParams = queryParamsStartAfter(\n      query._queryParams,\n      this._value,\n      this._key\n    );\n    validateLimit(newParams);\n    validateQueryEndpoints(newParams);\n    if (query._queryParams.hasStart()) {\n      throw new Error(\n        'startAfter: Starting point was already set (by another call to startAt, ' +\n          'startAfter, or equalTo).'\n      );\n    }\n    return new QueryImpl(\n      query._repo,\n      query._path,\n      newParams,\n      query._orderByCalled\n    );\n  }\n}\n\n/**\n * Creates a `QueryConstraint` with the specified starting point (exclusive).\n *\n * Using `startAt()`, `startAfter()`, `endBefore()`, `endAt()` and `equalTo()`\n * allows you to choose arbitrary starting and ending points for your queries.\n *\n * The starting point is exclusive. If only a value is provided, children\n * with a value greater than the specified value will be included in the query.\n * If a key is specified, then children must have a value greater than or equal\n * to the specified value and a a key name greater than the specified key.\n *\n * @param value - The value to start after. The argument type depends on which\n * `orderBy*()` function was used in this query. Specify a value that matches\n * the `orderBy*()` type. When used in combination with `orderByKey()`, the\n * value must be a string.\n * @param key - The child key to start after. This argument is only allowed if\n * ordering by child, value, or priority.\n */\nexport function startAfter(\n  value: number | string | boolean | null,\n  key?: string\n): QueryConstraint {\n  validateKey('startAfter', 'key', key, true);\n  return new QueryStartAfterConstraint(value, key);\n}\n\nclass QueryLimitToFirstConstraint extends QueryConstraint {\n  readonly type: 'limitToFirst';\n\n  constructor(private readonly _limit: number) {\n    super();\n  }\n\n  _apply<T>(query: QueryImpl): QueryImpl {\n    if (query._queryParams.hasLimit()) {\n      throw new Error(\n        'limitToFirst: Limit was already set (by another call to limitToFirst ' +\n          'or limitToLast).'\n      );\n    }\n    return new QueryImpl(\n      query._repo,\n      query._path,\n      queryParamsLimitToFirst(query._queryParams, this._limit),\n      query._orderByCalled\n    );\n  }\n}\n\n/**\n * Creates a new `QueryConstraint` that if limited to the first specific number\n * of children.\n *\n * The `limitToFirst()` method is used to set a maximum number of children to be\n * synced for a given callback. If we set a limit of 100, we will initially only\n * receive up to 100 `child_added` events. If we have fewer than 100 messages\n * stored in our Database, a `child_added` event will fire for each message.\n * However, if we have over 100 messages, we will only receive a `child_added`\n * event for the first 100 ordered messages. As items change, we will receive\n * `child_removed` events for each item that drops out of the active list so\n * that the total number stays at 100.\n *\n * You can read more about `limitToFirst()` in\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#filtering_data | Filtering data}.\n *\n * @param limit - The maximum number of nodes to include in this query.\n */\nexport function limitToFirst(limit: number): QueryConstraint {\n  if (typeof limit !== 'number' || Math.floor(limit) !== limit || limit <= 0) {\n    throw new Error('limitToFirst: First argument must be a positive integer.');\n  }\n  return new QueryLimitToFirstConstraint(limit);\n}\n\nclass QueryLimitToLastConstraint extends QueryConstraint {\n  readonly type: 'limitToLast';\n\n  constructor(private readonly _limit: number) {\n    super();\n  }\n\n  _apply<T>(query: QueryImpl): QueryImpl {\n    if (query._queryParams.hasLimit()) {\n      throw new Error(\n        'limitToLast: Limit was already set (by another call to limitToFirst ' +\n          'or limitToLast).'\n      );\n    }\n    return new QueryImpl(\n      query._repo,\n      query._path,\n      queryParamsLimitToLast(query._queryParams, this._limit),\n      query._orderByCalled\n    );\n  }\n}\n\n/**\n * Creates a new `QueryConstraint` that is limited to return only the last\n * specified number of children.\n *\n * The `limitToLast()` method is used to set a maximum number of children to be\n * synced for a given callback. If we set a limit of 100, we will initially only\n * receive up to 100 `child_added` events. If we have fewer than 100 messages\n * stored in our Database, a `child_added` event will fire for each message.\n * However, if we have over 100 messages, we will only receive a `child_added`\n * event for the last 100 ordered messages. As items change, we will receive\n * `child_removed` events for each item that drops out of the active list so\n * that the total number stays at 100.\n *\n * You can read more about `limitToLast()` in\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#filtering_data | Filtering data}.\n *\n * @param limit - The maximum number of nodes to include in this query.\n */\nexport function limitToLast(limit: number): QueryConstraint {\n  if (typeof limit !== 'number' || Math.floor(limit) !== limit || limit <= 0) {\n    throw new Error('limitToLast: First argument must be a positive integer.');\n  }\n\n  return new QueryLimitToLastConstraint(limit);\n}\n\nclass QueryOrderByChildConstraint extends QueryConstraint {\n  readonly type: 'orderByChild';\n\n  constructor(private readonly _path: string) {\n    super();\n  }\n\n  _apply<T>(query: QueryImpl): QueryImpl {\n    validateNoPreviousOrderByCall(query, 'orderByChild');\n    const parsedPath = new Path(this._path);\n    if (pathIsEmpty(parsedPath)) {\n      throw new Error(\n        'orderByChild: cannot pass in empty path. Use orderByValue() instead.'\n      );\n    }\n    const index = new PathIndex(parsedPath);\n    const newParams = queryParamsOrderBy(query._queryParams, index);\n    validateQueryEndpoints(newParams);\n\n    return new QueryImpl(\n      query._repo,\n      query._path,\n      newParams,\n      /*orderByCalled=*/ true\n    );\n  }\n}\n\n/**\n * Creates a new `QueryConstraint` that orders by the specified child key.\n *\n * Queries can only order by one key at a time. Calling `orderByChild()`\n * multiple times on the same query is an error.\n *\n * Firebase queries allow you to order your data by any child key on the fly.\n * However, if you know in advance what your indexes will be, you can define\n * them via the .indexOn rule in your Security Rules for better performance. See\n * the{@link https://firebase.google.com/docs/database/security/indexing-data}\n * rule for more information.\n *\n * You can read more about `orderByChild()` in\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sort_data | Sort data}.\n *\n * @param path - The path to order by.\n */\nexport function orderByChild(path: string): QueryConstraint {\n  if (path === '$key') {\n    throw new Error(\n      'orderByChild: \"$key\" is invalid.  Use orderByKey() instead.'\n    );\n  } else if (path === '$priority') {\n    throw new Error(\n      'orderByChild: \"$priority\" is invalid.  Use orderByPriority() instead.'\n    );\n  } else if (path === '$value') {\n    throw new Error(\n      'orderByChild: \"$value\" is invalid.  Use orderByValue() instead.'\n    );\n  }\n  validatePathString('orderByChild', 'path', path, false);\n  return new QueryOrderByChildConstraint(path);\n}\n\nclass QueryOrderByKeyConstraint extends QueryConstraint {\n  readonly type: 'orderByKey';\n\n  _apply<T>(query: QueryImpl): QueryImpl {\n    validateNoPreviousOrderByCall(query, 'orderByKey');\n    const newParams = queryParamsOrderBy(query._queryParams, KEY_INDEX);\n    validateQueryEndpoints(newParams);\n    return new QueryImpl(\n      query._repo,\n      query._path,\n      newParams,\n      /*orderByCalled=*/ true\n    );\n  }\n}\n\n/**\n * Creates a new `QueryConstraint` that orders by the key.\n *\n * Sorts the results of a query by their (ascending) key values.\n *\n * You can read more about `orderByKey()` in\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sort_data | Sort data}.\n */\nexport function orderByKey(): QueryConstraint {\n  return new QueryOrderByKeyConstraint();\n}\n\nclass QueryOrderByPriorityConstraint extends QueryConstraint {\n  readonly type: 'orderByPriority';\n\n  _apply<T>(query: QueryImpl): QueryImpl {\n    validateNoPreviousOrderByCall(query, 'orderByPriority');\n    const newParams = queryParamsOrderBy(query._queryParams, PRIORITY_INDEX);\n    validateQueryEndpoints(newParams);\n    return new QueryImpl(\n      query._repo,\n      query._path,\n      newParams,\n      /*orderByCalled=*/ true\n    );\n  }\n}\n\n/**\n * Creates a new `QueryConstraint` that orders by priority.\n *\n * Applications need not use priority but can order collections by\n * ordinary properties (see\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sort_data | Sort data}\n * for alternatives to priority.\n */\nexport function orderByPriority(): QueryConstraint {\n  return new QueryOrderByPriorityConstraint();\n}\n\nclass QueryOrderByValueConstraint extends QueryConstraint {\n  readonly type: 'orderByValue';\n\n  _apply<T>(query: QueryImpl): QueryImpl {\n    validateNoPreviousOrderByCall(query, 'orderByValue');\n    const newParams = queryParamsOrderBy(query._queryParams, VALUE_INDEX);\n    validateQueryEndpoints(newParams);\n    return new QueryImpl(\n      query._repo,\n      query._path,\n      newParams,\n      /*orderByCalled=*/ true\n    );\n  }\n}\n\n/**\n * Creates a new `QueryConstraint` that orders by value.\n *\n * If the children of a query are all scalar values (string, number, or\n * boolean), you can order the results by their (ascending) values.\n *\n * You can read more about `orderByValue()` in\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#sort_data | Sort data}.\n */\nexport function orderByValue(): QueryConstraint {\n  return new QueryOrderByValueConstraint();\n}\n\nclass QueryEqualToValueConstraint extends QueryConstraint {\n  readonly type: 'equalTo';\n\n  constructor(\n    private readonly _value: number | string | boolean | null,\n    private readonly _key?: string\n  ) {\n    super();\n  }\n\n  _apply<T>(query: QueryImpl): QueryImpl {\n    validateFirebaseDataArg('equalTo', this._value, query._path, false);\n    if (query._queryParams.hasStart()) {\n      throw new Error(\n        'equalTo: Starting point was already set (by another call to startAt/startAfter or ' +\n          'equalTo).'\n      );\n    }\n    if (query._queryParams.hasEnd()) {\n      throw new Error(\n        'equalTo: Ending point was already set (by another call to endAt/endBefore or ' +\n          'equalTo).'\n      );\n    }\n    return new QueryEndAtConstraint(this._value, this._key)._apply(\n      new QueryStartAtConstraint(this._value, this._key)._apply(query)\n    );\n  }\n}\n\n/**\n * Creates a `QueryConstraint` that includes children that match the specified\n * value.\n *\n * Using `startAt()`, `startAfter()`, `endBefore()`, `endAt()` and `equalTo()`\n * allows you to choose arbitrary starting and ending points for your queries.\n *\n * The optional key argument can be used to further limit the range of the\n * query. If it is specified, then children that have exactly the specified\n * value must also have exactly the specified key as their key name. This can be\n * used to filter result sets with many matches for the same value.\n *\n * You can read more about `equalTo()` in\n * {@link https://firebase.google.com/docs/database/web/lists-of-data#filtering_data | Filtering data}.\n *\n * @param value - The value to match for. The argument type depends on which\n * `orderBy*()` function was used in this query. Specify a value that matches\n * the `orderBy*()` type. When used in combination with `orderByKey()`, the\n * value must be a string.\n * @param key - The child key to start at, among the children with the\n * previously specified priority. This argument is only allowed if ordering by\n * child, value, or priority.\n */\nexport function equalTo(\n  value: number | string | boolean | null,\n  key?: string\n): QueryConstraint {\n  validateKey('equalTo', 'key', key, true);\n  return new QueryEqualToValueConstraint(value, key);\n}\n\n/**\n * Creates a new immutable instance of `Query` that is extended to also include\n * additional query constraints.\n *\n * @param query - The Query instance to use as a base for the new constraints.\n * @param queryConstraints - The list of `QueryConstraint`s to apply.\n * @throws if any of the provided query constraints cannot be combined with the\n * existing or new constraints.\n */\nexport function query(\n  query: Query,\n  ...queryConstraints: QueryConstraint[]\n): Query {\n  let queryImpl = getModularInstance(query) as QueryImpl;\n  for (const constraint of queryConstraints) {\n    queryImpl = constraint._apply(queryImpl);\n  }\n  return queryImpl;\n}\n\n/**\n * Define reference constructor in various modules\n *\n * We are doing this here to avoid several circular\n * dependency issues\n */\nsyncPointSetReferenceConstructor(ReferenceImpl);\nsyncTreeSetReferenceConstructor(ReferenceImpl);\n","/**\n * @license\n * Copyright 2021 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Deferred } from '@firebase/util';\n\nimport {\n  Repo,\n  repoOnDisconnectCancel,\n  repoOnDisconnectSet,\n  repoOnDisconnectSetWithPriority,\n  repoOnDisconnectUpdate\n} from '../core/Repo';\nimport { Path } from '../core/util/Path';\nimport {\n  validateFirebaseDataArg,\n  validateFirebaseMergeDataArg,\n  validatePriority,\n  validateWritablePath\n} from '../core/util/validation';\n\n/**\n * The `onDisconnect` class allows you to write or clear data when your client\n * disconnects from the Database server. These updates occur whether your\n * client disconnects cleanly or not, so you can rely on them to clean up data\n * even if a connection is dropped or a client crashes.\n *\n * The `onDisconnect` class is most commonly used to manage presence in\n * applications where it is useful to detect how many clients are connected and\n * when other clients disconnect. See\n * {@link https://firebase.google.com/docs/database/web/offline-capabilities | Enabling Offline Capabilities in JavaScript}\n * for more information.\n *\n * To avoid problems when a connection is dropped before the requests can be\n * transferred to the Database server, these functions should be called before\n * writing any data.\n *\n * Note that `onDisconnect` operations are only triggered once. If you want an\n * operation to occur each time a disconnect occurs, you'll need to re-establish\n * the `onDisconnect` operations each time you reconnect.\n */\nexport class OnDisconnect {\n  /** @hideconstructor */\n  constructor(private _repo: Repo, private _path: Path) {}\n\n  /**\n   * Cancels all previously queued `onDisconnect()` set or update events for this\n   * location and all children.\n   *\n   * If a write has been queued for this location via a `set()` or `update()` at a\n   * parent location, the write at this location will be canceled, though writes\n   * to sibling locations will still occur.\n   *\n   * @returns Resolves when synchronization to the server is complete.\n   */\n  cancel(): Promise<void> {\n    const deferred = new Deferred<void>();\n    repoOnDisconnectCancel(\n      this._repo,\n      this._path,\n      deferred.wrapCallback(() => {})\n    );\n    return deferred.promise;\n  }\n\n  /**\n   * Ensures the data at this location is deleted when the client is disconnected\n   * (due to closing the browser, navigating to a new page, or network issues).\n   *\n   * @returns Resolves when synchronization to the server is complete.\n   */\n  remove(): Promise<void> {\n    validateWritablePath('OnDisconnect.remove', this._path);\n    const deferred = new Deferred<void>();\n    repoOnDisconnectSet(\n      this._repo,\n      this._path,\n      null,\n      deferred.wrapCallback(() => {})\n    );\n    return deferred.promise;\n  }\n\n  /**\n   * Ensures the data at this location is set to the specified value when the\n   * client is disconnected (due to closing the browser, navigating to a new page,\n   * or network issues).\n   *\n   * `set()` is especially useful for implementing \"presence\" systems, where a\n   * value should be changed or cleared when a user disconnects so that they\n   * appear \"offline\" to other users. See\n   * {@link https://firebase.google.com/docs/database/web/offline-capabilities | Enabling Offline Capabilities in JavaScript}\n   * for more information.\n   *\n   * Note that `onDisconnect` operations are only triggered once. If you want an\n   * operation to occur each time a disconnect occurs, you'll need to re-establish\n   * the `onDisconnect` operations each time.\n   *\n   * @param value - The value to be written to this location on disconnect (can\n   * be an object, array, string, number, boolean, or null).\n   * @returns Resolves when synchronization to the Database is complete.\n   */\n  set(value: unknown): Promise<void> {\n    validateWritablePath('OnDisconnect.set', this._path);\n    validateFirebaseDataArg('OnDisconnect.set', value, this._path, false);\n    const deferred = new Deferred<void>();\n    repoOnDisconnectSet(\n      this._repo,\n      this._path,\n      value,\n      deferred.wrapCallback(() => {})\n    );\n    return deferred.promise;\n  }\n\n  /**\n   * Ensures the data at this location is set to the specified value and priority\n   * when the client is disconnected (due to closing the browser, navigating to a\n   * new page, or network issues).\n   *\n   * @param value - The value to be written to this location on disconnect (can\n   * be an object, array, string, number, boolean, or null).\n   * @param priority - The priority to be written (string, number, or null).\n   * @returns Resolves when synchronization to the Database is complete.\n   */\n  setWithPriority(\n    value: unknown,\n    priority: number | string | null\n  ): Promise<void> {\n    validateWritablePath('OnDisconnect.setWithPriority', this._path);\n    validateFirebaseDataArg(\n      'OnDisconnect.setWithPriority',\n      value,\n      this._path,\n      false\n    );\n    validatePriority('OnDisconnect.setWithPriority', priority, false);\n\n    const deferred = new Deferred<void>();\n    repoOnDisconnectSetWithPriority(\n      this._repo,\n      this._path,\n      value,\n      priority,\n      deferred.wrapCallback(() => {})\n    );\n    return deferred.promise;\n  }\n\n  /**\n   * Writes multiple values at this location when the client is disconnected (due\n   * to closing the browser, navigating to a new page, or network issues).\n   *\n   * The `values` argument contains multiple property-value pairs that will be\n   * written to the Database together. Each child property can either be a simple\n   * property (for example, \"name\") or a relative path (for example, \"name/first\")\n   * from the current location to the data to update.\n   *\n   * As opposed to the `set()` method, `update()` can be use to selectively update\n   * only the referenced properties at the current location (instead of replacing\n   * all the child properties at the current location).\n   *\n   * @param values - Object containing multiple values.\n   * @returns Resolves when synchronization to the Database is complete.\n   */\n  update(values: object): Promise<void> {\n    validateWritablePath('OnDisconnect.update', this._path);\n    validateFirebaseMergeDataArg(\n      'OnDisconnect.update',\n      values,\n      this._path,\n      false\n    );\n    const deferred = new Deferred<void>();\n    repoOnDisconnectUpdate(\n      this._repo,\n      this._path,\n      values as Record<string, unknown>,\n      deferred.wrapCallback(() => {})\n    );\n    return deferred.promise;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { assert } from '@firebase/util';\n\nimport {\n  tryParseInt,\n  MAX_NAME,\n  MIN_NAME,\n  INTEGER_32_MIN,\n  INTEGER_32_MAX\n} from '../util/util';\n\n// Modeled after base64 web-safe chars, but ordered by ASCII.\nconst PUSH_CHARS =\n  '-0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz';\n\nconst MIN_PUSH_CHAR = '-';\n\nconst MAX_PUSH_CHAR = 'z';\n\nconst MAX_KEY_LEN = 786;\n\n/**\n * Fancy ID generator that creates 20-character string identifiers with the\n * following properties:\n *\n * 1. They're based on timestamp so that they sort *after* any existing ids.\n * 2. They contain 72-bits of random data after the timestamp so that IDs won't\n *    collide with other clients' IDs.\n * 3. They sort *lexicographically* (so the timestamp is converted to characters\n *    that will sort properly).\n * 4. They're monotonically increasing. Even if you generate more than one in\n *    the same timestamp, the latter ones will sort after the former ones. We do\n *    this by using the previous random bits but \"incrementing\" them by 1 (only\n *    in the case of a timestamp collision).\n */\nexport const nextPushId = (function () {\n  // Timestamp of last push, used to prevent local collisions if you push twice\n  // in one ms.\n  let lastPushTime = 0;\n\n  // We generate 72-bits of randomness which get turned into 12 characters and\n  // appended to the timestamp to prevent collisions with other clients. We\n  // store the last characters we generated because in the event of a collision,\n  // we'll use those same characters except \"incremented\" by one.\n  const lastRandChars: number[] = [];\n\n  return function (now: number) {\n    const duplicateTime = now === lastPushTime;\n    lastPushTime = now;\n\n    let i;\n    const timeStampChars = new Array(8);\n    for (i = 7; i >= 0; i--) {\n      timeStampChars[i] = PUSH_CHARS.charAt(now % 64);\n      // NOTE: Can't use << here because javascript will convert to int and lose\n      // the upper bits.\n      now = Math.floor(now / 64);\n    }\n    assert(now === 0, 'Cannot push at time == 0');\n\n    let id = timeStampChars.join('');\n\n    if (!duplicateTime) {\n      for (i = 0; i < 12; i++) {\n        lastRandChars[i] = Math.floor(Math.random() * 64);\n      }\n    } else {\n      // If the timestamp hasn't changed since last push, use the same random\n      // number, except incremented by 1.\n      for (i = 11; i >= 0 && lastRandChars[i] === 63; i--) {\n        lastRandChars[i] = 0;\n      }\n      lastRandChars[i]++;\n    }\n    for (i = 0; i < 12; i++) {\n      id += PUSH_CHARS.charAt(lastRandChars[i]);\n    }\n    assert(id.length === 20, 'nextPushId: Length should be 20.');\n\n    return id;\n  };\n})();\n\nexport const successor = function (key: string) {\n  if (key === '' + INTEGER_32_MAX) {\n    // See https://firebase.google.com/docs/database/web/lists-of-data#data-order\n    return MIN_PUSH_CHAR;\n  }\n  const keyAsInt: number = tryParseInt(key);\n  if (keyAsInt != null) {\n    return '' + (keyAsInt + 1);\n  }\n  const next = new Array(key.length);\n\n  for (let i = 0; i < next.length; i++) {\n    next[i] = key.charAt(i);\n  }\n\n  if (next.length < MAX_KEY_LEN) {\n    next.push(MIN_PUSH_CHAR);\n    return next.join('');\n  }\n\n  let i = next.length - 1;\n\n  while (i >= 0 && next[i] === MAX_PUSH_CHAR) {\n    i--;\n  }\n\n  // `successor` was called on the largest possible key, so return the\n  // MAX_NAME, which sorts larger than all keys.\n  if (i === -1) {\n    return MAX_NAME;\n  }\n\n  const source = next[i];\n  const sourcePlusOne = PUSH_CHARS.charAt(PUSH_CHARS.indexOf(source) + 1);\n  next[i] = sourcePlusOne;\n\n  return next.slice(0, i + 1).join('');\n};\n\n// `key` is assumed to be non-empty.\nexport const predecessor = function (key: string) {\n  if (key === '' + INTEGER_32_MIN) {\n    return MIN_NAME;\n  }\n  const keyAsInt: number = tryParseInt(key);\n  if (keyAsInt != null) {\n    return '' + (keyAsInt - 1);\n  }\n  const next = new Array(key.length);\n  for (let i = 0; i < next.length; i++) {\n    next[i] = key.charAt(i);\n  }\n  // If `key` ends in `MIN_PUSH_CHAR`, the largest key lexicographically\n  // smaller than `key`, is `key[0:key.length - 1]`. The next key smaller\n  // than that, `predecessor(predecessor(key))`, is\n  //\n  // `key[0:key.length - 2] + (key[key.length - 1] - 1) + \\\n  //   { MAX_PUSH_CHAR repeated MAX_KEY_LEN - (key.length - 1) times }\n  //\n  // analogous to increment/decrement for base-10 integers.\n  //\n  // This works because lexigographic comparison works character-by-character,\n  // using length as a tie-breaker if one key is a prefix of the other.\n  if (next[next.length - 1] === MIN_PUSH_CHAR) {\n    if (next.length === 1) {\n      // See https://firebase.google.com/docs/database/web/lists-of-data#orderbykey\n      return '' + INTEGER_32_MAX;\n    }\n    delete next[next.length - 1];\n    return next.join('');\n  }\n  // Replace the last character with it's immediate predecessor, and\n  // fill the suffix of the key with MAX_PUSH_CHAR. This is the\n  // lexicographically largest possible key smaller than `key`.\n  next[next.length - 1] = PUSH_CHARS.charAt(\n    PUSH_CHARS.indexOf(next[next.length - 1]) - 1\n  );\n  return next.join('') + MAX_PUSH_CHAR.repeat(MAX_KEY_LEN - next.length);\n};\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n// eslint-disable-next-line import/no-extraneous-dependencies\nimport {\n  _FirebaseService,\n  _getProvider,\n  FirebaseApp,\n  getApp\n} from '@firebase/app';\nimport { AppCheckInternalComponentName } from '@firebase/app-check-interop-types';\nimport { FirebaseAuthInternalName } from '@firebase/auth-interop-types';\nimport { Provider } from '@firebase/component';\nimport {\n  getModularInstance,\n  createMockUserToken,\n  EmulatorMockTokenOptions,\n  getDefaultEmulatorHostnameAndPort\n} from '@firebase/util';\n\nimport { AppCheckTokenProvider } from '../core/AppCheckTokenProvider';\nimport {\n  AuthTokenProvider,\n  EmulatorTokenProvider,\n  FirebaseAuthTokenProvider\n} from '../core/AuthTokenProvider';\nimport { Repo, repoInterrupt, repoResume, repoStart } from '../core/Repo';\nimport { RepoInfo } from '../core/RepoInfo';\nimport { parseRepoInfo } from '../core/util/libs/parser';\nimport { newEmptyPath, pathIsEmpty } from '../core/util/Path';\nimport {\n  warn,\n  fatal,\n  log,\n  enableLogging as enableLoggingImpl\n} from '../core/util/util';\nimport { validateUrl } from '../core/util/validation';\nimport { BrowserPollConnection } from '../realtime/BrowserPollConnection';\nimport { TransportManager } from '../realtime/TransportManager';\nimport { WebSocketConnection } from '../realtime/WebSocketConnection';\n\nimport { ReferenceImpl } from './Reference_impl';\n\nexport { EmulatorMockTokenOptions } from '@firebase/util';\n/**\n * This variable is also defined in the firebase Node.js Admin SDK. Before\n * modifying this definition, consult the definition in:\n *\n * https://github.com/firebase/firebase-admin-node\n *\n * and make sure the two are consistent.\n */\nconst FIREBASE_DATABASE_EMULATOR_HOST_VAR = 'FIREBASE_DATABASE_EMULATOR_HOST';\n\n/**\n * Creates and caches `Repo` instances.\n */\nconst repos: {\n  [appName: string]: {\n    [dbUrl: string]: Repo;\n  };\n} = {};\n\n/**\n * If true, any new `Repo` will be created to use `ReadonlyRestClient` (for testing purposes).\n */\nlet useRestClient = false;\n\n/**\n * Update an existing `Repo` in place to point to a new host/port.\n */\nfunction repoManagerApplyEmulatorSettings(\n  repo: Repo,\n  host: string,\n  port: number,\n  tokenProvider?: AuthTokenProvider\n): void {\n  repo.repoInfo_ = new RepoInfo(\n    `${host}:${port}`,\n    /* secure= */ false,\n    repo.repoInfo_.namespace,\n    repo.repoInfo_.webSocketOnly,\n    repo.repoInfo_.nodeAdmin,\n    repo.repoInfo_.persistenceKey,\n    repo.repoInfo_.includeNamespaceInQueryParams,\n    /*isUsingEmulator=*/ true\n  );\n\n  if (tokenProvider) {\n    repo.authTokenProvider_ = tokenProvider;\n  }\n}\n\n/**\n * This function should only ever be called to CREATE a new database instance.\n * @internal\n */\nexport function repoManagerDatabaseFromApp(\n  app: FirebaseApp,\n  authProvider: Provider<FirebaseAuthInternalName>,\n  appCheckProvider?: Provider<AppCheckInternalComponentName>,\n  url?: string,\n  nodeAdmin?: boolean\n): Database {\n  let dbUrl: string | undefined = url || app.options.databaseURL;\n  if (dbUrl === undefined) {\n    if (!app.options.projectId) {\n      fatal(\n        \"Can't determine Firebase Database URL. Be sure to include \" +\n          ' a Project ID when calling firebase.initializeApp().'\n      );\n    }\n\n    log('Using default host for project ', app.options.projectId);\n    dbUrl = `${app.options.projectId}-default-rtdb.firebaseio.com`;\n  }\n\n  let parsedUrl = parseRepoInfo(dbUrl, nodeAdmin);\n  let repoInfo = parsedUrl.repoInfo;\n\n  let isEmulator: boolean;\n\n  let dbEmulatorHost: string | undefined = undefined;\n  if (typeof process !== 'undefined' && process.env) {\n    dbEmulatorHost = process.env[FIREBASE_DATABASE_EMULATOR_HOST_VAR];\n  }\n\n  if (dbEmulatorHost) {\n    isEmulator = true;\n    dbUrl = `http://${dbEmulatorHost}?ns=${repoInfo.namespace}`;\n    parsedUrl = parseRepoInfo(dbUrl, nodeAdmin);\n    repoInfo = parsedUrl.repoInfo;\n  } else {\n    isEmulator = !parsedUrl.repoInfo.secure;\n  }\n\n  const authTokenProvider =\n    nodeAdmin && isEmulator\n      ? new EmulatorTokenProvider(EmulatorTokenProvider.OWNER)\n      : new FirebaseAuthTokenProvider(app.name, app.options, authProvider);\n\n  validateUrl('Invalid Firebase Database URL', parsedUrl);\n  if (!pathIsEmpty(parsedUrl.path)) {\n    fatal(\n      'Database URL must point to the root of a Firebase Database ' +\n        '(not including a child path).'\n    );\n  }\n\n  const repo = repoManagerCreateRepo(\n    repoInfo,\n    app,\n    authTokenProvider,\n    new AppCheckTokenProvider(app.name, appCheckProvider)\n  );\n  return new Database(repo, app);\n}\n\n/**\n * Remove the repo and make sure it is disconnected.\n *\n */\nfunction repoManagerDeleteRepo(repo: Repo, appName: string): void {\n  const appRepos = repos[appName];\n  // This should never happen...\n  if (!appRepos || appRepos[repo.key] !== repo) {\n    fatal(`Database ${appName}(${repo.repoInfo_}) has already been deleted.`);\n  }\n  repoInterrupt(repo);\n  delete appRepos[repo.key];\n}\n\n/**\n * Ensures a repo doesn't already exist and then creates one using the\n * provided app.\n *\n * @param repoInfo - The metadata about the Repo\n * @returns The Repo object for the specified server / repoName.\n */\nfunction repoManagerCreateRepo(\n  repoInfo: RepoInfo,\n  app: FirebaseApp,\n  authTokenProvider: AuthTokenProvider,\n  appCheckProvider: AppCheckTokenProvider\n): Repo {\n  let appRepos = repos[app.name];\n\n  if (!appRepos) {\n    appRepos = {};\n    repos[app.name] = appRepos;\n  }\n\n  let repo = appRepos[repoInfo.toURLString()];\n  if (repo) {\n    fatal(\n      'Database initialized multiple times. Please make sure the format of the database URL matches with each database() call.'\n    );\n  }\n  repo = new Repo(repoInfo, useRestClient, authTokenProvider, appCheckProvider);\n  appRepos[repoInfo.toURLString()] = repo;\n\n  return repo;\n}\n\n/**\n * Forces us to use ReadonlyRestClient instead of PersistentConnection for new Repos.\n */\nexport function repoManagerForceRestClient(forceRestClient: boolean): void {\n  useRestClient = forceRestClient;\n}\n\n/**\n * Class representing a Firebase Realtime Database.\n */\nexport class Database implements _FirebaseService {\n  /** Represents a `Database` instance. */\n  readonly 'type' = 'database';\n\n  /** Track if the instance has been used (root or repo accessed) */\n  _instanceStarted: boolean = false;\n\n  /** Backing state for root_ */\n  private _rootInternal?: ReferenceImpl;\n\n  /** @hideconstructor */\n  constructor(\n    public _repoInternal: Repo,\n    /** The {@link @firebase/app#FirebaseApp} associated with this Realtime Database instance. */\n    readonly app: FirebaseApp\n  ) {}\n\n  get _repo(): Repo {\n    if (!this._instanceStarted) {\n      repoStart(\n        this._repoInternal,\n        this.app.options.appId,\n        this.app.options['databaseAuthVariableOverride']\n      );\n      this._instanceStarted = true;\n    }\n    return this._repoInternal;\n  }\n\n  get _root(): ReferenceImpl {\n    if (!this._rootInternal) {\n      this._rootInternal = new ReferenceImpl(this._repo, newEmptyPath());\n    }\n    return this._rootInternal;\n  }\n\n  _delete(): Promise<void> {\n    if (this._rootInternal !== null) {\n      repoManagerDeleteRepo(this._repo, this.app.name);\n      this._repoInternal = null;\n      this._rootInternal = null;\n    }\n    return Promise.resolve();\n  }\n\n  _checkNotDeleted(apiName: string) {\n    if (this._rootInternal === null) {\n      fatal('Cannot call ' + apiName + ' on a deleted database.');\n    }\n  }\n}\n\nfunction checkTransportInit() {\n  if (TransportManager.IS_TRANSPORT_INITIALIZED) {\n    warn(\n      'Transport has already been initialized. Please call this function before calling ref or setting up a listener'\n    );\n  }\n}\n\n/**\n * Force the use of websockets instead of longPolling.\n */\nexport function forceWebSockets() {\n  checkTransportInit();\n  BrowserPollConnection.forceDisallow();\n}\n\n/**\n * Force the use of longPolling instead of websockets. This will be ignored if websocket protocol is used in databaseURL.\n */\nexport function forceLongPolling() {\n  checkTransportInit();\n  WebSocketConnection.forceDisallow();\n  BrowserPollConnection.forceAllow();\n}\n\n/**\n * Returns the instance of the Realtime Database SDK that is associated\n * with the provided {@link @firebase/app#FirebaseApp}. Initializes a new instance with\n * with default settings if no instance exists or if the existing instance uses\n * a custom database URL.\n *\n * @param app - The {@link @firebase/app#FirebaseApp} instance that the returned Realtime\n * Database instance is associated with.\n * @param url - The URL of the Realtime Database instance to connect to. If not\n * provided, the SDK connects to the default instance of the Firebase App.\n * @returns The `Database` instance of the provided app.\n */\nexport function getDatabase(\n  app: FirebaseApp = getApp(),\n  url?: string\n): Database {\n  const db = _getProvider(app, 'database').getImmediate({\n    identifier: url\n  }) as Database;\n  if (!db._instanceStarted) {\n    const emulator = getDefaultEmulatorHostnameAndPort('database');\n    if (emulator) {\n      connectDatabaseEmulator(db, ...emulator);\n    }\n  }\n  return db;\n}\n\n/**\n * Modify the provided instance to communicate with the Realtime Database\n * emulator.\n *\n * <p>Note: This method must be called before performing any other operation.\n *\n * @param db - The instance to modify.\n * @param host - The emulator host (ex: localhost)\n * @param port - The emulator port (ex: 8080)\n * @param options.mockUserToken - the mock auth token to use for unit testing Security Rules\n */\nexport function connectDatabaseEmulator(\n  db: Database,\n  host: string,\n  port: number,\n  options: {\n    mockUserToken?: EmulatorMockTokenOptions | string;\n  } = {}\n): void {\n  db = getModularInstance(db);\n  db._checkNotDeleted('useEmulator');\n  if (db._instanceStarted) {\n    fatal(\n      'Cannot call useEmulator() after instance has already been initialized.'\n    );\n  }\n\n  const repo = db._repoInternal;\n  let tokenProvider: EmulatorTokenProvider | undefined = undefined;\n  if (repo.repoInfo_.nodeAdmin) {\n    if (options.mockUserToken) {\n      fatal(\n        'mockUserToken is not supported by the Admin SDK. For client access with mock users, please use the \"firebase\" package instead of \"firebase-admin\".'\n      );\n    }\n    tokenProvider = new EmulatorTokenProvider(EmulatorTokenProvider.OWNER);\n  } else if (options.mockUserToken) {\n    const token =\n      typeof options.mockUserToken === 'string'\n        ? options.mockUserToken\n        : createMockUserToken(options.mockUserToken, db.app.options.projectId);\n    tokenProvider = new EmulatorTokenProvider(token);\n  }\n\n  // Modify the repo to apply emulator settings\n  repoManagerApplyEmulatorSettings(repo, host, port, tokenProvider);\n}\n\n/**\n * Disconnects from the server (all Database operations will be completed\n * offline).\n *\n * The client automatically maintains a persistent connection to the Database\n * server, which will remain active indefinitely and reconnect when\n * disconnected. However, the `goOffline()` and `goOnline()` methods may be used\n * to control the client connection in cases where a persistent connection is\n * undesirable.\n *\n * While offline, the client will no longer receive data updates from the\n * Database. However, all Database operations performed locally will continue to\n * immediately fire events, allowing your application to continue behaving\n * normally. Additionally, each operation performed locally will automatically\n * be queued and retried upon reconnection to the Database server.\n *\n * To reconnect to the Database and begin receiving remote events, see\n * `goOnline()`.\n *\n * @param db - The instance to disconnect.\n */\nexport function goOffline(db: Database): void {\n  db = getModularInstance(db);\n  db._checkNotDeleted('goOffline');\n  repoInterrupt(db._repo);\n}\n\n/**\n * Reconnects to the server and synchronizes the offline Database state\n * with the server state.\n *\n * This method should be used after disabling the active connection with\n * `goOffline()`. Once reconnected, the client will transmit the proper data\n * and fire the appropriate events so that your client \"catches up\"\n * automatically.\n *\n * @param db - The instance to reconnect.\n */\nexport function goOnline(db: Database): void {\n  db = getModularInstance(db);\n  db._checkNotDeleted('goOnline');\n  repoResume(db._repo);\n}\n\n/**\n * Logs debugging information to the console.\n *\n * @param enabled - Enables logging if `true`, disables logging if `false`.\n * @param persistent - Remembers the logging state between page refreshes if\n * `true`.\n */\nexport function enableLogging(enabled: boolean, persistent?: boolean);\n\n/**\n * Logs debugging information to the console.\n *\n * @param logger - A custom logger function to control how things get logged.\n */\nexport function enableLogging(logger: (message: string) => unknown);\n\nexport function enableLogging(\n  logger: boolean | ((message: string) => unknown),\n  persistent?: boolean\n): void {\n  enableLoggingImpl(logger, persistent);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst SERVER_TIMESTAMP = {\n  '.sv': 'timestamp'\n};\n\n/**\n * Returns a placeholder value for auto-populating the current timestamp (time\n * since the Unix epoch, in milliseconds) as determined by the Firebase\n * servers.\n */\nexport function serverTimestamp(): object {\n  return SERVER_TIMESTAMP;\n}\n\n/**\n * Returns a placeholder value that can be used to atomically increment the\n * current database value by the provided delta.\n *\n * @param delta - the amount to modify the current value atomically.\n * @returns A placeholder value for modifying data atomically server-side.\n */\nexport function increment(delta: number): object {\n  return {\n    '.sv': {\n      'increment': delta\n    }\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { getModularInstance, Deferred } from '@firebase/util';\n\nimport { repoStartTransaction } from '../core/Repo';\nimport { PRIORITY_INDEX } from '../core/snap/indexes/PriorityIndex';\nimport { Node } from '../core/snap/Node';\nimport { validateWritablePath } from '../core/util/validation';\n\nimport { DatabaseReference } from './Reference';\nimport { DataSnapshot, onValue, ReferenceImpl } from './Reference_impl';\n\n/** An options object to configure transactions. */\nexport interface TransactionOptions {\n  /**\n   * By default, events are raised each time the transaction update function\n   * runs. So if it is run multiple times, you may see intermediate states. You\n   * can set this to false to suppress these intermediate states and instead\n   * wait until the transaction has completed before events are raised.\n   */\n  readonly applyLocally?: boolean;\n}\n\n/**\n * A type for the resolve value of {@link runTransaction}.\n */\nexport class TransactionResult {\n  /** @hideconstructor */\n  constructor(\n    /** Whether the transaction was successfully committed. */\n    readonly committed: boolean,\n    /** The resulting data snapshot. */\n    readonly snapshot: DataSnapshot\n  ) {}\n\n  /** Returns a JSON-serializable representation of this object. */\n  toJSON(): object {\n    return { committed: this.committed, snapshot: this.snapshot.toJSON() };\n  }\n}\n\n/**\n * Atomically modifies the data at this location.\n *\n * Atomically modify the data at this location. Unlike a normal `set()`, which\n * just overwrites the data regardless of its previous value, `runTransaction()` is\n * used to modify the existing value to a new value, ensuring there are no\n * conflicts with other clients writing to the same location at the same time.\n *\n * To accomplish this, you pass `runTransaction()` an update function which is\n * used to transform the current value into a new value. If another client\n * writes to the location before your new value is successfully written, your\n * update function will be called again with the new current value, and the\n * write will be retried. This will happen repeatedly until your write succeeds\n * without conflict or you abort the transaction by not returning a value from\n * your update function.\n *\n * Note: Modifying data with `set()` will cancel any pending transactions at\n * that location, so extreme care should be taken if mixing `set()` and\n * `runTransaction()` to update the same data.\n *\n * Note: When using transactions with Security and Firebase Rules in place, be\n * aware that a client needs `.read` access in addition to `.write` access in\n * order to perform a transaction. This is because the client-side nature of\n * transactions requires the client to read the data in order to transactionally\n * update it.\n *\n * @param ref - The location to atomically modify.\n * @param transactionUpdate - A developer-supplied function which will be passed\n * the current data stored at this location (as a JavaScript object). The\n * function should return the new value it would like written (as a JavaScript\n * object). If `undefined` is returned (i.e. you return with no arguments) the\n * transaction will be aborted and the data at this location will not be\n * modified.\n * @param options - An options object to configure transactions.\n * @returns A `Promise` that can optionally be used instead of the `onComplete`\n * callback to handle success and failure.\n */\nexport function runTransaction(\n  ref: DatabaseReference,\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  transactionUpdate: (currentData: any) => unknown,\n  options?: TransactionOptions\n): Promise<TransactionResult> {\n  ref = getModularInstance(ref);\n\n  validateWritablePath('Reference.transaction', ref._path);\n\n  if (ref.key === '.length' || ref.key === '.keys') {\n    throw (\n      'Reference.transaction failed: ' + ref.key + ' is a read-only object.'\n    );\n  }\n\n  const applyLocally = options?.applyLocally ?? true;\n  const deferred = new Deferred<TransactionResult>();\n\n  const promiseComplete = (\n    error: Error | null,\n    committed: boolean,\n    node: Node | null\n  ) => {\n    let dataSnapshot: DataSnapshot | null = null;\n    if (error) {\n      deferred.reject(error);\n    } else {\n      dataSnapshot = new DataSnapshot(\n        node,\n        new ReferenceImpl(ref._repo, ref._path),\n        PRIORITY_INDEX\n      );\n      deferred.resolve(new TransactionResult(committed, dataSnapshot));\n    }\n  };\n\n  // Add a watch to make sure we get server updates.\n  const unwatcher = onValue(ref, () => {});\n\n  repoStartTransaction(\n    ref._repo,\n    ref._path,\n    transactionUpdate,\n    promiseComplete,\n    unwatcher,\n    applyLocally\n  );\n\n  return deferred.promise;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { PersistentConnection } from '../core/PersistentConnection';\nimport { RepoInfo } from '../core/RepoInfo';\nimport { Connection } from '../realtime/Connection';\n\nimport { repoManagerForceRestClient } from './Database';\n\nexport const DataConnection = PersistentConnection;\n\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\n(PersistentConnection.prototype as any).simpleListen = function (\n  pathString: string,\n  onComplete: (a: unknown) => void\n) {\n  this.sendRequest('q', { p: pathString }, onComplete);\n};\n\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\n(PersistentConnection.prototype as any).echo = function (\n  data: unknown,\n  onEcho: (a: unknown) => void\n) {\n  this.sendRequest('echo', { d: data }, onEcho);\n};\n\n// RealTimeConnection properties that we use in tests.\nexport const RealTimeConnection = Connection;\n\n/**\n * @internal\n */\nexport const hijackHash = function (newHash: () => string) {\n  const oldPut = PersistentConnection.prototype.put;\n  PersistentConnection.prototype.put = function (\n    pathString,\n    data,\n    onComplete,\n    hash\n  ) {\n    if (hash !== undefined) {\n      hash = newHash();\n    }\n    oldPut.call(this, pathString, data, onComplete, hash);\n  };\n  return function () {\n    PersistentConnection.prototype.put = oldPut;\n  };\n};\n\nexport const ConnectionTarget = RepoInfo;\n\n/**\n * Forces the RepoManager to create Repos that use ReadonlyRestClient instead of PersistentConnection.\n * @internal\n */\nexport const forceRestClient = function (forceRestClient: boolean) {\n  repoManagerForceRestClient(forceRestClient);\n};\n","/**\n * Firebase Realtime Database\n *\n * @packageDocumentation\n */\n\n/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Database } from './api/Database';\nimport { registerDatabase } from './register';\n\nexport * from './api';\n\nregisterDatabase();\n\ndeclare module '@firebase/component' {\n  interface NameServiceMapping {\n    'database': Database;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Path } from '../util/Path';\n\nimport { Index } from './indexes/Index';\n\n/**\n * Node is an interface defining the common functionality for nodes in\n * a DataSnapshot.\n *\n * @interface\n */\nexport interface Node {\n  /**\n   * Whether this node is a leaf node.\n   * @returns Whether this is a leaf node.\n   */\n  isLeafNode(): boolean;\n\n  /**\n   * Gets the priority of the node.\n   * @returns The priority of the node.\n   */\n  getPriority(): Node;\n\n  /**\n   * Returns a duplicate node with the new priority.\n   * @param newPriorityNode - New priority to set for the node.\n   * @returns Node with new priority.\n   */\n  updatePriority(newPriorityNode: Node): Node;\n\n  /**\n   * Returns the specified immediate child, or null if it doesn't exist.\n   * @param childName - The name of the child to retrieve.\n   * @returns The retrieved child, or an empty node.\n   */\n  getImmediateChild(childName: string): Node;\n\n  /**\n   * Returns a child by path, or null if it doesn't exist.\n   * @param path - The path of the child to retrieve.\n   * @returns The retrieved child or an empty node.\n   */\n  getChild(path: Path): Node;\n\n  /**\n   * Returns the name of the child immediately prior to the specified childNode, or null.\n   * @param childName - The name of the child to find the predecessor of.\n   * @param childNode - The node to find the predecessor of.\n   * @param index - The index to use to determine the predecessor\n   * @returns The name of the predecessor child, or null if childNode is the first child.\n   */\n  getPredecessorChildName(\n    childName: string,\n    childNode: Node,\n    index: Index\n  ): string | null;\n\n  /**\n   * Returns a duplicate node, with the specified immediate child updated.\n   * Any value in the node will be removed.\n   * @param childName - The name of the child to update.\n   * @param newChildNode - The new child node\n   * @returns The updated node.\n   */\n  updateImmediateChild(childName: string, newChildNode: Node): Node;\n\n  /**\n   * Returns a duplicate node, with the specified child updated.  Any value will\n   * be removed.\n   * @param path - The path of the child to update.\n   * @param newChildNode - The new child node, which may be an empty node\n   * @returns The updated node.\n   */\n  updateChild(path: Path, newChildNode: Node): Node;\n\n  /**\n   * True if the immediate child specified exists\n   */\n  hasChild(childName: string): boolean;\n\n  /**\n   * @returns True if this node has no value or children.\n   */\n  isEmpty(): boolean;\n\n  /**\n   * @returns The number of children of this node.\n   */\n  numChildren(): number;\n\n  /**\n   * Calls action for each child.\n   * @param action - Action to be called for\n   * each child.  It's passed the child name and the child node.\n   * @returns The first truthy value return by action, or the last falsey one\n   */\n  forEachChild(index: Index, action: (a: string, b: Node) => void): unknown;\n\n  /**\n   * @param exportFormat - True for export format (also wire protocol format).\n   * @returns Value of this node as JSON.\n   */\n  val(exportFormat?: boolean): unknown;\n\n  /**\n   * @returns hash representing the node contents.\n   */\n  hash(): string;\n\n  /**\n   * @param other - Another node\n   * @returns -1 for less than, 0 for equal, 1 for greater than other\n   */\n  compareTo(other: Node): number;\n\n  /**\n   * @returns Whether or not this snapshot equals other\n   */\n  equals(other: Node): boolean;\n\n  /**\n   * @returns This node, with the specified index now available\n   */\n  withIndex(indexDefinition: Index): Node;\n\n  isIndexed(indexDefinition: Index): boolean;\n}\n\nexport class NamedNode {\n  constructor(public name: string, public node: Node) {}\n\n  static Wrap(name: string, node: Node) {\n    return new NamedNode(name, node);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { deepCopy, contains } from '@firebase/util';\n\n/**\n * Tracks a collection of stats.\n */\nexport class StatsCollection {\n  private counters_: { [k: string]: number } = {};\n\n  incrementCounter(name: string, amount: number = 1) {\n    if (!contains(this.counters_, name)) {\n      this.counters_[name] = 0;\n    }\n\n    this.counters_[name] += amount;\n  }\n\n  get() {\n    return deepCopy(this.counters_);\n  }\n}\n","import { initializeApp } from 'firebase/app';\nimport { getDatabase, ref, set } from 'firebase/database';\n\nconst API_KEY = 'AIzaSyDxNwmZzHZ-vdGILRkmWY0qu02lzG2Ospc';\n\nfirebaseConfig = {\n  databaseURL: `gs://books-project-c0eb5.appspot.com`,\n};\n\nconst app = initializeApp(firebaseConfig);\n\n// const database = getDatabase(app);\n\nfunction writeUserData(userId, name, email) {\n  const db = getDatabase(app);\n  console.log(db);\n\n  set(ref(db, 'users/' + userId), {\n    username: name,\n    email: email,\n  });\n}\n\nwriteUserData(\n  'DKt5yaLfQNTI9LVZtnLPhYqLJk63',\n  'ilya',\n  'tkachenkoilya07@icloud.com'\n);\n\nconst openBtn = document.querySelector('.user-btn');\nopenBtn.addEventListener('click', openModal);\n\nfunction openModal() {\n  const modal = document.querySelector('.modal-form-auth');\n  modal.style.display = 'block';\n  modal.innerHTML = getAuthForm();\n  document\n    .getElementById('auth-form')\n    .addEventListener('submit', authFormHandler, { once: true });\n  document\n    .querySelector('.close-button-auth')\n    .addEventListener('click', closeModal);\n}\n\nfunction closeModal(e) {\n  const modal = document.querySelector('.modal-form-auth');\n  modal.style.display = 'none';\n}\n\nfunction authFormHandler(e) {\n  e.preventDefault();\n  const email = document.getElementById('email').value;\n  const password = document.getElementById('password').value;\n\n  authWithEmailAmdPassword(email, password);\n}\n\nfunction getAuthForm() {\n  return `\n    <div class=\"modal-body-auth\">\n      <div class=\"modal-content-auth\">\n        <form class=\"form\" id=\"auth-form\">\n          <h2 class=\"title-auth\">Authentication</h2>\n          <div class=\"form-group\">\n            <input class=\"input-auth\" type=\"email\" id=\"email\"  required>\n            <label class=\"form-text-auth\" for=\"email\">Email</label>\n          </div>\n          <div class=\"form-group\">\n            <input class=\"input-auth\" type=\"password\" id=\"password\" name=\"password\" required>\n            <label class=\"form-text-auth\" for=\"password\">Пароль</label>\n          </div>\n          <button type=\"submit\" class=\"submit-btn\">Войти</button>\n          <button class=\"close-button-auth\">Закрыть</button>\n        </form>\n      </div>\n    </div>\n  `;\n}\n\nfunction authWithEmailAmdPassword(email, password) {\n  return fetch(\n    `https://identitytoolkit.googleapis.com/v1/accounts:signInWithPassword?key=${API_KEY}`,\n    {\n      method: 'POST',\n      body: JSON.stringify({\n        email,\n        password,\n        returnSecureToken: true,\n      }),\n      headers: {\n        'Content-Type': 'application/json',\n      },\n    }\n  )\n    .then(res => res.json())\n    .then(data => {\n      console.log(data);\n    });\n}\n"],"names":["$ef7689007096c8a0$export$6503ec6e8aabbaf","$ef7689007096c8a0$export$f7ad0328861e2f03","$ef7689007096c8a0$var$mapping","pairs","keys","Object","i","length","id","resolved","Error","parcelRequire","register","JSON","parse","$91c121cc5c1db5c1$exports","URL","resolve","import","meta","url","toString","$71c3df171358e3c8$exports","$8bd5ab39173201c3$exports","$f30b7d98444c0d1c$exports","$202af326571d535e$exports","$cdbd09cd0c4927ae$exports","$a96bd98d7a6c7a18$exports","$64f57042652a9010$exports","$d4142c814a51c06c$exports","$5daf0fa05610701c$exports","$01824121984d7183$exports","$ed3eb9de00996d34$exports","$7da966594977f5d5$exports","$bae4f5c581f3ceb6$exports","$2fc33e6d557174be$exports","$6900626ab4b4a11a$exports","$e94eab2edd7bef3c$exports","$cee3834f03e8eb1e$exports","$a1ade7d90e1dfcbe$var$supportArray","title","img","$parcel$interopDefault","img2x","$a1ade7d90e1dfcbe$var$supportList","document","querySelector","$a1ade7d90e1dfcbe$var$markup","map","ind","String","padStart","join","insertAdjacentHTML","addEventListener","evt","target","classList","contains","$a1ade7d90e1dfcbe$var$position","$a1ade7d90e1dfcbe$var$list","$a1ade7d90e1dfcbe$var$sliderButton","$a1ade7d90e1dfcbe$var$itemsSupport","querySelectorAll","$a1ade7d90e1dfcbe$var$itemsCount","forEach","item","style","minHeight","windowWidth","window","innerWidth","Math","abs","$a1ade7d90e1dfcbe$var$slidesToShow","$a1ade7d90e1dfcbe$var$getItemsBottom","$a1ade7d90e1dfcbe$var$slidesToScroll","transition","$a1ade7d90e1dfcbe$var$setPosition","setTimeout","transform","$cef2a1ae0ba54a58$export$29d05579bd9deab1","bookId","fetch","then","response","ok","status","json","$1924252fdcea616a$var$refs","divEl","allcategory","onecategoryEl","categoriesList","data","book","markup","list_name","e","preventDefault","activeBook","remove","add","titleCategory","titleTextContent","textContent","bookCategory","$1924252fdcea616a$var$renderMarkupBooksByCategory","author","book_image","_id","innerHTML","$4a2a19379962dbb9$var$refs","async","booksArr","category","markup_base","books","push","localStorage","setItem","stringify","nodeName","switchInput","addDarkClassToHTML","getItem","toggle","error","console","log","checked","event","removeItem","slider","updateSliderClass","$b602d53b73aaec65$var$modalBody","$b602d53b73aaec65$var$modalOpenWindow","$b602d53b73aaec65$var$modalMain","$b602d53b73aaec65$var$bookCover","$b602d53b73aaec65$var$modalTitle","$b602d53b73aaec65$var$modalAuthor","$b602d53b73aaec65$var$modalDescription","$b602d53b73aaec65$var$amazon","$b602d53b73aaec65$var$apple","$b602d53b73aaec65$var$bookShop","$b602d53b73aaec65$var$closeModal","visibility","opacity","removeEventListener","$b602d53b73aaec65$var$onOverlayCloseModal","$b602d53b73aaec65$var$onEscCloseModal","code","$b602d53b73aaec65$var$currentBook","card","dataset","src","alt","description","buy_links","arr","name","href","$b602d53b73aaec65$var$topBookShopLink","$b602d53b73aaec65$var$createMarkup","catch","$8aad853c076397e7$var$menuOpen","$8aad853c076397e7$var$iconBurger","$8aad853c076397e7$var$iconClose","$391299e0893a3dfa$var$cachedSetTimeout","$391299e0893a3dfa$var$cachedClearTimeout","$391299e0893a3dfa$var$process","$391299e0893a3dfa$exports","$391299e0893a3dfa$var$defaultSetTimout","$391299e0893a3dfa$var$defaultClearTimeout","$391299e0893a3dfa$var$runTimeout","fun","call","this","clearTimeout","e1","$391299e0893a3dfa$var$currentQueue","$391299e0893a3dfa$var$queue","$391299e0893a3dfa$var$draining","$391299e0893a3dfa$var$queueIndex","$391299e0893a3dfa$var$cleanUpNextTick","concat","$391299e0893a3dfa$var$drainQueue","timeout","len","run","marker","$391299e0893a3dfa$var$runClearTimeout","$391299e0893a3dfa$var$Item","array","$391299e0893a3dfa$var$noop","nextTick","args","Array","arguments","prototype","apply","browser","env","argv","version","versions","on","addListener","once","off","removeListener","removeAllListeners","emit","prependListener","prependOnceListener","listeners","binding","cwd","chdir","dir","umask","$b197424204fd80b4$export$588c7fdda06fbb0a","assertion","message","$b197424204fd80b4$export$a39cad550e7ab28a","$b197424204fd80b4$var$stringToByteArray$1","str","out","p","c","charCodeAt","charToByteMapWebSafe_","ENCODED_VALS_BASE","HAS_NATIVE_SUPPORT","atob","encodeByteArray","input","webSafe","isArray","init_","output","byte1","haveByte2","byte2","haveByte3","byte3","outByte1","outByte2","outByte3","outByte4","byteToCharMap","decodeString","bytes","pos","c1","fromCharCode","stringToByteArray","c2","u","c3","$b197424204fd80b4$var$byteArrayToString","decodeStringToByteArray","charToByteMap","charAt","byte4","$b197424204fd80b4$export$55ca9d4bee46aeb3","byteToCharMap_","charToByteMap_","byteToCharMapWebSafe_","ENCODED_VALS","ENCODED_VALS_WEBSAFE","$b197424204fd80b4$export$e510a73ee562749","utf8Bytes","$b197424204fd80b4$export$4b5284a3025a455","replace","$b197424204fd80b4$export$c62426fdd000a97e","$b197424204fd80b4$export$b3b2de96497acc47","$b197424204fd80b4$export$6c40052bed430212","$b197424204fd80b4$export$54e9fb29908872fa","source","constructor","Date","getTime","undefined","prop","hasOwnProperty","$parcel$global","$b197424204fd80b4$export$a4e55266d2135a7f","__FIREBASE_DEFAULTS__","$b197424204fd80b4$export$212bb2fc580a90a8","$b197424204fd80b4$var$getDefaultsFromGlobal","$b197424204fd80b4$var$getDefaultsFromEnvVariable","match","cookie","decoded","$b197424204fd80b4$var$getDefaultsFromCookie","info","$b197424204fd80b4$export$a3febcf1f14a3a0c","productName","host","_a","emulatorHosts","_b","$b197424204fd80b4$export$9c11895284c8adad","lastIndexOf","separatorIndex","port","parseInt","substring","$b197424204fd80b4$export$3dfb6827a9f89756","config","$b197424204fd80b4$export$85f6557964517f1a","wrapCallback","callback","value","reject","promise","Promise","$b197424204fd80b4$export$367bf224123348f1","token","projectId","uid","project","iat","sub","user_id","payload","assign","iss","alg","type","navigator","$b197424204fd80b4$export$872f8323f01d7ae0","test","$b197424204fd80b4$export$c36915b22ce77c19","$b197424204fd80b4$export$5d1d834fbbf8bab7","indexedDB","customData","$b197424204fd80b4$export$dd24e9cd51226c56","captureStackTrace","$b197424204fd80b4$export$3fa6e1b18a3b2d40","create","template","errors","key","$b197424204fd80b4$var$replaceTemplate","fullMessage","serviceName","fullCode","service","$b197424204fd80b4$export$c5a53ce6a17cf18d","$b197424204fd80b4$export$fac44ee5b035f737","$b197424204fd80b4$export$2f872c0f2117be69","header","claims","signature","parts","split","$b197424204fd80b4$export$9565ca3d387f8aa0","$b197424204fd80b4$export$2344b14b097df817","obj","$b197424204fd80b4$export$e51ae4db7b428f67","$b197424204fd80b4$export$dd1bc94b04021eeb","$307d2bd0b522285b$export$16fa2f45be04daa8","mode","instantiationMode","multipleInstances","props","serviceProps","onInstanceCreated","instanceFactory","$307d2bd0b522285b$export$2881499e37b75b9a","instancesDeferred","has","normalizedIdentifier","deferred","set","isInitialized","shouldAutoInitialize","get","normalizeInstanceIdentifier","options","identifier","optional","component","$307d2bd0b522285b$var$isComponentEager","getOrInitializeService","instanceIdentifier","instanceDeferred","entries","instance","delete","instancesOptions","instances","services","from","values","all","filter","INTERNAL","_delete","opts","isComponentSet","onInit","existingCallbacks","onInitCallbacks","Set","existingInstance","invokeOnInitCallbacks","callbacks","container","$577b55f579ec2041$var$instances","$577b55f579ec2041$export$243e62d78d3b544d","LogLevel1","$577b55f579ec2041$var$levelStringToEnum","DEBUG","VERBOSE","INFO","ERROR","SILENT","$577b55f579ec2041$var$defaultLogLevel","$577b55f579ec2041$var$ConsoleMethod","WARN","$577b55f579ec2041$var$defaultLogHandler","logType","logLevel","now","toISOString","method","_logLevel","val","TypeError","logHandler","_logHandler","userLogHandler","_userLogHandler","$a6f488ce4cf7dbe7$var$idbProxyableTypes","$a6f488ce4cf7dbe7$var$cursorAdvanceMethods","$a6f488ce4cf7dbe7$var$cursorRequestMap","WeakMap","$a6f488ce4cf7dbe7$var$transactionDoneMap","$a6f488ce4cf7dbe7$var$transactionStoreNamesMap","$a6f488ce4cf7dbe7$var$transformCache","$a6f488ce4cf7dbe7$export$407448d2b89b1813","$a6f488ce4cf7dbe7$var$idbProxyTraps","receiver","IDBTransaction","objectStoreNames","objectStore","$a6f488ce4cf7dbe7$export$efccba1c4a2ef57b","$a6f488ce4cf7dbe7$var$wrapFunction","func","IDBDatabase","transaction","IDBCursor","advance","continue","continuePrimaryKey","includes","$a6f488ce4cf7dbe7$export$3b14a55fb2447963","storeNames","tx","sort","$a6f488ce4cf7dbe7$var$transformCachableValue","done","unlisten","complete","DOMException","$a6f488ce4cf7dbe7$var$cacheDonePromiseForTransaction","object","IDBObjectStore","IDBIndex","some","Proxy","IDBRequest","request","success","result","$a6f488ce4cf7dbe7$var$promisifyRequest","newValue","$92f73a92431170de$export$ca0ed41b1a2af7e","blocked","upgrade","blocking","terminated","open","openPromise","oldVersion","newVersion","db","$92f73a92431170de$var$readMethods","$92f73a92431170de$var$writeMethods","$92f73a92431170de$var$cachedMethods","Map","$92f73a92431170de$var$getMethod","target1","targetFuncName","useIndex","isWrite","storeName","store","index","shift","oldTraps","$d7defabc17f02990$var$PlatformLoggerServiceImpl","getPlatformInfoString","getProviders","provider","getImmediate","databaseCompatName","$577b55f579ec2041$export$efa9a398d6368992","$d7defabc17f02990$var$PLATFORM_LOG_STRING","$d7defabc17f02990$export$b4e3c36c855b14b5","$d7defabc17f02990$export$fa5244b94c62d36a","app","addComponent","$d7defabc17f02990$var$logger","debug","$d7defabc17f02990$export$c930050e7bb63965","componentName","$d7defabc17f02990$export$9566bce3835c0f28","$d7defabc17f02990$export$fa0d6da0f5838f50","name1","heartbeatController","getProvider","triggerHeartbeat","$d7defabc17f02990$var$ERROR_FACTORY","_automaticDataCollectionEnabled","automaticDataCollectionEnabled","checkDestroyed","_name","_options","_config","_container","_isDeleted","isDeleted","appName","rawConfig","name4","existingApp","$b197424204fd80b4$export$9cb4719e2e525b7a","$307d2bd0b522285b$export$436a80eea5d5c0c5","$d7defabc17f02990$var$FirebaseAppImpl","newApp","name5","$d7defabc17f02990$export$c55cfd413944906d","$d7defabc17f02990$export$d29d5299a7137abc","libraryKeyOrName","version1","variant","library","versionMismatch","libraryMismatch","warning","warn","preExist","DB_CHECK_NAME","self","onsuccess","close","deleteDatabase","onupgradeneeded","onerror","$668b2310913a4fe8$var$SDK_VERSION","$668b2310913a4fe8$var$DOMStorageWrapper","domStorage_","prefixedName_","storedVal","prefix_","$668b2310913a4fe8$var$MemoryStorage","cache_","isInMemoryStorage","$668b2310913a4fe8$var$createStoragefor","domStorageName","domStorage","$668b2310913a4fe8$var$PersistentStorage","$668b2310913a4fe8$var$SessionStorage","$668b2310913a4fe8$var$sha1","$b197424204fd80b4$export$655666783217a925","sha11","$b197424204fd80b4$export$c85d589bf4e25fef","digest","sha1Bytes","$668b2310913a4fe8$var$buildLogMessage_","varArgs","arg","$668b2310913a4fe8$var$firstLog_","$668b2310913a4fe8$var$enableLogging$1","logger_","persistent","$b197424204fd80b4$export$a7a9523472993e97","$668b2310913a4fe8$var$logClient","$668b2310913a4fe8$var$logger","bind","$668b2310913a4fe8$var$log","$668b2310913a4fe8$var$logWrapper","prefix","$668b2310913a4fe8$var$isInvalidJSONNumber","Number","POSITIVE_INFINITY","NEGATIVE_INFINITY","$668b2310913a4fe8$var$nameCompare","a","b","bAsInt","aAsInt","$668b2310913a4fe8$var$requireKey","$668b2310913a4fe8$var$ObjectToUniqueKey","k","$668b2310913a4fe8$var$splitStringBySize","segsize","dataSegs","$668b2310913a4fe8$var$each","fn","v","bias","s","f","ln","Infinity","min","floor","LN2","round","pow","bits","reverse","hexByteString","hexByte","substr","toLowerCase","$668b2310913a4fe8$var$INTEGER_REGEXP_","RegExp","$668b2310913a4fe8$var$tryParseInt","intVal","$668b2310913a4fe8$var$exceptionGuard","stack","$668b2310913a4fe8$var$warn","$668b2310913a4fe8$var$setTimeoutNonBlocking","time","Deno","unrefTimer","forceRefresh","appCheck","getToken","listener","appCheckProvider","addTokenListener","notifyForInvalidToken","appName_","auth_","error2","addAuthTokenListener","firebaseOptions_","errorMessage","authProvider_","auth","$668b2310913a4fe8$var$EmulatorTokenProvider","accessToken","OWNER","$668b2310913a4fe8$var$RepoInfo","internalHost","_domain","_host","newHost","isCacheableHost","toURLString","persistenceKey","protocol","secure","query2","includeNamespaceInQueryParams","namespace","webSocketOnly","nodeAdmin","isUsingEmulator","indexOf","$668b2310913a4fe8$var$repoInfoConnectionURL","repoInfo","params","connURL","counters_","name2","amount","hashString","$668b2310913a4fe8$var$collections","$668b2310913a4fe8$var$StatsCollection","responseNum","closeAfterResponse","onClose","requestNum","pendingResponses","currentResponseNum","toProcess","onMessage_","curSegmentNum","onDisconnect1","$668b2310913a4fe8$var$PacketReceiver","onMessage","isClosed_","connectTimeoutTimer_","log_","onClosed_","readyState","wrappedFn","body","called","attachEvent","scriptTagHolder","$668b2310913a4fe8$var$FirebaseIFrameScriptHolder","command","arg1","arg2","arg3","arg4","incrementIncomingBytes_","everConnected_","password","sendNewPolls","myPacketOrderer","closeAfter","handleResponse","pN","urlFn","random","uniqueCallbackIdentifier","urlParams","connectURL","startLongPoll","addDisconnectPingFrame","forceAllow_","forceDisallow_","$668b2310913a4fe8$var$BrowserPollConnection","createElement","location","Windows","UI","myDisconnFrame","removeChild","shutdown_","onDisconnect_","bytesSent","dataStr","stats_","incrementCounter","base64data","enqueueSegment","pw","display","appendChild","bytesReceived","connId","applicationId","appCheckToken","authToken","transportSessionId","lastSessionId","$668b2310913a4fe8$var$statsManagerGetCollection","static","iframe","contentWindow","domain","contentDocument","doc","alive","myIFrame","onDisconnect2","onDisconnect","myID","myPW","newRequest_","outstandingRequests","size","pendingSegs","currentSerial","theURL","curDataString","d","theSeg","seg","ts","segnum","totalsegs","serial","keepaliveTimeout","doNewRequest","addTag","doNodeLongPoll","loadCB","newScript","onload","onreadystatechange","rstate","commandCB","onMessageCB","onDisconnect3","$668b2310913a4fe8$var$LUIDGenerator","createIFrame_","script","iframeContents","$668b2310913a4fe8$var$WebSocketImpl","MozWebSocket","WebSocket","$668b2310913a4fe8$var$WebSocketConnection","hostname","$668b2310913a4fe8$var$FORGE_DOMAIN_RE","onDisconnect4","device","headers","proxy","mySock","error3","onopen","onclose","onmessage","m","error4","isOldAndroid","userAgent","oldAndroidRegex","oldAndroidMatch","parseFloat","frames","totalFrames","fullMess","jsonMess","frameCount","extractFrameCount_","handleNewFrameCount_","mess","appendFrame_","remainingData","resetKeepAlive","sendString_","keepaliveTimer","clearInterval","setInterval","send","connectionURL_","responsesRequiredToBeHealthy","healthyTimeout","IS_TRANSPORT_INITIALIZED","globalTransportInitialized_","isWebSocketsAvailable","isSkipPollConnection","previouslyFailed","transports_","transports","transport","$668b2310913a4fe8$var$TransportManager","ALL_TRANSPORTS","initialTransport","upgradeTransport","initTransports_","$668b2310913a4fe8$var$Connection","start_","conn","transportManager_","conn_","nextTransportId_","repoInfo_","applicationId_","appCheckToken_","authToken_","primaryResponsesRequired_","onMessageReceived","connReceiver_","onConnectionLost","disconnReceiver_","tx_","secondaryConn_","isHealthy_","healthyTimeoutMS","healthyTimeout_","markConnectionHealthy","connectionCount","everConnected","onConnectionLost_","onSecondaryConnectionLost_","state_","onSecondaryMessageReceived_","dataMsg","controlData","cmd","upgradeIfSecondaryHealthy_","rx_","secondaryResponsesRequired_","parsedData","layer","onSecondaryControl_","pendingDataMessages","proceedWithUpgrade_","t","start","tryCleanupConnection","onControl_","onDataMessage_","onPrimaryResponse_","handshakePayload","h","onHandshake_","onConnectionShutdown_","onReset_","$668b2310913a4fe8$var$error","sendPingOnPrimaryIfNecessary_","handshake","timestamp","version2","onConnectionEstablished_","tryStartUpgrade_","sessionId","onDisconnect5","closeConnections_","onReady_","sendData_","reason","onKill_","$668b2310913a4fe8$var$ServerActions","pathString","onComplete","hash","refreshAuthToken","stats","eventType","listeners_","context","validateEventType_","eventData","getInitialEvent","splice","allowedEvents_","find","et","$668b2310913a4fe8$var$EventEmitter","$668b2310913a4fe8$var$OnlineMonitor","online_","trigger","pieceNum_","pieces_","pathOrString","pieceNum","copyTo","$668b2310913a4fe8$var$newEmptyPath","$668b2310913a4fe8$var$Path","$668b2310913a4fe8$var$pathGetFront","path","pieces","childPathObj","childPieces","$668b2310913a4fe8$var$pathIsEmpty","$668b2310913a4fe8$var$newRelativePath","outerPath","innerPath","outer","inner","$668b2310913a4fe8$var$pathPopFront","$668b2310913a4fe8$var$pathEquals","other","$668b2310913a4fe8$var$pathGetLength","j","$668b2310913a4fe8$var$pathContains","$668b2310913a4fe8$var$ValidationPath","errorPrefix_","parts_","$668b2310913a4fe8$var$pathSlice","byteLength_","max","$b197424204fd80b4$export$9536dc0a75b20bf9","$668b2310913a4fe8$var$validationPathCheckValid","validationPath","$668b2310913a4fe8$var$validationPathToErrorString","$668b2310913a4fe8$var$VisibilityMonitor","visible_","hidden","super","visibilityChange","visible","requestNumber_","curReqNum","msg","connected_","realtime_","sendRequest","onResponse","requestCBHash_","query3","initConnection_","outstandingGet","action","_path","q","_queryObject","outstandingGets_","outstandingGetCount_","sendGet_","query4","currentHashFn","tag","queryId","_queryIdentifier","listens","_queryParams","isDefault","loadsAllData","listenSpec","query","sendListen_","get1","query5","req","hashFn","$668b2310913a4fe8$var$PersistentConnection","warnOnListenWarnings_","removeListen_","query6","warnings","indexSpec","getIndex","indexPath","tryAuth","reduceReconnectDelayIfAdminCredential_","credential","$b197424204fd80b4$export$fc970ed23da99565","maxReconnectDelay_","refreshAppCheckToken","tryAppCheck","authMethod","requestData","cred","authOverride_","res","invalidAuthTokenCount_","onAuthRevoked_","invalidAppCheckTokenCount_","onAppCheckRevoked_","query7","sendUnlisten_","queryObj","sendOnDisconnect_","onDisconnectRequestQueue_","onDisconnectCancel","putInternal","outstandingPuts_","outstandingPutCount_","setMaxNode","MAX_NODE","sendPut_","queued","reportStats","errorReason","reqNum","onDataUpdate_","onListenRevoked_","onSecurityDebugPacket_","lastConnectionEstablishedTime_","handleTimestamp_","firstConnection_","sendConnectStats_","restoreState_","onConnectStatus_","establishConnectionTimer_","establishConnection_","scheduleConnect_","reconnectDelay_","online","onRealtimeDisconnect_","cancelSentTransactions_","timeSinceLastConnectAttempt","lastConnectionAttemptTime_","reconnectDelay","shouldReconnect_","onDataMessage","onReady","onDisconnect6","nextConnectionId_","connection","closeFn","canceled","sendRequestFn","nodeFromJSON","forceTokenRefresh_","authTokenProvider_","appCheckTokenProvider_","interrupt","error5","interruptReasons_","delta","onServerInfoUpdate_","put","query8","listen","normalizedPathString","map1","statusCode","explanation","securityDebugCallback_","queries","i2","clientName","getInstance","currentlyOnline","nextPersistentConnectionId_","onVisible_","onOnline_","$668b2310913a4fe8$var$NamedNode","name3","node","$668b2310913a4fe8$var$Index","compare","indexedValueChanged","oldNode","newNode","newWrapped","oldWrapped","MIN","__EMPTY_NODE","$668b2310913a4fe8$var$__EMPTY_NODE","indexValue","$668b2310913a4fe8$var$KeyIndex","nodeStack_","pop","resultGenerator_","isReverse_","left","isEmpty","right","startKey","comparator","cmp","$668b2310913a4fe8$var$LLRBNode","copy","color","count","inorderTraversal","reverseTraversal","min_","minKey","maxKey","insert","n","fixUp_","removeMin_","$668b2310913a4fe8$var$SortedMap","EMPTY_NODE","isRed_","moveRedLeft_","smallest","rotateRight_","moveRedRight_","rotateLeft_","colorFlip_","nl","RED","nr","checkMaxDepth_","blackDepth","check_","BLACK","comparator_","root_","rightParent","getIterator","resultGenerator","$668b2310913a4fe8$var$SortedMapIterator","$668b2310913a4fe8$var$NAME_ONLY_COMPARATOR","$668b2310913a4fe8$var$MAX_NODE$2","priority","$668b2310913a4fe8$var$validatePriorityNode","priorityNode","isLeafNode","getPriority","$668b2310913a4fe8$var$__childrenNodeConstructor","$668b2310913a4fe8$var$LeafNode","__childrenNodeConstructor","priorityNode_","updatePriority","newPriorityNode","value_","getImmediateChild","childName","getChild","getPredecessorChildName","childNode","updateImmediateChild","newChildNode","updateChild","front","numChildren","forEachChild","exportFormat","getValue","lazyHash_","toHash","$668b2310913a4fe8$var$priorityHashText","$668b2310913a4fe8$var$doubleToIEEE754String","compareTo","compareToLeafNode_","otherLeaf","otherLeafType","thisLeafType","otherIndex","VALUE_TYPE_ORDER","thisIndex","withIndex","isIndexed","equals","aPriority","bPriority","indexCmp","$668b2310913a4fe8$var$MAX_NODE$1","$668b2310913a4fe8$var$nodeFromJSON$1","bits_","current_","num","$668b2310913a4fe8$var$LOG_2","mask","childList","keyFn","mapSortFn","low","high","namedNode","middle","buildBalancedTree","root1","root","buildPennant","chunkSize","childTree","attachPennant","pennant","base12","isOne","nextBitIsOne","buildFrom12Array","$668b2310913a4fe8$var$Base12Num","Default","$668b2310913a4fe8$var$fallbackObject","$668b2310913a4fe8$var$PRIORITY_INDEX","$668b2310913a4fe8$var$_defaultIndexMap","$668b2310913a4fe8$var$IndexMap","indexKey","sortedMap","indexes_","indexDefinition","indexSet_","existingChildren","$668b2310913a4fe8$var$KEY_INDEX","sawIndexedValue","iter","Wrap","newIndex","next","getNext","isDefinedOn","$668b2310913a4fe8$var$buildChildSet","getCompare","indexName","newIndexSet","newIndexes","$b197424204fd80b4$export$871de8747c9eaa88","indexedChildren","existingSnap","newChildren","removeFromIndexes","$668b2310913a4fe8$var$ChildrenNode","$668b2310913a4fe8$var$EMPTY_NODE","$668b2310913a4fe8$var$NAME_COMPARATOR","children_","indexMap_","child2","hasChild","newIndexMap","addToIndexes","newPriority","newImmediateChild","numKeys","allIntegerKeys","INTEGER_REGEXP_","childHash","idx","resolveIndex_","predecessor","getPredecessorKey","getFirstChild","getFirstChildName","getLastChild","getLastChildName","wrappedNode","getIteratorFrom","minPost","startPost","iterator","peek","getReverseIteratorFrom","maxPost","endPost","$668b2310913a4fe8$var$MAX_NODE","hasIndex","addIndex","otherChildrenNode","thisIter","otherIter","thisCurrent","otherCurrent","defineProperties","$668b2310913a4fe8$var$nodeFromJSON","childData","children","childrenHavePriority","child3","childSet","sortedChildSet","$668b2310913a4fe8$var$PathIndex","extractChild","snap","indexPath_","aChild","bChild","name6","valueNode","MAX","makePost","name7","$668b2310913a4fe8$var$changeValue","snapshotNode","$668b2310913a4fe8$var$changeChildAdded","$668b2310913a4fe8$var$changeChildRemoved","$668b2310913a4fe8$var$changeChildChanged","oldSnap","startSet_","viewFrom_","indexStartValue_","getIndexStartName","startNameSet_","indexStartName_","endSet_","getIndexEndValue","indexEndValue_","getIndexEndName","endNameSet_","indexEndName_","hasLimit","limitSet_","hasAnchoredLimit","limit_","index_","$668b2310913a4fe8$export$7ba287e361c94330","startAfterSet_","endBeforeSet_","$668b2310913a4fe8$var$queryParamsToRestQueryStringParameters","queryParams","qs","orderBy","$668b2310913a4fe8$var$VALUE_INDEX","startParam","endParam","isViewFromLeft","viewFrom","$668b2310913a4fe8$var$ReadonlyRestClient","query9","query10","listenId","getListenId_","thisListen","listens_","queryStringParameters","restRequest_","error6","query11","query12","error7","referenceConstructor","$b197424204fd80b4$export$ac4103b836844853","xhr","XMLHttpRequest","responseText","rootNode_","newSnapshotNode","$668b2310913a4fe8$var$newSparseSnapshotTree","$668b2310913a4fe8$var$sparseSnapshotTreeRemember","sparseSnapshotTree","clear","childKey","$668b2310913a4fe8$var$sparseSnapshotTreeForEachTree","prefixPath","tree","$668b2310913a4fe8$var$StatsListener","newStats","collection_","last_","stat","statsListener_","statsToReport_","haveStatsToReport","server_","reportedStats","reportStats_","collection","$668b2310913a4fe8$var$OperationType","OperationType1","$668b2310913a4fe8$var$newOperationSourceServerTaggedQuery","fromUser","tagged","$668b2310913a4fe8$var$AckUserWrite","affectedTree","subtree","revert","ACK_USER_WRITE","fromServer","$668b2310913a4fe8$var$Overwrite","$668b2310913a4fe8$var$Merge","operationForChild","fullyInitialized_","isFiltered","filtered_","isCompleteForPath","isFullyInitialized","isCompleteForChild","node_","$668b2310913a4fe8$var$eventGeneratorGenerateEventsForType","eventGenerator","events","changes","registrations","eventCache","filteredChanges","change","aWrapped","bWrapped","$668b2310913a4fe8$var$eventGeneratorCompareChanges","materializedChange","prevName","$668b2310913a4fe8$var$eventGeneratorMaterializeSingleChange","registration","respondsTo","createEvent","query_","$668b2310913a4fe8$var$newViewCache","serverCache","viewCache","eventSnap","filtered","$668b2310913a4fe8$var$CacheNode","$668b2310913a4fe8$var$viewCacheUpdateServerSnap","serverSnap","$668b2310913a4fe8$var$viewCacheGetCompleteEventSnap","getNode","$668b2310913a4fe8$var$viewCacheGetCompleteServerSnap","$668b2310913a4fe8$var$emptyChildrenSingleton","$668b2310913a4fe8$var$ImmutableTree","childPath","childSnap","findRootMostMatchingPathAndValue","relativePath","predicate","child5","childExistingPathAndValue","$668b2310913a4fe8$var$pathChild","findRootMostValueAndPath","toSet","newChild","child7","child8","setTree","newTree","fold","fold_","pathSoFar","accum","findOnPath","findOnPath_","pathToFollow","nextChild","foreachOnPath_","currentRelativePath","foreach","foreach_","$668b2310913a4fe8$var$stringCompare","$668b2310913a4fe8$var$EmptyChildren","$668b2310913a4fe8$var$CompoundWrite","writeTree_","rootmost","rootMostPath","compoundWrite","newWriteTree1","$668b2310913a4fe8$var$compoundWriteAddWrites","updates","$668b2310913a4fe8$var$compoundWriteAddWrite","newWrite","$668b2310913a4fe8$var$compoundWriteRemoveWrite","empty","newWriteTree2","$668b2310913a4fe8$var$compoundWriteHasCompleteWrite","$668b2310913a4fe8$var$compoundWriteGetCompleteNode","$668b2310913a4fe8$var$compoundWriteChildCompoundWrite","shadowingNode","$668b2310913a4fe8$var$compoundWriteIsEmpty","$668b2310913a4fe8$var$compoundWriteApply","writeTree","priorityWrite","$668b2310913a4fe8$var$applySubtreeWrite","$668b2310913a4fe8$var$writeTreeChildWrites","$668b2310913a4fe8$var$newWriteTreeRef","$668b2310913a4fe8$var$writeTreeRemoveWrite","writeId","allWrites","findIndex","writeToRemove","removedWriteWasVisible","removedWriteOverlapsWithOtherWrites","currentWrite","$668b2310913a4fe8$var$writeTreeRecordContainsPath_","visibleWrites","$668b2310913a4fe8$var$writeTreeLayerTree_","$668b2310913a4fe8$var$writeTreeDefaultFilter_","lastWriteId","writeRecord","write","writes","treeRoot","writePath","child10","deepNode","$668b2310913a4fe8$var$writeTreeCalcCompleteEventCache","treePath","completeServerCache","writeIdsToExclude","includeHiddenWrites","merge","subMerge","$668b2310913a4fe8$var$writeTreeRefCalcCompleteEventCache","writeTreeRef","$668b2310913a4fe8$var$writeTreeRefCalcCompleteEventChildren","completeServerChildren","completeChildren","topLevelSet","$668b2310913a4fe8$var$writeTreeCalcCompleteEventChildren","$668b2310913a4fe8$var$writeTreeRefCalcEventCacheAfterServerOverwrite","existingEventSnap","existingServerSnap","childMerge","$668b2310913a4fe8$var$writeTreeCalcEventCacheAfterServerOverwrite","$668b2310913a4fe8$var$writeTreeRefShadowingWrite","completeServerData","toIterate","nodes","existingServerCache","oldChange","changeMap","oldType","$668b2310913a4fe8$var$NO_COMPLETE_CHILD_SOURCE","getCompleteChild","child","$668b2310913a4fe8$var$WriteTreeCompleteChildSource","viewCache_","serverNode","optCompleteServerCache_","$668b2310913a4fe8$var$writeTreeRefCalcCompleteChild","writes_","getChildAfterChild","child11","$668b2310913a4fe8$var$writeTreeRefCalcIndexedSlice","accumulator","$668b2310913a4fe8$var$ChildChangeAccumulator","newViewCache1","filterServerNode","operation","OVERWRITE","overwrite","$668b2310913a4fe8$var$viewProcessorApplyUserOverwrite","viewProcessor","oldViewCache","writesCache","completeCache","$668b2310913a4fe8$var$viewProcessorApplyServerOverwrite","MERGE","changedChildren","curViewCache","$668b2310913a4fe8$var$viewProcessorCacheHasChild","$668b2310913a4fe8$var$viewProcessorApplyUserMerge","$668b2310913a4fe8$var$viewProcessorApplyServerMerge","ackUserWrite","oldEventCache","newEventCache","serverChildren","updateFullNode","filtersNodes","$668b2310913a4fe8$var$viewProcessorRevertUserWrite","ackPath","name8","mergePath","serverCachePath","$668b2310913a4fe8$var$viewProcessorAckUserWrite","LISTEN_COMPLETE","oldServerNode","newViewCache5","$668b2310913a4fe8$var$viewProcessorGenerateEventCacheAfterServerEvent","$668b2310913a4fe8$var$viewProcessorListenComplete","getChanges","newViewCache2","isLeafOrEmpty","oldCompleteSnap","$668b2310913a4fe8$var$viewProcessorMaybeAddValueEvent","changePath","completeEventChildren","completeNode","oldEventNode","oldEventSnap","updatedPriority","childChangePath","eventChildUpdate","newEventChild","$668b2310913a4fe8$var$viewCacheUpdateEventSnap","changedSnap","serverFilter","getIndexedFilter","newServerCache","oldServerSnap","newServerNode","newViewCache3","newViewCache4","oldChild","$668b2310913a4fe8$var$pathGetBack","$668b2310913a4fe8$var$pathParent","$668b2310913a4fe8$var$viewProcessorApplyMerge","viewMergeTree","childMergeTree","isUnknownDeepMerge","$668b2310913a4fe8$var$viewGetCompleteServerCache","view","cache","$668b2310913a4fe8$var$viewApplyOperation","$668b2310913a4fe8$var$viewProcessorApplyOperation","processor_","$668b2310913a4fe8$var$viewGenerateEventsForChanges_","eventRegistration","eventRegistrations_","eventRegistrations","moves","$668b2310913a4fe8$var$eventGeneratorGenerateEventsForChanges","eventGenerator_","$668b2310913a4fe8$var$referenceConstructor$1","$668b2310913a4fe8$var$referenceConstructor","$668b2310913a4fe8$var$syncPointApplyOperation","syncPoint","optCompleteServerCache","views","$668b2310913a4fe8$var$syncPointGetCompleteServerCache","$668b2310913a4fe8$var$SyncTree","listenProvider_","syncPointTree_","pendingWriteTree_","tagToQueryMap","queryToTagMap","$668b2310913a4fe8$var$syncTreeApplyUserOverwrite","syncTree","newData","$668b2310913a4fe8$var$syncTreeApplyOperationToSyncPoints_","$668b2310913a4fe8$var$syncTreeAckUserWrite","record","$668b2310913a4fe8$var$writeTreeGetWrite","$668b2310913a4fe8$var$syncTreeApplyServerOverwrite","$668b2310913a4fe8$var$syncTreeApplyTaggedQueryOverwrite","queryKey","$668b2310913a4fe8$var$syncTreeQueryKeyForTag_","r","$668b2310913a4fe8$var$syncTreeParseQueryKey_","queryPath","$668b2310913a4fe8$var$syncTreeApplyTaggedOperation_","$668b2310913a4fe8$var$syncTreeCalcCompleteEventCache","serverCache1","$668b2310913a4fe8$var$syncTreeApplyOperationHelper_","syncPointTree","$668b2310913a4fe8$var$syncTreeApplyOperationDescendantsHelper_","childOperation","childServerCache","childWritesCache","$668b2310913a4fe8$var$writeTreeRefChild","child1","last","search","creatorFunction","changeTree","fromObject","encodeURIComponent","firebaseConfig","databaseURL","$8953c87b21bd174e$var$app","userId","email","$668b2310913a4fe8$export$d0dd861204d0bf72","$668b2310913a4fe8$export$adaa4cf7ef1b65be","$668b2310913a4fe8$export$eff4d24c3ff7876e","username","$8953c87b21bd174e$var$writeUserData","$8953c87b21bd174e$var$closeModal","$8953c87b21bd174e$var$authFormHandler","returnSecureToken","$8953c87b21bd174e$var$authWithEmailAmdPassword","getElementById","modal"],"version":3,"file":"index.8c9125d9.js.map"}